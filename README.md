# Trifecta Generator

> **North Star**: Un agente entienda cualquier segmento del repo en <60 segundos leyendo solo 3 archivos + 1 log.

## Problema

Los agentes de cÃ³digo (Claude, Gemini, Codex) parsean miles de lÃ­neas de cÃ³digo innecesariamente, consumen contexto, y terminan con informaciÃ³n obsoleta o incompleta.

## SoluciÃ³n

El sistema **Trifecta** proporciona una estructura estandarizada de **5 archivos** que permite:

- **ComprensiÃ³n rÃ¡pida**: <60 segundos para entender un segmento
- **Contexto eficiente**: Solo carga lo necesario (progressive disclosure)
- **Mantenimiento simple**: Estructura predecible, sin drift
- **Onboarding automÃ¡tico**: README con guÃ­a para nuevos agentes

---

## ğŸ—ï¸ Arquectura del Generador

> **âš ï¸ IMPORTANTE**: Este generador ya estÃ¡ implementado con Clean Architecture. No recrear desde cero.

```
trifecta_dope/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ domain/           # Entidades de negocio (Pydantic models)
â”‚   â”‚   â”œâ”€â”€ models.py     # TrifectaConfig, TrifectaPack, ValidationResult
â”‚   â”‚   â””â”€â”€ constants.py  # MAX_SKILL_LINES, etc.
â”‚   â”‚
â”‚   â”œâ”€â”€ application/      # Use cases (lÃ³gica de negocio)
â”‚   â”‚   â””â”€â”€ use_cases.py  # Create, Validate, RefreshPrime
â”‚   â”‚
â”‚   â””â”€â”€ infrastructure/   # Implementaciones concretas
â”‚       â”œâ”€â”€ cli.py        # Typer CLI (entrypoint)
â”‚       â”œâ”€â”€ templates.py  # TemplateRenderer (markdown generation)
â”‚       â””â”€â”€ file_system.py # FileSystemAdapter (disk I/O)
â”‚
â”œâ”€â”€ tests/                # Unit tests (pytest)
â”œâ”€â”€ braindope.md          # EspecificaciÃ³n completa
â””â”€â”€ README.md             # Este archivo
```

### Capas (Clean Architecture)

| Capa | Responsabilidad | Archivos clave |
|------|-----------------|----------------|
| **Domain** | Modelos de datos, validadores | `models.py`, `constants.py` |
| **Application** | Casos de uso, orquestaciÃ³n | `use_cases.py` |
| **Infrastructure** | CLI, templates, I/O | `cli.py`, `templates.py`, `file_system.py` |

### Flujo de CreaciÃ³n

```
CLI (cli.py)
    â†“
CreateTrifectaUseCase (use_cases.py)
    â†“
TemplateRenderer.render_{skill,prime,agent,session,readme}
    â†“
FileSystemAdapter.save_trifecta
    â†“
5 archivos en disco
```

### Reglas de DiseÃ±o

1. **Domain** â†’ sin dependencias externas (solo Pydantic)
2. **Application** â†’ solo depende de Domain
3. **Infrastructure** â†’ implementa interfaces de Application/Domain
4. **Templates** â†’ f-strings, sin Jinja2 (simplicidad)

### Extensiones

Para agregar un nuevo comando:

1. Crear use case en `application/use_cases.py`
2. Agregar comando en `infrastructure/cli.py`
3. Agregar tests en `tests/test_use_cases.py`

---

## Estructura Trifecta (Output)

```
<segment-name>/
â”œâ”€â”€ README.md                              # GuÃ­a rÃ¡pida del segmento
â”œâ”€â”€ skill.md                               # Reglas (MAX 100 lÃ­neas)
â””â”€â”€ _ctx/
    â”œâ”€â”€ prime_<segment-name>.md            # Lista de lectura
    â”œâ”€â”€ agent.md                           # Stack tÃ©cnico
    â””â”€â”€ session_<segment-name>.md          # Log de handoff (runtime)
```

### Archivos

| Archivo | PropÃ³sito | LÃ­neas aprox |
|---------|-----------|--------------|
| `README.md` | GuÃ­a rÃ¡pida + onboarding | ~50-80 |
| `skill.md` | Reglas, contratos, workflows | â‰¤100 |
| `prime_*.md` | Lista de lectura obligatoria | ~50-100 |
| `agent.md` | Stack tÃ©cnico, dependencies | ~100-150 |
| `session_*.md` | BitÃ¡cora de handoffs | Append-only |

## Perfiles de Output

El sistema usa perfiles (nvim-style modeline) para definir contratos de output:

| Profile | PropÃ³sito | Contract |
|---------|-----------|----------|
| `diagnose_micro` | MÃ¡ximo texto, cÃ³digo â‰¤3 lÃ­neas | `code_max_lines: 3` |
| `impl_patch` | Patch con verificaciÃ³n | `require: [FilesTouched, CommandsToVerify]` |
| `only_code` | Solo archivos + diff + comandos | `forbid: [explanations]` |
| `plan` | DoD + pasos (sin cÃ³digo) | `forbid: [code_blocks]` |
| `handoff_log` | BitÃ¡cora + handoff | `append_only: true` |

## Progressive Disclosure

| Nivel | Trigger | Tokens |
|-------|---------|--------|
| **L0** | Score < 0.6 | ~50 (solo frontmatter) |
| **L1** | Score 0.6-0.9 | ~500-1000 (skill completo) |
| **L2** | Score > 0.9 | ~200-500 (resources) |

## Uso

### Generar Trifecta (CLI)
```bash
# Desde la raÃ­z del repo
cd trifecta_dope

# Crear trifecta para un segmento
uv run python -m src.infrastructure.cli create \
    --segment eval-harness \
    --path eval/eval-harness/ \
    --scan-docs eval/docs/

# Validar trifecta existente
uv run python -m src.infrastructure.cli validate --path eval/eval-harness/

# Actualizar prime (re-escanea docs)
uv run python -m src.infrastructure.cli refresh-prime \
    --path eval/eval-harness/ \
    --scan-docs eval/docs/
```

### Generar Context Pack (Token-Optimized)

El **Context Pack** es un JSON estructurado que permite a los LLMs ingerir documentaciÃ³n de manera eficiente sin cargar textos completos en el prompt.

```bash
# Generar context_pack.json en _ctx/
python scripts/ingest_trifecta.py --segment debug_terminal

# Con repo root personalizado
python scripts/ingest_trifecta.py --segment hemdov --repo-root /path/to/projects

# Output personalizado
python scripts/ingest_trifecta.py --segment eval --output custom/pack.json
```

**Estructura del Context Pack:**

```json
{
  "schema_version": 1,
  "segment": "debug_terminal",
  "created_at": "2025-12-29T15:47:37.502279Z",
  "digest": [           // Siempre en prompt (~10-30 lÃ­neas)
    {"doc": "skill", "summary": "...", "source_chunk_ids": [...]}
  ],
  "index": [            // Siempre en prompt (referencias)
    {"id": "skill:a1b2...", "title_path": [...], "preview": "...", "token_est": 150}
  ],
  "chunks": [           // Entregado bajo demanda vÃ­a tool
    {"id": "skill:a1b2...", "text": "...", "source_path": "..."}
  ]
}
```

**Para usarlo en un agente:**

1. **Prompt base** incluye solo `digest` + `index`
2. **Tool** `get_context(chunk_id)` devuelve `chunks["text"]` cuando se necesita
3. **Resultado**: Agente entiende el contexto sin quemar tokens

> Ver [`docs/plans/2025-12-29-context-pack-ingestion.md`](./docs/plans/2025-12-29-context-pack-ingestion.md) para especificaciÃ³n completa.

## Mini-RAG (Contexto Local)

Este repo integra Mini-RAG para consultas rÃ¡pidas sobre la documentaciÃ³n (RAG local).

### Setup (local source)

```bash
# Desde la raÃ­z del proyecto
make minirag-setup MINIRAG_SOURCE=~/Developer/Minirag
make minirag-index
```

### Consultas

```bash
make minirag-query MINIRAG_QUERY="PCC"
```

> El Ã­ndice usa `docs/**/*.md` y `knowledge/**` definidos en `.mini-rag/config.yaml`.
## InstalaciÃ³n

```bash
cd trifecta_dope
uv sync
```

## Tests

```bash
uv run pytest tests/ -v
```

## Desarrollo

```bash
# Ejecutar CLI con Typer
uv run typer src/infrastructure/cli.py run create --help
```

## Referencias

- [`docs/braindope.md`](./docs/braindope.md) - EspecificaciÃ³n completa del sistema
- [`writing-skills`](../.claude/skills/superpowers/writing-skills/) - MetodologÃ­a para crear SKILL.md

## Roadmap

### CLI & Templates
- [x] EspecificaciÃ³n completa (braindope.md)
- [x] Clean Architecture implementation
- [x] CLI con comandos `create`, `validate`, `refresh-prime`
- [x] README.md automÃ¡tico en cada segmento
- [x] Enhanced templates (skill, agent, prime) con ejemplos concretos
- [x] CLI UX improvements: validaciÃ³n, errores contextuales, dry-run
- [x] Fish shell completions

### Context Pack
- [x] Context Pack ingestion script (token-optimized)
- [x] Schema v1 con digest + index + chunks
- [x] Fence-aware chunking (respeta bloques de cÃ³digo)
- [x] Digest determinista (scoring system)
- [x] IDs estables (normalized hash)
- [x] E2E tests (34 tests passing)

### Pending
- [ ] Prueba con segmentos reales (`debug_terminal`, `hemdov`, `eval`)
- [ ] MCP Discovery Tool para activaciÃ³n automÃ¡tica
- [ ] Progressive Disclosure (L0/L1/L2) en hooks
- [ ] Phase 2: SQLite runtime para context packs grandes
