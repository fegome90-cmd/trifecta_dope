# Informe TÃ©cnico: Progressive Disclosure en Trifecta

**Fecha**: 2026-01-02
**Autor**: AnÃ¡lisis tÃ©cnico del cÃ³digo fuente
**VersiÃ³n**: v1.0

---

## Resumen Ejecutivo

Trifecta implementa un sistema de **Progressive Disclosure (PD)** de 2 capas funcionales (L0 y L1) con mecanismos de presupuesto de tokens y fallback robusto. Este documento detalla la arquitectura actual, implementaciÃ³n, gaps identificados y roadmap.

---

## Tabla de Contenidos

1. [Arquitectura General](#1-arquitectura-general)
2. [Capa L0: Skeleton Mode](#2-capa-l0-skeleton-mode)
3. [Capa L1: AST y LSP](#3-capa-l1-ast-y-lsp)
4. [Capa L2: Estado Actual](#4-capa-l2-estado-actual)
5. [CLI y Ejemplos de Uso](#5-cli-y-ejemplos-de-uso)
6. [Gaps y Recomendaciones](#6-gaps-y-recomendaciones)
7. [Anexos](#7-anexos)

---

## 1. Arquitectura General

### 1.1 Componentes Principales

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     Trifecta CLI                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚   ctx sync    â”‚  â”‚   ctx search  â”‚  â”‚    ctx get    â”‚   â”‚
â”‚  â”‚   (Build)     â”‚  â”‚  (Discovery)  â”‚  â”‚  (Retrieval)  â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚          â”‚                  â”‚                  â”‚           â”‚
â”‚          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚
â”‚                             â”‚                               â”‚
â”‚                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”                      â”‚
â”‚                    â”‚ ContextService  â”‚                      â”‚
â”‚                    â”‚  (L0 Logic)     â”‚                      â”‚
â”‚                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜                      â”‚
â”‚                             â”‚                               â”‚
â”‚              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”               â”‚
â”‚              â”‚                             â”‚               â”‚
â”‚      â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”        â”‚
â”‚      â”‚ context_pack   â”‚          â”‚   LSP Daemon   â”‚        â”‚
â”‚      â”‚   (Index)      â”‚          â”‚   (L1 Logic)   â”‚        â”‚
â”‚      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 1.2 Flujo de Datos

```mermaid
graph TD
    A[Usuario: ctx search] --> B[ContextService.search]
    B --> C[ContextPack Index]
    C --> D[SearchHits con Scores]

    E[Usuario: ctx get] --> F[ContextService.get]
    F --> G{Mode?}
    G -->|raw| H[Full Content]
    G -->|excerpt| I[Primeras 25 lÃ­neas]
    G -->|skeleton| J[_skeletonize]

    K[Usuario: ast symbols] --> L[cli_ast.py]
    L --> M{LSP Ready?}
    M -->|SÃ­| N[LSP Daemon]
    M -->|No| O[ASTParser Fallback]
```

---

## 2. Capa L0: Skeleton Mode

### 2.1 DefiniciÃ³n

**L0 Skeleton** es una transformaciÃ³n del contenido que extrae Ãºnicamente la estructura esencial:
- Encabezados Markdown (`#`)
- Marcadores de bloques de cÃ³digo (```)
- Primeras lÃ­neas de bloques que contienen firmas de funciones/clases

### 2.2 ImplementaciÃ³n

**UbicaciÃ³n**: `src/application/context_service.py:265-301`

```python
def _skeletonize(self, text: str) -> str:
    """
    Extract headings and code block markers to create a structure view.
    """
    skeleton_lines = []
    in_code_block = False

    for line in text.splitlines():
        line_strip = line.strip()

        # Keep headings
        if line_strip.startswith("#"):
            skeleton_lines.append(line)
            continue

        # Keep code block markers
        if line_strip.startswith("```"):
            skeleton_lines.append(line)
            in_code_block = not in_code_block
            continue

        # If inside code block, keep first line (signature)
        if (
            in_code_block
            and len(skeleton_lines) > 0
            and skeleton_lines[-1].strip().startswith("```")
        ):
            if any(
                kw in line
                for kw in ["def ", "class ", "interface ", "function ", "const ", "var "]
            ):
                skeleton_lines.append(f"  {line_strip}")

    return "\n".join(skeleton_lines) if skeleton_lines else text[:200] + "..."
```

### 2.3 Ejemplo de Salida

**Entrada** (Archivo completo de 200 lÃ­neas):
```python
"""
MÃ³dulo de ejemplo con muchas funciones.
"""

def suma(a, b):
    """Suma dos nÃºmeros."""
    return a + b

# [50 lÃ­neas mÃ¡s de implementaciÃ³n...]

class Calculadora:
    """Clase principal."""

    def __init__(self):
        self.valor = 0

    # [100 lÃ­neas mÃ¡s de mÃ©todos...]
```

**Salida Skeleton**:
```python
"""
MÃ³dulo de ejemplo con muchas funciones.
"""

def suma(a, b):

class Calculadora:
```

### 2.4 Modos de OperaciÃ³n L0

| Modo | ParÃ¡metro | Comportamiento | Tokens TÃ­picos |
|------|-----------|----------------|----------------|
| **raw** | `mode="raw"` | Contenido completo con guardrail de budget | 100% |
| **excerpt** | `mode="excerpt"` | Primeras 25 lÃ­neas | ~15-25% |
| **skeleton** | `mode="skeleton"` | Solo estructura (L0 puro) | ~5-10% |
| **auto** | (no implementado) | Basado en score del chunk | - |

### 2.5 Presupuesto de Tokens (Backpressure)

**UbicaciÃ³n**: `src/application/context_service.py:111-223`

```python
def get(
    self,
    ids: list[str],
    mode: Literal["raw", "excerpt", "skeleton"] = "raw",
    budget_token_est: Optional[int] = None,
    max_chunks: Optional[int] = None,
    stop_on_evidence: bool = False,
    query: Optional[str] = None,
) -> GetResult:
```

**Comportamiento**:
- Default budget: 1200 tokens
- Si un chunk excede el presupuesto en modo `raw`, se reduce a 20 lÃ­neas
- Se deja de procesar IDs cuando se alcanza el presupuesto
- `stop_reason`: `"complete"`, `"budget"`, `"max_chunks"`, `"evidence"`

---

## 3. Capa L1: AST y LSP

### 3.1 Arquitectura L1

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Capa L1                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚
â”‚  â”‚ cli_ast.py   â”‚â”€â”€â”€â”€â”€â”€â”‚ SymbolResolver       â”‚        â”‚
â”‚  â”‚              â”‚      â”‚ (URI â†’ File)         â”‚        â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚
â”‚         â”‚                                                 â”‚
â”‚         â”œâ”€â”€â–º LSP Daemon (si READY)                       â”‚
â”‚         â”‚    â””â”€> textDocument/hover                     â”‚
â”‚         â”‚                                                 â”‚
â”‚         â””â”€â”€â–º ASTParser (fallback)                       â”‚
â”‚              â””â”€> tree-sitter (o stub)                   â”‚
â”‚                                                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 3.2 LSP Daemon

**UbicaciÃ³n**: `src/infrastructure/lsp_daemon.py`

**CaracterÃ­sticas**:
- **Socket IPC**: ComunicaciÃ³n vÃ­a Unix socket
- **TTL**: 180 segundos de inactividad antes de shutdown
- **Lifecycle**: `connect_or_spawn()` â†’ Spawn Ãºnico â†’ Warm wait â†’ Ready
- **TelemetrÃ­a**: Eventos `lsp.daemon_status`, `lsp.request`, `lsp.fallback`

**Flujo de ConexiÃ³n**:

```python
# cli_ast.py:41-44
from src.infrastructure.lsp_daemon import LSPDaemonClient

client = LSPDaemonClient(root)
client.connect_or_spawn()  # Fire & Forget spawn if needed
```

**Estado del Daemon**:
```
SPAWNED â†’ WARMING â†’ READY â†’ (TTL) â†’ SHUTDOWN
         â†‘                        â†“
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ fallback â”€â”€â”€â”€â”˜
```

### 3.3 AST Parser

**UbicaciÃ³n**: `src/application/ast_parser.py`

**Estado Actual**: ImplementaciÃ³n simplificada (stub)

```python
class ASTParser:
    def parse(self, file_path: Path) -> Tuple[List[ChildSymbol], str]:
        content = file_path.read_text(errors="replace")
        sha8 = hashlib.sha256(content.encode()).hexdigest()[:8]

        # Fake children para demostraciÃ³n
        children = [
            ChildSymbol(
                name="example_func",
                kind="function",
                range=Range(start_line=1, end_line=10),
                signature_stub="def example_func():",
            ),
        ]
        return children, sha8
```

**Nota**: El cÃ³digo indica que tree-sitter fue usado en "Phase 2a" pero fue simplificado para "restoration risk management".

### 3.4 Comandos CLI L1

#### `ast symbols`
```bash
uv run trifecta ast symbols sym://python/mod/context_service/ContextService
```

**Flujo**:
1. Parse URI â†’ `SymbolQuery`
2. `SymbolResolver` resuelve a archivo
3. Check LSP readiness â†’ Fallback a AST si no ready
4. Parse con ASTParser â†’ Output skeleton JSON

#### `ast hover`
```bash
uv run trifecta ast hover src/application/context_service.py -l 50 -c 15
```

**Flujo**:
1. Spawn/connect LSP Daemon
2. Warm wait hasta 200ms
3. Si READY â†’ `textDocument/hover` request
4. Si no â†’ Fallback a AST skeleton

---

## 4. Capa L2: Estado Actual

### 4.1 Â¿Existe L2?

**Respuesta**: **NO**, L2 no estÃ¡ implementado actualmente.

**Evidencia**:
- No hay menciÃ³n de L2 en el cÃ³digo fuente
- `SCOPE_PD_L0_REPORT.md` solo documenta L0 y L1
- No hay comandos CLI que correspondan a L2

### 4.2 Â¿QuÃ© serÃ­a L2?

Basado en la arquitectura, L2 potencialmente serÃ­a:
- **Full content retrieval**: Sin skeletonizaciÃ³n ni truncado
- **Multi-file context**: Chunks de mÃºltiples archivos relacionados
- **Deep analysis**: InformaciÃ³n de tipos, referencias cruzadas, call graphs

### 4.3 ImplementaciÃ³n ImplÃ­cita

El modo `raw` con `budget_token_est` alto podrÃ­a considerarse una forma de L2:

```python
# Equivalente a L2 "de facto"
ctx.get(ids=["chunk_id"], mode="raw", budget_token_est=10000)
```

Sin embargo, esto no es una "capa" arquitectÃ³nica, solo un parÃ¡metro de configuraciÃ³n.

---

## 5. CLI y Ejemplos de Uso

### 5.1 Comandos Disponibles

```bash
# Build & Index
uv run trifecta ctx sync -s .

# Search (L0)
uv run trifecta ctx search -s . -q "Verification"

# Get con modos (L0)
uv run trifecta ctx get -s . -i "skill:abc123" --mode skeleton
uv run trifecta ctx get -s . -i "skill:abc123" --mode excerpt
uv run trifecta ctx get -s . -i "skill:abc123" --mode raw

# AST/LSP (L1)
uv run trifecta ast symbols sym://python/mod/context_service
uv run trifecta ast hover src/application/context_service.py -l 50 -c 15
```

### 5.2 Ejemplo Completo de Uso

```bash
# 1. Sincronizar contexto
$ uv run trifecta ctx sync -s .
ðŸ”„ Running build...
âœ… Build complete. Validating...
âœ… Validation Passed
ðŸ”„ Regenerating stubs...
   âœ… Regenerated: repo_map.md, symbols_stub.md

# 2. Buscar chunks relevantes
$ uv run trifecta ctx search -s . -q "telemetry"
Search Results (3 hits):
1. [skill:abc123] telemetry.md
   Score: 1.00 | Tokens: ~450
2. [prime:def456] prime_telemetry.md
   Score: 0.75 | Tokens: ~200

# 3. Obtener L0 skeleton
$ uv run trifecta ctx get -s . -i "skill:abc123" --mode skeleton
Selected Chunks (1):
1. [skill:abc123] telemetry.md
   ## Overview
   ## Usage
   def record_event():
   def flush():
   ...
Total Tokens: ~45

# 4. Obtener L1 hover info
$ uv run trifecta ast hover src/infrastructure/telemetry.py -l 42 -c 10
{
  "status": "ok",
  "kind": "skeleton",
  "data": {
    "uri": "src/infrastructure/telemetry.py",
    "range": {"start_line": 42, "end_line": 52},
    "children": []
  }
}
```

---

## 6. Gaps y Recomendaciones

### 6.1 Gaps Identificados

| Gap | Severidad | UbicaciÃ³n | Impacto |
|-----|-----------|-----------|---------|
| **Score-based Auto PD** | Alta | `ContextService.get` | El agente debe elegir modo manualmente |
| **LSP value prop** | Media | `cli_ast.py` | LSP se usa pero output es siempre AST skeleton |
| **AST Parser stub** | Media | `ast_parser.py` | tree-sitter fue removido por "risk management" |
| **L2 no existe** | Alta | Arquitectura | No hay capa de anÃ¡lisis profundo |
| **Cross-file skeleton** | Baja | `context_pack.json` | No hay skeleton pre-calculado en index |

### 6.2 Roadmap Sugerido

#### Corto Plazo (Sprints 1-2)
1. **Score-based Auto PD**
   ```python
   def get(self, ..., auto_mode=True):
       if auto_mode and score < 0.6:
           mode = "skeleton"  # L0 auto
   ```

2. **LSP Real Output**
   ```python
   # En hover, retornar resultado real de LSP
   if result := client.request("textDocument/hover", ...):
       return ASTResponse(kind="lsp", data=result)
   ```

#### Medio Plazo (Sprints 3-4)
3. **Restore tree-sitter** o parser robusto
4. **L2 Definition**: DiseÃ±ar quÃ© significa L2 (multi-file? types?)

#### Largo Plazo (Sprints 5+)
5. **Cross-file Index**: Skeletons pre-calculados en `context_pack.json`
6. **Semantic Search**: Embeddings + similarity vs keyword matching

---

## 7. Anexos

### 7.1 Modelos de Dominio

**UbicaciÃ³n**: `src/domain/context_models.py`

```python
class ContextChunk(BaseModel):
    id: str
    doc: str
    title_path: List[str]
    text: str
    token_est: int
    source_path: str

class GetResult(BaseModel):
    chunks: List[ContextChunk]
    total_tokens: int
    stop_reason: str  # "complete", "budget", "max_chunks", "evidence"
    evidence_metadata: dict
```

### 7.2 Referencias de Archivos

| Componente | Archivo Principal |
|------------|-------------------|
| L0 Logic | `src/application/context_service.py` |
| L1 CLI | `src/infrastructure/cli_ast.py` |
| LSP Daemon | `src/infrastructure/lsp_daemon.py` |
| AST Parser | `src/application/ast_parser.py` |
| Domain Models | `src/domain/context_models.py` |
| Telemetry | `src/infrastructure/telemetry.py` |

### 7.3 MÃ©tricas de TelemetrÃ­a

| Evento | Props | MÃ©tricas |
|--------|-------|----------|
| `selector.resolve` | `symbol_query`, `resolved` | `duration_ms` |
| `ast.parse` | `file`, `symbols_count` | `cache_hit` |
| `lsp.request` | `method`, `resolved` | `duration_ms` |
| `lsp.fallback` | `reason`, `fallback_to` | `warm_wait_ms` |
| `lsp.daemon_status` | `state` | `warm_wait_ms` |

---

## ConclusiÃ³n

Trifecta tiene **L0 funcional** (skeletonization sÃ³lida) y **L1 parcial** (LSP daemon + AST fallback). **L2 no existe** como capa arquitectÃ³nica.

Los gaps principales son:
1. Auto-selecciÃ³n de modo basado en score
2. LSP no aporta valor real en el output
3. Falta definiciÃ³n de quÃ© es L2

El sistema es **auditable**, **robusto** (fallbacks), y **telemetrizado** bien, pero necesita iteraciÃ³n para cumplir la visiÃ³n completa de Progressive Disclosure.
