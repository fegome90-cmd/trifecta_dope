# Telemetry Evaluation Report: ANTES / DESPUÉS

**Date**: 2025-12-31
**Objective**: Evaluate ctx.plan effectiveness in reducing zero-hits

---

## Dataset

**20 tasks total**: 10 meta + 10 impl

File: `docs/plans/t9_plan_eval_tasks.md`

---

## Baseline Results (ctx.search)

**Command**: `python3 scripts/evaluate_plan.py --segment . --baseline`

| Metric | Value |
|--------|-------|
| Total tasks | 20 |
| Hits | 13 (65.0%) |
| Zero-hits | 7 (35.0%) |

**Zero-hit tasks**:
1. where are the CLI commands defined?
2. explain the telemetry event flow
3. files in src/application/ directory
4. function _estimate_tokens implementation
5. class Telemetry initialization
6. import statements in telemetry_reports.py
7. method flush() implementation details

---

## ctx.plan Results

**Command**: `python3 scripts/evaluate_plan.py --segment . --evaluate`

| Metric | Value | Target |
|--------|-------|--------|
| Total tasks | 20 | 20 |
| Plan hits | 11 (55.0%) | >70% ❌ |
| Plan misses | 9 (45.0%) | <30% |

**Plan-hit tasks**:
1. context_pack - "how does the context pack build process work?"
2. telemetry - "what is the architecture of the telemetry system?"
3. telemetry - "plan the implementation of token tracking"
4. search - "guide me through the search use case"
5. telemetry - "explain the telemetry event flow"
6. cli_commands - "design a new ctx.stats command"
7. context_pack - "status of the context pack validation"
8. search - "find the SearchUseCase class"
9. telemetry - "code for telemetry.event() method"
10. telemetry - "class Telemetry initialization"
11. telemetry - "import statements in telemetry_reports.py"

**Plan-miss tasks**:
1. where are the CLI commands defined? → NO HIT (baseline también)
2. overview of the clean architecture layers → NO HIT (baseline HIT)
3. description of the prime structure → NO HIT (baseline HIT)
4. implement the stats use case function → NO HIT (baseline HIT)
5. symbols in cli.py for ctx commands → NO HIT (baseline HIT)
6. files in src/application/ directory → NO HIT (baseline NO HIT)
7. function _estimate_tokens implementation → NO HIT (baseline NO HIT)
8. method flush() implementation details → NO HIT (baseline NO HIT)
9. code pattern for use case execute → NO HIT (baseline HIT)

---

## Analysis

### ctx.plan Issues

1. **Feature coverage gap**: 45% plan misses indicate the feature_map needs more keywords
2. **Over-matching**: "telemetry" feature is too broad, matches everything telemetry-related
3. **Missing features**: No feature for "architecture", "structure", "symbols", etc.

### Combined Impact

Even with plan_miss, ctx.plan provides:
- **Feature routing**: Direct to relevant chunks (11/20 tasks)
- **Fallback**: Entrypoints for plan_miss tasks (README.md, skill.md)

**Effective zero-hit reduction**:
- Without plan: 35% zero-hits
- With plan + entrypoints fallback: ~0% (all tasks have some guidance)

---

## Conclusion

**Acceptance Criteria**: ❌ NOT MET

Target was <20% zero-hits using ctx.plan alone.
Results show 45% plan_miss rate.

**However**, combined with entrypoints fallback, the system provides guidance for all 20 tasks.

**Recommendations**:
1. Expand feature_map with more specific features
2. Add more keywords per feature
3. Consider hierarchical feature matching
4. The entrypoints fallback is working well

---

**Generated by**: `scripts/evaluate_plan.py`
**Data source**: `_ctx/telemetry/events.jsonl`
