# Desalineaciones Conceptuales â€” README Analysis (REVISADO)

**Fecha**: 2025-12-30  
**Contexto**: ArtÃ­culo "Advanced Context Use: Context as Invokable Tools" (autor: Felipe GonzÃ¡lez, 2025)  
**InspiraciÃ³n**: Anthropic's "Advanced Tool Use" pattern  
**MÃ©todo**: Trifecta CLI + Feedback del usuario

---

## ğŸ¯ Concepto Central (del artÃ­culo)

**Trifecta NO es RAG. Es "Programming Context Calling".**

> "Instead of tools, we treat context chunks as invokable resources."  
> â€” "Advanced Context Use" (aplicando el patrÃ³n de Anthropic al contexto)

La analogÃ­a 1:1:

- **Tool Search Tool** â†’ **Context Search** (`ctx.search`)
- **Programmatic Tool Calling** â†’ **Programmatic Context Calling** (`ctx.get`)
- **Tool Use Examples** â†’ **Context Use Examples** (session.md)

**Clave**: El agente **llama explÃ­citamente** a `ctx.get --ids X`, no "el sistema inyecta contexto automÃ¡ticamente".

---

## ğŸš¨ Desalineaciones Reales (Revisadas)

### 1. **RedacciÃ³n confusa en "Context Pack" (L206-244)**

**UbicaciÃ³n**: `README.md:206-244`

**Problema de redacciÃ³n**:

```markdown
El **Context Pack** es un JSON estructurado que permite a los LLMs ingerir
documentaciÃ³n de manera eficiente sin cargar textos completos en el prompt.
```

**Por quÃ© es confuso**:

- Usa lenguaje RAG: "ingerir", "sin cargar textos completos"
- Sugiere que el sistema "entrega" contexto automÃ¡ticamente
- No refleja que el agente **llama explÃ­citamente** a `ctx.get`

**CorrecciÃ³n propuesta** (alineada con Anthropic):

```markdown
### Context Pack: Ãndice de Chunks Invocables

El Context Pack es un **Ã­ndice estructurado** que permite al agente:
1. Descubrir quÃ© chunks existen (`ctx.search`)
2. Invocar chunks especÃ­ficos (`ctx.get --ids X`)
3. Operar con presupuesto estricto (budget-aware)

**AnalogÃ­a**: Como "Tool Search Tool" de Anthropic, pero para contexto.

El agente decide quÃ© cargar, cuÃ¡ndo y con quÃ© presupuesto.  
NO es recuperaciÃ³n automÃ¡tica.
```

---

### 2. **Script legacy `ingest_trifecta.py` (L210-218)**

**UbicaciÃ³n**: `README.md:210-218`

**Problema**:

```bash
# Generar context_pack.json en _ctx/
python scripts/ingest_trifecta.py --segment debug_terminal
```

**Por quÃ© es un problema**:

- Recomienda script legacy cuando existe `trifecta ctx build` (CLI oficial)
- Contradice "usar IDEAS no PRODUCTOS" (filosofÃ­a del proyecto)
- Riesgo de divergencia entre script y CLI

**CorrecciÃ³n propuesta**:

```markdown
### Generar Context Pack

```bash
# Comando oficial (recomendado)
trifecta ctx build --segment /path/to/segment

# Validar integridad
trifecta ctx validate --segment /path/to/segment
```

> **DEPRECADO**: `scripts/ingest_trifecta.py` serÃ¡ removido en v2.  
> Usar solo para debugging interno del CLI.

```

---

### 3. **Mini-RAG sin contexto (L247-265)**

**UbicaciÃ³n**: `README.md:247-265`

**Problema**:
```markdown
## Mini-RAG (Contexto Local)

Este repo integra Mini-RAG para consultas rÃ¡pidas sobre la documentaciÃ³n (RAG local).
```

**Por quÃ© es confuso**:

- No aclara que Mini-RAG es **herramienta de desarrollo**, NO parte de Trifecta
- Contradice "Trifecta NO ES un RAG genÃ©rico" (L25)
- Los agentes pueden confundir Mini-RAG con el paradigma PCC

**CorrecciÃ³n propuesta**:

```markdown
## ğŸ”§ Mini-RAG (Herramienta de Desarrollo)

> **NOTA**: Mini-RAG es una herramienta **externa** para que TÃš (desarrollador) consultes  
> la documentaciÃ³n del CLI. **NO es parte del paradigma Trifecta.**

Trifecta usa bÃºsqueda lexical (grep-like), NO embeddings.

### Setup (solo para desarrollo del CLI)

```bash
make minirag-setup MINIRAG_SOURCE=~/Developer/Minirag
make minirag-query MINIRAG_QUERY="PCC"
```

**Para agentes**: Usar `trifecta ctx search`, NO Mini-RAG.

```

---

## ğŸ“Š Features Avanzados (NO son desalineaciones)

Estos conceptos estÃ¡n **correctos** pero son **Fase 3** (futuro):

### A. **Progressive Disclosure con Scores (L157-163)**

**Status**: âœ… Correcto, pero Fase 3

- Es un feature avanzado, como LSP y AST
- El objetivo es llegar ahÃ­ cuando el MVP estÃ© funcional
- No es una contradicciÃ³n, es una **meta futura**

**AcciÃ³n**: Agregar nota de fase:

```markdown
## Progressive Disclosure (Fase 3 â€” Futuro)

> **NOTA**: Feature avanzado. Implementar solo despuÃ©s de validar MVP.

| Nivel | Trigger | Tokens |
|-------|---------|--------|
| **L0** | Score < 0.6 | ~50 (solo frontmatter) |
...
```

### B. **AST/LSP Integration (mencionado en Anthropic)**

**Status**: âœ… Correcto, pero Fase 3

Del artÃ­culo de Anthropic (L374-413):
> "When you're working with 5 files that change constantly, markdown headings aren't enough.  
> This is where Tree-sitter and LSP come in."

**AcciÃ³n**: Ya estÃ¡ correctamente categorizado como Fase 3 en el Roadmap.

---

## ğŸ“‹ Resumen de Acciones

| Ãtem | AcciÃ³n | Prioridad |
|------|--------|-----------|
| Context Pack redacciÃ³n | Reescribir con lenguaje PCC (no RAG) | ğŸ”´ ALTA |
| Script legacy | Deprecar `ingest_trifecta.py` | ğŸ”´ ALTA |
| Mini-RAG secciÃ³n | Aclarar que es herramienta externa | ğŸŸ¡ MEDIA |
| Progressive Disclosure | Agregar nota "Fase 3" | ğŸŸ¢ BAJA |
| AST/LSP | Ya estÃ¡ correcto (Roadmap Pending) | âœ… OK |

---

## âœ… Principio Rector (del artÃ­culo de Anthropic)

**"Advanced Context Use is a mindset shift: from documents to invokable capabilities."**

- El agente **llama** a `ctx.search` y `ctx.get`
- El sistema **NO inyecta** contexto automÃ¡ticamente
- El presupuesto es **estricto** (budget-aware)
- La evidencia es **citada** con `[chunk_id]`

**Trifecta = Programming Context Calling, NO RAG.**

---

## ğŸ“– Referencias

- **GonzÃ¡lez, F.** (2025). "Advanced Context Use: Context as Invokable Tools" (artÃ­culo original del usuario)
  - Aplica el patrÃ³n de Anthropic's "Advanced Tool Use" al dominio de contexto
  - Introduce la analogÃ­a: Tool Search â†’ Context Search, Programmatic Tool Calling â†’ Programmatic Context Calling
- **Anthropic** (2024). "Advanced Tool Use in Claude AI". <https://www.anthropic.com/engineering/advanced-tool-use>
  - ArtÃ­culo original que inspira el patrÃ³n aplicado en Trifecta
- **Liu et al.** (2023). "Lost in the Middle: How Language Models Use Long Contexts"
