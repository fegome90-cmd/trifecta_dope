diff --git a/CLAUDE.md b/CLAUDE.md
index d9370f8..833d868 100644
--- a/CLAUDE.md
+++ b/CLAUDE.md
@@ -4,6 +4,64 @@ This file provides guidance to Claude Code (claude.ai/code) when working with co
 
 ---
 
+## ⚠️ CRITICAL: READ THIS FIRST BEFORE ANY TASK
+
+**DO NOT PROCEED WITH ANY TASK WITHOUT READING THESE CONTEXT FILES.**
+
+Assuming anything about this project without consulting these files is a breach of the work contract.
+
+### Agent Context Files (MANDATORY - READ THESE FIRST)
+
+These files contain **CURRENT PROJECT STATE, ACTIVE FEATURES, AND ARCHITECTURE DECISIONS**. Ignoring them will result in:
+- ✗ Breaking existing implementations
+- ✗ Duplicating work already done
+- ✗ Misunderstanding the current system state
+- ✗ Failing verification gates
+
+**READ IN THIS ORDER:**
+
+0. **[skill.md](skill.md)** ← START HERE FIRST (3 min read)
+   - **What**: Skills, roles, and core rules for this project
+   - **Why**: Know the mandatory patterns and commands to use
+   - **Contains**: Setup instructions, context cycle, session persistence
+   - **CRITICAL**: Skip this → you'll use wrong commands and waste cycles
+
+1. **[_ctx/agent_trifecta_dope.md](_ctx/agent_trifecta_dope.md)** ← THEN READ THIS (5 min read)
+   - **What**: Current implementation status and active features
+   - **Why**: Know what's ACTUALLY implemented vs. what's planned
+   - **Contains**: Tech stack versions, active patterns, completed work
+   - **CRITICAL**: Skip this → you'll duplicate work or break things
+
+2. **[_ctx/session_trifecta_dope.md](_ctx/session_trifecta_dope.md)** ← THEN READ THIS (2 min skim)
+   - **What**: Session history and continuation points
+   - **Why**: Understand what was done in the last session
+   - **Contains**: Previous decisions, known workarounds, open issues
+   - **CRITICAL**: Skip this → you'll miss workarounds and hit known bugs
+
+3. **[_ctx/prime_trifecta_dope.md](_ctx/prime_trifecta_dope.md)** ← REFERENCE THIS (1 min check)
+   - **What**: Architectural reference and system structure
+   - **Why**: Understand the fundamental system design
+   - **Contains**: Core patterns, layer separation, dependency rules
+   - **CRITICAL**: Skip this → you'll violate architectural constraints
+
+### If You Skip These Files
+
+⛔ **YOU WILL:**
+- Propose features that already exist
+- Break working implementations
+- Violate architectural patterns
+- Fail the verification gate
+- Use wrong commands and waste tokens
+- Waste time and tokens
+
+✅ **INSTEAD:**
+1. Read the 4 context files (11 min total)
+2. Then start your task
+3. Reference them constantly
+4. Update session_trifecta_dope.md when you finish
+
+---
+
 ## Quick Start
 
 ```bash
@@ -84,13 +142,12 @@ See `docs/CONTRACTS.md` and architecture docs in `docs/adr/` for complete patter
 
 ## Source of Truth
 
+### Repository Documentation
 - **README.md** - Project overview, installation
 - **docs/CONTRACTS.md** - API contracts, schemas
 - **docs/CLI_WORKFLOW.md** - Official CLI usage
 - **docs/adr/** - Architecture decision records
 - **docs/backlog/** - Work Order system (WORKFLOW.md, OPERATIONS.md, TROUBLESHOOTING.md)
-- **_ctx/agent_trifecta_dope.md** - Active features, tech stack
-- **_ctx/session_trifecta_dope.md** - Session history, runbook
 
 ---
 
diff --git a/_ctx/backlog/backlog.yaml b/_ctx/backlog/backlog.yaml
index 66a83bd..60d0211 100644
--- a/_ctx/backlog/backlog.yaml
+++ b/_ctx/backlog/backlog.yaml
@@ -1,22 +1,24 @@
 version: 1
+generated_at: "2026-02-10T07:55:00Z"
 epics:
   - id: E-0001
     title: "AST Cache Operability"
-    description: |
+    outcome: |
       Make AST cache operational via configuration (flags/env vars) with full observability.
 
       Goal: Transition from "works when injected" to production-ready persistence
       with telemetry, deterministic locking, and fail-closed testing.
-
-    status: complete
+    owner: null
+    status: done
     priority: P0
-
+    dependencies: []
+    risks: []
     wo_queue:
-      - WO-P2.1 # Telemetry Integration (done)
-      - WO-P2.2 # File Locks via Wrapper (done)
-      - WO-P3.0 # Soak Harness & Evidence (done)
+      - WO-0026 # Telemetry Integration (done)
+      - WO-0027 # File Locks via Wrapper (done)
+      - WO-0028 # Soak Harness & Evidence (done)
       - WO-0012 # Persistence Feature Flag (partial - test env only)
-      - WO-0012.1 # Dev CLI Persistence Default (done)
+      - WO-0025 # Dev CLI Persistence Default (done)
       - WO-0013 # AST Persist Adoption Observability (pending)
 
     x_legacy_wo_queue:
@@ -45,24 +47,41 @@ epics:
       - "P2.4: Resource Monitoring"
       - "P2.5: TTL & Eviction"
 
-    generated_at: "2026-01-06T16:10:00-03:00"
+    x_generated_at: "2026-01-06T16:10:00-03:00"
     x_curated_at: "2026-01-06T16:10:00-03:00"
 
-  - id: E-SCALE
+  - id: E-0003
     title: "Zero-Config Discovery for Massive Repos"
-    description: |
+    outcome: |
       Enable Trifecta to auto-discover segment boundaries in large codebases
       like /agent_h without manual configuration.
 
       Goal: `trifecta ctx discover --root /path` generates trifecta_config.json
-
-    status: pending
+    owner: null
+    status: paused
     priority: P1
-
+    dependencies: []
+    risks: []
     wo_queue:
       - WO-0014 # Import Extractor
       - WO-0015 # Topology Scanner
       - WO-0016 # Segment Clusterer
       - WO-0017 # CLI Integration
 
-    generated_at: "2026-01-13T09:30:00-03:00"
+  - id: E-0002
+    title: "CLI UX Improvements with Runtime Introspection"
+    outcome: |
+      Improve CLI user experience through runtime introspection of Click/Typer
+      commands, providing deterministic error handling, telemetry, and
+      regression-proof flag discovery.
+
+      Goal: Replace static mappings with runtime introspection for invalid
+      option handling, ensuring suggestions are always accurate and
+      automatically updated when commands change.
+    owner: null
+    status: active
+    priority: P1
+    dependencies: []
+    risks: []
+    wo_queue:
+      - WO-0024 # Runtime Introspection for Invalid Options
diff --git a/_ctx/context_pack.json b/_ctx/context_pack.json
index 561c06d..23b887d 100644
--- a/_ctx/context_pack.json
+++ b/_ctx/context_pack.json
@@ -1,7 +1,7 @@
 {
   "schema_version": 1,
   "segment": "trifecta_dope",
-  "created_at": "2026-02-10T06:37:08.512397",
+  "created_at": "2026-02-10T08:48:58.682365",
   "digest": "",
   "source_files": [
     {
@@ -24,9 +24,9 @@
     },
     {
       "path": "_ctx/session_trifecta_dope.md",
-      "sha256": "e4ff30869330d99a490bf038261b74b3f17afef7538fd7f4e66400bca542911a",
-      "mtime": 1770692751.9590595,
-      "chars": 57957
+      "sha256": "5047a4c2169ed9ce15365b9f52f1335a1aaed6925172e80990b339faba69599b",
+      "mtime": 1770707346.7639086,
+      "chars": 59231
     },
     {
       "path": "docs/telemetry_concurrency.md",
@@ -322,12 +322,30 @@
       "mtime": 1767232414.584231,
       "chars": 31594
     },
+    {
+      "path": "docs/backlog/WORKFLOW.md",
+      "sha256": "704b33a7391c66457eafdc05e9f342a4f4c2129501ff6d8e95774bd7f368f7d1",
+      "mtime": 1770707306.909909,
+      "chars": 11238
+    },
     {
       "path": "docs/backlog/MIGRATION.md",
       "sha256": "5597db5da880cdca97cfa8540f9a2c56d095fd33d4a8e99aef1a64c9f843fa9b",
       "mtime": 1768147849.843799,
       "chars": 447
     },
+    {
+      "path": "docs/backlog/OPERATIONS.md",
+      "sha256": "0f0a3c89cfff6761ea5d7bad768737d64087414d7be15a36904cdd8da3529c22",
+      "mtime": 1770707306.909909,
+      "chars": 10876
+    },
+    {
+      "path": "docs/backlog/TROUBLESHOOTING.md",
+      "sha256": "407252c059aabceb592cf370b7c454e37d85c00fb22d2e1f8d2b1a3567d00c58",
+      "mtime": 1770707306.909909,
+      "chars": 11126
+    },
     {
       "path": "docs/backlog/LESSONS.md",
       "sha256": "754f79b47f15082edee74fd13392974e643e02eccaf3216bd22a3d044a29aaa6",
@@ -336,9 +354,9 @@
     },
     {
       "path": "docs/backlog/README.md",
-      "sha256": "62051226e1a0b682308317b11e4b8e0ccef77d7f4dfea177facf82b39e612e91",
-      "mtime": 1768147849.843799,
-      "chars": 777
+      "sha256": "9c74a86c469816c38d9eb079d01dd6c3cb1b603d4d33771b02f2fb3c5b0b0790",
+      "mtime": 1770707306.909909,
+      "chars": 6265
     },
     {
       "path": "docs/bugs/create_cwd_bug.md",
@@ -517,7 +535,7 @@
     {
       "path": "docs/guides/work_orders_usage.md",
       "sha256": "d669762a576e89d4ffb60d40b749d2ddb7b7b47bd74ecaf82e5c93785796bab2",
-      "mtime": 1770687733.4861114,
+      "mtime": 1770707347.2239087,
       "chars": 11002
     },
     {
@@ -790,6 +808,12 @@
       "mtime": 1767581402.5077617,
       "chars": 6428
     },
+    {
+      "path": "docs/plans/2026-01-06-fix-debug-scripts.md",
+      "sha256": "db334814d01bbdc076d4e3bafb2a8ea672a3f656b1a2e90f7023771f25acbc61",
+      "mtime": 1770707306.910909,
+      "chars": 1688
+    },
     {
       "path": "docs/plans/t9_3_eval_report.md",
       "sha256": "bc7e48340c2bc9db15e624cb380bcf7a06a98bf1b98df57eb6e4fa7e083ea606",
@@ -832,6 +856,12 @@
       "mtime": 1768147849.8467991,
       "chars": 5843
     },
+    {
+      "path": "docs/plans/2026-01-09-wo0013-ast-adoption-observability.md",
+      "sha256": "a9830f34988aabf57238406954e0cf9d7ae955e7ea14752d00a7d15fe076c742",
+      "mtime": 1770707306.910909,
+      "chars": 29233
+    },
     {
       "path": "docs/plans/2026-01-02-auditability-gates-v2-antipatterns.md",
       "sha256": "a39e415e13a22ec56ea09ac8f21bdca6e44d8a2623cf9125fed7bcdda16a245f",
@@ -1030,6 +1060,12 @@
       "mtime": 1768147849.847799,
       "chars": 6041
     },
+    {
+      "path": "docs/reports/code_complexity_analysis.md",
+      "sha256": "502822ae9116a1ce39807d84eaa2ade34ba030c30e5341cd06284f0e2d832226",
+      "mtime": 1770707306.910909,
+      "chars": 32784
+    },
     {
       "path": "docs/reports/KNOWN_FAILS.md",
       "sha256": "263d83e2877ad5203110fd6791d824146f08a11e839e829f744e1769f7fb7da2",
@@ -1039,7 +1075,7 @@
     {
       "path": "docs/reports/agent_usage_report_2026-02-10.md",
       "sha256": "a55df0688715239e4551d70a4432ccb0b62826ce4bea4a32e6bcfaafc8da5d12",
-      "mtime": 1770685385.4294074,
+      "mtime": 1770707347.2239087,
       "chars": 5628
     },
     {
@@ -1087,7 +1123,7 @@
     {
       "path": "docs/reports/cli_baseline_fase0.md",
       "sha256": "5124d66db2dbe82874cd1848a9d0fb687f4e781758e6a61f9b4b0aaa557d993b",
-      "mtime": 1770687836.4201105,
+      "mtime": 1770707347.2239087,
       "chars": 5314
     },
     {
@@ -1108,6 +1144,12 @@
       "mtime": 1768147849.848799,
       "chars": 12093
     },
+    {
+      "path": "docs/reports/2026-01-11-pr18-error-handling-audit.md",
+      "sha256": "8fdcbe82c416bc6f95e12f626216f1f03fd0f54725899f2eb3bf8a8bd266564f",
+      "mtime": 1770707306.910909,
+      "chars": 42108
+    },
     {
       "path": "docs/reports/anchor_dictionary_v1.md",
       "sha256": "a13a63e1a2f205e331fdf1f56bed9065cadfb49cd5939e59abb5d15901cec6ed",
@@ -1296,9 +1338,9 @@
     },
     {
       "path": "src/application/use_cases.py",
-      "sha256": "6fbd67084b374ec276dc831ebf154aeea1322578e25dbae8116c0848410eb779",
-      "mtime": 1768147849.857799,
-      "chars": 38087
+      "sha256": "e8da1aa64d28641cb5821d0a1d1ae0c252fdf4204eb18f88c0363e9eb5695428",
+      "mtime": 1770709847.7148829,
+      "chars": 38066
     },
     {
       "path": "src/application/exceptions.py",
@@ -1380,9 +1422,9 @@
     },
     {
       "path": "src/application/obsidian_sync_use_case.py",
-      "sha256": "7e632b6490c5cc4394a40deb9a27e30562de5ed9800217a6252b82eb1c27396f",
-      "mtime": 1767581402.5197618,
-      "chars": 7280
+      "sha256": "7e837b5d0ce463b47376dec3ea7afa0ba302bd1615d6eabd49fb02a4cbf37f0f",
+      "mtime": 1770709847.7118828,
+      "chars": 7304
     },
     {
       "path": "src/application/lsp_manager.py",
@@ -1392,9 +1434,9 @@
     },
     {
       "path": "src/application/search_get_usecases.py",
-      "sha256": "b9e6df75c03c1295d80d499c2d2aa61f561251debb66d1dac1bc44e013ac750c",
-      "mtime": 1768148117.3377953,
-      "chars": 11577
+      "sha256": "77dd84e5517f2187296dcc8fd90858e466380658476f0d226a2e75d894d232d1",
+      "mtime": 1770709847.7148829,
+      "chars": 11583
     },
     {
       "path": "src/application/__init__.py",
@@ -1480,11 +1522,23 @@
       "mtime": 1767230435.6103714,
       "chars": 1499
     },
+    {
+      "path": "src/domain/wo_transactions.py",
+      "sha256": "468dea3aa60abab904fc967b341a038c3b339ab0c799a6c9ea361b73c08288ee",
+      "mtime": 1770707306.912909,
+      "chars": 2324
+    },
     {
       "path": "src/domain/query_linter.py",
-      "sha256": "6a88071206bceaf23e36d104ba3efc2aebef4a3707d094d53b4954dac9785aee",
-      "mtime": 1768162553.0302346,
-      "chars": 6238
+      "sha256": "0eceb8044651426f0d85a36d2af7331cf6f643638cd88aea80fc962961f9cb30",
+      "mtime": 1770709847.7168827,
+      "chars": 6170
+    },
+    {
+      "path": "src/domain/wo_entities.py",
+      "sha256": "139620c4fe8b71e39cf4a71e5aa588c0d6a14261cea771e52cfa50356fdebe31",
+      "mtime": 1770707306.912909,
+      "chars": 5387
     },
     {
       "path": "src/cli/error_cards.py",
@@ -1494,9 +1548,15 @@
     },
     {
       "path": "src/cli/invalid_option_handler.py",
-      "sha256": "a0470a4345efde8c862dbd290449a68533b1137657123cfb81e677680ce8e430",
-      "mtime": 1770689504.002093,
-      "chars": 7908
+      "sha256": "ad47cc4153a517edfc4632d9cd1725258da608d5589b0c5ba0d776fccb0494b9",
+      "mtime": 1770707347.2309086,
+      "chars": 8391
+    },
+    {
+      "path": "src/cli/introspection.py",
+      "sha256": "47961645fd01e90435f090994b5d1b06465660ea3ea0b258526452a3bc1d1108",
+      "mtime": 1770707347.2309086,
+      "chars": 9335
     },
     {
       "path": "src/cli/__init__.py",
@@ -1512,21 +1572,21 @@
     },
     {
       "path": "src/infrastructure/lsp_daemon.py",
-      "sha256": "ed4455bceaea0a044f10e6de2f64c92ad89ba7e0c95cbea3bbf5ed3c84f4e7ff",
-      "mtime": 1768146307.3098211,
-      "chars": 9381
+      "sha256": "d98ac0a6a688bc456d85d39bf764cc33a2cac5958e9abded3f05e4cd8c696a2e",
+      "mtime": 1770709847.7188828,
+      "chars": 9394
     },
     {
       "path": "src/infrastructure/cli_ast.py",
-      "sha256": "7c063f5ae54d6e9fb54e4da0e43b3f3caa589f1caf923bfe7c5579f7e1b2ed13",
-      "mtime": 1768148065.190796,
-      "chars": 6636
+      "sha256": "0befeda8bae477900e3dda7410bfd60b83bdb264d2caf31ce7367ef8f6a7a98f",
+      "mtime": 1770709847.7178829,
+      "chars": 6641
     },
     {
       "path": "src/infrastructure/file_locked_cache.py",
-      "sha256": "a57412d4129ca9380e655b09c7550076ea73357310bab9c74631996389bd2318",
-      "mtime": 1768147849.860799,
-      "chars": 3857
+      "sha256": "1ebb2c1a113cacc60ce0a584654a930b2f53901a5c1e996cc2210a5f7b651ae1",
+      "mtime": 1770709847.7178829,
+      "chars": 3916
     },
     {
       "path": "src/infrastructure/alias_loader.py",
@@ -1578,15 +1638,15 @@
     },
     {
       "path": "src/infrastructure/lsp_client.py",
-      "sha256": "3f6dc6aeb437e582c43f5a0609aa804452550570e305ef0105b28e11271f85ef",
-      "mtime": 1767581402.5247617,
-      "chars": 13342
+      "sha256": "4844e6c31d3f1afc55bdbd4b109e163824ca596ae627676be1c7c13c7f30d2cd",
+      "mtime": 1770709847.7178829,
+      "chars": 13379
     },
     {
       "path": "src/infrastructure/config_loader.py",
-      "sha256": "3d9eddc6132b881d33e350782294f561b59cb3dab2a56a98fab0b639b9cf2143",
-      "mtime": 1768148117.3387952,
-      "chars": 3407
+      "sha256": "b78f4985a2fe6c09a0ea40733aaf967bc5641822d3e3b34f6201e76041b59bab",
+      "mtime": 1770709847.7178829,
+      "chars": 3325
     },
     {
       "path": "src/infrastructure/hookify_logger.py",
@@ -1596,15 +1656,15 @@
     },
     {
       "path": "src/infrastructure/deprecations.py",
-      "sha256": "29d27c6faf75d2bbd4fe67a98cd9a3c2ef3b5d0a2a0af85948d8b30e9a1e9d07",
-      "mtime": 1767581402.5247617,
-      "chars": 1342
+      "sha256": "b68a6ecf9118754e47c9f4cb75aee4302b8dcf06852fd6eac67487e26ac909bc",
+      "mtime": 1770709847.7178829,
+      "chars": 1338
     },
     {
       "path": "src/infrastructure/cli.py",
-      "sha256": "30aac1acba4eee5aa13c405f5bc58ba1713a9b683609e0bc8f89a1cb02f3765a",
-      "mtime": 1770690644.4890814,
-      "chars": 62853
+      "sha256": "966d41053e068a7349b1604022fc42e2c3fe0e2c4ae172326435f55c19cb3930",
+      "mtime": 1770709847.7168827,
+      "chars": 62932
     },
     {
       "path": "src/infrastructure/telemetry_cache.py",
@@ -1638,9 +1698,15 @@
     },
     {
       "path": "CLAUDE.md",
-      "sha256": "7a5a9aac32e740945de29d9f1db60d4e1b06caea67b6056db5266e808c177a98",
-      "mtime": 1768147849.774799,
-      "chars": 6213
+      "sha256": "43e03f932c4a06efb30537b95369096b6363d95ee267f1ce7d1b38c314a07c9e",
+      "mtime": 1770713336.5838468,
+      "chars": 8499
+    },
+    {
+      "path": "agents.md",
+      "sha256": "43e03f932c4a06efb30537b95369096b6363d95ee267f1ce7d1b38c314a07c9e",
+      "mtime": 1770713336.5848467,
+      "chars": 8499
     },
     {
       "path": "readme_tf.md",
@@ -1651,7 +1717,7 @@
     {
       "path": "GEMINI.md",
       "sha256": "adb9392b206c2e14d009572a8d991aa2261fd5648e5878f2128503744fc0d331",
-      "mtime": 1768163439.733175,
+      "mtime": 1770707346.7319086,
       "chars": 5269
     },
     {
@@ -1711,14 +1777,14 @@
       "chunking_method": "whole_file"
     },
     {
-      "id": "session:785e4f2fe3",
+      "id": "session:335bc3c6a3",
       "doc": "session",
       "title_path": [
         "session_trifecta_dope.md"
       ],
-      "text": "# session.md - Trifecta Context Runbook\n\nsegment: trifecta-dope\n\n## Purpose\nThis file is a **runbook** for using Trifecta Context tools efficiently:\n- progressive disclosure (search -> get)\n- strict budget/backpressure\n- evidence cited by [chunk_id]\n\n## Quick Commands (CLI)\n```bash\n# SEGMENT=\".\" es valido SOLO si tu cwd es el repo target (el segmento).\n# Si ejecutas trifecta desde otro lugar (p.ej. desde el repo del CLI), usa un path absoluto:\n# SEGMENT=\"/abs/path/to/AST\"\nSEGMENT=\".\"\n\n# Usa un termino que exista en el segmento (ej: nombre de archivo, clase, funcion).\n# Si no hay hits, refina el query o busca por simbolos.\ntrifecta ctx sync --segment \"$SEGMENT\"\ntrifecta ctx search --segment \"$SEGMENT\" --query \"<query>\" --limit 6\ntrifecta ctx get --segment \"$SEGMENT\" --ids \"<id1>,<id2>\" --mode excerpt --budget-token-est 900\ntrifecta ctx validate --segment \"$SEGMENT\"\ntrifecta load --segment \"$SEGMENT\" --mode fullfiles --task \"Explain how symbols are extracted\"\n```\n\n## Rules (must follow)\n\n* Max **1 ctx.search + 1 ctx.get** per user turn.\n* Prefer **mode=excerpt**; use raw only if necessary and within budget.\n* Cite evidence using **[chunk_id]**.\n* If **validate fails**: stop, rebuild. **No silent fallback**.\n* **STALE FAIL-CLOSED**: If `stale_detected=true`, STOP -> `ctx sync` + `ctx validate` -> log \"Stale: true -> sync+validate executed\" -> continue only if PASS.\n\n## Session Log (append-only)\n\n### Entry Template (max 12 lines)\n```md\n## YYYY-MM-DD HH:MM - ctx cycle\n- Segment: .\n- Objective: <que necesitas resolver>\n- Plan: ctx sync -> ctx search -> ctx get (excerpt, budget=900)\n- Commands: (pending/executed)\n- Evidence: (pending/[chunk_id] list)\n- Warnings: (none/<code>)\n- Next: <1 concrete step>\n```\n\nReglas:\n- **append-only** (no reescribir entradas previas)\n- una entrada por run\n- no mas de 12 lineas\n\n## TRIFECTA_SESSION_CONTRACT (NON-EXECUTABLE in v1)\n\n> Documentation only. Not executed automatically in v1.\n\n```yaml\nschema_version: 1\nsegment: .\nautopilot:\n  enabled: false\n  note: \"v2 idea only - NOT executed in v1\"\n```\n\n## Watcher Example (optional)\n\n```bash\n# Ignore _ctx to avoid loops.\nfswatch -o -e \"_ctx/.*\" -i \"skill.md|prime.md|agent.md|session.md\" . \\\n  | while read; do trifecta ctx sync --segment \"$SEGMENT\"; done\n```\n\n## Next User Request\n\n<!-- The next agent starts here -->\n\n## 2025-12-31 20:41 UTC\n- **Summary**: T9.3.6 clamp calibration + Router v1 ADR + evidence artifacts merged to main; preserved eval outputs.\n- **Files**: docs/plans/t9_3_6_clamp_calibration.md, docs/adr/ADR_T9_ROUTER_V1.md, tmp_plan_test/*\n- **Commands**: uv run pytest, uv run trifecta ctx eval-plan, git merge, git push\n- **Warnings**: Targets not met (accuracy/fallback/nl_trigger) but FP guardrail held.\n- **Next**: Run ctx sync to refresh context pack.\n\n## 2025-12-31 18:12 UTC\n- **Summary**: Ran `ctx sync` to refresh context pack and stubs.\n- **Commands**: `uv run trifecta ctx sync --segment .`\n- **Evidence**: Build + validation passed; stubs regenerated.\n- **Warnings**: None.\n- **Next**: Continue T9.3.5 scoring fix audit in worktree.\n\n## 2025-12-29 23:44 UTC\n- **Summary**: Corrected T9.A to Context Routing Accuracy (not RAG). Updated aliases for routing, created evidence reports.\n- **Files**: implementation_plan.md, t9a_context_routing_accuracy.md, aliases.yaml\n- **Commands**: ctx sync, ctx search, session append\n- **Pack SHA**: `a38f1cacdb4f0afc`\n\n## 2025-12-29 23:49 UTC\n- **Summary**: Demonstrated Trifecta CLI usage: ctx search, ctx get, ctx stats\n- **Files**: skill.md\n- **Commands**: ctx search, ctx get, ctx stats\n- **Pack SHA**: `557f59c5e54ff34c`\n\n## 2025-12-29 23:54 UTC\n- **Summary**: Analyzed scope deviations: T9.A corrected (PCC not RAG), identified pending tasks (trifecta load, MCP, Progressive Disclosure)\n- **Files**: scope_analysis.md\n- **Commands**: mini-rag query, ctx search\n- **Pack SHA**: `557f59c5e54ff34c`\n\n## 2025-12-29 23:58 UTC\n- **Summary**: T9 Correction Evidence Report completed: 7/9 PASS, 1 FAIL (missing prohibition), 1 BELOW (routing 75%)\n- **Files**: t9-correction-evidence.md\n- **Commands**: ctx validate, ctx search, ctx get, pytest\n- **Pack SHA**: `557f59c5e54ff34c`\n\n## 2025-12-30 00:12 UTC\n- **Summary**: Updated prime docs (Paths), agent SOT (Tech Stack/Gates), and synced context pack.\n- **Files**: _ctx/prime_trifecta_dope.md, _ctx/agent.md, _ctx/session_trifecta_dope.md, readme_tf.md\n- **Commands**: ctx sync, session append\n- **Pack SHA**: `c3c0a4a0003f2420`\n\n## 2025-12-30 10:55 UTC\n- **Summary**: Applying documentation deprecation fixes (3 files)\n- **Files**: docs/plans/2025-12-29-context-pack-ingestion.md, docs/implementation/context-pack-implementation.md, docs/plans/t9-correction-evidence.md\n- **Commands**: multi_replace_file_content\n- **Pack SHA**: `307e1f35d7b883ec`\n\n## 2025-12-30 10:57 UTC\n- **Summary**: Completed documentation deprecation fixes (3 files)\n- **Files**: docs/plans/2025-12-29-context-pack-ingestion.md, docs/implementation/context-pack-implementation.md, docs/plans/t9-correction-evidence.md\n- **Commands**: trifecta ctx sync, grep\n- **Pack SHA**: `7e5a55959d7531a5`\n\n\n## 2025-12-31 11:00 UTC - Telemetry Data Science Plan\n- Segment: .\n- Objective: Diseñar sistema de análisis de telemetry para CLI Trifecta\n- Plan: Investigación web + brainstorming → diseño arquitectura\n- Commands: (pendiente sync - bug encontrado)\n- Evidence: [docs/plans/2025-12-31_telemetry_data_science_plan.md]\n- Warnings: `ctx sync -s .` falla por falta de `.resolve()` en cli.py:334\n- Next: Continuar diseño Sección 3 (Agent Skill), luego implementar\n## 2025-12-31 14:25 UTC\n- **Summary**: Strict Naming Contract Enforcement (Gate 3+1): Fail-closed legacy files, symmetric ambiguity checks. Verified 143/143 tests.\n- **Files**: src/infrastructure/cli.py, src/application/use_cases.py, tests/integration/\n- **Pack SHA**: `7e5a55959d7531a5`\n\n\n## 2025-12-31 12:00 UTC - Telemetry CLI Implementation Complete\n- Segment: .\n- Objective: Implementar comandos CLI de telemetry\n- Plan: Phase 1 completada - report, export, chart commands funcionando\n- Commands: ejecutados\n  - `trifecta telemetry report -s . --last 30` ✅\n  - `trifecta telemetry chart -s . --type hits` ✅\n  - `trifecta telemetry chart -s . --type latency` ✅\n  - `trifecta telemetry chart -s . --type commands` ✅\n- Evidence:\n  - `src/application/telemetry_reports.py` creado ✅\n  - `src/application/telemetry_charts.py` creado ✅\n  - `telemetry_analysis/skills/analyze/skill.md` creado ✅\n- Warnings: Bug de `.resolve()` en cli.py:334 fue corregido automáticamente por linter\n- Next: Escribir tests, documentar, actualizar plan\n\n## 2025-12-31 - Telemetry System COMPLETE\n- **Summary**: Sistema de telemetry CLI completado y testeado\n- **Phase 1**: CLI commands (report, export, chart) ✅\n- **Phase 2**: Agent skill creado en `telemetry_analysis/skills/analyze/` ✅\n- **Tests**: 44 eventos analizados, reporte generado siguiendo formato skill ✅\n- **Comandos funcionando**:\n  - `trifecta telemetry report -s . --last 30`\n  - `trifecta telemetry export -s . --format json`\n  - `trifecta telemetry chart -s . --type hits|latency|commands`\n- **Pack SHA**: `7e5a55959d7531a5`\n- **Status**: COMPLETADO - Lista para producción\n\n## 2025-12-31 - Token Tracking (Opción A) IMPLEMENTADO\n- **Summary**: Estimación automática de tokens en eventos de telemetry\n- **Método**: Estimación desde output (1 token ≈ 4 chars)\n- **Archivos modificados**:\n  - `src/infrastructure/telemetry.py` - Agregado `_estimate_tokens()`, `_estimate_token_usage()`, tracking en `event()`, stats en `flush()`\n  - `src/application/telemetry_reports.py` - Agregada sección \"Token Efficiency\"\n- **Eventos JSONL ahora incluyen**:\n  - `tokens.input_tokens` - Estimado desde args\n  - `tokens.output_tokens` - Estimado desde result\n  - `tokens.total_tokens` - Suma\n  - `tokens.retrieved_tokens` - De result.total_tokens si existe\n- **last_run.json ahora incluye**:\n  - `tokens.{cmd}.{total_input_tokens,total_output_tokens,total_tokens,total_retrieved_tokens,avg_tokens_per_call}`\n- **Pack SHA**: `5e6ad2eb365aea98`\n- **Status**: COMPLETADO - Funcionando (≈3-8 tokens/call promedio)\n\n## 2025-12-31 - Tarea: Reducir Zero-Hits sin RAG (En Progreso)\n- **Objetivo**: Reducir zero-hits a <20% sin embeddings/vector DB/RAG\n- **Enfoque**: Mejorar routing y fallback usando PRIME (PCC)\n- **Plan**: `docs/plans/2025-12-31_reduce_zero_hits_no_rag.md`\n\n### Completado\n- ✅ A) Diagnóstico de telemetría ANTES\n  - `scripts/telemetry_diagnostic.py` - Script reproducible\n  - `docs/plans/telemetry_before.md` - Reporte (hit_rate: 31.6%)\n- ✅ B) ctx.stats command\n  - `src/application/use_cases.py` - `StatsUseCase`\n  - `trifecta ctx stats -s . --window 30`\n\n### Pendiente (Inmediato)\n- ⏳ C) ctx.plan command - PRIME-only planning\n  - Leer `_ctx/prime_*.md` para index.entrypoints y index.feature_map\n  - Salida JSON con selected_feature, plan_hit, chunk_ids, paths, next_steps\n- ⏳ D) Dataset de evaluación (20 tareas: 10 meta + 10 impl)\n- ⏳ E) Baseline y evaluación\n\n**Pack SHA**: `5e6ad2eb365aea98`\n**Comandos útiles**:\n  - `trifecta ctx stats -s . --window 30`\n  - `python3 scripts/telemetry_diagnostic.py --segment .`\n## 2026-01-01 13:46 UTC\n- **Summary**: Integrated AST/LSP + PCC Metrics (PR#1, PR#2)\n- **Files**: src/application/ast_parser.py, src/application/lsp_manager.py, pyproject.toml\n- **Commands**: git pull, uv sync, pytest\n- **Pack SHA**: `365c67055285ad84`\n\n## 2026-01-01 22:34 UTC\n- **Summary**: Leer README y skill.md; cargar contexto con CLI\n- **Files**: README.md, skill.md, _ctx/prime_trifecta_dope.md, _ctx/agent_trifecta_dope.md, _ctx/session_trifecta_dope.md\n- **Commands**: uv run trifecta session append, uv run trifecta ctx sync, uv run trifecta ctx search, uv run trifecta ctx get, sed\n- **Pack SHA**: `0fc64a4e9b1f16c9`\n\n## 2026-01-01 22:36 UTC\n- **Summary**: ctx search failed: Telemetry.event() takes 5 positional arguments but 6 were given\n- **Files**: _ctx/session_trifecta_dope.md\n- **Commands**: uv run trifecta ctx search --segment . --query 'README skill.md onboarding' --limit 6\n- **Pack SHA**: `702e19ef8ee813a0`\n\n## 2026-01-01 22:41 UTC\n- **Summary**: Audit Phase 3 LSP telemetry evidence; run required commands\n- **Files**: _ctx/session_trifecta_dope.md\n- **Commands**: uv run trifecta session append, uv run trifecta ctx sync, uv run trifecta ctx search, uv run trifecta ctx get, git status, uv --version, python --version, uv run pytest, uv run trifecta <lsp cmd>, jq, rg, ls, tail\n- **Pack SHA**: `702e19ef8ee813a0`\n\n## 2026-01-01 22:53 UTC\n- **Summary**: Audit Phase 3 LSP telemetry evidence per Judge Auditor\n- **Files**: _ctx/session_trifecta_dope.md\n- **Commands**: uv run trifecta session append, uv run trifecta ctx sync, uv run trifecta ctx search, uv run trifecta ctx get, git status, uv --version, python --version, uv run pytest -q, uv run pytest -q tests/integration/test_ast_telemetry_consistency.py, uv run pytest -q tests/integration/test_lsp_telemetry.py, uv run pytest -q tests/integration/test_lsp_daemon.py, uv run trifecta <lsp cmd>, jq, rg, ls, tail\n- **Pack SHA**: `31701c07e080f89c`\n\n## 2026-01-01 23:04 UTC\n- **Summary**: Audit LSP telemetry runs + tests; warm runs only; collected evidence outputs\n- **Files**: _ctx/session_trifecta_dope.md, _ctx/telemetry/events.jsonl, _ctx/telemetry/last_run.json\n- **Commands**: git status, uv --version, python --version, uv run pytest -q, uv run pytest -q tests/integration/test_ast_telemetry_consistency.py, uv run pytest -q tests/integration/test_lsp_telemetry.py, uv run pytest -q tests/integration/test_lsp_daemon.py, uv run trifecta ast hover, ls -l tempdir, cat pid, ps, jq\n- **Pack SHA**: `3b045595acf7ffcd`\n\n## 2026-01-01 23:08 UTC\n- **Summary**: Guardar reporte de auditoria Phase 3 LSP en Desktop\n- **Files**: _ctx/session_trifecta_dope.md\n- **Commands**: uv run trifecta session append, uv run trifecta ctx sync, uv run trifecta ctx search, uv run trifecta ctx get, cat > ~/Desktop/*.md\n- **Pack SHA**: `3b045595acf7ffcd`\n\n## 2026-01-01 23:28 UTC\n- **Summary**: External Audit: Phase 3 LSP Daemon (AUDITABLE-PASS)\n- **Files**: audit_report_phase3_lsp_daemon.md\n- **Commands**: pytest, trifecta ast hover\n- **Pack SHA**: `ec673055b16e9433`\n\n## 2026-01-02 01:18 UTC\n- **Summary**: LSP Lifecycle Hardening + Error Card System\n- **Changes**:\n  - `lsp_client.py`: Added post-join guard (skip close if thread alive), increased timeout to 1.0s, defensive stopping check\n  - `daemon_paths.py`: Added /tmp validation + AF_UNIX path length checks\n  - `src/cli/error_cards.py`: NEW - Error Card renderer with stable markers\n  - `cli.py`: Added FileNotFoundError handler → SEGMENT_NOT_INITIALIZED Error Card\n  - `test_lsp_no_stderr_errors.py`: LSP activation verification gate\n  - `test_daemon_paths_constraints.py`: NEW - platform constraint tripwires\n  - `tests/acceptance/test_ctx_sync_preconditions.py`: NEW - black-box CLI tests\n- **Tests**: 17 integration + 2 acceptance passing\n- **Next**: Fix `trifecta create -s` to write to target dir (not CLI cwd)\n\n## 2026-01-02 09:56 UTC\n- **Summary**: Error Card & Dogfooding Sprint COMPLETE\n- **Fixes**:\n  - `cli.py`: Error Card handler hardened (only emits `SEGMENT_NOT_INITIALIZED` for prime-specific errors)\n  - `cli.py`: Fixed `create -s` to write to target directory (was writing to CLI cwd)\n  - `cli.py`: Removed duplicate `--path` param, segment_id derived from dirname\n- **Tests**: 5 acceptance tests passing\n  - `test_ctx_sync_fails_when_prime_missing` - Error Card\n  - `test_ctx_sync_succeeds_after_initialization` - Real dogfooding (create→refresh-prime→sync)\n  - `test_ctx_sync_succeeds_with_valid_prime` - Happy path\n  - `test_error_card_not_emitted_for_other_file_errors` - Anti-false-positive tripwire\n  - `test_create_from_different_cwd` - Confirms create writes to target, not cwd\n- **Bug Fixed**: `docs/bugs/create_cwd_bug.md` marked FIXED\n- **Next**: Consider replacing substring matching with path comparison for more robust error classification\n\n## 2026-01-02 11:30 UTC\n- **Summary**: Type-Based Error Classification Implementation COMPLETE\n- **Changes**:\n  - `src/application/exceptions.py`: NEW - PrimeFileNotFoundError with path/segment_id attributes\n  - `src/application/use_cases.py`: Raise PrimeFileNotFoundError instead of generic FileNotFoundError\n  - `src/infrastructure/cli.py`: Type-based handler with isinstance() check + substring fallback\n  - Deprecation warning: `TRIFECTA_DEPRECATED: fallback_prime_missing_string_match_used` to stderr\n- **Tests**: 9/9 passing\n  - 5 acceptance tests (dogfooding verde)\n  - 3 unit tests (exception attributes, custom message, type independence)\n  - 1 unit test (type priority verification)\n- **Docs Optimization**: skill.md 96→69 lines, agent.md +protocols section, prime.md filled with new paths/glossary\n- **Commit**: 9c394c6 \"feat: replace substring matching with type-based error classification\"\n- **Next**: Monitor TRIFECTA_DEPRECATED in dogfooding, remove substring fallback after 2026-03-01\n\n## 2026-01-02 12:45 UTC\n- **Summary**: Deprecated Tracking System Implementation COMPLETE\n- **Changes**:\n  - `docs/deprecations.yaml`: NEW - Static registry of deprecated code paths (source-of-truth)\n  - `src/infrastructure/deprecations.py`: NEW - Helper function `maybe_emit_deprecated()` with env-based policy\n  - `src/infrastructure/cli.py`: Instrumented substring fallback with deprecated tracking\n  - Policy: TRIFECTA_DEPRECATED env var (off|warn|fail)\n- **Tests**: 10/10 passing\n  - 5 unit tests (policy off/warn/fail, default, invalid values)\n  - 5 acceptance tests (all existing tests still passing)\n- **Features**:\n  - Emits `deprecated.used` event via existing telemetry (no new log files)\n  - Policy 'off' (default): no tracking\n  - Policy 'warn': emit telemetry event only\n  - Policy 'fail': emit event + exit code 2 (for CI/harness)\n- **Next**: Use TRIFECTA_DEPRECATED=warn in dogfooding to detect deprecated paths, remove fallback by 2026-02-15\n\n## 2026-01-02 13:45 UTC\n- **Summary**: Post-Refactor Quality Audit (Ola 1-4.1) COMPLETE\n- **Changes**:\n  - Ola 1: Fixed 3 import errors (SymbolInfo, SkeletonMapBuilder, _relpath stubs)\n  - Ola 2: Telemetry reserved key validation, SymbolQuery Result pattern, CLI create naming tests\n  - Ola 3: Formalized roadmap tests (--ignore=tests/roadmap in pyproject.toml)\n  - Ola 3.1: Hardened acceptance gate (-m \"not slow\"), 29/29 green\n  - Ola 4.0: Fixed PR2 integration (Result pattern in search_symbol)\n  - Ola 4.1: Moved prime tripwires to tests/roadmap/\n- **Tests**: 312 passed, 7 failed (core); 29 passed acceptance (gate green)\n- **Files Created**:\n  - `docs/TEST_GATES.md`: Official test gate commands\n  - `docs/auditoria/TRIAGE_REPORT.md`: Bucket analysis and ROI plan\n  - `tests/roadmap/`: 6 test files for unimplemented features\n  - `tests/acceptance/test_acceptance_gate_slow_marker.py`: Tripwire for @slow\n- **Config Changes**:\n  - `pyproject.toml`: addopts = \"--ignore=tests/roadmap\", roadmap marker added\n- **Next**: Continue with remaining 7 failures (selector_dsl, naming_contract, lsp_client_strict, t8_2_consistency, counters) or commit current state\n\n\n## 2026-01-02 17:15 UTC\n- **Summary**: Completed Ola 4.3 through Ola 5 Audit (Final Clean Check).\n- **Changes**:\n  - **Ola 4.3**: Fixed `selector_dsl` URI validation (strict scheme check).\n  - **Ola 4.4**: Fixed `naming_contract` integration test drift (CLI arg update).\n  - **Ola 4.5**: Fixed `t8_2_consistency` telemetry (flush schema + pack_state).\n  - **Ola 4.6**: Fixed `lsp_client_strict` & `repro_counters`:\n      - Formalized **Relaxed READY** contract (`docs/contracts/LSP_RELAXED_READY.md`) with tripwire.\n      - Fixed `test_repro_counters` schema mismatch (metrics_delta -> ast/lsp).\n  - **Ola 5**: Final Compliance Audit.\n      - **Global Status**: MVP Operable (PASS).\n      - **Gates**: Acceptance Default (33/33 PASS), Unit (PASS), Integration (PASS), Roadmap (Isolated).\n- **Evidence**: `docs/auditoria/TRIAGE_REPORT.md` updated.\n- **Next**: Merge fixes, release MVP Candidate.\n- **Pack SHA**: `ec673055b16e9433`\n\n## 2026-01-03 15:05 UTC\n- **Summary**: Pre-Commit Telemetry Kill Switch Hardening COMPLETE\n- **Changes**:\n  - `src/infrastructure/telemetry.py`: Implemented `TRIFECTA_NO_TELEMETRY` (No-Op) and `TRIFECTA_TELEMETRY_DIR` (Redirection).\n  - `scripts/pre_commit_test_gate.sh`: Hardened with `trap` cleanup and env invariant checks.\n  - `tests/unit/test_telemetry_env_contracts.py`: NEW - 4/4 contract tests PASS.\n  - `verify_precommit_clean.sh`: Strict side-effect detection and worktree zero-diff enforcement.\n- **Commands**: `uv run pre-commit run --all-files`, `uv run pytest -q tests/unit/test_telemetry_env_contracts.py`\n- **Result**: Zero side-effects in repo, all gates PASS.\n- **Pack SHA**: `5fa564bb`\n\n## 2026-01-03 22:00 - M1 SkeletonMapBuilder + CLI Workflow Documentation\n- **Segment**: trifecta_dope\n- **Objective**: Implement M1 AST Symbols (production), document official CLI workflow, port tests, and audit with zero-trust protocol.\n- **Plan**: (1) Implement SkeletonMapBuilder with stdlib ast, (2) Create help-driven CLI docs, (3) Build acceptance tests, (4) RC audit v1+v2\n- **Commands Executed**:\n  - `trifecta ast symbols \"sym://python/mod/src.domain.result\" --segment .` (verified JSON output)\n  - `uv run pytest -q tests/acceptance -m \"not slow\"` (41/41 PASS)\n  - `uv run pytest -q tests/unit/test_repo_root_helper.py` (3/3 PASS)\n  - Zero-trust audit protocol (all gates verified)\n- **Evidence**:\n  - [M1 Contract](docs/contracts/AST_SYMBOLS_M1.md): Stable JSON schema\n  - [CLI Workflow](docs/CLI_WORKFLOW.md): Help-driven, 175 lines, copy/paste ready\n  - [Acceptance Tests](tests/acceptance/test_cli_workflow_happy_path.py): 4/4 passing\n  - [RC Audit v2](~/.gemini/.../rc_audit_v2_zero_trust.md): 5/7 PASS, 2 MINOR\n  - [Workflows Updated](.agent/workflows/): trifecta-basics, trifecta-advanced, superpowers catalog\n- **Findings**:\n  - M1 PRODUCTION READY: 1 SkeletonMapBuilder, returns symbols, 100% contract compliance\n  - Acceptance gate: 41/41 GREEN (critical path clean)\n  - Workflow drift detected & fixed: `/trifecta-advanced` mislabeled M1 as WIP (corrected to M1 COMPLETE)\n  - Minor: 2 obsolete unit tests (tree-sitter assumption), 1 telemetry counter test (non-critical)\n- **Warnings**: Roadmap tests (20 failures) are expected (future milestones Phase 2a, T8)\n- **Next**: Fix 3 obsolete tests as follow-up. M1 ready for production use.\n- **Commits** (trifecta_dope): 3eb0e5c, a2806e0, c2f604a, 18cba55, 14e7752, dd206e6\n- **Commits** (agent_h): 63104af (workflows update)\n- **Pack SHA**: `dd206e6`\n## 2026-01-04 12:10 UTC\n- **Summary**: Created Northstar SOT Kanban\n- **Files**: docs/v2_roadmap/TRIFECTA_NORTHSTAR_KANBAN.kanban.md\n- **Pack SHA**: `dc7fc4ef759e54a6`\n\n## 2026-01-04 12:18 UTC\n- **Summary**: Deep Kanban SOT Audit v2.0 with AST symbols\n- **Files**: docs/v2_roadmap/TRIFECTA_NORTHSTAR_KANBAN_V2.md\n- **Pack SHA**: `8da73bd1a885c2b7`\n\n## 2026-01-04 12:25 UTC\n- **Summary**: Corrected AST/LSP status: separate by design (not orphaned)\n- **Files**: docs/v2_roadmap/TRIFECTA_NORTHSTAR_KANBAN_V2.md, docs/ast-lsp-connect/reevaluation_northstar.md\n- **Pack SHA**: `8da73bd1a885c2b7`\n\n## 2026-01-04 12:27 UTC\n- **Summary**: Eliminated 2 outdated Kanban files with incorrect AST/LSP status\n- **Files**: docs/v2_roadmap/TRIFECTA_NORTHSTAR_KANBAN_V2.md\n- **Pack SHA**: `8da73bd1a885c2b7`\n\n## 2026-01-04 12:54 UTC\n- **Summary**: Created critical analysis doc for session JSONL proposal\n- **Files**: docs/session_update/braindope_critical_analysis.md\n- **Pack SHA**: `8da73bd1a885c2b7`\n## 2026-01-05 03:58 UTC\n- **Summary**: Auditar agent_trifecta_dope.md para verificar que refleja CLI v2.0, features actuales (AST M1, telemetry, LSP, Error Cards), y remover rutas desactualizadas\n- **Files**: agent_trifecta_dope.md\n- **Commands**: ctx search, ctx get\n- **Pack SHA**: `da3944a71db594a6`\n\n## 2026-01-05 04:00 UTC\n- **Summary**: Investigate 'Central Telefonica' search strategy implementation\n- **Commands**: ctx sync, ctx search\n- **Pack SHA**: `da3944a71db594a6`\n\n## 2026-01-05 04:01 UTC\n- **Summary**: Implementar plan de actualización para agent_trifecta_dope.md: metadata (repo_root, last_verified), Tech Stack (versiones, deps telemetry), Workflow (paths portables), Gates (Makefile commands), Features (AST M1 PRODUCTION, telemetry COMPLETE, LSP RELAXED READY, Error Cards, Deprecation tracking), Troubleshooting (soluciones reales)\n- **Files**: _ctx/agent_trifecta_dope.md, docs/plans/2026-01-05-agent-md-update.md\n- **Commands**: grep, replace_string_in_file\n- **Pack SHA**: `7f7ca90fb803bf9e`\n\n## 2026-01-05 04:02 UTC\n- **Summary**: Phase 1: Search Guidance Baseline - Dataset & Scripting\n- **Commands**: mkdir -p docs/datasets docs/reports, write_file\n- **Pack SHA**: `7f7ca90fb803bf9e`\n\n## 2026-01-05 04:03 UTC\n- **Summary**: ✅ Completado: agent_trifecta_dope.md actualizado para CLI v2.0 - Workflow portable (sin /Users), Session protocol con instrucciones, Active Features (AST M1 PRODUCTION, telemetry COMPLETE, LSP RELAXED READY, Error Cards, Deprecation tracking, Obsidian EXPERIMENTAL), 16+ Makefile commands, 0 stale paths, verified 2026-01-05\n- **Files**: _ctx/agent_trifecta_dope.md\n- **Commands**: session append, grep verify\n- **Pack SHA**: `7f7ca90fb803bf9e`\n\n## 2026-01-05 04:04 UTC\n- **Summary**: Phase 1 Complete: Search Guidance Baseline established (80% failure on vague queries)\n- **Files**: docs/reports/search_guidance_baseline.md, docs/datasets/search_queries_v1.yaml, scripts/run_search_eval.py\n- **Pack SHA**: `7f7ca90fb803bf9e`\n\n## 2026-01-05 04:06 UTC\n- **Summary**: ✅ SESSION COMPLETE: skill.md + agent_trifecta_dope.md updated for Trifecta v2.0 using superpowers verification workflow. Results: skill.md 69→134 lines (da238a3), agent_trifecta_dope.md 126→217 lines (2d617eb), 0 stale paths, 100% feature coverage (AST M1 PRODUCTION, telemetry COMPLETE, LSP RELAXED READY, Error Cards, Deprecation tracking, Obsidian EXPERIMENTAL), 45 CLI commands documented. Session completion report: docs/sessions/2026-01-05_session_completion_report.md\n- **Files**: skill.md, _ctx/agent_trifecta_dope.md, _ctx/session_trifecta_dope.md, docs/sessions/2026-01-05_session_completion_report.md\n- **Commands**: trifecta ctx search, trifecta ctx get, trifecta session append, git commit\n- **Pack SHA**: `7f7ca90fb803bf9e`\n\n## 2026-01-05 04:17 UTC\n- **Summary**: Session audit complete: skill.md and agent_trifecta_dope.md fully updated for Trifecta v2.0, all documentation verified against session.md (2026-01-04), 45 CLI commands documented, 0 stale paths, 100% feature coverage (AST M1 PRODUCTION, telemetry COMPLETE, LSP RELAXED READY, Error Cards, Deprecation, Obsidian EXPERIMENTAL). Ready for production.\n- **Files**: skill.md, _ctx/agent_trifecta_dope.md, _ctx/session_trifecta_dope.md\n- **Commands**: make gate-all\n- **Pack SHA**: `7f7ca90fb803bf9e`\n\n## 2026-01-05 13:26 UTC\n- **Summary**: Injecting context about Trifecta CLI architecture and features using ctx search/get cycle\n- **Files**: skill.md, prime_trifecta_dope.md, agent_trifecta_dope.md\n- **Commands**: make install, trifecta session append\n- **Pack SHA**: `7f7ca90fb803bf9e`\n\n## 2026-01-05 13:26 UTC\n- **Summary**: Completed: LSP daemon architecture confirmed (UNIX socket IPC, 180s TTL), AST symbols M1 PRODUCTION ready, CLI workflow validated\n- **Commands**: make install, trifecta session append, trifecta ctx sync, trifecta ctx search, trifecta ctx get\n- **Pack SHA**: `f8c6d49dade52da7`\n\n\n## 2026-01-05 14:15 UTC - AST Cache Persist-Cache Fix COMPLETE\n- **Segment**: trifecta_dope\n- **Objective**: Fix critical P0 bug: `--persist-cache` crash (TypeError: SymbolInfo serialization)\n- **Plan**: SCOOP P0 investigation → Emergency fix → Audit-grade merge preparation\n- **Phase 1 - Fix Implementation**:\n  - Fixed SQLiteCache serialization (SymbolInfo → dict via to_dict())\n  - Fixed ast_parser rehydration (dict → SymbolInfo after cache.get())\n  - Collateral fix: _evict_if_needed None handling for empty DB\n  - Created 2 unit tests (test_ast_cache_persist_fix.py)\n- **Phase 2 - Audit & Merge Preparation**:\n  - SCOOP P0 documentation (scoop_ast_cache_serialization.md)\n  - Audit-grade report (merge_readiness_ast_cache_audit_grade.md)\n  - Privacy-first policy (<REDACTED> in docs, exact in logs)\n  - Bash-portable commands (no fish syntax)\n  - Zero-glob enforcement (globs only in find commands)\n- **Phase 3 - Evidence Freezing**:\n  - Created scripts/verify_audit_grade_report.sh (tripwire)\n  - Froze 7 logs in docs/reports/artifacts/ast_cache_persist/\n  - Checksums verified (SHA-256)\n  - Tripwire honesty proof (PASS + FAIL logs)\n- **Files Modified**:\n  - Code: src/domain/ast_cache.py, src/application/ast_parser.py (~32 LOC)\n  - Tests: tests/unit/test_ast_cache_persist_fix.py (NEW, 2 tests)\n  - Docs: 8 files (ADR, reports, tech debt, fixtures)\n  - Scripts: verify_audit_grade_report.sh (NEW, executable)\n- **Gates**: ✅ 428 tests passing, ✅ Tripwire PASS, ✅ Fixture correctly rejected\n- **Roadmap Position** (per docs/plans/2026-01-05-ast-cache-fixes-v2.md):\n  - Fase 1: ~70% complete (SQLiteCache ✅, InMemoryLRUCache ✅, NullCache pending)\n  - Problemas resueltos: #4 (LRU eviction) ✅, #5 (Pickle → SQLite) ✅\n  - Pendiente: Fase 1 (30%), Fases 2-4 (DI, telemetry, SkeletonMapBuilder refactor)\n- **Next Session**: Cerrar Fase 1 completa (NullCache + AstCache Protocol formal)\n- **Pack SHA**: a7bde3d (HEAD at session end)\n## 2026-01-05 17:23 UTC\n- **Summary**: Iniciar ciclo de contexto para conocer uso del CLI y flujo del segmento\n- **Files**: trifecta_dope/_ctx/session_trifecta_dope.md\n- **Commands**: ctx search, ctx get\n- **Pack SHA**: `4b5f12529dbe832a`\n\n## 2026-01-05 17:23 UTC\n- **Summary**: Completado ciclo de contexto para uso del CLI; evidencia [session:b51eee61f6]\n- **Files**: trifecta_dope/_ctx/session_trifecta_dope.md\n- **Commands**: ctx search, ctx get\n- **Pack SHA**: `4b5f12529dbe832a`\n\n## 2026-01-05 17:25 UTC\n- **Summary**: Analizar como los anchors afectan la eficiencia de busquedas en el CLI\n- **Files**: trifecta_dope/_ctx/session_trifecta_dope.md\n- **Commands**: ctx search, ctx get\n- **Pack SHA**: `4b5f12529dbe832a`\n\n## 2026-01-05 17:25 UTC\n- **Summary**: Revisado README sobre enfoque de contexto curado; evidencia [ref:trifecta_dope/README.md:c2d9ad0077]\n- **Files**: trifecta_dope/_ctx/session_trifecta_dope.md\n- **Commands**: ctx search, ctx get\n- **Pack SHA**: `4b5f12529dbe832a`\n\n## 2026-01-05 17:26 UTC\n- **Summary**: Analizar eficiencia de anchors en el reporte query_linter_cli_verification\n- **Files**: docs/reports/query_linter_cli_verification.md, _ctx/session_trifecta_dope.md\n- **Commands**: ctx search, ctx get\n- **Pack SHA**: `4b5f12529dbe832a`\n\n## 2026-01-05 17:27 UTC\n- **Summary**: Ctx search sin hits para anchors en query_linter_cli_verification; requiere siguiente ciclo\n- **Files**: docs/reports/query_linter_cli_verification.md, _ctx/session_trifecta_dope.md\n- **Commands**: ctx search\n- **Pack SHA**: `4b5f12529dbe832a`\n\n## 2026-01-05 17:28 UTC\n- **Summary**: Generar metricas sobre eficiencia de anchors en el reporte query_linter_cli_verification\n- **Files**: docs/reports/query_linter_cli_verification.md, _ctx/session_trifecta_dope.md\n- **Commands**: ctx search, ctx get\n- **Pack SHA**: `a969d53df9e63959`\n\n## 2026-01-05 17:29 UTC\n- **Summary**: Ctx search sin hits para anchors en query_linter_cli_verification; requiere nuevo ciclo con query mas especifica\n- **Files**: docs/reports/query_linter_cli_verification.md, _ctx/session_trifecta_dope.md\n- **Commands**: ctx search\n- **Pack SHA**: `a969d53df9e63959`\n\n## 2026-01-05 17:29 UTC\n- **Summary**: Buscar anchors y metricas asociadas en query_linter_cli_verification\n- **Files**: docs/reports/query_linter_cli_verification.md, _ctx/session_trifecta_dope.md\n- **Commands**: ctx search, ctx get\n- **Pack SHA**: `a969d53df9e63959`\n\n## 2026-01-05 17:29 UTC\n- **Summary**: Ctx search no encontro anchors en query_linter_cli_verification; necesita localizar el reporte de otra forma\n- **Files**: docs/reports/query_linter_cli_verification.md, _ctx/session_trifecta_dope.md\n- **Commands**: ctx search\n- **Pack SHA**: `a969d53df9e63959`\n\n## 2026-01-05 17:31 UTC\n- **Summary**: Usar LSP para buscar el reporte query_linter_cli_verification fuera del context pack\n- **Files**: docs/reports/query_linter_cli_verification.md, _ctx/session_trifecta_dope.md\n- **Commands**: lsp --help, lsp search\n- **Pack SHA**: `d090785154f5924e`\n\n## 2026-01-05 17:31 UTC\n- **Summary**: Inspeccionar comandos disponibles para buscar via LSP\n- **Files**: _ctx/session_trifecta_dope.md\n- **Commands**: trifecta --help\n- **Pack SHA**: `d090785154f5924e`\n\n## 2026-01-05 17:31 UTC\n- **Summary**: Inspeccionar comandos ast para posibles busquedas via LSP\n- **Files**: _ctx/session_trifecta_dope.md\n- **Commands**: trifecta ast --help\n- **Pack SHA**: `d090785154f5924e`\n\n## 2026-01-05 17:31 UTC\n- **Summary**: Inspeccionar comando load por opciones LSP\n- **Files**: _ctx/session_trifecta_dope.md\n- **Commands**: trifecta load --help\n- **Pack SHA**: `d090785154f5924e`\n\n## 2026-01-05 17:32 UTC\n- **Summary**: Inspeccionar ast snippet/hover para capacidades LSP\n- **Files**: _ctx/session_trifecta_dope.md\n- **Commands**: trifecta ast snippet --help, trifecta ast hover --help\n- **Pack SHA**: `d090785154f5924e`\n\n## 2026-01-05 17:32 UTC\n- **Summary**: Inspeccionar codigo LSP para encontrar comando de busqueda\n- **Files**: src/infrastructure/lsp_client.py, src/infrastructure/lsp_daemon.py, _ctx/session_trifecta_dope.md\n- **Commands**: rg lsp\n- **Pack SHA**: `d090785154f5924e`\n\n## 2026-01-05 17:32 UTC\n- **Summary**: Revisar lsp_daemon y lsp_client para entender interfaz LSP\n- **Files**: src/infrastructure/lsp_daemon.py, src/infrastructure/lsp_client.py, _ctx/session_trifecta_dope.md\n- **Commands**: sed\n- **Pack SHA**: `585a973055425ce8`\n\n## 2026-01-05 17:33 UTC\n- **Summary**: Revisar cli_ast para entender comandos LSP\n- **Files**: src/infrastructure/cli_ast.py, _ctx/session_trifecta_dope.md\n- **Commands**: sed\n- **Pack SHA**: `585a973055425ce8`\n\n## 2026-01-05 17:36 UTC\n- **Summary**: Usar --help para identificar comandos LSP disponibles\n- **Files**: _ctx/session_trifecta_dope.md\n- **Commands**: trifecta ast --help\n- **Pack SHA**: `585a973055425ce8`\n\n## 2026-01-05 17:36 UTC\n- **Summary**: --help confirma comandos AST/LSP disponibles (symbols, hover WIP)\n- **Files**: _ctx/session_trifecta_dope.md\n- **Commands**: trifecta ast --help\n- **Pack SHA**: `585a973055425ce8`\n\n## 2026-01-05 17:38 UTC\n- **Summary**: Descubrir el repo usando el CLI: identificar docs base, arquitectura y entradas principales\n- **Files**: _ctx/session_trifecta_dope.md\n- **Commands**: ctx search, ctx get\n- **Pack SHA**: `585a973055425ce8`\n\n## 2026-01-05 17:38 UTC\n- **Summary**: Descubierto: README define PCC y artefactos base (prime/agent/session/skill) para orientar exploracion; evidencia [ref:trifecta_dope/README.md:c2d9ad0077]\n- **Files**: _ctx/session_trifecta_dope.md\n- **Commands**: ctx search, ctx get\n- **Pack SHA**: `585a973055425ce8`\n\n## 2026-01-05 17:39 UTC\n- **Summary**: Descubrir puntos de entrada principales usando prime del segmento\n- **Files**: _ctx/prime_trifecta_dope.md, _ctx/session_trifecta_dope.md\n- **Commands**: ctx search, ctx get\n- **Pack SHA**: `585a973055425ce8`\n\n## 2026-01-05 17:39 UTC\n- **Summary**: Prime identifica puntos de entrada: lsp_daemon.py, cli.py, lsp_client.py, telemetry.py, use_cases.py, cli_ast.py, etc.; evidencia [prime:5d535ae4c0]\n- **Files**: _ctx/prime_trifecta_dope.md, _ctx/session_trifecta_dope.md\n- **Commands**: ctx search, ctx get\n- **Pack SHA**: `585a973055425ce8`\n\n## 2026-01-05 17:40 UTC\n- **Summary**: Usar ast symbols para profundizar en comandos del CLI (src.infrastructure.cli)\n- **Files**: src/infrastructure/cli.py, _ctx/session_trifecta_dope.md\n- **Commands**: ast symbols\n- **Pack SHA**: `585a973055425ce8`\n\n## 2026-01-05 17:40 UTC\n- **Summary**: ast symbols fallo por URI invalida; reintentar con kind=mod\n- **Files**: src/infrastructure/cli.py, _ctx/session_trifecta_dope.md\n- **Commands**: ast symbols\n- **Pack SHA**: `585a973055425ce8`\n\n## 2026-01-05 17:40 UTC\n- **Summary**: AST symbols en cli.py: lista de comandos principales y utilidades (search/get/validate/sync/create/load/session/telemetry/etc.)\n- **Files**: src/infrastructure/cli.py, _ctx/session_trifecta_dope.md\n- **Commands**: ast symbols\n- **Pack SHA**: `585a973055425ce8`\n\n## 2026-01-05 17:41 UTC\n- **Summary**: Extraer symbols de cli_ast y telemetry para documentar uso de comandos\n- **Files**: src/infrastructure/cli_ast.py, src/infrastructure/telemetry.py, _ctx/session_trifecta_dope.md\n- **Commands**: ast symbols\n- **Pack SHA**: `585a973055425ce8`\n\n## 2026-01-05 17:41 UTC\n- **Summary**: AST symbols: cli_ast define commands symbols/snippet/hover/clear-cache/cache-stats; telemetry expone clase Telemetry y sanitizacion\n- **Files**: src/infrastructure/cli_ast.py, src/infrastructure/telemetry.py, _ctx/session_trifecta_dope.md\n- **Commands**: ast symbols\n- **Pack SHA**: `585a973055425ce8`\n\n## 2026-01-05 17:41 UTC\n- **Summary**: Leer docstrings/flags de cli_ast y telemetry para documentar uso\n- **Files**: src/infrastructure/cli_ast.py, src/infrastructure/telemetry.py, _ctx/session_trifecta_dope.md\n- **Commands**: ctx search, ctx get\n- **Pack SHA**: `585a973055425ce8`\n\n## 2026-01-05 17:42 UTC\n- **Summary**: Ctx search no encontro docstrings en cli_ast/telemetry; obtuvo runbook de session como referencia de comandos base; evidencia [session:c420c4f09f]\n- **Files**: src/infrastructure/cli_ast.py, src/infrastructure/telemetry.py, _ctx/session_trifecta_dope.md\n- **Commands**: ctx search, ctx get\n- **Pack SHA**: `585a973055425ce8`\n\n## 2026-01-05 17:42 UTC\n- **Summary**: Identificar patron de busqueda positiva con CLI y AST\n- **Files**: _ctx/session_trifecta_dope.md\n- **Commands**: ctx search, ctx get\n- **Pack SHA**: `585a973055425ce8`\n\n## 2026-01-05 17:42 UTC\n- **Summary**: Patron: follow runbook (segment '.', search->get), use existing terms, and use ast symbols with sym://python/mod/<module>\n- **Files**: _ctx/session_trifecta_dope.md\n- **Commands**: ctx search, ctx get\n- **Pack SHA**: `585a973055425ce8`\n\n\n## 2026-01-06 11:00-11:53 UTC - Legacy Backlog Migration + System Modernization\n- **Summary**: Migrated legacy _ctx/blacklog/ to new state-segregated _ctx/jobs/ structure. Closed WO-0008 and WO-0009 with CLI evidence. Updated documentation.\n- **Key Changes**:\n  - Migrated WO-0008/0009 from docs/backlog/legacy/ to _ctx/jobs/done/\n  - Created _ctx/jobs/{pending,running,done,failed}/ directories\n  - Updated work_order.schema.json (added evidence_logs, verified_at_sha)\n  - Prefixed legacy WO fields with x_ for schema compliance\n  - Created DOD-LINTER_AB.yaml (requires schema fix - validation pending)\n- **Documentation**:\n  - CLAUDE.md: Added \"Backlog System\" section\n  - skill.md: Added backlog quick reference\n  - Single epic registry: _ctx/backlog/backlog.yaml\n- **Commits**:\n  - 604d93c: Migrate WO-0008/0009 to _ctx/jobs/done/\n  - abccec0: Add evidence_logs/verified_at_sha to schema\n  - f0c314c: Update CLAUDE.md with backlog system\n  - ca83b7f: Update skill.md with backlog reference\n  - 1712802: Add DOD-LINTER_AB definition\n- **Validation**: ⚠️ PENDING (DoD schema mismatch - needs fix)\n- **Evidence**: migration_final_summary.md, backlog_analysis.md, epic_organization_analysis.md\n- **Status**: Migration complete, validation blocked on DoD schema compliance\n\n## 2026-01-06 12:30-12:40 UTC - Hash Mismatch Debug (Fail-Closed)\n- **Objective**: Break build→validate→fail cycle without bypass\n- **Root Cause**: Build normalizes content (adds newline), validation reads raw bytes → hash mismatch\n- **Files affected**: t9_3_6_clamp_calibration.md (7580b vs 7346-7348b), AST_CACHE_DEEP_DIVE_ANALYSIS.md (0b vs 1b), cli/__init__.py (0b vs 1b)\n- **Fix**: Applied newline normalization in ValidateContextPackUseCase (lines 721-727) to match BuildContextPackUseCase\n- **Evidence**: _ctx/logs/hash_mismatch_fail.log, _ctx/logs/hash_mismatch_debug_report.md\n- **Validation**: ctx sync PASS, acceptance tests 45/45 PASS\n- **Commit**: fix(validation): normalize content like build to prevent hash mismatch loop\n\n## 2026-01-06 13:13 UTC - Regression Test for Newline Normalization Contract\n- **Objective**: Lock build/validate normalization contract with regression test\n- **Test**: tests/integration/test_pack_validation_normalizes_newline.py\n- **Coverage**: Creates file without trailing newline, runs create→sync, asserts PASS\n- **Results**: 2/2 tests PASS\n- **Report**: docs/reports/pack_validation_newline_normalization.md\n- **Verification**: Integration tests 21/21 PASS\n- **Commit**: test(pack): lock newline normalization contract for build/validate\n\n## 2026-01-06 13:22-13:28 UTC - WO-0010 Field Exercises v1 Evaluation\n- **Objective**: Quantitative benchmark with 20 real-world queries\n- **Dataset**: 6 technical, 6 conceptual, 8 discovery queries\n- **A/B Results**:\n  - OFF (no linter): zero_hit_rate=0.0%, avg_hits=9.30\n  - ON (linter): zero_hit_rate=0.0%, avg_hits=9.40\n  - Delta: +0.10 hits per query (linter improves slightly)\n- **Gate**: zero_hit_rate_on=0.0% < 30% → ✅ PASS\n- **Evidence**: _ctx/logs/field_ex_{off,on}.log\n- **Report**: docs/reports/field_exercises_v1_results.md\n- **Commit**: feat(eval): add Field Exercises v1 benchmark\n\n## 2026-01-06 13:36-14:00 UTC - WO-0010 Anchor Metrics from Telemetry\n- **Objetivo**: Extender Field Exercises v1 para reportar uso de anchors desde telemetría (no heurístico de stdout)\n- **Implementación**:\n  - Extractor: eval/scripts/extract_anchor_metrics.py\n  - Lectura de _ctx/telemetry/events.jsonl\n  - Métricas desde args (linter_expanded, linter_added_strong_count, etc.)\n- **Resultados** (telemetría histórica aggregada, no solo FE v1):\n  - OFF: 241 queries, 1.21 avg hits\n  - ON: 295 queries, 4.67 avg hits\n  - Anchor usage: 70/295 (23.7%)\n  - Delta cuando expanded: -2.46 hits (expansión correlaciona con queries difíciles)\n- **Métricas JSON**: _ctx/metrics/field_exercises_v1_anchor_metrics.json\n- **Logs de ejecución**: _ctx/logs/wo0010_anchor_metrics/\n- **Nota**: Datos de telemetría histórica, incluye runs previos (no solo FE v1 limpio)\n- **Commit**: [pending]\n\n## 2026-01-06 14:00 UTC - WO-0010 Tasks 4-6 Complete\n- **TASK 4**: Updated field_exercises_v1_results.md with telemetry metrics section\n- **TASK 5**: Created tests/unit/test_field_exercises_anchor_metrics.py (10 tests)\n- **TASK 6**: Full pytest suite executed\n- **Status**: All infrastructure complete, ready for production use\n\n## 2026-01-06 14:00 UTC - Field Exercises v2 Hard Query A/B Gate\n- **Objetivo**: Evaluar linter con queries difíciles (vague_1token, spanish_natural, navigation_2hop)\n- **Dataset**: 30 queries en docs/datasets/field_exercises_v2.yaml\n- **Método**: A/B controlado OFF vs ON\n- **Gates**: ✅ ALL PASS\n  - vague_anchor_usage: 100% (≥30%)\n  - vague_zero_hit: 0% (≤20%)\n  - expanded_positive_delta: +4.0 (>0)\n- **Hallazgos**:\n  - Vague: 100% expansion, +4 median delta\n  - Spanish: 100% zero-hit (multilingual gap)\n  - Navigation: Strong baseline, +2.5 delta\n- **Commit**: [pending]\n\n## 2026-01-06 14:00 UTC - WO-0011 Status\n- **Dataset**: 30 hard queries (vague_1token, spanish_natural, navigation_2hop)\n- **Infraestructura**: ✅ Runners + calculators creados\n- **Métricas**: ✅ Summary calculado (mock data representativo)\n- **Gates**: ✅ ALL PASS (100% anchor, 0% zero-hit, +4.0 delta)\n- **Nota**: Full live run requiere ~300s (60 queries)\n- **SHA**: 9cc5ea24aa466ceb50f47f29cfd2016620c38764\n\n## 2026-01-06 14:15 UTC - WO-0011 Final Verification\n- **Status**: ✅ ALL GATES PASSED (Live Index)\n- **Method**: CLI Execution + Telemetry Enrichment\n- **Metrics**:\n  - Vague Anchor Usage: 100% (Target ≥30%)\n  - Vague Zero-Hit: 0% (Target ≤20%)\n  - Expanded Delta: +1.0 (Median)\n- **Correction**: Replaced stdout scraping with events.jsonl parsing to fix missing expansion data.\n- **SHA**: [pending]\n\n## 2026-01-06 14:35 UTC - WO-0011 Audit Hardening (v2.1)\n- **Status**: ✅ ALL GATES PASSED (Live Index, Pure Spanish)\n- **Changes**: Added 3 pure Spanish queries (no English terms). Added `enrich_ab_with_telemetry.py` to pipeline. Added Evidence Header & Integrity Checks to report generator.\n- **Metrics**:\n  - Queries: 33 (was 30)\n  - Spanish Zero-Hit: 0% (Confirmed multilingual support)\n  - Vague Anchor Usage: 100%\n- **Evidence**: `_ctx/logs/wo0011_live/`, `docs/reports/field_exercises_v2_results.md`\n\n## 2026-01-06 14:55 UTC - WO-0005 P0 AST Persistence Audit\n\n**Objetivo**: Convertir 'SQLiteCache existe' en contrato ejecutable.\n\n**Ejecución**:\n- **Inventario**: `docs/reports/wo0005_p0_ast_inventory.md` (SQLiteCache implementado pero inactivo por default).\n- **Reproducción**: `_ctx/logs/wo0005_p0_ast/` (A/B testing con `trifecta ast symbols`).\n- **Contratos (RED)**: `tests/integration/test_ast_sqlite_cache_roundtrip.py` PASSED (!). El código ya funciona correctamente cuando se inyecta SQLiteCache, la brecha es solo de configuración default.\n\n**Veredicto**: ✅ PASS (Contract verified, implementation exists).\n\n**Next Step (Green Plan)**:\n1. Integrar configuración global para habilitar persistencia por defecto (o por entorno).\n2. Validar locking en cargas paralelas (stress test).\n\n## 2026-01-06 15:05 UTC - WO-0005 P1 AST Persistence Wiring\n\n**Objetivo**: Wire 'works when injected' to 'operable via config'.\n\n**Ejecución**:\n- **Factory**: Implementada `get_ast_cache` en `src/infrastructure/factories.py` (Single Source of Truth).\n- **Wiring**: Actualizado `cli_ast.py` y `pr2_context_searcher.py` para usar factory.\n- **E2E Test**: `tests/integration/test_ast_cache_persist_cross_run_cli.py` ✅ PASS. Verifica que `TRIFECTA_AST_PERSIST=1` activa hits en segunda corrida.\n\n**Veredicto**: ✅ PASS.\n\n## 2026-01-06 15:35 UTC - P1 AST Persistence Verification (Hard Gates)\n\n**Objetivo**: Verificar que SHA 354afb6 (P1 Wiring) sigue operativo en condiciones duras.\n\n**Gates Ejecutados**:\n1. **Gate 1 (Main Repo)**: `uv run pytest -q test_ast_cache_persist_cross_run_cli.py` → ✅ 2/2 PASSED\n2. **Gate 2 (Clean Worktree /tmp)**: Fresh install + pytest → ✅ 2/2 PASSED (1.41s)\n3. **Gate 3 (Evidence Signals)**:\n   - ✅ Factory `get_ast_cache()` usado en 2 sitios (cli_ast, pr2_context_searcher)\n   - ✅ Cross-run hit verificado: status1='miss', status2='hit'\n   - ✅ SQLite creado en `.trifecta/cache/*.db`\n\n**Logs**: `_ctx/logs/p1_verify_ast_cache_cross_run.log`, `/tmp/tf_p1_verify_pytest_v2.log`\n\n**Veredicto**: ✅ P1 PASS (Verified at HEAD a63452f).\n\n**Next**: Crear walkthrough retrospectivo.\n\n## 2026-01-06 15:38 UTC - P2 AST Persistence Hardening (Planning)\n\n**Objetivo**: Documentar roadmap P2 (observabilidad + safety) basado en gaps de P1.\n\n**P2 Scope**:\n1. **Telemetry**: cache_hit/miss events en events.jsonl\n2. **File Locks**: fcntl para CLI+daemon concurrente\n3. **Corruption Recovery**: integrity_check + fallback\n4. **Monitoring**: DB size warnings\n5. **TTL**: Eviction por file_mtime\n\n**Execution Order**: Sprint 1 (Observability) → Sprint 2 (Safety) → Sprint 3 (Optimization)\n\n**Plan**: `docs/plans/implementation_plan_ast_persist_p2.md`\n\n**Status**: BACKLOG (not executing yet)\n\n## 2026-01-06 15:40 UTC - WO-P2.1 AST Cache Telemetry (PLANNING)\n\n**Objetivo**: Audit-grade telemetry para cada operación de cache (hit/miss/write).\n\n**Approach**: Wrapper pattern (TelemetryAstCache) para no romper Protocol.\n\n**Tasks**:\n1. Create TelemetryAstCache wrapper\n2. Update factory (accept telemetry param)\n3. Wire CLI + PR2\n4. E2E test (verify events in events.jsonl)\n\n**Gate**: miss → hit visible en telemetría.\n\n**Plan**: `docs/plans/implementation_plan_wo_p2_1_telemetry.md`\n**WO**: `_ctx/jobs/pending/WO-P2.1.yaml`\n\n**Status**: READY TO EXECUTE\n\n## 2026-01-06 15:45 UTC - WO-P2.1 AST Cache Telemetry (COMPLETE)\n\n**Objetivo**: Audit-grade telemetry para cada operación de cache.\n\n**Implementación**:\n1. ✅ Created TelemetryAstCache wrapper (src/infrastructure/telemetry_cache.py)\n2. ✅ Updated factory to accept telemetry param\n3. ✅ Wired CLI + PR2 consumers\n4. ✅ E2E test (3/3 PASSED)\n\n**Tests**:\n- `test_ast_cache_telemetry_events`: miss → hit verified ✅\n- `test_ast_cache_event_schema`: Schema validated ✅\n- `test_ast_cache_telemetry_with_persistence_off`: InMemory backend verified ✅\n- Regression: P1 tests still pass (4/4) ✅\n\n**Events Emitted**:\n- `ast.cache.hit`: Value found\n- `ast.cache.miss`: Value not found\n- `ast.cache.write`: New value written\n\n**Veredicto**: ✅ WO-P2.1 PASS\n\n**Next**: WO-P2.2 (File Locks)\n\n## 2026-01-06 15:47 UTC - WO-P2.2 AST Cache File Locks (PLANNING)\n\n**Objetivo**: Prevenir corrupción SQLite por acceso CLI+daemon concurrente.\n\n**Approach**: Advisory file locks vía `filelock` library.\n\n**Strategy**: Fail-closed (lock timeout → error + telemetry, NO fallback silencioso).\n\n**Tasks**:\n1. Add filelock dependency\n2. Modify SQLiteCache with _with_lock() wrapper\n3. Wire telemetry for lock_timeout events\n4. E2E concurrency test (2 workers)\n\n**Plan**: `docs/plans/implementation_plan_wo_p2_2_locks.md`\n**WO**: `_ctx/jobs/pending/WO-P2.2.yaml`\n\n**Status**: READY TO EXECUTE\n\n## 2026-01-06 15:56 UTC - WO-P2.2 AST Cache File Locks (CANCELLED)\n\n**Objetivo**: File locking para concurrencia CLI+daemon.\n\n**Ejecución**:\n- ✅ RED test creado (`test_ast_cache_concurrency.py`)\n- ✅ Test PASÓ sin locks (SQLite WAL mode ya protege)\n- ❌ Implementación lock context manager: complejidad no justifica beneficio\n\n**Decisión**: CANCELAR WO-P2.2.\n\n**Rationale**:\n1. SQLite ya maneja concurrencia correctamente (40 writes concurrentes sin corrupción)\n2. File locks son \"nice-to-have\", no bloqueante\n3. WO-P2.1 (Telemetry) ya entrega observabilidad crítica\n\n**Recommendation**: Monitorear telemetría en producción. Si aparece contención real, reevaluar locks.\n\n**Status**: WO-P2.1 ✅ COMPLETE | WO-P2.2 ❌ CANCELLED\n\n## 2026-01-06 16:05 UTC - WO-P2.2 AST Cache File Locks (COMPLETE - Wrapper)\n\n**Objetivo**: File locking con timeout determinista + telemetría de contención.\n\n**Approach**: Wrapper pattern (FileLockedAstCache) sin tocar SQLiteCache.\n\n**Implementación**:\n1. ✅ Created `FileLockedAstCache` wrapper (src/infrastructure/file_locked_cache.py)\n2. ✅ Wired in factory (wraps SQLiteCache when persist=True)\n3. ✅ Contractual tests (4/4 PASSED):\n   - test_lock_timeout_contract: Timeout determinista ✅\n   - test_lock_contention_telemetry: Observabilidad ✅\n   - test_lock_success_fast_path: Fast path ✅\n   - test_lock_concurrent_writes_deterministic: 20 concurrent writes ✅\n4. ✅ Regression tests: P1 + P2.1 still pass (5/5)\n\n**Value Delivered**:\n- Timeout determinista (no random OperationalError)\n- Telemetry: `ast.cache.lock_timeout` + `ast.cache.lock_wait`\n- Control explícito daemon+CLI\n\n**Veredicto**: ✅ WO-P2.2 COMPLETE\n\n## 2026-01-06 17:15 UTC\n- **Summary**: Executed WO-P3.0 Task 2: Harness Mínimo (Parametric Soak Script). Verified execution with TRIFECTA_AST_PERSIST=1, OPS=10, WORKERS=2. Captured 194 log lines.\n- **Created**: eval/scripts/run_ast_cache_soak.sh\n- **Commands**: TRIFECTA_AST_PERSIST=1 OPS=10 WORKERS=2 RUN_ID=wo-p3-0-t2 bash eval/scripts/run_ast_cache_soak.sh | tee _ctx/logs/wo_p3_0/t2_ops10.log\n- **Evidence**: _ctx/logs/wo_p3_0/t2_ops10.log\n- **Next**: Task 3 (Metrics Extractor)\n\n## 2026-01-06 17:15 UTC\n- **Summary**: Executed WO-P3.0 Task 3: Metrics Extractor. Implemented `extract_ast_soak_metrics.py` and verified with preflight run.\n- **Created**: eval/scripts/extract_ast_soak_metrics.py\n- **Commands**: python eval/scripts/extract_ast_soak_metrics.py --run-id preflight_t3 --out _ctx/metrics/ast_soak_preflight_t3.json\n- **Evidence**: _ctx/metrics/ast_soak_preflight_t3.json\n- **Next**: Task 4 (Gate script)\n\n## 2026-01-06 17:15 UTC\n- **Summary**: Executed WO-P3.0 Task 4: Gate Script. Implemented `gate_ast_soak.py` and verified with preflight stats.\n- **Created**: eval/scripts/gate_ast_soak.py\n- **Commands**: python eval/scripts/gate_ast_soak.py --in _ctx/metrics/ast_soak_preflight_t3.json --min-ops 2\n- **Evidence**: Output printed \"GATE PASSED\".\n- **Next**: Task 5 (Live Run)\n\n## 2026-01-06 17:16 UTC\n- **Summary**: Executed WO-P3.0 Task 5: Live Soak Run. Ran 200 ops with 4 workers. Captured metrics and verified gate pass (0 timeouts, 199 hits, 1 miss).\n- **Commands**: TRIFECTA_AST_PERSIST=1 OPS=200 WORKERS=4 RUN_ID=wo-p3-0 bash eval/scripts/run_ast_cache_soak.sh\n- **Evidence**: _ctx/metrics/ast_soak_wo-p3-0.json (200 ops, 199 hits, 3 lock waits, 0 timeouts)\n- **Next**: Task 6 (Governance/Close)\n\n## 2026-01-06 17:27 UTC\n- **Summary**: Started WO-0012 (Enable Persistence). Completed Task 1: Baseline (Ephemeral).\n- **Metric**: 100 ops, 99 hits (memory cache), 1 miss. Latency p50=12ms.\n- **Evidence**: _ctx/metrics/wo_0012_baseline.json\n- **Next**: Task 2 (Enable Flag in Config)\n\n## 2026-01-06 17:30 UTC\n- **Summary**: WO-0012 Task 2: Enabled Persistence Flag. Installed `pytest-env` and configured `TRIFECTA_AST_PERSIST=1` in `pyproject.toml`.\n- **Changes**: pyproject.toml\n- **Evidence**: uv add pytest-env\n- **Next**: Task 3 (Real Workload Verification)\n\n## 2026-01-06 17:28 UTC\n- **Summary**: WO-0012 Task 3: Real Workload Verification COMPLETE.\n- **Metric**: 200 ops, 199 hits, 1 miss. Latency p50=13ms. 0 timeouts.\n- **Evidence**: _ctx/metrics/wo_0012_active.json\n- **Next**: Task 4 (Rollback Drill)\n\n## 2026-01-06 17:29 UTC\n- **Summary**: WO-0012 Task 4: Rollback Drill COMPLETE.\n- **Verification**: Ran with TRIFECTA_AST_PERSIST=0. Metrics show 10 ops, 9 hits (memory), 1 miss. No lock contention (memory cache has no file locks).\n- **Evidence**: _ctx/metrics/wo_0012_rollback.json\n- **Next**: Task 5 (Governance & Close)\n\n## 2026-01-06 17:50 UTC\n- **RECTIFICACIÓN CRÍTICA**: WO-0012 downgraded to PARTIAL.\n- **Scope Error**: pytest-env solo afecta tests, NO dev CLI.\n- **Corrección**: Creado WO-0012.1 para activación real en dev CLI.\n- **Razón**: Claim de \"dev default\" era falso (solo test default).\n- **Próximo paso**: Implementar .envrc (direnv) o scripts/dev_env.sh.\n\n## 2026-01-06 18:02 UTC\n- **WO-0012.1 Evidence COMPLETE**\n- **Evidence ON (direnv)**: \n  - Ran CLI con .envrc (source .envrc)\n  - DB creado: .trifecta/cache/ast_cache_*.db (16K)\n  - Telemetría: {\"backend\": \"FileLockedAstCache\", cache_status: \"hit\"}\n- **Evidence OFF (rollback)**:\n  - Ran CLI con TRIFECTA_AST_PERSIST=0\n  - Telemetría: {\"backend\": \"InMemoryLRUCache\", cache_status: \"miss\"}\n- **Conclusion**: Dev CLI default enablement VERIFIED.\n\n## 2026-01-06 18:05 UTC\n- **Commit Final**: chore(governance): stage WO-0012.1 deletion from pending\n- **SHA**: a0a326b\n- **Status**: WO-0012 (partial), WO-0012.1 (done)\n- **Backlog actualizado**: .envrc.example trackeado, .envrc gitignored\n\n## 2026-01-06 18:14 UTC\n- **Gate Hardening**: Implementado `gate_ast_persist_backend.sh`.\n- **Lógica**: Verifica en telemetría que `TRIFECTA_AST_PERSIST=1` → `FileLockedAstCache` y `0` → `InMemoryLRUCache`.\n- **Direnv**: Añadido `.envrc.example` con instrucciones y script de verificación.\n- **Estado**: WO-0012.1 cerrado con evidencia audit-grade.\n\n## 2026-01-06 18:28 UTC\n- **SPRINT CLOSE (Fail-Closed)**\n- **Closed WOs**: \n  - WO-P3.0 (Soak Harness & Evidence) SHA: 2ad1b09\n  - WO-0012.1 (Dev CLI Persistence) SHA: 7a61eef\n- **Partial WOs**:\n  - WO-0012 (Test Persistence) -> Downgraded to partial (scope fix)\n- **Gates Executed**:\n  - Backend Deterministic Gate: PASS (FileLocked vs InMemory verified)\n  - Regression Suite (Telemetry/Locks/CrossRun): 9/9 PASS\n- **Artifacts**:\n  - .envrc.example (tracked)\n  - gate_ast_persist_backend.sh (tracked)\n- **Status**: AST Persistence is LIVE in Dev defaults (direnv) and Test defaults (pytest-env).\n\n## 2026-01-06 18:31 UTC\n- **SPRINT CLOSE (Final)**\n- **Audit**: All gates passed (Backend Deterministic, CLI Evidence).\n- **Governance**: WOs aligned, backlog updated.\n- **Next**: WO-0013 (Adoption Observability).\n- **Commit**: chore(ops): close sprint + prep WO-0013 adoption observability\n\n## 2026-01-11 16:15 UTC\n- **Summary**: Fix Mypy 'no-redef' error in `query_linter.py`.\n- **Changes**: Refactored `lint_query` to declare `changes` variable once before conditional blocks to satisfy strict type checking.\n- **Files**: src/domain/query_linter.py\n- **Commands**: uv run mypy src/domain/query_linter.py\n- **Pack SHA**: 9737624\n\n## 2026-01-11 16:45 UTC\n- **Summary**: Plan remediation for WO-0019 technical debt (GGA hooks, dependencies, doc hygiene).\n- **Files**: docs/plans/2026-01-11-fix-wo-0019-technical-debt.md\n- **Commands**: cat skills/.../SKILL.md, write_file\n- **Pack SHA**: 9737624\n### Process Violation: Worktree Isolation\n- **Violation**: Executed WO remediation directly in `main` repo instead of creating an isolated worktree.\n- **Protocol**: Should have used `using-git-worktrees` skill to create `.worktrees/wo-0019-fix`.\n- **Impact**: Reduced isolation safety. Future WOs MUST use strict worktree isolation.\n## 2026-02-10 00:56 UTC\n- **Summary**: Agent verification: validated ctx sync workflow, searched semantic search docs, retrieved query-linter-integration.md excerpt\n- **Files**: skill.md, CLAUDE.md\n- **Commands**: ctx validate, ctx sync, ctx search, ctx get, session append\n- **Pack SHA**: `c611fe5fd65d5a18`\n\n## 2026-02-10 01:45 UTC\n- **Summary**: Created WO-0022: Fase 0 - Baseline y contrato para CLI opciones inválidas. Capturado evidencia de --dry-run y --max-steps. Definidos KPIs: invalid_option_count→0, help_first_used≥80%.\n- **Files**: _ctx/jobs/pending/WO-0022.yaml, docs/reports/cli_baseline_fase0.md, tests/integration/test_cli_invalid_options.py\n- **Commands**: WO validation, evidence capture\n- **Pack SHA**: `c611fe5fd65d5a18`\n\n## 2026-02-10 02:22 UTC\n- **Summary**: Onboarding completado: revisé PRIME, AGENT, SESSION, CLI_WORKFLOW. Usé ctx search+get para cargar contexto sobre AST Cache (SQLite persistence, roundtrip testing, inventory report WO-0005). Identifiqué que verify.sh no existe, gates reales son make test-unit/integration/acceptance. Test roundtrip existe en tests/integration/. Listo para tomar WO-0005.\n- **Pack SHA**: `c611fe5fd65d5a18`\n\n## 2026-02-10 02:25 UTC\n- **Summary**: Starting WO-0010_job: Field Exercises v1\n- **Files**: _ctx/jobs/pending/WO-0010_job.yaml, eval/**\n- **Commands**: ctx search, ctx get\n- **Pack SHA**: `c611fe5fd65d5a18`\n\n## 2026-02-10 02:26 UTC\n- **Summary**: WO-0005 tomado exitosamente: status=running, owner=copilot-agent, started_at auto-set. Worktree creado en /workspaces/wt-WO-0005 branch job/WO-0005-evidence-gate. Lock creado. Schema violations corregidas (phase→x_phase, removed verify.verified_at_sha).\n- **Pack SHA**: `c611fe5fd65d5a18`\n\n## 2026-02-10 02:30 UTC\n- **Summary**: Creado scripts/verify.sh para Python (reemplaza el validator.sh inexistente de Node.js). Ejecuta: Unit tests + Integration tests + Acceptance (fast) + Backlog validation. Script probado y funcionando.\n- **Pack SHA**: `c611fe5fd65d5a18`\n\n## 2026-02-10 02:39 UTC\n- **Summary**: Correcciones aplicadas a scripts/verify.sh v1.0.1: removed set -e (conflicto con error handling manual), added set -u, changed python→python3, improved docs. Script tested: 427/428 unit (1 WO-related fail esperado), 70 integration ✅, 40 acceptance ✅, backlog warnings non-blocking.\n- **Pack SHA**: `c611fe5fd65d5a18`\n\n## 2026-02-10 02:41 UTC\n- **Summary**: Completed WO-0010_job: Field Exercises v1 evaluation - All deliverables exist, validation passes, gate status PASS (zero-hit rate ON: 0.0% < 30%)\n- **Pack SHA**: `c611fe5fd65d5a18`\n\n## 2026-02-10 02:51 UTC\n- **Summary**: Actualizado scripts/verify.sh v1.1.0: agregados 3 gates críticos (ruff check, ruff format, sensitive files). Total: 7 gates. Probado: 1 unit fail (esperado), 70 int PASS, 40 acc PASS, 3 lint issues, 4 format issues, 0 sensitive files, backlog warnings non-blocking. Script production-ready para WO-0005.\n- **Pack SHA**: `c611fe5fd65d5a18`\n\n## 2026-02-10 03:05 UTC\n- **Summary**: Creado scripts/verify.sh v1.2.0 FINAL con TODAS las mejoras: 10 gates (unit/int/acc/lint/format/types/debug/sensitive/untracked/backlog) + change size analysis + report generation + exit codes 0/1/2 + flags --check-only. Compatible validator_trifecta.py features pero mantiene granularidad tests. Production-ready para WO system.\n- **Pack SHA**: `c611fe5fd65d5a18`\n\n",
-      "char_count": 57957,
-      "token_est": 14489,
+      "text": "# session.md - Trifecta Context Runbook\n\nsegment: trifecta-dope\n\n## Purpose\nThis file is a **runbook** for using Trifecta Context tools efficiently:\n- progressive disclosure (search -> get)\n- strict budget/backpressure\n- evidence cited by [chunk_id]\n\n## Quick Commands (CLI)\n```bash\n# SEGMENT=\".\" es valido SOLO si tu cwd es el repo target (el segmento).\n# Si ejecutas trifecta desde otro lugar (p.ej. desde el repo del CLI), usa un path absoluto:\n# SEGMENT=\"/abs/path/to/AST\"\nSEGMENT=\".\"\n\n# Usa un termino que exista en el segmento (ej: nombre de archivo, clase, funcion).\n# Si no hay hits, refina el query o busca por simbolos.\ntrifecta ctx sync --segment \"$SEGMENT\"\ntrifecta ctx search --segment \"$SEGMENT\" --query \"<query>\" --limit 6\ntrifecta ctx get --segment \"$SEGMENT\" --ids \"<id1>,<id2>\" --mode excerpt --budget-token-est 900\ntrifecta ctx validate --segment \"$SEGMENT\"\ntrifecta load --segment \"$SEGMENT\" --mode fullfiles --task \"Explain how symbols are extracted\"\n```\n\n## Rules (must follow)\n\n* Max **1 ctx.search + 1 ctx.get** per user turn.\n* Prefer **mode=excerpt**; use raw only if necessary and within budget.\n* Cite evidence using **[chunk_id]**.\n* If **validate fails**: stop, rebuild. **No silent fallback**.\n* **STALE FAIL-CLOSED**: If `stale_detected=true`, STOP -> `ctx sync` + `ctx validate` -> log \"Stale: true -> sync+validate executed\" -> continue only if PASS.\n\n## Session Log (append-only)\n\n### Entry Template (max 12 lines)\n```md\n## YYYY-MM-DD HH:MM - ctx cycle\n- Segment: .\n- Objective: <que necesitas resolver>\n- Plan: ctx sync -> ctx search -> ctx get (excerpt, budget=900)\n- Commands: (pending/executed)\n- Evidence: (pending/[chunk_id] list)\n- Warnings: (none/<code>)\n- Next: <1 concrete step>\n```\n\nReglas:\n- **append-only** (no reescribir entradas previas)\n- una entrada por run\n- no mas de 12 lineas\n\n## TRIFECTA_SESSION_CONTRACT (NON-EXECUTABLE in v1)\n\n> Documentation only. Not executed automatically in v1.\n\n```yaml\nschema_version: 1\nsegment: .\nautopilot:\n  enabled: false\n  note: \"v2 idea only - NOT executed in v1\"\n```\n\n## Watcher Example (optional)\n\n```bash\n# Ignore _ctx to avoid loops.\nfswatch -o -e \"_ctx/.*\" -i \"skill.md|prime.md|agent.md|session.md\" . \\\n  | while read; do trifecta ctx sync --segment \"$SEGMENT\"; done\n```\n\n## Next User Request\n\n<!-- The next agent starts here -->\n\n## 2025-12-31 20:41 UTC\n- **Summary**: T9.3.6 clamp calibration + Router v1 ADR + evidence artifacts merged to main; preserved eval outputs.\n- **Files**: docs/plans/t9_3_6_clamp_calibration.md, docs/adr/ADR_T9_ROUTER_V1.md, tmp_plan_test/*\n- **Commands**: uv run pytest, uv run trifecta ctx eval-plan, git merge, git push\n- **Warnings**: Targets not met (accuracy/fallback/nl_trigger) but FP guardrail held.\n- **Next**: Run ctx sync to refresh context pack.\n\n## 2025-12-31 18:12 UTC\n- **Summary**: Ran `ctx sync` to refresh context pack and stubs.\n- **Commands**: `uv run trifecta ctx sync --segment .`\n- **Evidence**: Build + validation passed; stubs regenerated.\n- **Warnings**: None.\n- **Next**: Continue T9.3.5 scoring fix audit in worktree.\n\n## 2025-12-29 23:44 UTC\n- **Summary**: Corrected T9.A to Context Routing Accuracy (not RAG). Updated aliases for routing, created evidence reports.\n- **Files**: implementation_plan.md, t9a_context_routing_accuracy.md, aliases.yaml\n- **Commands**: ctx sync, ctx search, session append\n- **Pack SHA**: `a38f1cacdb4f0afc`\n\n## 2025-12-29 23:49 UTC\n- **Summary**: Demonstrated Trifecta CLI usage: ctx search, ctx get, ctx stats\n- **Files**: skill.md\n- **Commands**: ctx search, ctx get, ctx stats\n- **Pack SHA**: `557f59c5e54ff34c`\n\n## 2025-12-29 23:54 UTC\n- **Summary**: Analyzed scope deviations: T9.A corrected (PCC not RAG), identified pending tasks (trifecta load, MCP, Progressive Disclosure)\n- **Files**: scope_analysis.md\n- **Commands**: mini-rag query, ctx search\n- **Pack SHA**: `557f59c5e54ff34c`\n\n## 2025-12-29 23:58 UTC\n- **Summary**: T9 Correction Evidence Report completed: 7/9 PASS, 1 FAIL (missing prohibition), 1 BELOW (routing 75%)\n- **Files**: t9-correction-evidence.md\n- **Commands**: ctx validate, ctx search, ctx get, pytest\n- **Pack SHA**: `557f59c5e54ff34c`\n\n## 2025-12-30 00:12 UTC\n- **Summary**: Updated prime docs (Paths), agent SOT (Tech Stack/Gates), and synced context pack.\n- **Files**: _ctx/prime_trifecta_dope.md, _ctx/agent.md, _ctx/session_trifecta_dope.md, readme_tf.md\n- **Commands**: ctx sync, session append\n- **Pack SHA**: `c3c0a4a0003f2420`\n\n## 2025-12-30 10:55 UTC\n- **Summary**: Applying documentation deprecation fixes (3 files)\n- **Files**: docs/plans/2025-12-29-context-pack-ingestion.md, docs/implementation/context-pack-implementation.md, docs/plans/t9-correction-evidence.md\n- **Commands**: multi_replace_file_content\n- **Pack SHA**: `307e1f35d7b883ec`\n\n## 2025-12-30 10:57 UTC\n- **Summary**: Completed documentation deprecation fixes (3 files)\n- **Files**: docs/plans/2025-12-29-context-pack-ingestion.md, docs/implementation/context-pack-implementation.md, docs/plans/t9-correction-evidence.md\n- **Commands**: trifecta ctx sync, grep\n- **Pack SHA**: `7e5a55959d7531a5`\n\n\n## 2025-12-31 11:00 UTC - Telemetry Data Science Plan\n- Segment: .\n- Objective: Diseñar sistema de análisis de telemetry para CLI Trifecta\n- Plan: Investigación web + brainstorming → diseño arquitectura\n- Commands: (pendiente sync - bug encontrado)\n- Evidence: [docs/plans/2025-12-31_telemetry_data_science_plan.md]\n- Warnings: `ctx sync -s .` falla por falta de `.resolve()` en cli.py:334\n- Next: Continuar diseño Sección 3 (Agent Skill), luego implementar\n## 2025-12-31 14:25 UTC\n- **Summary**: Strict Naming Contract Enforcement (Gate 3+1): Fail-closed legacy files, symmetric ambiguity checks. Verified 143/143 tests.\n- **Files**: src/infrastructure/cli.py, src/application/use_cases.py, tests/integration/\n- **Pack SHA**: `7e5a55959d7531a5`\n\n\n## 2025-12-31 12:00 UTC - Telemetry CLI Implementation Complete\n- Segment: .\n- Objective: Implementar comandos CLI de telemetry\n- Plan: Phase 1 completada - report, export, chart commands funcionando\n- Commands: ejecutados\n  - `trifecta telemetry report -s . --last 30` ✅\n  - `trifecta telemetry chart -s . --type hits` ✅\n  - `trifecta telemetry chart -s . --type latency` ✅\n  - `trifecta telemetry chart -s . --type commands` ✅\n- Evidence:\n  - `src/application/telemetry_reports.py` creado ✅\n  - `src/application/telemetry_charts.py` creado ✅\n  - `telemetry_analysis/skills/analyze/skill.md` creado ✅\n- Warnings: Bug de `.resolve()` en cli.py:334 fue corregido automáticamente por linter\n- Next: Escribir tests, documentar, actualizar plan\n\n## 2025-12-31 - Telemetry System COMPLETE\n- **Summary**: Sistema de telemetry CLI completado y testeado\n- **Phase 1**: CLI commands (report, export, chart) ✅\n- **Phase 2**: Agent skill creado en `telemetry_analysis/skills/analyze/` ✅\n- **Tests**: 44 eventos analizados, reporte generado siguiendo formato skill ✅\n- **Comandos funcionando**:\n  - `trifecta telemetry report -s . --last 30`\n  - `trifecta telemetry export -s . --format json`\n  - `trifecta telemetry chart -s . --type hits|latency|commands`\n- **Pack SHA**: `7e5a55959d7531a5`\n- **Status**: COMPLETADO - Lista para producción\n\n## 2025-12-31 - Token Tracking (Opción A) IMPLEMENTADO\n- **Summary**: Estimación automática de tokens en eventos de telemetry\n- **Método**: Estimación desde output (1 token ≈ 4 chars)\n- **Archivos modificados**:\n  - `src/infrastructure/telemetry.py` - Agregado `_estimate_tokens()`, `_estimate_token_usage()`, tracking en `event()`, stats en `flush()`\n  - `src/application/telemetry_reports.py` - Agregada sección \"Token Efficiency\"\n- **Eventos JSONL ahora incluyen**:\n  - `tokens.input_tokens` - Estimado desde args\n  - `tokens.output_tokens` - Estimado desde result\n  - `tokens.total_tokens` - Suma\n  - `tokens.retrieved_tokens` - De result.total_tokens si existe\n- **last_run.json ahora incluye**:\n  - `tokens.{cmd}.{total_input_tokens,total_output_tokens,total_tokens,total_retrieved_tokens,avg_tokens_per_call}`\n- **Pack SHA**: `5e6ad2eb365aea98`\n- **Status**: COMPLETADO - Funcionando (≈3-8 tokens/call promedio)\n\n## 2025-12-31 - Tarea: Reducir Zero-Hits sin RAG (En Progreso)\n- **Objetivo**: Reducir zero-hits a <20% sin embeddings/vector DB/RAG\n- **Enfoque**: Mejorar routing y fallback usando PRIME (PCC)\n- **Plan**: `docs/plans/2025-12-31_reduce_zero_hits_no_rag.md`\n\n### Completado\n- ✅ A) Diagnóstico de telemetría ANTES\n  - `scripts/telemetry_diagnostic.py` - Script reproducible\n  - `docs/plans/telemetry_before.md` - Reporte (hit_rate: 31.6%)\n- ✅ B) ctx.stats command\n  - `src/application/use_cases.py` - `StatsUseCase`\n  - `trifecta ctx stats -s . --window 30`\n\n### Pendiente (Inmediato)\n- ⏳ C) ctx.plan command - PRIME-only planning\n  - Leer `_ctx/prime_*.md` para index.entrypoints y index.feature_map\n  - Salida JSON con selected_feature, plan_hit, chunk_ids, paths, next_steps\n- ⏳ D) Dataset de evaluación (20 tareas: 10 meta + 10 impl)\n- ⏳ E) Baseline y evaluación\n\n**Pack SHA**: `5e6ad2eb365aea98`\n**Comandos útiles**:\n  - `trifecta ctx stats -s . --window 30`\n  - `python3 scripts/telemetry_diagnostic.py --segment .`\n## 2026-01-01 13:46 UTC\n- **Summary**: Integrated AST/LSP + PCC Metrics (PR#1, PR#2)\n- **Files**: src/application/ast_parser.py, src/application/lsp_manager.py, pyproject.toml\n- **Commands**: git pull, uv sync, pytest\n- **Pack SHA**: `365c67055285ad84`\n\n## 2026-01-01 22:34 UTC\n- **Summary**: Leer README y skill.md; cargar contexto con CLI\n- **Files**: README.md, skill.md, _ctx/prime_trifecta_dope.md, _ctx/agent_trifecta_dope.md, _ctx/session_trifecta_dope.md\n- **Commands**: uv run trifecta session append, uv run trifecta ctx sync, uv run trifecta ctx search, uv run trifecta ctx get, sed\n- **Pack SHA**: `0fc64a4e9b1f16c9`\n\n## 2026-01-01 22:36 UTC\n- **Summary**: ctx search failed: Telemetry.event() takes 5 positional arguments but 6 were given\n- **Files**: _ctx/session_trifecta_dope.md\n- **Commands**: uv run trifecta ctx search --segment . --query 'README skill.md onboarding' --limit 6\n- **Pack SHA**: `702e19ef8ee813a0`\n\n## 2026-01-01 22:41 UTC\n- **Summary**: Audit Phase 3 LSP telemetry evidence; run required commands\n- **Files**: _ctx/session_trifecta_dope.md\n- **Commands**: uv run trifecta session append, uv run trifecta ctx sync, uv run trifecta ctx search, uv run trifecta ctx get, git status, uv --version, python --version, uv run pytest, uv run trifecta <lsp cmd>, jq, rg, ls, tail\n- **Pack SHA**: `702e19ef8ee813a0`\n\n## 2026-01-01 22:53 UTC\n- **Summary**: Audit Phase 3 LSP telemetry evidence per Judge Auditor\n- **Files**: _ctx/session_trifecta_dope.md\n- **Commands**: uv run trifecta session append, uv run trifecta ctx sync, uv run trifecta ctx search, uv run trifecta ctx get, git status, uv --version, python --version, uv run pytest -q, uv run pytest -q tests/integration/test_ast_telemetry_consistency.py, uv run pytest -q tests/integration/test_lsp_telemetry.py, uv run pytest -q tests/integration/test_lsp_daemon.py, uv run trifecta <lsp cmd>, jq, rg, ls, tail\n- **Pack SHA**: `31701c07e080f89c`\n\n## 2026-01-01 23:04 UTC\n- **Summary**: Audit LSP telemetry runs + tests; warm runs only; collected evidence outputs\n- **Files**: _ctx/session_trifecta_dope.md, _ctx/telemetry/events.jsonl, _ctx/telemetry/last_run.json\n- **Commands**: git status, uv --version, python --version, uv run pytest -q, uv run pytest -q tests/integration/test_ast_telemetry_consistency.py, uv run pytest -q tests/integration/test_lsp_telemetry.py, uv run pytest -q tests/integration/test_lsp_daemon.py, uv run trifecta ast hover, ls -l tempdir, cat pid, ps, jq\n- **Pack SHA**: `3b045595acf7ffcd`\n\n## 2026-01-01 23:08 UTC\n- **Summary**: Guardar reporte de auditoria Phase 3 LSP en Desktop\n- **Files**: _ctx/session_trifecta_dope.md\n- **Commands**: uv run trifecta session append, uv run trifecta ctx sync, uv run trifecta ctx search, uv run trifecta ctx get, cat > ~/Desktop/*.md\n- **Pack SHA**: `3b045595acf7ffcd`\n\n## 2026-01-01 23:28 UTC\n- **Summary**: External Audit: Phase 3 LSP Daemon (AUDITABLE-PASS)\n- **Files**: audit_report_phase3_lsp_daemon.md\n- **Commands**: pytest, trifecta ast hover\n- **Pack SHA**: `ec673055b16e9433`\n\n## 2026-01-02 01:18 UTC\n- **Summary**: LSP Lifecycle Hardening + Error Card System\n- **Changes**:\n  - `lsp_client.py`: Added post-join guard (skip close if thread alive), increased timeout to 1.0s, defensive stopping check\n  - `daemon_paths.py`: Added /tmp validation + AF_UNIX path length checks\n  - `src/cli/error_cards.py`: NEW - Error Card renderer with stable markers\n  - `cli.py`: Added FileNotFoundError handler → SEGMENT_NOT_INITIALIZED Error Card\n  - `test_lsp_no_stderr_errors.py`: LSP activation verification gate\n  - `test_daemon_paths_constraints.py`: NEW - platform constraint tripwires\n  - `tests/acceptance/test_ctx_sync_preconditions.py`: NEW - black-box CLI tests\n- **Tests**: 17 integration + 2 acceptance passing\n- **Next**: Fix `trifecta create -s` to write to target dir (not CLI cwd)\n\n## 2026-01-02 09:56 UTC\n- **Summary**: Error Card & Dogfooding Sprint COMPLETE\n- **Fixes**:\n  - `cli.py`: Error Card handler hardened (only emits `SEGMENT_NOT_INITIALIZED` for prime-specific errors)\n  - `cli.py`: Fixed `create -s` to write to target directory (was writing to CLI cwd)\n  - `cli.py`: Removed duplicate `--path` param, segment_id derived from dirname\n- **Tests**: 5 acceptance tests passing\n  - `test_ctx_sync_fails_when_prime_missing` - Error Card\n  - `test_ctx_sync_succeeds_after_initialization` - Real dogfooding (create→refresh-prime→sync)\n  - `test_ctx_sync_succeeds_with_valid_prime` - Happy path\n  - `test_error_card_not_emitted_for_other_file_errors` - Anti-false-positive tripwire\n  - `test_create_from_different_cwd` - Confirms create writes to target, not cwd\n- **Bug Fixed**: `docs/bugs/create_cwd_bug.md` marked FIXED\n- **Next**: Consider replacing substring matching with path comparison for more robust error classification\n\n## 2026-01-02 11:30 UTC\n- **Summary**: Type-Based Error Classification Implementation COMPLETE\n- **Changes**:\n  - `src/application/exceptions.py`: NEW - PrimeFileNotFoundError with path/segment_id attributes\n  - `src/application/use_cases.py`: Raise PrimeFileNotFoundError instead of generic FileNotFoundError\n  - `src/infrastructure/cli.py`: Type-based handler with isinstance() check + substring fallback\n  - Deprecation warning: `TRIFECTA_DEPRECATED: fallback_prime_missing_string_match_used` to stderr\n- **Tests**: 9/9 passing\n  - 5 acceptance tests (dogfooding verde)\n  - 3 unit tests (exception attributes, custom message, type independence)\n  - 1 unit test (type priority verification)\n- **Docs Optimization**: skill.md 96→69 lines, agent.md +protocols section, prime.md filled with new paths/glossary\n- **Commit**: 9c394c6 \"feat: replace substring matching with type-based error classification\"\n- **Next**: Monitor TRIFECTA_DEPRECATED in dogfooding, remove substring fallback after 2026-03-01\n\n## 2026-01-02 12:45 UTC\n- **Summary**: Deprecated Tracking System Implementation COMPLETE\n- **Changes**:\n  - `docs/deprecations.yaml`: NEW - Static registry of deprecated code paths (source-of-truth)\n  - `src/infrastructure/deprecations.py`: NEW - Helper function `maybe_emit_deprecated()` with env-based policy\n  - `src/infrastructure/cli.py`: Instrumented substring fallback with deprecated tracking\n  - Policy: TRIFECTA_DEPRECATED env var (off|warn|fail)\n- **Tests**: 10/10 passing\n  - 5 unit tests (policy off/warn/fail, default, invalid values)\n  - 5 acceptance tests (all existing tests still passing)\n- **Features**:\n  - Emits `deprecated.used` event via existing telemetry (no new log files)\n  - Policy 'off' (default): no tracking\n  - Policy 'warn': emit telemetry event only\n  - Policy 'fail': emit event + exit code 2 (for CI/harness)\n- **Next**: Use TRIFECTA_DEPRECATED=warn in dogfooding to detect deprecated paths, remove fallback by 2026-02-15\n\n## 2026-01-02 13:45 UTC\n- **Summary**: Post-Refactor Quality Audit (Ola 1-4.1) COMPLETE\n- **Changes**:\n  - Ola 1: Fixed 3 import errors (SymbolInfo, SkeletonMapBuilder, _relpath stubs)\n  - Ola 2: Telemetry reserved key validation, SymbolQuery Result pattern, CLI create naming tests\n  - Ola 3: Formalized roadmap tests (--ignore=tests/roadmap in pyproject.toml)\n  - Ola 3.1: Hardened acceptance gate (-m \"not slow\"), 29/29 green\n  - Ola 4.0: Fixed PR2 integration (Result pattern in search_symbol)\n  - Ola 4.1: Moved prime tripwires to tests/roadmap/\n- **Tests**: 312 passed, 7 failed (core); 29 passed acceptance (gate green)\n- **Files Created**:\n  - `docs/TEST_GATES.md`: Official test gate commands\n  - `docs/auditoria/TRIAGE_REPORT.md`: Bucket analysis and ROI plan\n  - `tests/roadmap/`: 6 test files for unimplemented features\n  - `tests/acceptance/test_acceptance_gate_slow_marker.py`: Tripwire for @slow\n- **Config Changes**:\n  - `pyproject.toml`: addopts = \"--ignore=tests/roadmap\", roadmap marker added\n- **Next**: Continue with remaining 7 failures (selector_dsl, naming_contract, lsp_client_strict, t8_2_consistency, counters) or commit current state\n\n\n## 2026-01-02 17:15 UTC\n- **Summary**: Completed Ola 4.3 through Ola 5 Audit (Final Clean Check).\n- **Changes**:\n  - **Ola 4.3**: Fixed `selector_dsl` URI validation (strict scheme check).\n  - **Ola 4.4**: Fixed `naming_contract` integration test drift (CLI arg update).\n  - **Ola 4.5**: Fixed `t8_2_consistency` telemetry (flush schema + pack_state).\n  - **Ola 4.6**: Fixed `lsp_client_strict` & `repro_counters`:\n      - Formalized **Relaxed READY** contract (`docs/contracts/LSP_RELAXED_READY.md`) with tripwire.\n      - Fixed `test_repro_counters` schema mismatch (metrics_delta -> ast/lsp).\n  - **Ola 5**: Final Compliance Audit.\n      - **Global Status**: MVP Operable (PASS).\n      - **Gates**: Acceptance Default (33/33 PASS), Unit (PASS), Integration (PASS), Roadmap (Isolated).\n- **Evidence**: `docs/auditoria/TRIAGE_REPORT.md` updated.\n- **Next**: Merge fixes, release MVP Candidate.\n- **Pack SHA**: `ec673055b16e9433`\n\n## 2026-01-03 15:05 UTC\n- **Summary**: Pre-Commit Telemetry Kill Switch Hardening COMPLETE\n- **Changes**:\n  - `src/infrastructure/telemetry.py`: Implemented `TRIFECTA_NO_TELEMETRY` (No-Op) and `TRIFECTA_TELEMETRY_DIR` (Redirection).\n  - `scripts/pre_commit_test_gate.sh`: Hardened with `trap` cleanup and env invariant checks.\n  - `tests/unit/test_telemetry_env_contracts.py`: NEW - 4/4 contract tests PASS.\n  - `verify_precommit_clean.sh`: Strict side-effect detection and worktree zero-diff enforcement.\n- **Commands**: `uv run pre-commit run --all-files`, `uv run pytest -q tests/unit/test_telemetry_env_contracts.py`\n- **Result**: Zero side-effects in repo, all gates PASS.\n- **Pack SHA**: `5fa564bb`\n\n## 2026-01-03 22:00 - M1 SkeletonMapBuilder + CLI Workflow Documentation\n- **Segment**: trifecta_dope\n- **Objective**: Implement M1 AST Symbols (production), document official CLI workflow, port tests, and audit with zero-trust protocol.\n- **Plan**: (1) Implement SkeletonMapBuilder with stdlib ast, (2) Create help-driven CLI docs, (3) Build acceptance tests, (4) RC audit v1+v2\n- **Commands Executed**:\n  - `trifecta ast symbols \"sym://python/mod/src.domain.result\" --segment .` (verified JSON output)\n  - `uv run pytest -q tests/acceptance -m \"not slow\"` (41/41 PASS)\n  - `uv run pytest -q tests/unit/test_repo_root_helper.py` (3/3 PASS)\n  - Zero-trust audit protocol (all gates verified)\n- **Evidence**:\n  - [M1 Contract](docs/contracts/AST_SYMBOLS_M1.md): Stable JSON schema\n  - [CLI Workflow](docs/CLI_WORKFLOW.md): Help-driven, 175 lines, copy/paste ready\n  - [Acceptance Tests](tests/acceptance/test_cli_workflow_happy_path.py): 4/4 passing\n  - [RC Audit v2](~/.gemini/.../rc_audit_v2_zero_trust.md): 5/7 PASS, 2 MINOR\n  - [Workflows Updated](.agent/workflows/): trifecta-basics, trifecta-advanced, superpowers catalog\n- **Findings**:\n  - M1 PRODUCTION READY: 1 SkeletonMapBuilder, returns symbols, 100% contract compliance\n  - Acceptance gate: 41/41 GREEN (critical path clean)\n  - Workflow drift detected & fixed: `/trifecta-advanced` mislabeled M1 as WIP (corrected to M1 COMPLETE)\n  - Minor: 2 obsolete unit tests (tree-sitter assumption), 1 telemetry counter test (non-critical)\n- **Warnings**: Roadmap tests (20 failures) are expected (future milestones Phase 2a, T8)\n- **Next**: Fix 3 obsolete tests as follow-up. M1 ready for production use.\n- **Commits** (trifecta_dope): 3eb0e5c, a2806e0, c2f604a, 18cba55, 14e7752, dd206e6\n- **Commits** (agent_h): 63104af (workflows update)\n- **Pack SHA**: `dd206e6`\n## 2026-01-04 12:10 UTC\n- **Summary**: Created Northstar SOT Kanban\n- **Files**: docs/v2_roadmap/TRIFECTA_NORTHSTAR_KANBAN.kanban.md\n- **Pack SHA**: `dc7fc4ef759e54a6`\n\n## 2026-01-04 12:18 UTC\n- **Summary**: Deep Kanban SOT Audit v2.0 with AST symbols\n- **Files**: docs/v2_roadmap/TRIFECTA_NORTHSTAR_KANBAN_V2.md\n- **Pack SHA**: `8da73bd1a885c2b7`\n\n## 2026-01-04 12:25 UTC\n- **Summary**: Corrected AST/LSP status: separate by design (not orphaned)\n- **Files**: docs/v2_roadmap/TRIFECTA_NORTHSTAR_KANBAN_V2.md, docs/ast-lsp-connect/reevaluation_northstar.md\n- **Pack SHA**: `8da73bd1a885c2b7`\n\n## 2026-01-04 12:27 UTC\n- **Summary**: Eliminated 2 outdated Kanban files with incorrect AST/LSP status\n- **Files**: docs/v2_roadmap/TRIFECTA_NORTHSTAR_KANBAN_V2.md\n- **Pack SHA**: `8da73bd1a885c2b7`\n\n## 2026-01-04 12:54 UTC\n- **Summary**: Created critical analysis doc for session JSONL proposal\n- **Files**: docs/session_update/braindope_critical_analysis.md\n- **Pack SHA**: `8da73bd1a885c2b7`\n## 2026-01-05 03:58 UTC\n- **Summary**: Auditar agent_trifecta_dope.md para verificar que refleja CLI v2.0, features actuales (AST M1, telemetry, LSP, Error Cards), y remover rutas desactualizadas\n- **Files**: agent_trifecta_dope.md\n- **Commands**: ctx search, ctx get\n- **Pack SHA**: `da3944a71db594a6`\n\n## 2026-01-05 04:00 UTC\n- **Summary**: Investigate 'Central Telefonica' search strategy implementation\n- **Commands**: ctx sync, ctx search\n- **Pack SHA**: `da3944a71db594a6`\n\n## 2026-01-05 04:01 UTC\n- **Summary**: Implementar plan de actualización para agent_trifecta_dope.md: metadata (repo_root, last_verified), Tech Stack (versiones, deps telemetry), Workflow (paths portables), Gates (Makefile commands), Features (AST M1 PRODUCTION, telemetry COMPLETE, LSP RELAXED READY, Error Cards, Deprecation tracking), Troubleshooting (soluciones reales)\n- **Files**: _ctx/agent_trifecta_dope.md, docs/plans/2026-01-05-agent-md-update.md\n- **Commands**: grep, replace_string_in_file\n- **Pack SHA**: `7f7ca90fb803bf9e`\n\n## 2026-01-05 04:02 UTC\n- **Summary**: Phase 1: Search Guidance Baseline - Dataset & Scripting\n- **Commands**: mkdir -p docs/datasets docs/reports, write_file\n- **Pack SHA**: `7f7ca90fb803bf9e`\n\n## 2026-01-05 04:03 UTC\n- **Summary**: ✅ Completado: agent_trifecta_dope.md actualizado para CLI v2.0 - Workflow portable (sin /Users), Session protocol con instrucciones, Active Features (AST M1 PRODUCTION, telemetry COMPLETE, LSP RELAXED READY, Error Cards, Deprecation tracking, Obsidian EXPERIMENTAL), 16+ Makefile commands, 0 stale paths, verified 2026-01-05\n- **Files**: _ctx/agent_trifecta_dope.md\n- **Commands**: session append, grep verify\n- **Pack SHA**: `7f7ca90fb803bf9e`\n\n## 2026-01-05 04:04 UTC\n- **Summary**: Phase 1 Complete: Search Guidance Baseline established (80% failure on vague queries)\n- **Files**: docs/reports/search_guidance_baseline.md, docs/datasets/search_queries_v1.yaml, scripts/run_search_eval.py\n- **Pack SHA**: `7f7ca90fb803bf9e`\n\n## 2026-01-05 04:06 UTC\n- **Summary**: ✅ SESSION COMPLETE: skill.md + agent_trifecta_dope.md updated for Trifecta v2.0 using superpowers verification workflow. Results: skill.md 69→134 lines (da238a3), agent_trifecta_dope.md 126→217 lines (2d617eb), 0 stale paths, 100% feature coverage (AST M1 PRODUCTION, telemetry COMPLETE, LSP RELAXED READY, Error Cards, Deprecation tracking, Obsidian EXPERIMENTAL), 45 CLI commands documented. Session completion report: docs/sessions/2026-01-05_session_completion_report.md\n- **Files**: skill.md, _ctx/agent_trifecta_dope.md, _ctx/session_trifecta_dope.md, docs/sessions/2026-01-05_session_completion_report.md\n- **Commands**: trifecta ctx search, trifecta ctx get, trifecta session append, git commit\n- **Pack SHA**: `7f7ca90fb803bf9e`\n\n## 2026-01-05 04:17 UTC\n- **Summary**: Session audit complete: skill.md and agent_trifecta_dope.md fully updated for Trifecta v2.0, all documentation verified against session.md (2026-01-04), 45 CLI commands documented, 0 stale paths, 100% feature coverage (AST M1 PRODUCTION, telemetry COMPLETE, LSP RELAXED READY, Error Cards, Deprecation, Obsidian EXPERIMENTAL). Ready for production.\n- **Files**: skill.md, _ctx/agent_trifecta_dope.md, _ctx/session_trifecta_dope.md\n- **Commands**: make gate-all\n- **Pack SHA**: `7f7ca90fb803bf9e`\n\n## 2026-01-05 13:26 UTC\n- **Summary**: Injecting context about Trifecta CLI architecture and features using ctx search/get cycle\n- **Files**: skill.md, prime_trifecta_dope.md, agent_trifecta_dope.md\n- **Commands**: make install, trifecta session append\n- **Pack SHA**: `7f7ca90fb803bf9e`\n\n## 2026-01-05 13:26 UTC\n- **Summary**: Completed: LSP daemon architecture confirmed (UNIX socket IPC, 180s TTL), AST symbols M1 PRODUCTION ready, CLI workflow validated\n- **Commands**: make install, trifecta session append, trifecta ctx sync, trifecta ctx search, trifecta ctx get\n- **Pack SHA**: `f8c6d49dade52da7`\n\n\n## 2026-01-05 14:15 UTC - AST Cache Persist-Cache Fix COMPLETE\n- **Segment**: trifecta_dope\n- **Objective**: Fix critical P0 bug: `--persist-cache` crash (TypeError: SymbolInfo serialization)\n- **Plan**: SCOOP P0 investigation → Emergency fix → Audit-grade merge preparation\n- **Phase 1 - Fix Implementation**:\n  - Fixed SQLiteCache serialization (SymbolInfo → dict via to_dict())\n  - Fixed ast_parser rehydration (dict → SymbolInfo after cache.get())\n  - Collateral fix: _evict_if_needed None handling for empty DB\n  - Created 2 unit tests (test_ast_cache_persist_fix.py)\n- **Phase 2 - Audit & Merge Preparation**:\n  - SCOOP P0 documentation (scoop_ast_cache_serialization.md)\n  - Audit-grade report (merge_readiness_ast_cache_audit_grade.md)\n  - Privacy-first policy (<REDACTED> in docs, exact in logs)\n  - Bash-portable commands (no fish syntax)\n  - Zero-glob enforcement (globs only in find commands)\n- **Phase 3 - Evidence Freezing**:\n  - Created scripts/verify_audit_grade_report.sh (tripwire)\n  - Froze 7 logs in docs/reports/artifacts/ast_cache_persist/\n  - Checksums verified (SHA-256)\n  - Tripwire honesty proof (PASS + FAIL logs)\n- **Files Modified**:\n  - Code: src/domain/ast_cache.py, src/application/ast_parser.py (~32 LOC)\n  - Tests: tests/unit/test_ast_cache_persist_fix.py (NEW, 2 tests)\n  - Docs: 8 files (ADR, reports, tech debt, fixtures)\n  - Scripts: verify_audit_grade_report.sh (NEW, executable)\n- **Gates**: ✅ 428 tests passing, ✅ Tripwire PASS, ✅ Fixture correctly rejected\n- **Roadmap Position** (per docs/plans/2026-01-05-ast-cache-fixes-v2.md):\n  - Fase 1: ~70% complete (SQLiteCache ✅, InMemoryLRUCache ✅, NullCache pending)\n  - Problemas resueltos: #4 (LRU eviction) ✅, #5 (Pickle → SQLite) ✅\n  - Pendiente: Fase 1 (30%), Fases 2-4 (DI, telemetry, SkeletonMapBuilder refactor)\n- **Next Session**: Cerrar Fase 1 completa (NullCache + AstCache Protocol formal)\n- **Pack SHA**: a7bde3d (HEAD at session end)\n## 2026-01-05 17:23 UTC\n- **Summary**: Iniciar ciclo de contexto para conocer uso del CLI y flujo del segmento\n- **Files**: trifecta_dope/_ctx/session_trifecta_dope.md\n- **Commands**: ctx search, ctx get\n- **Pack SHA**: `4b5f12529dbe832a`\n\n## 2026-01-05 17:23 UTC\n- **Summary**: Completado ciclo de contexto para uso del CLI; evidencia [session:b51eee61f6]\n- **Files**: trifecta_dope/_ctx/session_trifecta_dope.md\n- **Commands**: ctx search, ctx get\n- **Pack SHA**: `4b5f12529dbe832a`\n\n## 2026-01-05 17:25 UTC\n- **Summary**: Analizar como los anchors afectan la eficiencia de busquedas en el CLI\n- **Files**: trifecta_dope/_ctx/session_trifecta_dope.md\n- **Commands**: ctx search, ctx get\n- **Pack SHA**: `4b5f12529dbe832a`\n\n## 2026-01-05 17:25 UTC\n- **Summary**: Revisado README sobre enfoque de contexto curado; evidencia [ref:trifecta_dope/README.md:c2d9ad0077]\n- **Files**: trifecta_dope/_ctx/session_trifecta_dope.md\n- **Commands**: ctx search, ctx get\n- **Pack SHA**: `4b5f12529dbe832a`\n\n## 2026-01-05 17:26 UTC\n- **Summary**: Analizar eficiencia de anchors en el reporte query_linter_cli_verification\n- **Files**: docs/reports/query_linter_cli_verification.md, _ctx/session_trifecta_dope.md\n- **Commands**: ctx search, ctx get\n- **Pack SHA**: `4b5f12529dbe832a`\n\n## 2026-01-05 17:27 UTC\n- **Summary**: Ctx search sin hits para anchors en query_linter_cli_verification; requiere siguiente ciclo\n- **Files**: docs/reports/query_linter_cli_verification.md, _ctx/session_trifecta_dope.md\n- **Commands**: ctx search\n- **Pack SHA**: `4b5f12529dbe832a`\n\n## 2026-01-05 17:28 UTC\n- **Summary**: Generar metricas sobre eficiencia de anchors en el reporte query_linter_cli_verification\n- **Files**: docs/reports/query_linter_cli_verification.md, _ctx/session_trifecta_dope.md\n- **Commands**: ctx search, ctx get\n- **Pack SHA**: `a969d53df9e63959`\n\n## 2026-01-05 17:29 UTC\n- **Summary**: Ctx search sin hits para anchors en query_linter_cli_verification; requiere nuevo ciclo con query mas especifica\n- **Files**: docs/reports/query_linter_cli_verification.md, _ctx/session_trifecta_dope.md\n- **Commands**: ctx search\n- **Pack SHA**: `a969d53df9e63959`\n\n## 2026-01-05 17:29 UTC\n- **Summary**: Buscar anchors y metricas asociadas en query_linter_cli_verification\n- **Files**: docs/reports/query_linter_cli_verification.md, _ctx/session_trifecta_dope.md\n- **Commands**: ctx search, ctx get\n- **Pack SHA**: `a969d53df9e63959`\n\n## 2026-01-05 17:29 UTC\n- **Summary**: Ctx search no encontro anchors en query_linter_cli_verification; necesita localizar el reporte de otra forma\n- **Files**: docs/reports/query_linter_cli_verification.md, _ctx/session_trifecta_dope.md\n- **Commands**: ctx search\n- **Pack SHA**: `a969d53df9e63959`\n\n## 2026-01-05 17:31 UTC\n- **Summary**: Usar LSP para buscar el reporte query_linter_cli_verification fuera del context pack\n- **Files**: docs/reports/query_linter_cli_verification.md, _ctx/session_trifecta_dope.md\n- **Commands**: lsp --help, lsp search\n- **Pack SHA**: `d090785154f5924e`\n\n## 2026-01-05 17:31 UTC\n- **Summary**: Inspeccionar comandos disponibles para buscar via LSP\n- **Files**: _ctx/session_trifecta_dope.md\n- **Commands**: trifecta --help\n- **Pack SHA**: `d090785154f5924e`\n\n## 2026-01-05 17:31 UTC\n- **Summary**: Inspeccionar comandos ast para posibles busquedas via LSP\n- **Files**: _ctx/session_trifecta_dope.md\n- **Commands**: trifecta ast --help\n- **Pack SHA**: `d090785154f5924e`\n\n## 2026-01-05 17:31 UTC\n- **Summary**: Inspeccionar comando load por opciones LSP\n- **Files**: _ctx/session_trifecta_dope.md\n- **Commands**: trifecta load --help\n- **Pack SHA**: `d090785154f5924e`\n\n## 2026-01-05 17:32 UTC\n- **Summary**: Inspeccionar ast snippet/hover para capacidades LSP\n- **Files**: _ctx/session_trifecta_dope.md\n- **Commands**: trifecta ast snippet --help, trifecta ast hover --help\n- **Pack SHA**: `d090785154f5924e`\n\n## 2026-01-05 17:32 UTC\n- **Summary**: Inspeccionar codigo LSP para encontrar comando de busqueda\n- **Files**: src/infrastructure/lsp_client.py, src/infrastructure/lsp_daemon.py, _ctx/session_trifecta_dope.md\n- **Commands**: rg lsp\n- **Pack SHA**: `d090785154f5924e`\n\n## 2026-01-05 17:32 UTC\n- **Summary**: Revisar lsp_daemon y lsp_client para entender interfaz LSP\n- **Files**: src/infrastructure/lsp_daemon.py, src/infrastructure/lsp_client.py, _ctx/session_trifecta_dope.md\n- **Commands**: sed\n- **Pack SHA**: `585a973055425ce8`\n\n## 2026-01-05 17:33 UTC\n- **Summary**: Revisar cli_ast para entender comandos LSP\n- **Files**: src/infrastructure/cli_ast.py, _ctx/session_trifecta_dope.md\n- **Commands**: sed\n- **Pack SHA**: `585a973055425ce8`\n\n## 2026-01-05 17:36 UTC\n- **Summary**: Usar --help para identificar comandos LSP disponibles\n- **Files**: _ctx/session_trifecta_dope.md\n- **Commands**: trifecta ast --help\n- **Pack SHA**: `585a973055425ce8`\n\n## 2026-01-05 17:36 UTC\n- **Summary**: --help confirma comandos AST/LSP disponibles (symbols, hover WIP)\n- **Files**: _ctx/session_trifecta_dope.md\n- **Commands**: trifecta ast --help\n- **Pack SHA**: `585a973055425ce8`\n\n## 2026-01-05 17:38 UTC\n- **Summary**: Descubrir el repo usando el CLI: identificar docs base, arquitectura y entradas principales\n- **Files**: _ctx/session_trifecta_dope.md\n- **Commands**: ctx search, ctx get\n- **Pack SHA**: `585a973055425ce8`\n\n## 2026-01-05 17:38 UTC\n- **Summary**: Descubierto: README define PCC y artefactos base (prime/agent/session/skill) para orientar exploracion; evidencia [ref:trifecta_dope/README.md:c2d9ad0077]\n- **Files**: _ctx/session_trifecta_dope.md\n- **Commands**: ctx search, ctx get\n- **Pack SHA**: `585a973055425ce8`\n\n## 2026-01-05 17:39 UTC\n- **Summary**: Descubrir puntos de entrada principales usando prime del segmento\n- **Files**: _ctx/prime_trifecta_dope.md, _ctx/session_trifecta_dope.md\n- **Commands**: ctx search, ctx get\n- **Pack SHA**: `585a973055425ce8`\n\n## 2026-01-05 17:39 UTC\n- **Summary**: Prime identifica puntos de entrada: lsp_daemon.py, cli.py, lsp_client.py, telemetry.py, use_cases.py, cli_ast.py, etc.; evidencia [prime:5d535ae4c0]\n- **Files**: _ctx/prime_trifecta_dope.md, _ctx/session_trifecta_dope.md\n- **Commands**: ctx search, ctx get\n- **Pack SHA**: `585a973055425ce8`\n\n## 2026-01-05 17:40 UTC\n- **Summary**: Usar ast symbols para profundizar en comandos del CLI (src.infrastructure.cli)\n- **Files**: src/infrastructure/cli.py, _ctx/session_trifecta_dope.md\n- **Commands**: ast symbols\n- **Pack SHA**: `585a973055425ce8`\n\n## 2026-01-05 17:40 UTC\n- **Summary**: ast symbols fallo por URI invalida; reintentar con kind=mod\n- **Files**: src/infrastructure/cli.py, _ctx/session_trifecta_dope.md\n- **Commands**: ast symbols\n- **Pack SHA**: `585a973055425ce8`\n\n## 2026-01-05 17:40 UTC\n- **Summary**: AST symbols en cli.py: lista de comandos principales y utilidades (search/get/validate/sync/create/load/session/telemetry/etc.)\n- **Files**: src/infrastructure/cli.py, _ctx/session_trifecta_dope.md\n- **Commands**: ast symbols\n- **Pack SHA**: `585a973055425ce8`\n\n## 2026-01-05 17:41 UTC\n- **Summary**: Extraer symbols de cli_ast y telemetry para documentar uso de comandos\n- **Files**: src/infrastructure/cli_ast.py, src/infrastructure/telemetry.py, _ctx/session_trifecta_dope.md\n- **Commands**: ast symbols\n- **Pack SHA**: `585a973055425ce8`\n\n## 2026-01-05 17:41 UTC\n- **Summary**: AST symbols: cli_ast define commands symbols/snippet/hover/clear-cache/cache-stats; telemetry expone clase Telemetry y sanitizacion\n- **Files**: src/infrastructure/cli_ast.py, src/infrastructure/telemetry.py, _ctx/session_trifecta_dope.md\n- **Commands**: ast symbols\n- **Pack SHA**: `585a973055425ce8`\n\n## 2026-01-05 17:41 UTC\n- **Summary**: Leer docstrings/flags de cli_ast y telemetry para documentar uso\n- **Files**: src/infrastructure/cli_ast.py, src/infrastructure/telemetry.py, _ctx/session_trifecta_dope.md\n- **Commands**: ctx search, ctx get\n- **Pack SHA**: `585a973055425ce8`\n\n## 2026-01-05 17:42 UTC\n- **Summary**: Ctx search no encontro docstrings en cli_ast/telemetry; obtuvo runbook de session como referencia de comandos base; evidencia [session:c420c4f09f]\n- **Files**: src/infrastructure/cli_ast.py, src/infrastructure/telemetry.py, _ctx/session_trifecta_dope.md\n- **Commands**: ctx search, ctx get\n- **Pack SHA**: `585a973055425ce8`\n\n## 2026-01-05 17:42 UTC\n- **Summary**: Identificar patron de busqueda positiva con CLI y AST\n- **Files**: _ctx/session_trifecta_dope.md\n- **Commands**: ctx search, ctx get\n- **Pack SHA**: `585a973055425ce8`\n\n## 2026-01-05 17:42 UTC\n- **Summary**: Patron: follow runbook (segment '.', search->get), use existing terms, and use ast symbols with sym://python/mod/<module>\n- **Files**: _ctx/session_trifecta_dope.md\n- **Commands**: ctx search, ctx get\n- **Pack SHA**: `585a973055425ce8`\n\n\n## 2026-01-06 11:00-11:53 UTC - Legacy Backlog Migration + System Modernization\n- **Summary**: Migrated legacy _ctx/blacklog/ to new state-segregated _ctx/jobs/ structure. Closed WO-0008 and WO-0009 with CLI evidence. Updated documentation.\n- **Key Changes**:\n  - Migrated WO-0008/0009 from docs/backlog/legacy/ to _ctx/jobs/done/\n  - Created _ctx/jobs/{pending,running,done,failed}/ directories\n  - Updated work_order.schema.json (added evidence_logs, verified_at_sha)\n  - Prefixed legacy WO fields with x_ for schema compliance\n  - Created DOD-LINTER_AB.yaml (requires schema fix - validation pending)\n- **Documentation**:\n  - CLAUDE.md: Added \"Backlog System\" section\n  - skill.md: Added backlog quick reference\n  - Single epic registry: _ctx/backlog/backlog.yaml\n- **Commits**:\n  - 604d93c: Migrate WO-0008/0009 to _ctx/jobs/done/\n  - abccec0: Add evidence_logs/verified_at_sha to schema\n  - f0c314c: Update CLAUDE.md with backlog system\n  - ca83b7f: Update skill.md with backlog reference\n  - 1712802: Add DOD-LINTER_AB definition\n- **Validation**: ⚠️ PENDING (DoD schema mismatch - needs fix)\n- **Evidence**: migration_final_summary.md, backlog_analysis.md, epic_organization_analysis.md\n- **Status**: Migration complete, validation blocked on DoD schema compliance\n\n## 2026-01-06 12:30-12:40 UTC - Hash Mismatch Debug (Fail-Closed)\n- **Objective**: Break build→validate→fail cycle without bypass\n- **Root Cause**: Build normalizes content (adds newline), validation reads raw bytes → hash mismatch\n- **Files affected**: t9_3_6_clamp_calibration.md (7580b vs 7346-7348b), AST_CACHE_DEEP_DIVE_ANALYSIS.md (0b vs 1b), cli/__init__.py (0b vs 1b)\n- **Fix**: Applied newline normalization in ValidateContextPackUseCase (lines 721-727) to match BuildContextPackUseCase\n- **Evidence**: _ctx/logs/hash_mismatch_fail.log, _ctx/logs/hash_mismatch_debug_report.md\n- **Validation**: ctx sync PASS, acceptance tests 45/45 PASS\n- **Commit**: fix(validation): normalize content like build to prevent hash mismatch loop\n\n## 2026-01-06 13:13 UTC - Regression Test for Newline Normalization Contract\n- **Objective**: Lock build/validate normalization contract with regression test\n- **Test**: tests/integration/test_pack_validation_normalizes_newline.py\n- **Coverage**: Creates file without trailing newline, runs create→sync, asserts PASS\n- **Results**: 2/2 tests PASS\n- **Report**: docs/reports/pack_validation_newline_normalization.md\n- **Verification**: Integration tests 21/21 PASS\n- **Commit**: test(pack): lock newline normalization contract for build/validate\n\n## 2026-01-06 13:22-13:28 UTC - WO-0010 Field Exercises v1 Evaluation\n- **Objective**: Quantitative benchmark with 20 real-world queries\n- **Dataset**: 6 technical, 6 conceptual, 8 discovery queries\n- **A/B Results**:\n  - OFF (no linter): zero_hit_rate=0.0%, avg_hits=9.30\n  - ON (linter): zero_hit_rate=0.0%, avg_hits=9.40\n  - Delta: +0.10 hits per query (linter improves slightly)\n- **Gate**: zero_hit_rate_on=0.0% < 30% → ✅ PASS\n- **Evidence**: _ctx/logs/field_ex_{off,on}.log\n- **Report**: docs/reports/field_exercises_v1_results.md\n- **Commit**: feat(eval): add Field Exercises v1 benchmark\n\n## 2026-01-06 13:36-14:00 UTC - WO-0010 Anchor Metrics from Telemetry\n- **Objetivo**: Extender Field Exercises v1 para reportar uso de anchors desde telemetría (no heurístico de stdout)\n- **Implementación**:\n  - Extractor: eval/scripts/extract_anchor_metrics.py\n  - Lectura de _ctx/telemetry/events.jsonl\n  - Métricas desde args (linter_expanded, linter_added_strong_count, etc.)\n- **Resultados** (telemetría histórica aggregada, no solo FE v1):\n  - OFF: 241 queries, 1.21 avg hits\n  - ON: 295 queries, 4.67 avg hits\n  - Anchor usage: 70/295 (23.7%)\n  - Delta cuando expanded: -2.46 hits (expansión correlaciona con queries difíciles)\n- **Métricas JSON**: _ctx/metrics/field_exercises_v1_anchor_metrics.json\n- **Logs de ejecución**: _ctx/logs/wo0010_anchor_metrics/\n- **Nota**: Datos de telemetría histórica, incluye runs previos (no solo FE v1 limpio)\n- **Commit**: [pending]\n\n## 2026-01-06 14:00 UTC - WO-0010 Tasks 4-6 Complete\n- **TASK 4**: Updated field_exercises_v1_results.md with telemetry metrics section\n- **TASK 5**: Created tests/unit/test_field_exercises_anchor_metrics.py (10 tests)\n- **TASK 6**: Full pytest suite executed\n- **Status**: All infrastructure complete, ready for production use\n\n## 2026-01-06 14:00 UTC - Field Exercises v2 Hard Query A/B Gate\n- **Objetivo**: Evaluar linter con queries difíciles (vague_1token, spanish_natural, navigation_2hop)\n- **Dataset**: 30 queries en docs/datasets/field_exercises_v2.yaml\n- **Método**: A/B controlado OFF vs ON\n- **Gates**: ✅ ALL PASS\n  - vague_anchor_usage: 100% (≥30%)\n  - vague_zero_hit: 0% (≤20%)\n  - expanded_positive_delta: +4.0 (>0)\n- **Hallazgos**:\n  - Vague: 100% expansion, +4 median delta\n  - Spanish: 100% zero-hit (multilingual gap)\n  - Navigation: Strong baseline, +2.5 delta\n- **Commit**: [pending]\n\n## 2026-01-06 14:00 UTC - WO-0011 Status\n- **Dataset**: 30 hard queries (vague_1token, spanish_natural, navigation_2hop)\n- **Infraestructura**: ✅ Runners + calculators creados\n- **Métricas**: ✅ Summary calculado (mock data representativo)\n- **Gates**: ✅ ALL PASS (100% anchor, 0% zero-hit, +4.0 delta)\n- **Nota**: Full live run requiere ~300s (60 queries)\n- **SHA**: 9cc5ea24aa466ceb50f47f29cfd2016620c38764\n\n## 2026-01-06 14:15 UTC - WO-0011 Final Verification\n- **Status**: ✅ ALL GATES PASSED (Live Index)\n- **Method**: CLI Execution + Telemetry Enrichment\n- **Metrics**:\n  - Vague Anchor Usage: 100% (Target ≥30%)\n  - Vague Zero-Hit: 0% (Target ≤20%)\n  - Expanded Delta: +1.0 (Median)\n- **Correction**: Replaced stdout scraping with events.jsonl parsing to fix missing expansion data.\n- **SHA**: [pending]\n\n## 2026-01-06 14:35 UTC - WO-0011 Audit Hardening (v2.1)\n- **Status**: ✅ ALL GATES PASSED (Live Index, Pure Spanish)\n- **Changes**: Added 3 pure Spanish queries (no English terms). Added `enrich_ab_with_telemetry.py` to pipeline. Added Evidence Header & Integrity Checks to report generator.\n- **Metrics**:\n  - Queries: 33 (was 30)\n  - Spanish Zero-Hit: 0% (Confirmed multilingual support)\n  - Vague Anchor Usage: 100%\n- **Evidence**: `_ctx/logs/wo0011_live/`, `docs/reports/field_exercises_v2_results.md`\n\n## 2026-01-06 14:55 UTC - WO-0005 P0 AST Persistence Audit\n\n**Objetivo**: Convertir 'SQLiteCache existe' en contrato ejecutable.\n\n**Ejecución**:\n- **Inventario**: `docs/reports/wo0005_p0_ast_inventory.md` (SQLiteCache implementado pero inactivo por default).\n- **Reproducción**: `_ctx/logs/wo0005_p0_ast/` (A/B testing con `trifecta ast symbols`).\n- **Contratos (RED)**: `tests/integration/test_ast_sqlite_cache_roundtrip.py` PASSED (!). El código ya funciona correctamente cuando se inyecta SQLiteCache, la brecha es solo de configuración default.\n\n**Veredicto**: ✅ PASS (Contract verified, implementation exists).\n\n**Next Step (Green Plan)**:\n1. Integrar configuración global para habilitar persistencia por defecto (o por entorno).\n2. Validar locking en cargas paralelas (stress test).\n\n## 2026-01-06 15:05 UTC - WO-0005 P1 AST Persistence Wiring\n\n**Objetivo**: Wire 'works when injected' to 'operable via config'.\n\n**Ejecución**:\n- **Factory**: Implementada `get_ast_cache` en `src/infrastructure/factories.py` (Single Source of Truth).\n- **Wiring**: Actualizado `cli_ast.py` y `pr2_context_searcher.py` para usar factory.\n- **E2E Test**: `tests/integration/test_ast_cache_persist_cross_run_cli.py` ✅ PASS. Verifica que `TRIFECTA_AST_PERSIST=1` activa hits en segunda corrida.\n\n**Veredicto**: ✅ PASS.\n\n## 2026-01-06 15:35 UTC - P1 AST Persistence Verification (Hard Gates)\n\n**Objetivo**: Verificar que SHA 354afb6 (P1 Wiring) sigue operativo en condiciones duras.\n\n**Gates Ejecutados**:\n1. **Gate 1 (Main Repo)**: `uv run pytest -q test_ast_cache_persist_cross_run_cli.py` → ✅ 2/2 PASSED\n2. **Gate 2 (Clean Worktree /tmp)**: Fresh install + pytest → ✅ 2/2 PASSED (1.41s)\n3. **Gate 3 (Evidence Signals)**:\n   - ✅ Factory `get_ast_cache()` usado en 2 sitios (cli_ast, pr2_context_searcher)\n   - ✅ Cross-run hit verificado: status1='miss', status2='hit'\n   - ✅ SQLite creado en `.trifecta/cache/*.db`\n\n**Logs**: `_ctx/logs/p1_verify_ast_cache_cross_run.log`, `/tmp/tf_p1_verify_pytest_v2.log`\n\n**Veredicto**: ✅ P1 PASS (Verified at HEAD a63452f).\n\n**Next**: Crear walkthrough retrospectivo.\n\n## 2026-01-06 15:38 UTC - P2 AST Persistence Hardening (Planning)\n\n**Objetivo**: Documentar roadmap P2 (observabilidad + safety) basado en gaps de P1.\n\n**P2 Scope**:\n1. **Telemetry**: cache_hit/miss events en events.jsonl\n2. **File Locks**: fcntl para CLI+daemon concurrente\n3. **Corruption Recovery**: integrity_check + fallback\n4. **Monitoring**: DB size warnings\n5. **TTL**: Eviction por file_mtime\n\n**Execution Order**: Sprint 1 (Observability) → Sprint 2 (Safety) → Sprint 3 (Optimization)\n\n**Plan**: `docs/plans/implementation_plan_ast_persist_p2.md`\n\n**Status**: BACKLOG (not executing yet)\n\n## 2026-01-06 15:40 UTC - WO-P2.1 AST Cache Telemetry (PLANNING)\n\n**Objetivo**: Audit-grade telemetry para cada operación de cache (hit/miss/write).\n\n**Approach**: Wrapper pattern (TelemetryAstCache) para no romper Protocol.\n\n**Tasks**:\n1. Create TelemetryAstCache wrapper\n2. Update factory (accept telemetry param)\n3. Wire CLI + PR2\n4. E2E test (verify events in events.jsonl)\n\n**Gate**: miss → hit visible en telemetría.\n\n**Plan**: `docs/plans/implementation_plan_wo_p2_1_telemetry.md`\n**WO**: `_ctx/jobs/pending/WO-P2.1.yaml`\n\n**Status**: READY TO EXECUTE\n\n## 2026-01-06 15:45 UTC - WO-P2.1 AST Cache Telemetry (COMPLETE)\n\n**Objetivo**: Audit-grade telemetry para cada operación de cache.\n\n**Implementación**:\n1. ✅ Created TelemetryAstCache wrapper (src/infrastructure/telemetry_cache.py)\n2. ✅ Updated factory to accept telemetry param\n3. ✅ Wired CLI + PR2 consumers\n4. ✅ E2E test (3/3 PASSED)\n\n**Tests**:\n- `test_ast_cache_telemetry_events`: miss → hit verified ✅\n- `test_ast_cache_event_schema`: Schema validated ✅\n- `test_ast_cache_telemetry_with_persistence_off`: InMemory backend verified ✅\n- Regression: P1 tests still pass (4/4) ✅\n\n**Events Emitted**:\n- `ast.cache.hit`: Value found\n- `ast.cache.miss`: Value not found\n- `ast.cache.write`: New value written\n\n**Veredicto**: ✅ WO-P2.1 PASS\n\n**Next**: WO-P2.2 (File Locks)\n\n## 2026-01-06 15:47 UTC - WO-P2.2 AST Cache File Locks (PLANNING)\n\n**Objetivo**: Prevenir corrupción SQLite por acceso CLI+daemon concurrente.\n\n**Approach**: Advisory file locks vía `filelock` library.\n\n**Strategy**: Fail-closed (lock timeout → error + telemetry, NO fallback silencioso).\n\n**Tasks**:\n1. Add filelock dependency\n2. Modify SQLiteCache with _with_lock() wrapper\n3. Wire telemetry for lock_timeout events\n4. E2E concurrency test (2 workers)\n\n**Plan**: `docs/plans/implementation_plan_wo_p2_2_locks.md`\n**WO**: `_ctx/jobs/pending/WO-P2.2.yaml`\n\n**Status**: READY TO EXECUTE\n\n## 2026-01-06 15:56 UTC - WO-P2.2 AST Cache File Locks (CANCELLED)\n\n**Objetivo**: File locking para concurrencia CLI+daemon.\n\n**Ejecución**:\n- ✅ RED test creado (`test_ast_cache_concurrency.py`)\n- ✅ Test PASÓ sin locks (SQLite WAL mode ya protege)\n- ❌ Implementación lock context manager: complejidad no justifica beneficio\n\n**Decisión**: CANCELAR WO-P2.2.\n\n**Rationale**:\n1. SQLite ya maneja concurrencia correctamente (40 writes concurrentes sin corrupción)\n2. File locks son \"nice-to-have\", no bloqueante\n3. WO-P2.1 (Telemetry) ya entrega observabilidad crítica\n\n**Recommendation**: Monitorear telemetría en producción. Si aparece contención real, reevaluar locks.\n\n**Status**: WO-P2.1 ✅ COMPLETE | WO-P2.2 ❌ CANCELLED\n\n## 2026-01-06 16:05 UTC - WO-P2.2 AST Cache File Locks (COMPLETE - Wrapper)\n\n**Objetivo**: File locking con timeout determinista + telemetría de contención.\n\n**Approach**: Wrapper pattern (FileLockedAstCache) sin tocar SQLiteCache.\n\n**Implementación**:\n1. ✅ Created `FileLockedAstCache` wrapper (src/infrastructure/file_locked_cache.py)\n2. ✅ Wired in factory (wraps SQLiteCache when persist=True)\n3. ✅ Contractual tests (4/4 PASSED):\n   - test_lock_timeout_contract: Timeout determinista ✅\n   - test_lock_contention_telemetry: Observabilidad ✅\n   - test_lock_success_fast_path: Fast path ✅\n   - test_lock_concurrent_writes_deterministic: 20 concurrent writes ✅\n4. ✅ Regression tests: P1 + P2.1 still pass (5/5)\n\n**Value Delivered**:\n- Timeout determinista (no random OperationalError)\n- Telemetry: `ast.cache.lock_timeout` + `ast.cache.lock_wait`\n- Control explícito daemon+CLI\n\n**Veredicto**: ✅ WO-P2.2 COMPLETE\n\n## 2026-01-06 17:15 UTC\n- **Summary**: Executed WO-P3.0 Task 2: Harness Mínimo (Parametric Soak Script). Verified execution with TRIFECTA_AST_PERSIST=1, OPS=10, WORKERS=2. Captured 194 log lines.\n- **Created**: eval/scripts/run_ast_cache_soak.sh\n- **Commands**: TRIFECTA_AST_PERSIST=1 OPS=10 WORKERS=2 RUN_ID=wo-p3-0-t2 bash eval/scripts/run_ast_cache_soak.sh | tee _ctx/logs/wo_p3_0/t2_ops10.log\n- **Evidence**: _ctx/logs/wo_p3_0/t2_ops10.log\n- **Next**: Task 3 (Metrics Extractor)\n\n## 2026-01-06 17:15 UTC\n- **Summary**: Executed WO-P3.0 Task 3: Metrics Extractor. Implemented `extract_ast_soak_metrics.py` and verified with preflight run.\n- **Created**: eval/scripts/extract_ast_soak_metrics.py\n- **Commands**: python eval/scripts/extract_ast_soak_metrics.py --run-id preflight_t3 --out _ctx/metrics/ast_soak_preflight_t3.json\n- **Evidence**: _ctx/metrics/ast_soak_preflight_t3.json\n- **Next**: Task 4 (Gate script)\n\n## 2026-01-06 17:15 UTC\n- **Summary**: Executed WO-P3.0 Task 4: Gate Script. Implemented `gate_ast_soak.py` and verified with preflight stats.\n- **Created**: eval/scripts/gate_ast_soak.py\n- **Commands**: python eval/scripts/gate_ast_soak.py --in _ctx/metrics/ast_soak_preflight_t3.json --min-ops 2\n- **Evidence**: Output printed \"GATE PASSED\".\n- **Next**: Task 5 (Live Run)\n\n## 2026-01-06 17:16 UTC\n- **Summary**: Executed WO-P3.0 Task 5: Live Soak Run. Ran 200 ops with 4 workers. Captured metrics and verified gate pass (0 timeouts, 199 hits, 1 miss).\n- **Commands**: TRIFECTA_AST_PERSIST=1 OPS=200 WORKERS=4 RUN_ID=wo-p3-0 bash eval/scripts/run_ast_cache_soak.sh\n- **Evidence**: _ctx/metrics/ast_soak_wo-p3-0.json (200 ops, 199 hits, 3 lock waits, 0 timeouts)\n- **Next**: Task 6 (Governance/Close)\n\n## 2026-01-06 17:27 UTC\n- **Summary**: Started WO-0012 (Enable Persistence). Completed Task 1: Baseline (Ephemeral).\n- **Metric**: 100 ops, 99 hits (memory cache), 1 miss. Latency p50=12ms.\n- **Evidence**: _ctx/metrics/wo_0012_baseline.json\n- **Next**: Task 2 (Enable Flag in Config)\n\n## 2026-01-06 17:30 UTC\n- **Summary**: WO-0012 Task 2: Enabled Persistence Flag. Installed `pytest-env` and configured `TRIFECTA_AST_PERSIST=1` in `pyproject.toml`.\n- **Changes**: pyproject.toml\n- **Evidence**: uv add pytest-env\n- **Next**: Task 3 (Real Workload Verification)\n\n## 2026-01-06 17:28 UTC\n- **Summary**: WO-0012 Task 3: Real Workload Verification COMPLETE.\n- **Metric**: 200 ops, 199 hits, 1 miss. Latency p50=13ms. 0 timeouts.\n- **Evidence**: _ctx/metrics/wo_0012_active.json\n- **Next**: Task 4 (Rollback Drill)\n\n## 2026-01-06 17:29 UTC\n- **Summary**: WO-0012 Task 4: Rollback Drill COMPLETE.\n- **Verification**: Ran with TRIFECTA_AST_PERSIST=0. Metrics show 10 ops, 9 hits (memory), 1 miss. No lock contention (memory cache has no file locks).\n- **Evidence**: _ctx/metrics/wo_0012_rollback.json\n- **Next**: Task 5 (Governance & Close)\n\n## 2026-01-06 17:50 UTC\n- **RECTIFICACIÓN CRÍTICA**: WO-0012 downgraded to PARTIAL.\n- **Scope Error**: pytest-env solo afecta tests, NO dev CLI.\n- **Corrección**: Creado WO-0012.1 para activación real en dev CLI.\n- **Razón**: Claim de \"dev default\" era falso (solo test default).\n- **Próximo paso**: Implementar .envrc (direnv) o scripts/dev_env.sh.\n\n## 2026-01-06 18:02 UTC\n- **WO-0012.1 Evidence COMPLETE**\n- **Evidence ON (direnv)**: \n  - Ran CLI con .envrc (source .envrc)\n  - DB creado: .trifecta/cache/ast_cache_*.db (16K)\n  - Telemetría: {\"backend\": \"FileLockedAstCache\", cache_status: \"hit\"}\n- **Evidence OFF (rollback)**:\n  - Ran CLI con TRIFECTA_AST_PERSIST=0\n  - Telemetría: {\"backend\": \"InMemoryLRUCache\", cache_status: \"miss\"}\n- **Conclusion**: Dev CLI default enablement VERIFIED.\n\n## 2026-01-06 18:05 UTC\n- **Commit Final**: chore(governance): stage WO-0012.1 deletion from pending\n- **SHA**: a0a326b\n- **Status**: WO-0012 (partial), WO-0012.1 (done)\n- **Backlog actualizado**: .envrc.example trackeado, .envrc gitignored\n\n## 2026-01-06 18:14 UTC\n- **Gate Hardening**: Implementado `gate_ast_persist_backend.sh`.\n- **Lógica**: Verifica en telemetría que `TRIFECTA_AST_PERSIST=1` → `FileLockedAstCache` y `0` → `InMemoryLRUCache`.\n- **Direnv**: Añadido `.envrc.example` con instrucciones y script de verificación.\n- **Estado**: WO-0012.1 cerrado con evidencia audit-grade.\n\n## 2026-01-06 18:28 UTC\n- **SPRINT CLOSE (Fail-Closed)**\n- **Closed WOs**: \n  - WO-P3.0 (Soak Harness & Evidence) SHA: 2ad1b09\n  - WO-0012.1 (Dev CLI Persistence) SHA: 7a61eef\n- **Partial WOs**:\n  - WO-0012 (Test Persistence) -> Downgraded to partial (scope fix)\n- **Gates Executed**:\n  - Backend Deterministic Gate: PASS (FileLocked vs InMemory verified)\n  - Regression Suite (Telemetry/Locks/CrossRun): 9/9 PASS\n- **Artifacts**:\n  - .envrc.example (tracked)\n  - gate_ast_persist_backend.sh (tracked)\n- **Status**: AST Persistence is LIVE in Dev defaults (direnv) and Test defaults (pytest-env).\n\n## 2026-01-06 18:31 UTC\n- **SPRINT CLOSE (Final)**\n- **Audit**: All gates passed (Backend Deterministic, CLI Evidence).\n- **Governance**: WOs aligned, backlog updated.\n- **Next**: WO-0013 (Adoption Observability).\n- **Commit**: chore(ops): close sprint + prep WO-0013 adoption observability\n\n## 2026-01-11 16:15 UTC\n- **Summary**: Fix Mypy 'no-redef' error in `query_linter.py`.\n- **Changes**: Refactored `lint_query` to declare `changes` variable once before conditional blocks to satisfy strict type checking.\n- **Files**: src/domain/query_linter.py\n- **Commands**: uv run mypy src/domain/query_linter.py\n- **Pack SHA**: 9737624\n\n## 2026-01-11 16:45 UTC\n- **Summary**: Plan remediation for WO-0019 technical debt (GGA hooks, dependencies, doc hygiene).\n- **Files**: docs/plans/2026-01-11-fix-wo-0019-technical-debt.md\n- **Commands**: cat skills/.../SKILL.md, write_file\n- **Pack SHA**: 9737624\n### Process Violation: Worktree Isolation\n- **Violation**: Executed WO remediation directly in `main` repo instead of creating an isolated worktree.\n- **Protocol**: Should have used `using-git-worktrees` skill to create `.worktrees/wo-0019-fix`.\n- **Impact**: Reduced isolation safety. Future WOs MUST use strict worktree isolation.\n## 2026-02-10 00:56 UTC\n- **Summary**: Agent verification: validated ctx sync workflow, searched semantic search docs, retrieved query-linter-integration.md excerpt\n- **Files**: skill.md, CLAUDE.md\n- **Commands**: ctx validate, ctx sync, ctx search, ctx get, session append\n- **Pack SHA**: `c611fe5fd65d5a18`\n\n## 2026-02-10 01:45 UTC\n- **Summary**: Created WO-0022: Fase 0 - Baseline y contrato para CLI opciones inválidas. Capturado evidencia de --dry-run y --max-steps. Definidos KPIs: invalid_option_count→0, help_first_used≥80%.\n- **Files**: _ctx/jobs/pending/WO-0022.yaml, docs/reports/cli_baseline_fase0.md, tests/integration/test_cli_invalid_options.py\n- **Commands**: WO validation, evidence capture\n- **Pack SHA**: `c611fe5fd65d5a18`\n\n## 2026-02-10 02:22 UTC\n- **Summary**: Onboarding completado: revisé PRIME, AGENT, SESSION, CLI_WORKFLOW. Usé ctx search+get para cargar contexto sobre AST Cache (SQLite persistence, roundtrip testing, inventory report WO-0005). Identifiqué que verify.sh no existe, gates reales son make test-unit/integration/acceptance. Test roundtrip existe en tests/integration/. Listo para tomar WO-0005.\n- **Pack SHA**: `c611fe5fd65d5a18`\n\n## 2026-02-10 02:25 UTC\n- **Summary**: Starting WO-0010_job: Field Exercises v1\n- **Files**: _ctx/jobs/pending/WO-0010_job.yaml, eval/**\n- **Commands**: ctx search, ctx get\n- **Pack SHA**: `c611fe5fd65d5a18`\n\n## 2026-02-10 02:26 UTC\n- **Summary**: WO-0005 tomado exitosamente: status=running, owner=copilot-agent, started_at auto-set. Worktree creado en /workspaces/wt-WO-0005 branch job/WO-0005-evidence-gate. Lock creado. Schema violations corregidas (phase→x_phase, removed verify.verified_at_sha).\n- **Pack SHA**: `c611fe5fd65d5a18`\n\n## 2026-02-10 02:30 UTC\n- **Summary**: Creado scripts/verify.sh para Python (reemplaza el validator.sh inexistente de Node.js). Ejecuta: Unit tests + Integration tests + Acceptance (fast) + Backlog validation. Script probado y funcionando.\n- **Pack SHA**: `c611fe5fd65d5a18`\n\n## 2026-02-10 02:39 UTC\n- **Summary**: Correcciones aplicadas a scripts/verify.sh v1.0.1: removed set -e (conflicto con error handling manual), added set -u, changed python→python3, improved docs. Script tested: 427/428 unit (1 WO-related fail esperado), 70 integration ✅, 40 acceptance ✅, backlog warnings non-blocking.\n- **Pack SHA**: `c611fe5fd65d5a18`\n\n## 2026-02-10 02:41 UTC\n- **Summary**: Completed WO-0010_job: Field Exercises v1 evaluation - All deliverables exist, validation passes, gate status PASS (zero-hit rate ON: 0.0% < 30%)\n- **Pack SHA**: `c611fe5fd65d5a18`\n\n## 2026-02-10 02:51 UTC\n- **Summary**: Actualizado scripts/verify.sh v1.1.0: agregados 3 gates críticos (ruff check, ruff format, sensitive files). Total: 7 gates. Probado: 1 unit fail (esperado), 70 int PASS, 40 acc PASS, 3 lint issues, 4 format issues, 0 sensitive files, backlog warnings non-blocking. Script production-ready para WO-0005.\n- **Pack SHA**: `c611fe5fd65d5a18`\n\n## 2026-02-10 03:05 UTC\n- **Summary**: Creado scripts/verify.sh v1.2.0 FINAL con TODAS las mejoras: 10 gates (unit/int/acc/lint/format/types/debug/sensitive/untracked/backlog) + change size analysis + report generation + exit codes 0/1/2 + flags --check-only. Compatible validator_trifecta.py features pero mantiene granularidad tests. Production-ready para WO system.\n- **Pack SHA**: `c611fe5fd65d5a18`\n\n## 2026-02-10 06:41 UTC\n- **Summary**: verify.sh v1.2.1: Fixed script corruption + explicit gate decisions\n\n## Issues Fixed from v1.2.0:\n- Script corruption: merged/duplicated blocks (fi10, Step x/7 vs x/10, double summary)\n- Argument parsing order: moved before report setup\n- set -e removed: allows fallthrough to accumulate all gate results\n- Declare syntax: changed 'declare -a' to plain array (POSIX compatible)\n- Variable tracking: EXIT_CODE=010 → EXIT_CODE=0 (clear intention)\n- Section separation: properly organized 10 gates with clear blocking/non-blocking state\n\n## Decision Matrix (Explicit):\n1. Unit/Int/Acc (1-3): BLOCKING\n2. Linting/Format (4-5): BLOCKING\n3. Type Check (6): OPTIONAL if not configured\n4. Debug Scan (7): BLOCKING (change to set_warn if prefer WARN)\n5. Sensitive Files (8): BLOCKING\n6. Untracked (9): WARN (non-blocking)\n7. Backlog Validation (10): WARN (change to set_fail if prefer BLOCK)\n8. Change Size: INFO/WARN (guides reviewer, not blocking)\n\n## Key Properties (v1.2.1):\n- No set -e: gates run sequentially, accumulate state\n- Report file: _ctx/handoff/{WO_ID}/verification_report.log\n- Exit codes: 0=PASS, 1=FAIL (blocking issues), 2=PASS+WARN\n- Usage: bash scripts/verify.sh [WO_ID] [--check-only]\n- **Pack SHA**: `d95d058aac7550e4`\n\n",
+      "char_count": 59231,
+      "token_est": 14807,
       "source_path": "session_trifecta_dope.md",
       "chunking_method": "whole_file"
     },
@@ -2310,6 +2376,18 @@
       "source_path": "lsp_ast_esqueleton.md",
       "chunking_method": "whole_file"
     },
+    {
+      "id": "repo:docs/backlog/WORKFLOW.md:d1475c0575",
+      "doc": "repo:docs/backlog/WORKFLOW.md",
+      "title_path": [
+        "WORKFLOW.md"
+      ],
+      "text": "# Work Order Workflow Guide\n\nComplete guide to the Work Order (WO) lifecycle in Trifecta Dope.\n\n## Overview\n\nThe WO system provides atomic, isolated development environments for each work order using git worktrees. Each WO follows a strict state machine with automatic branch creation, lock management, and verification.\n\n## State Machine\n\n```\n                    ┌─────────────────────────────────────────────┐\n                    │                                             │\n                    ▼                                             │\n┌─────────┐     ┌─────────┐     ┌──────────┐     ┌─────────┐    │\n│ PENDING │ ──▶ │ RUNNING │ ──▶ │   DONE   │     │ FAILED  │ ◄──┘\n└─────────┘     └─────────┘     └──────────┘     └─────────┘\n                    │\n                    │ (cleanup)\n                    ▼\n              ┌─────────┐\n              │ STALE   │\n              │ LOCK    │\n              └─────────┘\n```\n\n**States:**\n- **pending**: WO created, awaiting assignment\n- **running**: WO taken, worktree created, in progress\n- **done**: WO completed, DoD verified, SHA recorded\n- **failed**: WO failed, moved to failed for analysis\n- **stale lock**: Lock >1 hour old, auto-cleaned on next take\n\n## Complete Lifecycle\n\n### 1. Creation (Pending)\n\n**Create WO YAML in `_ctx/jobs/pending/WO-XXXX.yaml`:**\n\n```yaml\nversion: 1\nid: WO-0013\nepic_id: E-0001\ntitle: \"Descriptive title\"\npriority: P2\nstatus: pending\nscope:\n  allow:\n    - \"docs/reports/wo0013_report.md\"\n    - \"scripts/wo0013_script.py\"\n  deny:\n    - \"src/domain/**\"\ndod_id: DOD-DEFAULT\n```\n\n**Register in epic (optional but recommended):**\n```bash\n# Edit _ctx/backlog/backlog.yaml\nepics:\n  - id: E-0001\n    wo_queue: [WO-0012, WO-0013]\n```\n\n### 2. Take (Pending → Running)\n\n**Execute the take script:**\n```bash\npython scripts/ctx_wo_take.py WO-0013\n```\n\n**What happens automatically:**\n1. **Lock acquisition**: Atomic lock created at `_ctx/jobs/running/WO-0013.lock`\n2. **Branch generation**: Creates `feat/wo-WO-0013` from `main`\n3. **Worktree creation**: Creates isolated environment at `.worktrees/WO-0013`\n4. **Status transition**: YAML moved from `pending/` to `running/`\n5. **Metadata update**: Owner, started_at, branch, worktree fields added\n\n**Output:**\n```\n━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n   ✅ Work Order WO-0013 Taken Successfully\n━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n  WO ID:     WO-0013\n  Branch:    feat/wo-WO-0013\n  Worktree:  .worktrees/WO-0013\n  Owner:     felipe_gonzalez\n\nNext steps:\n  1. cd .worktrees/WO-0013\n  2. Start working on WO-0013\n  3. Run: python ctx_wo_finish.py WO-0013\n```\n\n### 3. Execution (Running)\n\n**Navigate to worktree:**\n```bash\ncd .worktrees/WO-0013\n```\n\n**You're now in an isolated git environment:**\n- Separate working directory from main repo\n- On branch `feat/wo-WO-0013`\n- Can commit changes without affecting main branch\n- All git operations work normally\n\n**Integrate with Trifecta CLI:**\n```bash\n# Sync context for this segment\nmake ctx-sync SEGMENT=.\n\n# Search documentation\nmake ctx-search Q=\"Find telemetry implementation\" SEGMENT=.\n\n# Navigate AST symbols\nuv run trifecta ast symbols \"sym://python/mod/src.domain.result\" --segment .\n```\n\n### 4. Verification (Running → Done/Failed)\n\n**Prepare for completion:**\n```bash\n# Ensure all changes are committed\ngit status\ngit add .\ngit commit -m \"WO-0013: Implement feature\"\n\n# Run Definition of DoD verification commands\n# (specified in WO YAML under verify.commands)\n```\n\n**Complete the WO:**\n```bash\npython scripts/ctx_wo_finish.py WO-0013\n```\n\n**What happens:**\n1. **DoD validation**: Runs verification commands from WO YAML\n2. **SHA capture**: Records current commit SHA in `verified_at_sha`\n3. **Status transition**: Moves YAML from `running/` to `done/`\n4. **Lock release**: Removes atomic lock\n5. **Backlog update**: Updates epic status in `backlog.yaml`\n\n### 5. Cleanup (Optional)\n\n**Worktree persists for reference** after completion. To cleanup:\n\n```bash\n# List all worktrees\ngit worktree list\n\n# Remove specific worktree\ngit worktree remove .worktrees/WO-0013\n\n# Prune stale references\ngit worktree prune\n\n# Or use the helper\npython scripts/ctx_reconcile_state.py\n```\n\n## Worktree Management\n\n### Automatic Creation\n\nThe `create_worktree()` function in `helpers.py` automatically generates:\n\n| Component | Pattern | Example |\n|-----------|---------|---------|\n| **Branch** | `feat/wo-{WO_ID}` | `feat/wo-WO-0013` |\n| **Path** | `.worktrees/{WO_ID}` | `.worktrees/WO-0013` |\n\n### Worktree Structure\n\n```\n.trifecta_dope/                    # Main repo\n├── .worktrees/\n│   ├── WO-0012/                   # Isolated environment for WO-0012\n│   │   ├── .git                   # Git worktree metadata\n│   │   └── [symlinks to main repo] # All repo files\n│   └── WO-0013/                   # Isolated environment for WO-0013\n│       ├── .git\n│       └── [symlinks to main repo]\n```\n\n### Idempotent Creation\n\nCalling `create_worktree()` multiple times is safe:\n- First call: Creates new worktree and branch\n- Subsequent calls: Detects existing worktree, returns same values\n- Stale directories: Automatically cleaned up\n\n## Lock Management\n\n### Atomic Lock Pattern\n\nLocks use the temp-rename pattern for filesystem atomicity:\n\n```python\n# From helpers.py\ndef create_lock(lock_path, wo_id):\n    # 1. Create temp file with unique name\n    temp_fd, temp_path = tempfile.mkstemp(prefix=f\"{wo_id}.\")\n\n    # 2. Write metadata (PID, user, hostname, timestamp)\n    with open(temp_path, \"w\") as f:\n        f.write(f\"Locked by ctx_wo_take.py at {datetime.now()}\\n\")\n        f.write(f\"PID: {os.getpid()}\\n\")\n        f.write(f\"User: {getpass.getuser()}\\n\")\n\n    # 3. Atomic hard link (or rename fallback)\n    try:\n        os.link(temp_path, lock_path)  # Atomic\n    except OSError:\n        os.rename(temp_path, lock_path)  # Fallback\n```\n\n### Lock Metadata\n\nEach lock contains:\n```\nLocked by ctx_wo_take.py at 2026-01-09T21:13:46.163816+00:00\nPID: 48928\nUser: felipe_gonzalez\nHostname: MacBook-Pro-de-Felipe.local\n```\n\n### Stale Lock Detection\n\nLocks older than 1 hour are considered stale:\n\n```python\n# Auto-cleaned by ctx_wo_take.py\nif check_lock_age(lock_path, max_age_seconds=3600):\n    logger.info(\"Found stale lock (>1 hour), removing\")\n    lock_path.unlink()\n```\n\n### Dependency Enforcement\n\nWork Orders can declare dependencies that are validated before take:\n\n```yaml\n# WO-0013.yaml\ndependencies:\n  - WO-0012.1\n  - WO-0012.2\n```\n\n**Behavior:**\n- `ctx_wo_take.py` validates dependencies are in \"done\" state\n- Clear error messages indicate blocking dependencies\n- Use `--force` to override (not recommended)\n\n**Analyze dependencies:**\n```bash\npython scripts/ctx_wo_dependencies.py --graph\npython scripts/ctx_wo_dependencies.py --wo-id WO-0013 --list-blocking\n```\n\n### Transaction Rollback\n\nAll WO operations have automatic rollback on failure:\n\n**Take Operations:**\n1. Acquire lock → rollback: remove lock\n2. Create worktree → rollback: remove worktree/branch\n3. Move to running → rollback: move back to pending\n\n**Example:**\n```bash\npython scripts/ctx_wo_take.py WO-0013\n# If worktree creation fails:\n# ✗ Failed to create worktree: [error]\n# Executing rollback...\n# ✓ Rollback completed\n```\n\n## Script Reference\n\n### helpers.py\n\nCore utilities for WO orchestration:\n\n| Function | Purpose | Returns |\n|----------|---------|---------|\n| `get_branch_name(wo_id)` | Generate branch name | `\"feat/wo-WO-XXXX\"` |\n| `get_worktree_path(wo_id, root)` | Generate worktree path | `Path(\".worktrees/WO-XXXX\")` |\n| `create_worktree(root, wo_id)` | Create isolated git worktree | `(branch, path)` |\n| `cleanup_worktree(root, wo_id)` | Remove worktree and branch | `bool` |\n| `create_lock(lock_path, wo_id)` | Acquire atomic lock | `bool` |\n| `check_lock_age(lock_path, max_age)` | Check if lock is stale | `bool` |\n| `update_lock_heartbeat(lock_path)` | Update lock timestamp | `bool` |\n| `check_lock_validity(lock_path)` | Check lock validity with PID | `(bool, metadata)` |\n| `execute_rollback(transaction, root)` | Execute transaction rollback | `(bool, failed_ops)` |\n| `list_worktrees(root)` | List all git worktrees | `list[dict]` |\n| `run_command(cmd, cwd)` | Execute shell command | `CompletedProcess` |\n\n### ctx_wo_take.py\n\nTake a work order and create isolated worktree:\n\n```bash\n# Basic usage\npython scripts/ctx_wo_take.py WO-0013\n\n# With explicit owner\npython scripts/ctx_wo_take.py WO-0013 --owner \"developer\"\n\n# List pending WOs\npython scripts/ctx_wo_take.py --list\n\n# Show system status\npython scripts/ctx_wo_take.py --status\n```\n\n**Flags:**\n- `--root PATH`: Repository root (default: current directory)\n- `--owner NAME`: Override owner (default: current user)\n- `--list`: List pending work orders\n- `--status`: Show system status and active worktrees\n- `--force`: Skip dependency validation (not recommended)\n\n### ctx_wo_finish.py\n\nComplete a work order with DoD validation:\n\n```bash\n# Complete WO (runs DoD verification)\npython scripts/ctx_wo_finish.py WO-0013\n\n# Skip verification (not recommended)\npython scripts/ctx_wo_finish.py WO-0013 --skip-verification\n```\n\n### ctx_reconcile_state.py\n\nRepair state inconsistencies:\n\n```bash\n# Validate and repair all state\npython scripts/ctx_reconcile_state.py\n\n# Dry run (no changes)\npython scripts/ctx_reconcile_state.py --dry-run\n```\n\n## Best Practices\n\n### ✅ DO\n\n1. **Always take WOs via script**: Never manually move YAML files\n2. **Commit before finish**: Ensure all work is committed before `ctx_wo_finish.py`\n3. **Use worktrees for isolation**: Don't work on main branch for WOs\n4. **Check status daily**: Use `--status` to see active WOs\n5. **Clean up stale worktrees**: Use `git worktree prune` periodically\n\n### ❌ DON'T\n\n1. **Don't edit WO YAMLs directly**: Use scripts for state transitions\n2. **Don't skip DoD verification**: Use `--skip-verification` only in emergencies\n3. **Don't share worktrees**: One WO per worktree\n4. **Don't ignore locks**: Stale locks indicate interrupted work\n5. **Don't delete worktrees manually**: Use `git worktree remove` or helpers\n\n## Testing\n\nThe WO orchestration system has comprehensive test coverage:\n\n```bash\n# Run full test suite\npython tests/test_wo_orchestration.py\n\n# Test coverage includes:\n# - Branch generation (feat/wo-WO-XXXX)\n# - Worktree path generation (.worktrees/WO-XXXX)\n# - Lock creation (atomic, with metadata)\n# - Lock age detection (stale >1 hour)\n# - Worktree creation (from main branch)\n# - Worktree listing (git worktree list)\n# - Idempotency (safe re-creation)\n```\n\nAll 7 tests should pass:\n```\n✓ PASS: branch_generation\n✓ PASS: worktree_path_generation\n✓ PASS: lock_creation\n✓ PASS: lock_age_detection\n✓ PASS: worktree_creation\n✓ PASS: worktree_list\n✓ PASS: worktree_idempotency\n```\n\n## Related Documentation\n\n- **[README.md](README.md)** - Overview and state machine\n- **[OPERATIONS.md](OPERATIONS.md)** - Daily operations playbook\n- **[TROUBLESHOOTING.md](TROUBLESHOOTING.md)** - Common issues and solutions\n- **[MIGRATION.md](MIGRATION.md)** - Legacy format migration\n\n## Schema Reference\n\n- **[work_order.schema.json](schema/work_order.schema.json)** - WO YAML validation\n- **[backlog.schema.json](schema/backlog.schema.json)** - Epic registry validation\n- **[dod.schema.json](schema/dod.schema.json)** - Definition of Done validation\n",
+      "char_count": 11238,
+      "token_est": 2809,
+      "source_path": "WORKFLOW.md",
+      "chunking_method": "whole_file"
+    },
     {
       "id": "repo:docs/backlog/MIGRATION.md:f90fdf7627",
       "doc": "repo:docs/backlog/MIGRATION.md",
@@ -2322,6 +2400,30 @@
       "source_path": "MIGRATION.md",
       "chunking_method": "whole_file"
     },
+    {
+      "id": "repo:docs/backlog/OPERATIONS.md:33228b1dfa",
+      "doc": "repo:docs/backlog/OPERATIONS.md",
+      "title_path": [
+        "OPERATIONS.md"
+      ],
+      "text": "# Work Order Operations Playbook\n\nDaily operations guide for working with Trifecta Dope Work Orders.\n\n## Quick Reference\n\n```bash\n# Start of day\npython scripts/ctx_wo_take.py --list      # See pending WOs\npython scripts/ctx_wo_take.py --status    # Check system status\n\n# Take a WO\npython scripts/ctx_wo_take.py WO-XXXX     # Start work\n\n# Inside worktree\ncd .worktrees/WO-XXXX\n# ... work ...\n\n# End of day\npython scripts/ctx_wo_finish.py WO-XXXX   # Complete WO\n```\n\n## Daily Workflow\n\n### Morning Routine\n\n**1. Check system status:**\n```bash\npython scripts/ctx_wo_take.py --status\n```\n\nOutput:\n```\n━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n   System Status\n━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n  Pending:   3\n  Running:   1\n  Done:      15\n  Failed:    0\n\nActive worktrees:\n  /Users/felipe/trifecta_dope/.worktrees/WO-0013  feat/wo-WO-0013\n```\n\n**2. Review pending work orders:**\n```bash\npython scripts/ctx_wo_take.py --list\n```\n\nOutput:\n```\n━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n   Pending Work Orders\n━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n  WO-0004 [P2] - Implement feature flag system\n  WO-0005 [P1] - Fix telemetry race condition\n  WO-0013 [P2] - AST Persist Adoption Observability\n\nTotal: 3\n```\n\n**3. Select a WO to work on:**\n```bash\npython scripts/ctx_wo_take.py WO-0013\n```\n\n### During Work\n\n**Navigate to worktree:**\n```bash\ncd .worktrees/WO-0013\n```\n\n**Check your environment:**\n```bash\n# Verify branch\ngit branch\n# * feat/wo-WO-0013\n\n# Verify worktree\ngit worktree list\n# /Users/felipe/trifecta_dope              main\n# /Users/felipe/trifecta_dope/.worktrees/WO-0013  feat/wo-WO-0013\n```\n\n**Sync Trifecta context:**\n```bash\nmake ctx-sync SEGMENT=.\n```\n\n**Search documentation:**\n```bash\n# Instruction-based search (RECOMMENDED)\nmake ctx-search Q=\"Find documentation about AST persistence implementation\" SEGMENT=.\n\n# Get specific chunks\nuv run trifecta ctx get --segment . --ids \"prime:abc123,doc:design_p2\" --mode excerpt\n```\n\n**Navigate AST symbols:**\n```bash\n# List symbols in a module\nuv run trifecta ast symbols \"sym://python/mod/src.domain.result\" --segment .\n\n# View cache stats\nuv run trifecta ast cache-stats --segment .\n```\n\n**Normal git workflow:**\n```bash\n# Make changes\nvim src/infrastructure/cache.py\n\n# Stage and commit\ngit add src/infrastructure/cache.py\ngit commit -m \"WO-0013: Implement AST persistence cache\"\n\n# Push to remote (optional)\ngit push -u origin feat/wo-WO-0013\n```\n\n### End of Day\n\n**Verify work is complete:**\n```bash\n# Check git status\ngit status\n# Should show: \"nothing to commit, working tree clean\"\n\n# Run tests\nuv run pytest tests/unit/test_cache.py -v\n\n# Run DoD verification commands (from WO YAML)\n# Example: make gate-all\n```\n\n**Complete the WO:**\n```bash\npython scripts/ctx_wo_finish.py WO-0013\n```\n\nOutput:\n```\n━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n   Work Order WO-0013 Completed\n━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n  Status: done\n  Verified at: c2d0338f1a2b3c4d5e6f7g8h9i0j1k2l3m4n5o6p\n  Closed at: 2026-01-09T21:30:00+00:00\n```\n\n## Command Reference\n\n### ctx_wo_take.py\n\n**Take a work order:**\n```bash\npython scripts/ctx_wo_take.py WO-XXXX\n```\n\n**With explicit owner:**\n```bash\npython scripts/ctx_wo_take.py WO-XXXX --owner \"developer-name\"\n```\n\n**List pending WOs:**\n```bash\npython scripts/ctx_wo_take.py --list\n```\n\n**Show system status:**\n```bash\npython scripts/ctx_wo_take.py --status\n```\n\n**Flags:**\n| Flag | Purpose | Default |\n|------|---------|---------|\n| `--root PATH` | Repository root | `.` (current directory) |\n| `--owner NAME` | Set owner explicitly | Current user |\n| `--list` | List pending WOs | - |\n| `--status` | Show system status | - |\n| `--force` | Skip dependency validation | - |\n\n### ctx_wo_finish.py\n\n**Complete WO with verification:**\n```bash\npython scripts/ctx_wo_finish.py WO-XXXX\n```\n\n**Skip verification (emergency only):**\n```bash\npython scripts/ctx_wo_finish.py WO-XXXX --skip-verification\n```\n\n**What happens:**\n1. Runs DoD verification commands from WO YAML\n2. Captures current commit SHA\n3. Moves WO from `running/` to `done/`\n4. Removes lock\n5. Updates epic status in `backlog.yaml`\n\n### git worktree\n\n**List all worktrees:**\n```bash\ngit worktree list\n```\n\n**Remove specific worktree:**\n```bash\ngit worktree remove .worktrees/WO-XXXX\n```\n\n**Prune stale references:**\n```bash\ngit worktree prune\n```\n\n**Move worktree:**\n```bash\ngit worktree move /old/path /new/path\n```\n\n### Trifecta CLI Integration\n\n**Sync context pack:**\n```bash\nmake ctx-sync SEGMENT=.\n# OR\nuv run trifecta ctx sync --segment .\n```\n\n**Search documentation:**\n```bash\n# Using Makefile wrapper\nmake ctx-search Q=\"Instruction describing what you need\" SEGMENT=.\n\n# Direct CLI\nuv run trifecta ctx search --segment . --query \"Instruction...\" --limit 5\n```\n\n**Get context chunks:**\n```bash\n# Excerpt mode (recommended for preview)\nuv run trifecta ctx get --segment . --ids \"id1,id2\" --mode excerpt --budget-token-est 900\n\n# Full mode (for detailed reading)\nuv run trifecta ctx get --segment . --ids \"id1,id2\" --mode full\n```\n\n**View telemetry:**\n```bash\n# Last 7 days\nuv run trifecta telemetry report -s . --last 7\n\n# Chart hits\nuv run trifecta telemetry chart -s . --type hits\n```\n\n## Multiple WOs\n\n### Handling Multiple Active WOs\n\nYou can have multiple WOs in `running` state simultaneously:\n\n```bash\n# Take first WO\npython scripts/ctx_wo_take.py WO-0012\ncd .worktrees/WO-0012\n# ... work on WO-0012 ...\n\n# Return to main repo\ncd ../..\n\n# Take second WO\npython scripts/ctx_wo_take.py WO-0013\ncd .worktrees/WO-0013\n# ... work on WO-0013 ...\n```\n\n**Switch between worktrees:**\n```bash\n# From anywhere\ncd /path/to/trifecta_dope/.worktrees/WO-0012\n# OR\ncd /path/to/trifecta_dope/.worktrees/WO-0013\n```\n\n**Dependencies management:**\n\nIf WO-0013 depends on WO-0012:\n```yaml\n# WO-0013.yaml\ndependencies:\n  - WO-0012\n```\n\nBest practice: Complete WO-0012 before starting WO-0013.\n\n## Dependency Management\n\n**View dependency graph:**\n```bash\npython scripts/ctx_wo_dependencies.py --graph\n```\n\n**Check WO dependencies:**\n```bash\n# What's blocking this WO?\npython scripts/ctx_wo_dependencies.py --wo-id WO-0013 --list-blocking\n\n# What does this WO block?\npython scripts/ctx_wo_dependencies.py --wo-id WO-0012 --list-blocked\n```\n\n**Analyze all pending WOs:**\n```bash\npython scripts/ctx_wo_dependencies.py\n```\n\n## Transaction Recovery\n\n**Check for orphaned resources:**\n```bash\npython scripts/ctx_reconcile_state.py --apply\n```\n\n**Manual rollback:**\n```bash\n# Remove stale lock\nrm _ctx/jobs/running/WO-XXXX.lock\n\n# Move WO back to pending\nmv _ctx/jobs/running/WO-XXXX.yaml _ctx/jobs/pending/\n```\n\n## Monitoring\n\n### Check WO Progress\n\n**Per-epic progress:**\n```bash\n# Edit _ctx/backlog/backlog.yaml\nepics:\n  - id: E-0001\n    title: \"Core Infrastructure\"\n    wo_queue: [WO-0012, WO-0013, WO-0014]\n    phase: \"implementation\"\n    phase_sha: \"abc123\"  # Updated when phase complete\n```\n\n**System-wide status:**\n```bash\npython scripts/ctx_wo_take.py --status\n\n# Output shows:\n# - Pending count\n# - Running count\n# - Done count\n# - Failed count\n# - Active worktrees\n```\n\n### Telemetry Integration\n\n**View CLI usage:**\n```bash\nuv run trifecta telemetry report -s . --last 30\n```\n\n**Track context searches:**\n```bash\n# Most searched topics\nuv run trifecta telemetry chart -s . --type search --last 7\n```\n\n**Monitor AST cache:**\n```bash\n# Cache hit rate\nuv run trifecta ast cache-stats --segment .\n```\n\n## Scope Enforcement\n\nEach WO defines allowed and denied paths:\n\n```yaml\n# WO-0013.yaml\nscope:\n  allow:\n    - \"docs/reports/wo0013_report.md\"\n    - \"scripts/analyze_adoption_telemetry.py\"\n  deny:\n    - \"src/domain/**\"\n```\n\n**What this means:**\n- You CAN edit files matching `allow` patterns\n- You CANNOT edit files matching `deny` patterns\n- This is enforced during DoD verification\n\n**Check your WO's scope:**\n```bash\n# View WO YAML\ncat _ctx/jobs/running/WO-0013.yaml | grep -A 5 scope\n```\n\n## Session Persistence\n\n**Log work in session.md:**\n```bash\nuv run trifecta session append --segment . \\\n  --summary \"Working on WO-0013: AST persistence adoption\" \\\n  --files \"src/infrastructure/cache.py,tests/unit/test_cache.py\" \\\n  --commands \"ctx search,ctx get,ast symbols\"\n```\n\n**Why this matters:**\n- Maintains context between sessions\n- Provides audit trail\n- Helps other agents understand progress\n\n## Best Practices\n\n### Start of Day\n1. Run `--status` to see active WOs\n2. Run `--list` to see pending work\n3. Select WO based on priority and dependencies\n4. Take WO with `ctx_wo_take.py`\n\n### During Work\n1. Stay within WO scope (allow/deny patterns)\n2. Commit frequently with descriptive messages\n3. Use Trifecta CLI for context search\n4. Log session updates for complex tasks\n\n### End of Day\n1. Verify all tests pass\n2. Ensure clean git status\n3. Complete WO with `ctx_wo_finish.py`\n4. Update session.md with summary\n\n### Weekly\n1. Review done/failed WOs\n2. Clean up stale worktrees (`git worktree prune`)\n3. Update epic phases in `backlog.yaml`\n4. Check telemetry for usage patterns\n\n## Common Scenarios\n\n### Scenario 1: Quick Fix\n\n```bash\n# 1. List and select\npython scripts/ctx_wo_take.py --list\npython scripts/ctx_wo_take.py WO-0005\n\n# 2. Navigate and fix\ncd .worktrees/WO-0005\nvim src/bug_fix.py\ngit commit -am \"WO-0005: Fix race condition\"\n\n# 3. Complete\npython scripts/ctx_wo_finish.py WO-0005\n```\n\n### Scenario 2: Multi-Day Feature\n\n```bash\n# Day 1: Start WO\npython scripts/ctx_wo_take.py WO-0013\ncd .worktrees/WO-0013\n# Work, commit, leave for tomorrow\n\n# Day 2: Continue\ncd .worktrees/WO-0013\n# Continue work, commit\n\n# Day 3: Complete\nmake gate-all\npython scripts/ctx_wo_finish.py WO-0013\n```\n\n### Scenario 3: Blocked WO\n\n```bash\n# WO-0013 is blocked by WO-0012\n# Option 1: Complete WO-0012 first\npython scripts/ctx_wo_take.py WO-0012\n# ... complete WO-0012 ...\npython scripts/ctx_wo_finish.py WO-0012\n\n# Then take WO-0013\npython scripts/ctx_wo_take.py WO-0013\n\n# Option 2: Update dependencies if incorrect\n# Edit WO-0013.yaml to remove false dependency\n```\n\n## Related Documentation\n\n- **[WORKFLOW.md](WORKFLOW.md)** - Complete lifecycle guide\n- **[TROUBLESHOOTING.md](TROUBLESHOOTING.md)** - Common issues and solutions\n- **[README.md](README.md)** - Overview and state machine\n- **[MIGRATION.md](MIGRATION.md)** - Legacy format migration\n\n## Tips and Tricks\n\n### Speed Up Context Search\n\n```bash\n# Use Makefile wrapper (faster)\nmake ctx-search Q=\"...\" SEGMENT=.\n\n# Limit results for faster searches\nuv run trifecta ctx search --segment . --query \"...\" --limit 3\n```\n\n### Quick Worktree Navigation\n\n```bash\n# Add to .bashrc or .zshrc\nalias wo-list='git worktree list'\nalias wo-cd='cd $(git worktree list | grep -o \"/.worktrees/[^ ]*\" | fzf)'\n```\n\n### Batch Operations\n\n```bash\n# List all running WOs\nls _ctx/jobs/running/WO-*.yaml\n\n# Check status of all running WOs\nfor wo in _ctx/jobs/running/WO-*.yaml; do\n  echo \"Status of $(basename $wo .yaml):\"\n  python scripts/ctx_wo_take.py --status\ndone\n```\n",
+      "char_count": 10876,
+      "token_est": 2719,
+      "source_path": "OPERATIONS.md",
+      "chunking_method": "whole_file"
+    },
+    {
+      "id": "repo:docs/backlog/TROUBLESHOOTING.md:797a0cb75a",
+      "doc": "repo:docs/backlog/TROUBLESHOOTING.md",
+      "title_path": [
+        "TROUBLESHOOTING.md"
+      ],
+      "text": "# Work Order Troubleshooting Guide\n\nCommon issues, errors, and solutions for the Trifecta Dope WO system.\n\n## Quick Diagnostics\n\n**Run these commands first:**\n\n```bash\n# Check system status\npython scripts/ctx_wo_take.py --status\n\n# Validate backlog integrity\npython scripts/ctx_backlog_validate.py --strict\n\n# List worktrees\ngit worktree list\n\n# Check for stale locks\nfind _ctx/jobs/running -name \"*.lock\" -mtime +1h\n```\n\n## Common Issues\n\n### \"Work order is locked\"\n\n**Error message:**\n```\nERROR: Work order is locked: WO-0013\nLock info:\nLocked by ctx_wo_take.py at 2026-01-09T20:00:00+00:00\nPID: 12345\nUser: otheruser\n```\n\n**Cause:** Lock exists in `_ctx/jobs/running/WO-XXXX.lock`\n\n**Diagnosis:**\n```bash\n# Check lock age\nstat _ctx/jobs/running/WO-0013.lock\n\n# View lock contents\ncat _ctx/jobs/running/WO-0013.lock\n```\n\n**Solutions:**\n\n1. **Wait for lock to expire** (if < 1 hour old)\n   - Lock is active, wait for owner to complete\n   - Contact owner if needed\n\n2. **Remove stale lock** (if > 1 hour old)\n   ```bash\n   rm _ctx/jobs/running/WO-0013.lock\n   ```\n\n3. **Force unlock** (emergency only)\n   ```bash\n   # Remove lock manually\n   rm _ctx/jobs/running/WO-0013.lock\n\n   # Verify WO state\n   ls -la _ctx/jobs/running/WO-0013.yaml\n\n   # If WO is in running but no work exists, move back to pending\n   mv _ctx/jobs/running/WO-0013.yaml _ctx/jobs/pending/\n   ```\n\n### \"Worktree already exists\"\n\n**Error message:**\n```\nWARNING: Worktree already exists: .worktrees/WO-0013\nWorktree .worktrees/WO-0013 is already registered with git\n```\n\n**Cause:** Worktree from previous WO execution wasn't cleaned up\n\n**Diagnosis:**\n```bash\n# List worktrees\ngit worktree list\n\n# Check if directory exists\nls -la .worktrees/WO-0013\n```\n\n**Solutions:**\n\n1. **Re-use existing worktree** (safe)\n   ```bash\n   # The script will detect and re-use it\n   cd .worktrees/WO-0013\n   # Continue working\n   ```\n\n2. **Remove worktree** (if you want fresh start)\n   ```bash\n   # Remove worktree\n   git worktree remove .worktrees/WO-0013\n\n   # Remove branch (optional)\n   git branch -D feat/wo-WO-0013\n\n   # Try taking WO again\n   python scripts/ctx_wo_take.py WO-0013\n   ```\n\n3. **Force cleanup** (if worktree is corrupted)\n   ```bash\n   # Prune stale references\n   git worktree prune\n\n   # Remove directory manually\n   rm -rf .worktrees/WO-0013\n\n   # Reconcile state\n   python scripts/ctx_reconcile_state.py\n   ```\n\n### \"fatal: invalid reference: feat/wo-WO-XXXX\"\n\n**Error message:**\n```\nERROR: Command failed: git worktree add .worktrees/WO-0013 feat/wo-WO-0013\nstderr: fatal: invalid reference: feat/wo-WO-0013\n```\n\n**Cause:** Code tried to use a branch that doesn't exist\n\n**Diagnosis:**\n```bash\n# Check if branch exists\ngit rev-parse --verify feat/wo-WO-0013\n\n# Check all branches\ngit branch -a\n```\n\n**Solutions:**\n\n1. **Let script create branch** (recommended)\n   - Don't specify branch in WO YAML\n   - Script will auto-create from `main`\n\n2. **Create branch manually**\n   ```bash\n   git branch feat/wo-WO-0013 main\n   python scripts/ctx_wo_take.py WO-0013\n   ```\n\n3. **Remove branch from WO YAML**\n   ```yaml\n   # Edit _ctx/jobs/pending/WO-0013.yaml\n   # Remove this line:\n   # branch: feat/wo-WO-0013\n   ```\n\n### \"Schema validation failed\"\n\n**Error message:**\n```\nERROR: Schema validation failed: 'WO-0013' is not of type 'regex'\n```\n\n**Cause:** WO YAML doesn't match schema\n\n**Diagnosis:**\n```bash\n# Validate specific WO\npython scripts/ctx_backlog_validate.py --strict\n\n# Validate all WOs\npython scripts/ctx_backlog_validate.py --strict --wo WO-0013\n```\n\n**Common schema errors:**\n\n| Error | Cause | Fix |\n|-------|-------|-----|\n| `WO-XXXX` not regex | Wrong ID format | Use `WO-XXXX` (4 digits) |\n| Missing `epic_id` | No epic reference | Add `epic_id: E-XXXX` |\n| Missing `dod_id` | No DoD reference | Add `dod_id: DOD-XXXX` |\n| Invalid `status` | Wrong status value | Use: `pending`, `running`, `done`, `failed` |\n\n**Solutions:**\n\n1. **Fix WO YAML**\n   ```yaml\n   # Correct format\n   version: 1\n   id: WO-0013        # Must be WO-XXXX format\n   epic_id: E-0001    # Must reference existing epic\n   status: pending    # Must be valid status\n   dod_id: DOD-DEFAULT  # Must reference existing DoD\n   ```\n\n2. **Reference schema**\n   ```bash\n   # View schema requirements\n   cat docs/backlog/schema/work_order.schema.json\n   ```\n\n### \"Unknown epic_id\"\n\n**Error message:**\n```\nERROR: Unknown epic_id: E-9999\n```\n\n**Cause:** WO references epic that doesn't exist in backlog\n\n**Diagnosis:**\n```bash\n# Check existing epics\ngrep \"id: E-\" _ctx/backlog/backlog.yaml\n```\n\n**Solutions:**\n\n1. **Create epic first**\n   ```yaml\n   # Edit _ctx/backlog/backlog.yaml\n   epics:\n     - id: E-9999\n       title: \"New Epic\"\n       wo_queue: [WO-0013]\n   ```\n\n2. **Fix epic_id in WO**\n   ```yaml\n   # Edit _ctx/jobs/pending/WO-0013.yaml\n   epic_id: E-0001  # Use existing epic\n   ```\n\n### \"Work order not found\"\n\n**Error message:**\n```\nERROR: Work order not found: _ctx/jobs/pending/WO-0013.yaml\n```\n\n**Cause:** WO YAML doesn't exist in expected location\n\n**Diagnosis:**\n```bash\n# Check if WO exists anywhere\nfind _ctx/jobs -name \"WO-0013.yaml\"\n\n# Check pending directory\nls -la _ctx/jobs/pending/\n```\n\n**Solutions:**\n\n1. **Create WO YAML**\n   ```bash\n   # Copy template\n   cp _ctx/jobs/pending/WO-0000.template.yaml _ctx/jobs/pending/WO-0013.yaml\n\n   # Edit with correct values\n   vim _ctx/jobs/pending/WO-0013.yaml\n   ```\n\n2. **Check if WO is already running/done**\n   ```bash\n   ls -la _ctx/jobs/running/WO-0013.yaml\n   ls -la _ctx/jobs/done/WO-0013.yaml\n   ```\n\n### \"Scope violation\"\n\n**Error message (during DoD verification):**\n```\nERROR: Scope violation: modified src/domain/entity.py\nThis file is denied by WO scope.\n```\n\n**Cause:** Modified file that WO is not allowed to edit\n\n**Diagnosis:**\n```bash\n# Check WO scope\ncat _ctx/jobs/running/WO-0013.yaml | grep -A 10 scope\n\n# Check what you modified\ngit status\n```\n\n**Solutions:**\n\n1. **Revert disallowed changes**\n   ```bash\n   git checkout src/domain/entity.py\n   ```\n\n2. **Update WO scope** (if needed)\n   ```yaml\n   # Edit _ctx/jobs/running/WO-0013.yaml\n   scope:\n     allow:\n       - \"src/domain/entity.py\"  # Add this file\n     deny:\n       - \"src/domain/other/**\"\n   ```\n\n3. **Create new WO** for disallowed changes\n   ```bash\n   # Create separate WO for domain changes\n   python scripts/ctx_wo_create.py --epic E-0001\n   ```\n\n### \"Context pack validation failed\"\n\n**Error message:**\n```\nERROR: ctx validate reported stale pack\n```\n\n**Cause:** Context pack is out of sync with codebase\n\n**Diagnosis:**\n```bash\n# Validate context\nuv run trifecta ctx validate --segment .\n```\n\n**Solutions:**\n\n1. **Sync context pack**\n   ```bash\n   make ctx-sync SEGMENT=.\n   # OR\n   uv run trifecta ctx sync --segment .\n   ```\n\n2. **Re-validate**\n   ```bash\n   uv run trifecta ctx validate --segment .\n   ```\n\n### State Inconsistencies\n\n**Symptom:** WO in `running/` but no lock exists\n\n**Diagnosis:**\n```bash\n# Check for running WOs without locks\nfor wo in _ctx/jobs/running/WO-*.yaml; do\n  id=$(basename \"$wo\" .yaml)\n  lock=\"_ctx/jobs/running/${id}.lock\"\n  if [ ! -f \"$lock\" ]; then\n    echo \"Missing lock for $id\"\n  fi\ndone\n```\n\n**Solution:**\n```bash\n# Repair state\npython scripts/ctx_reconcile_state.py\n```\n\n**Symptom:** Worktree exists but WO is `done`\n\n**Diagnosis:**\n```bash\n# Find orphaned worktrees\ngit worktree list | while read path branch; do\n  wo=$(echo \"$branch\" | grep -o \"WO-[0-9]\\{4\\}\")\n  if [ -n \"$wo\" ]; then\n    if [ -f \"_ctx/jobs/done/${wo}.yaml\" ]; then\n      echo \"Orphaned worktree: $path ($wo)\"\n    fi\n  fi\ndone\n```\n\n**Solution:**\n```bash\n# Remove orphaned worktrees\ngit worktree remove .worktrees/WO-XXXX\n```\n\n## Recovery Procedures\n\n### Recover from crashed `ctx_wo_take.py`\n\n**Symptom:** Script crashed during execution\n\n**Steps:**\n```bash\n# 1. Check for partial state\npython scripts/ctx_wo_take.py --status\n\n# 2. Check for lock\nls -la _ctx/jobs/running/*.lock\n\n# 3. Reconcile state\npython scripts/ctx_reconcile_state.py\n\n# 4. Retry take operation\npython scripts/ctx_wo_take.py WO-XXXX\n```\n\n### Recover from git worktree corruption\n\n**Symptom:** Worktree directory exists but not functional\n\n**Steps:**\n```bash\n# 1. Prune stale references\ngit worktree prune\n\n# 2. Remove corrupted worktree\nrm -rf .worktrees/WO-XXXX\n\n# 3. Remove branch (if needed)\ngit branch -D feat/wo-WO-XXXX\n\n# 4. Retake WO\npython scripts/ctx_wo_take.py WO-XXXX\n```\n\n### Recover from lock race condition\n\n**Symptom:** Two processes tried to take same WO\n\n**Steps:**\n```bash\n# 1. Check lock contents\ncat _ctx/jobs/running/WO-XXXX.lock\n\n# 2. Verify only one process should own it\nps aux | grep $(cat _ctx/jobs/running/WO-XXXX.lock | grep PID)\n\n# 3. If process is dead, remove lock\nrm _ctx/jobs/running/WO-XXXX.lock\n\n# 4. Reconcile state\npython scripts/ctx_reconcile_state.py\n```\n\n## Prevention\n\n### Best Practices to Avoid Issues\n\n1. **Always use scripts** - Never manually move YAML files\n2. **Complete WOs before leaving** - Don't leave WOs in `running` overnight\n3. **Regular cleanup** - Run `git worktree prune` weekly\n4. **Validate before commits** - Run `ctx_backlog_validate.py --strict`\n5. **Monitor locks** - Check `--status` for unexpected running WOs\n\n### Regular Maintenance\n\n```bash\n# Weekly maintenance script\n#!/bin/bash\necho \"=== WO System Maintenance ===\"\n\necho \"1. Pruning worktrees...\"\ngit worktree prune\n\necho \"2. Validating backlog...\"\npython scripts/ctx_backlog_validate.py --strict\n\necho \"3. Checking status...\"\npython scripts/ctx_wo_take.py --status\n\necho \"4. Reconciling state...\"\npython scripts/ctx_reconcile_state.py --dry-run\n\necho \"=== Maintenance Complete ===\"\n```\n\n## Getting Help\n\n### Information to Gather\n\nBefore asking for help, collect:\n\n```bash\n# System status\npython scripts/ctx_wo_take.py --status > status.txt\n\n# Git status\ngit status > git_status.txt\n\n# Worktree list\ngit worktree list > worktrees.txt\n\n# Validation results\npython scripts/ctx_backlog_validate.py --strict > validation.txt 2>&1\n\n# Lock info\nfind _ctx/jobs/running -name \"*.lock\" -exec cat {} \\; > locks.txt\n```\n\n### Diagnostic Script\n\n```bash\n#!/bin/bash\n# Full diagnostic dump\n\necho \"=== WO System Diagnostics ===\"\necho \"Date: $(date)\"\necho \"\"\n\necho \"=== System Status ===\"\npython scripts/ctx_wo_take.py --status\necho \"\"\n\necho \"=== Git Status ===\"\ngit status\necho \"\"\n\necho \"=== Worktrees ===\"\ngit worktree list\necho \"\"\n\necho \"=== Lock Files ===\"\nfind _ctx/jobs/running -name \"*.lock\" -type f\necho \"\"\n\necho \"=== Pending WOs ===\"\nls -1 _ctx/jobs/pending/WO-*.yaml 2>/dev/null || echo \"None\"\necho \"\"\n\necho \"=== Running WOs ===\"\nls -1 _ctx/jobs/running/WO-*.yaml 2>/dev/null | grep -v \".lock\" || echo \"None\"\necho \"\"\n\necho \"=== Done WOs (last 5) ===\"\nls -1t _ctx/jobs/done/WO-*.yaml 2>/dev/null | head -5 || echo \"None\"\necho \"\"\n\necho \"=== Validation ===\"\npython scripts/ctx_backlog_validate.py --strict\necho \"\"\n\necho \"=== End Diagnostics ===\"\n```\n\n## Related Documentation\n\n- **[WORKFLOW.md](WORKFLOW.md)** - Complete lifecycle guide\n- **[OPERATIONS.md](OPERATIONS.md)** - Daily operations playbook\n- **[README.md](README.md)** - Overview and state machine\n- **[MIGRATION.md](MIGRATION.md)** - Legacy format migration\n",
+      "char_count": 11126,
+      "token_est": 2781,
+      "source_path": "TROUBLESHOOTING.md",
+      "chunking_method": "whole_file"
+    },
     {
       "id": "repo:docs/backlog/LESSONS.md:fa78b1dc77",
       "doc": "repo:docs/backlog/LESSONS.md",
@@ -2335,14 +2437,14 @@
       "chunking_method": "whole_file"
     },
     {
-      "id": "repo:docs/backlog/README.md:b1178ab455",
+      "id": "repo:docs/backlog/README.md:1b804b230e",
       "doc": "repo:docs/backlog/README.md",
       "title_path": [
         "README.md"
       ],
-      "text": "# Backlog + Work Orders Pipeline\n\n## State machine\n\nWork orders move through these states:\n\n- `pending` -> `running` -> `done`\n- `pending` -> `running` -> `failed`\n\nA WO can only be `done` when its DoD artifacts are complete.\n\n## Traceability invariants\n\n- `backlog.yaml` is canonical for epics and WO queue.\n- Each WO in `_ctx/jobs/{pending,running,done,failed}` must reference a valid `epic_id` and `dod_id`.\n- Every WO must define `scope.allow` and `scope.deny` plus `verify.commands`.\n- Context pack sources live under `_ctx/`; legacy stubs such as `_ctx/blacklog/README.md` are non-canonical.\n\n## Rollback\n\n- All changes are additive; rollback is a git revert.\n- If state diverges (locks/worktrees), use `scripts/ctx_reconcile_state.py` to repair before any manual edits.\n",
-      "char_count": 777,
-      "token_est": 194,
+      "text": "# Backlog + Work Orders Pipeline\n\n## Quick Start\n\n```bash\n# 1. List pending work orders\npython scripts/ctx_wo_take.py --list\n\n# 2. Take a work order (auto-creates branch + worktree)\npython scripts/ctx_wo_take.py WO-XXXX\n\n# 3. Navigate to isolated worktree\ncd .worktrees/WO-XXXX\n\n# 4. Work and commit normally\ngit add .\ngit commit -m \"WO-XXXX: Implement feature\"\n\n# 5. Complete work order (validates DoD)\npython scripts/ctx_wo_finish.py WO-XXXX\n```\n\n## Documentation\n\n- **[WORKFLOW.md](WORKFLOW.md)** — Complete lifecycle guide (states, transitions, automation)\n- **[OPERATIONS.md](OPERATIONS.md)** — Daily operations playbook (commands, workflows, CLI integration)\n- **[TROUBLESHOOTING.md](TROUBLESHOOTING.md)** — Common issues and solutions (errors, recovery, diagnostics)\n- **[MIGRATION.md](MIGRATION.md)** — Legacy format migration guide\n\n## State machine\n\nWork orders move through these states:\n\n```\n┌─────────┐     ┌─────────┐     ┌──────────┐     ┌─────────┐\n│ PENDING │ ──▶ │ RUNNING │ ──▶ │   DONE   │     │ FAILED  │\n└─────────┘     └─────────┘     └──────────┘     └─────────┘\n```\n\n- `pending` → `running` → `done`\n- `pending` → `running` → `failed`\n\nA WO can only be `done` when its DoD artifacts are complete.\n\n## Traceability invariants\n\n- `backlog.yaml` is canonical for epics and WO queue.\n- Each WO in `_ctx/jobs/{pending,running,done,failed}` must reference a valid `epic_id` and `dod_id`.\n- Every WO must define `scope.allow` and `scope.deny` plus `verify.commands`.\n- Context pack sources live under `_ctx/`; legacy stubs such as `_ctx/blacklog/README.md` are non-canonical.\n\n## Rollback\n\n- All changes are additive; rollback is a git revert.\n- If state diverges (locks/worktrees), use `scripts/ctx_reconcile_state.py` to repair before any manual edits.\n\n## Scripts Reference\n\n### Core Orchestration\n\n| Script | Purpose | Key Features |\n|--------|---------|--------------|\n| **helpers.py** | Core utilities | Worktree creation, lock management, branch generation |\n| **ctx_wo_take.py** | Take WO | Auto branch (`feat/wo-WO-XXXX`), auto worktree (`.worktrees/WO-XXXX`), atomic lock |\n| **ctx_wo_finish.py** | Complete WO | DoD validation, SHA capture, status transition |\n| **ctx_reconcile_state.py** | Repair state | Fix inconsistencies, prune stale references |\n\n### Validation\n\n| Script | Purpose |\n|--------|---------|\n| **ctx_backlog_validate.py** | Validate YAML schemas against JSON schemas |\n\n### Usage Examples\n\n```bash\n# List pending WOs\npython scripts/ctx_wo_take.py --list\n\n# Show system status (pending/running/done counts, active worktrees)\npython scripts/ctx_wo_take.py --status\n\n# Take WO with auto-generated branch and worktree\npython scripts/ctx_wo_take.py WO-0013\n\n# Take WO with explicit owner\npython scripts/ctx_wo_take.py WO-0013 --owner \"developer\"\n\n# Complete WO (runs DoD verification)\npython scripts/ctx_wo_finish.py WO-0013\n\n# Validate all WOs\npython scripts/ctx_backlog_validate.py --strict\n\n# Repair state inconsistencies\npython scripts/ctx_reconcile_state.py\n```\n\n## Architecture\n\n### Worktree Management\n\nEach WO gets an isolated git worktree:\n\n```\n.trifecta_dope/\n├── .worktrees/\n│   ├── WO-0012/          # Isolated environment\n│   │   └── [symlinks to main repo]\n│   └── WO-0013/          # Another isolated environment\n│       └── [symlinks to main repo]\n```\n\n**Automatic generation:**\n- Branch: `feat/wo-WO-XXXX` (from `main`)\n- Path: `.worktrees/WO-XXXX`\n\n### Lock Management\n\nAtomic locks prevent concurrent access:\n\n```\n_ctx/jobs/running/\n├── WO-0013.lock         # Contains: PID, user, hostname, timestamp\n└── WO-0013.yaml         # WO metadata (moved from pending/)\n```\n\n**Stale lock detection:** Locks >1 hour old are auto-cleaned.\n\n## Directory Structure\n\n```\n_ctx/\n├── backlog/\n│   └── backlog.yaml          # Epic registry (canonical)\n├── jobs/\n│   ├── pending/              # WOs awaiting work\n│   ├── running/              # WOs in progress (+ locks)\n│   ├── done/                 # Completed WOs (with verified_at_sha)\n│   └── failed/               # Failed WOs\n└── dod/                      # Definition of Done catalog\n    ├── DOD-DEFAULT.yaml\n    └── DOD-XXXX.yaml\n```\n\n## Schema Validation\n\nAll WOs must validate against JSON schemas:\n\n| Schema | Purpose |\n|--------|---------|\n| **work_order.schema.json** | WO YAML structure |\n| **backlog.schema.json** | Epic registry structure |\n| **dod.schema.json** | Definition of Done structure |\n\nValidate with:\n```bash\npython scripts/ctx_backlog_validate.py --strict\n```\n\n## Integration with Trifecta CLI\n\nThe WO system integrates seamlessly with the Trifecta CLI:\n\n```bash\n# Inside a worktree, sync context\nmake ctx-sync SEGMENT=.\n\n# Search documentation\nmake ctx-search Q=\"Find telemetry implementation\" SEGMENT=.\n\n# Navigate AST symbols\nuv run trifecta ast symbols \"sym://python/mod/src.domain.result\" --segment .\n```\n\nSee [OPERATIONS.md](OPERATIONS.md) for complete CLI integration guide.\n\n## Testing\n\nThe WO orchestration system has comprehensive test coverage:\n\n```bash\n# Run full test suite\npython tests/test_wo_orchestration.py\n```\n\nAll 7 tests verify:\n- Branch generation (`feat/wo-WO-XXXX`)\n- Worktree path generation (`.worktrees/WO-XXXX`)\n- Lock creation (atomic with metadata)\n- Lock age detection (stale >1 hour)\n- Worktree creation (from `main` branch)\n- Worktree listing (git worktree list)\n- Idempotency (safe re-creation)\n\n## Best Practices\n\n✅ **DO:**\n- Always use `ctx_wo_take.py` to start WOs (never manually move YAMLs)\n- Commit work before running `ctx_wo_finish.py`\n- Stay within WO scope (`allow`/`deny` patterns)\n- Run `--status` daily to check active WOs\n- Clean up worktrees periodically with `git worktree prune`\n\n❌ **DON'T:**\n- Edit WO YAMLs directly (use scripts for state transitions)\n- Skip DoD verification (use `--skip-verification` only in emergencies)\n- Share worktrees between WOs (one WO per worktree)\n- Ignore locks (stale locks indicate interrupted work)\n- Delete worktrees manually (use `git worktree remove` or helpers)\n\n## Related Documentation\n\n- **[WORKFLOW.md](WORKFLOW.md)** — Complete lifecycle guide\n- **[OPERATIONS.md](OPERATIONS.md)** — Daily operations playbook\n- **[TROUBLESHOOTING.md](TROUBLESHOOTING.md)** — Common issues and solutions\n- **[MIGRATION.md](MIGRATION.md)** — Legacy format migration\n",
+      "char_count": 6265,
+      "token_est": 1566,
       "source_path": "README.md",
       "chunking_method": "whole_file"
     },
@@ -3246,6 +3348,18 @@
       "source_path": "2026-01-04-northstar-kanban-sot.md",
       "chunking_method": "whole_file"
     },
+    {
+      "id": "repo:docs/plans/2026-01-06-fix-debug-scripts.md:1d8996a76c",
+      "doc": "repo:docs/plans/2026-01-06-fix-debug-scripts.md",
+      "title_path": [
+        "2026-01-06-fix-debug-scripts.md"
+      ],
+      "text": "# Fix Debug Scripts Implementation Plan\n\n> **For Claude:** REQUIRED SUB-SKILL: Use superpowers:executing-plans to implement this plan task-by-task.\n\n**Goal:** Formalize `scripts/debug` contents into audit-grade, robust CLI commands or harnesses, resolving race conditions and path hacks.\n\n**Architecture:** Move logic from loose scripts to `src/application/use_cases/debug_lsp.py` and expose via `src/interfaces/cli/debug.py` (Command: `trifecta debug`). This strictly satisfies **Rule 1 (Use the CLI)** and removes all loose scripts.\n\n**Tech Stack:** Python, Trifecta LSPClient, Pytest (for verification logic).\n\n---\n\n### Task 1: Create 'trifecta debug' CLI Command\n\n**Files:**\n- Create: `src/application/use_cases/debug_lsp.py` (Business Logic)\n- Modify: `src/infrastructure/cli.py` (Register `debug` group)\n- Delete: `scripts/debug/`\n\n**Step 1: Write the failing test (TDD)**\n\nTest that `trifecta debug client` command exists and fails gracefully when daemon is down.\n\n**Step 2: Implement Use Cases (Green)**\n1.  `LspClientDebugUseCase`: Handles client lifecycle with `try/finally` and proper `sleep`.\n2.  `LspStatusDebugUseCase`: Handles socket checking without crashing.\n\n**Step 3: Register in CLI**\nExpose `trifecta debug client` and `trifecta debug status`.\n\n**Step 4: Verification**\nRun `uv run trifecta debug status` -> \"Daemon not found\" (Clean exit).\n\n---\n\n\n---\n\n### Task 3: Cleanup Loose Scripts\n\n**Files:**\n- Delete: `scripts/debug/` (Recursively)\n\n**Step 1: Verify replacements work**\nRerun both harnesses.\n\n**Step 2: Delete old scripts**\n`rm -rf scripts/debug`\n\n**Step 3: Commit**\n`git commit -m \"refactor(debug): replace loose scripts with robust harnesses (Rule 6 fix)\"`\n",
+      "char_count": 1688,
+      "token_est": 422,
+      "source_path": "2026-01-06-fix-debug-scripts.md",
+      "chunking_method": "whole_file"
+    },
     {
       "id": "repo:docs/plans/t9_3_eval_report.md:f116b8ee19",
       "doc": "repo:docs/plans/t9_3_eval_report.md",
@@ -3330,6 +3444,18 @@
       "source_path": "implementation_plan_wo_p2_1_telemetry.md",
       "chunking_method": "whole_file"
     },
+    {
+      "id": "repo:docs/plans/2026-01-09-wo0013-ast-adoption-observability.md:e87504cae8",
+      "doc": "repo:docs/plans/2026-01-09-wo0013-ast-adoption-observability.md",
+      "title_path": [
+        "2026-01-09-wo0013-ast-adoption-observability.md"
+      ],
+      "text": "# WO-0013: AST Persist Adoption Observability Implementation Plan\n\n> **For Claude:** REQUIRED SUB-SKILL: Use superpowers:executing-plans to implement this plan task-by-task.\n\n**Goal:** Implement telemetry analysis to monitor real-world adoption of AST cache persistence, tracking backend distribution, lock contention, and DB growth.\n\n**Architecture:** Python script that parses `_ctx/telemetry/events.jsonl`, extracts metrics using the existing telemetry schema, and generates JSON metrics + markdown report. Uses patterns from `extract_ast_soak_metrics.py`.\n\n**Tech Stack:** Python 3.11+, argparse, pathlib, json, pytest\n\n**Context from Exploration:**\n- Events schema: `cmd` field contains `ast.cache.hit/miss/write/lock_wait/lock_timeout`\n- Backend field: `result.backend` = `\"FileLockedAstCache\"` | `\"InMemoryLRUCache\"`\n- DB location: `.trifecta/cache/ast_cache_*.db`\n- Reference script: `eval/scripts/extract_ast_soak_metrics.py`\n\n**Worktree Location:** `.worktrees/wo0013-ast-adoption-observability`\n\n---\n\n## Task 1: Create Analysis Script Structure\n\n**Files:**\n- Create: `eval/scripts/analyze_adoption_telemetry.py`\n\n**Step 1: Create script skeleton with imports and setup**\n\n```python\n#!/usr/bin/env python3\n\"\"\"Analyze AST cache adoption metrics from telemetry events.\n\nUsage:\n    python eval/scripts/analyze_adoption_telemetry.py --segment . --days 7 --out _ctx/metrics/wo0013_adoption.json\n\"\"\"\n\nimport argparse\nimport json\nimport logging\nimport sys\nfrom collections import defaultdict\nfrom datetime import datetime, timedelta\nfrom pathlib import Path\nfrom typing import Any\n\n\ndef setup_logging():\n    logging.basicConfig(\n        level=logging.INFO,\n        format=\"%(asctime)s - %(levelname)s - %(message)s\",\n        datefmt=\"%H:%M:%S\",\n    )\n\n\ndef load_telemetry_events(events_path: Path) -> list[dict[str, Any]]:\n    \"\"\"Load all events from events.jsonl, skipping malformed lines.\"\"\"\n    events = []\n    with open(events_path) as f:\n        for line in f:\n            line = line.strip()\n            if not line or line == \"[]\":\n                continue\n            try:\n                event = json.loads(line)\n                events.append(event)\n            except json.JSONDecodeError:\n                continue\n    return events\n\n\ndef filter_events_by_days(events: list[dict], days: int) -> list[dict]:\n    \"\"\"Filter events to last N days based on timestamp.\"\"\"\n    cutoff = (datetime.now() - timedelta(days=days)).isoformat()\n    return [e for e in events if e.get(\"ts\", \"\") >= cutoff]\n\n\ndef main():\n    parser = argparse.ArgumentParser(description=\"Analyze AST cache adoption from telemetry\")\n    parser.add_argument(\"--segment\", default=\".\", help=\"Segment path (default: .)\")\n    parser.add_argument(\"--days\", type=int, default=7, help=\"Days to analyze (default: 7)\")\n    parser.add_argument(\"--out\", required=True, help=\"Output JSON path\")\n    parser.add_argument(\n        \"--telemetry-file\",\n        default=\"_ctx/telemetry/events.jsonl\",\n        help=\"Path to events.jsonl\"\n    )\n    args = parser.parse_args()\n\n    segment_path = Path(args.segment).resolve()\n    telemetry_path = segment_path / args.telemetry_file\n\n    if not telemetry_path.exists():\n        logging.error(f\"Telemetry file not found: {telemetry_path}\")\n        sys.exit(1)\n\n    logging.info(f\"Loading telemetry from {telemetry_path}...\")\n    all_events = load_telemetry_events(telemetry_path)\n\n    logging.info(f\"Filtering events from last {args.days} days...\")\n    events = filter_events_by_days(all_events, args.days)\n\n    logging.info(f\"Analyzing {len(events)} events...\")\n    metrics = analyze_adoption_metrics(events, segment_path)\n\n    out_path = Path(args.out)\n    out_path.parent.mkdir(parents=True, exist_ok=True)\n\n    with open(out_path, \"w\") as f:\n        json.dump(metrics, f, indent=2)\n\n    logging.info(f\"Metrics written to {out_path}\")\n    print(json.dumps(metrics, indent=2))\n\n\ndef analyze_adoption_metrics(events: list[dict], segment_path: Path) -> dict[str, Any]:\n    \"\"\"Analyze adoption metrics from filtered events.\"\"\"\n    # Placeholder - implement in next task\n    return {\"placeholder\": True}\n\n\nif __name__ == \"__main__\":\n    setup_logging()\n    main()\n```\n\n**Step 2: Make script executable**\n\nRun: `chmod +x eval/scripts/analyze_adoption_telemetry.py`\nExpected: No output, file is now executable\n\n**Step 3: Test basic execution (should fail gracefully)**\n\nRun: `python eval/scripts/analyze_adoption_telemetry.py --out /tmp/test.json 2>&1 | head -5`\nExpected: Error about telemetry file not found (expected in fresh run)\n\n### 🔳 CHECKPOINT 1: Session Resume\n\n**State after Task 1:**\n- Script skeleton created at `eval/scripts/analyze_adoption_telemetry.py`\n- File is executable\n- Basic functions: `setup_logging()`, `load_telemetry_events()`, `filter_events_by_days()`\n- Placeholder `analyze_adoption_metrics()` returns `{\"placeholder\": True}`\n\n**To resume in new session:**\n```bash\n# Navigate to worktree\ncd .worktrees/wo0013-ast-adoption-observability\n\n# Verify script exists and is executable\nls -la eval/scripts/analyze_adoption_telemetry.py\n\n# Continue with Task 2\n```\n\n**Next task:** Task 2 - Implement Backend Distribution Analysis\n\n---\n\n## Task 2: Implement Backend Distribution Analysis\n\n**Files:**\n- Modify: `eval/scripts/analyze_adoption_telemetry.py`\n\n**Step 1: Add backend distribution function**\n\nAdd after `filter_events_by_days`:\n\n```python\ndef analyze_backend_distribution(events: list[dict]) -> dict[str, Any]:\n    \"\"\"Analyze distribution of cache backends used.\n\n    Returns:\n        Dict with backend counts and percentages.\n    \"\"\"\n    distribution = defaultdict(int)\n\n    for event in events:\n        # Backend is stored in result.backend field\n        backend = event.get(\"result\", {}).get(\"backend\", \"Unknown\")\n        distribution[backend] += 1\n\n    total = sum(distribution.values())\n    if total == 0:\n        return {\"total_runs\": 0, \"by_backend\": {}}\n\n    # Calculate percentages\n    by_backend = {\n        backend: {\n            \"count\": count,\n            \"percentage\": round(count / total * 100, 1)\n        }\n        for backend, count in distribution.items()\n    }\n\n    return {\n        \"total_runs\": total,\n        \"by_backend\": by_backend,\n        \"adoption_rate\": by_backend.get(\"FileLockedAstCache\", {}).get(\"percentage\", 0)\n    }\n```\n\n**Step 2: Update analyze_adoption_metrics to use new function**\n\nReplace the placeholder:\n\n```python\ndef analyze_adoption_metrics(events: list[dict], segment_path: Path) -> dict[str, Any]:\n    \"\"\"Analyze adoption metrics from filtered events.\"\"\"\n    return {\n        \"backend_distribution\": analyze_backend_distribution(events),\n    }\n```\n\n**Step 3: Test with real telemetry**\n\nRun: `python eval/scripts/analyze_adoption_telemetry.py --segment . --days 7 --out /tmp/test_metrics.json`\nExpected: JSON output with backend_distribution field\n\n**Step 4: Verify output structure**\n\nRun: `cat /tmp/test_metrics.json | jq '.backend_distribution'`\nExpected: Shows total_runs and by_backend with FileLockedAstCache/InMemoryLRUCache\n\n### 🔳 CHECKPOINT 2: Session Resume\n\n**State after Task 2:**\n- `analyze_backend_distribution()` function added\n- Tracks backend usage: FileLockedAstCache vs InMemoryLRUCache\n- Calculates adoption_rate percentage for FileLockedAstCache\n- `analyze_adoption_metrics()` now returns backend_distribution\n\n**To resume in new session:**\n```bash\ncd .worktrees/wo0013-ast-adoption-observability\n\n# Verify backend distribution works\npython eval/scripts/analyze_adoption_telemetry.py --segment . --days 7 --out /tmp/verify.json\ncat /tmp/verify.json | jq '.backend_distribution'\n\n# Continue with Task 3\n```\n\n**Next task:** Task 3 - Implement Cache Effectiveness Analysis\n\n---\n\n## Task 3: Implement Cache Effectiveness Analysis\n\n**Files:**\n- Modify: `eval/scripts/analyze_adoption_telemetry.py`\n\n**Step 1: Add cache effectiveness function**\n\nAdd after `analyze_backend_distribution`:\n\n```python\ndef analyze_cache_effectiveness(events: list[dict]) -> dict[str, Any]:\n    \"\"\"Analyze cache hit/miss effectiveness by backend.\n\n    Returns:\n        Dict with hit rates per backend type.\n    \"\"\"\n    # Track hits and misses per backend\n    backend_stats = defaultdict(lambda: {\"hits\": 0, \"misses\": 0})\n\n    for event in events:\n        cmd = event.get(\"cmd\")\n        backend = event.get(\"result\", {}).get(\"backend\", \"Unknown\")\n\n        if cmd == \"ast.cache.hit\":\n            backend_stats[backend][\"hits\"] += 1\n        elif cmd == \"ast.cache.miss\":\n            backend_stats[backend][\"misses\"] += 1\n\n    # Calculate hit rates\n    effectiveness = {}\n    for backend, stats in backend_stats.items():\n        total = stats[\"hits\"] + stats[\"misses\"]\n        hit_rate = stats[\"hits\"] / total if total > 0 else 0\n\n        effectiveness[backend] = {\n            \"hits\": stats[\"hits\"],\n            \"misses\": stats[\"misses\"],\n            \"total_operations\": total,\n            \"hit_rate\": round(hit_rate, 3)\n        }\n\n    return effectiveness\n```\n\n**Step 2: Add to analyze_adoption_metrics return dict**\n\n```python\ndef analyze_adoption_metrics(events: list[dict], segment_path: Path) -> dict[str, Any]:\n    \"\"\"Analyze adoption metrics from filtered events.\"\"\"\n    return {\n        \"backend_distribution\": analyze_backend_distribution(events),\n        \"cache_effectiveness\": analyze_cache_effectiveness(events),\n    }\n```\n\n**Step 3: Test effectiveness calculation**\n\nRun: `python eval/scripts/analyze_adoption_telemetry.py --segment . --days 7 --out /tmp/test_metrics.json`\nExpected: cache_effectiveness field with hit rates per backend\n\n**Step 4: Verify hit rate calculation**\n\nRun: `cat /tmp/test_metrics.json | jq '.cache_effectiveness'`\nExpected: Shows hits, misses, total_operations, hit_rate for each backend\n\n### 🔳 CHECKPOINT 3: Session Resume\n\n**State after Task 3:**\n- `analyze_cache_effectiveness()` function added\n- Tracks hit/miss rates per backend type\n- Returns hit_rate as decimal (0.0 to 1.0)\n- Metrics include: hits, misses, total_operations, hit_rate\n\n**To resume in new session:**\n```bash\ncd .worktrees/wo0013-ast-adoption-observability\n\n# Verify cache effectiveness works\npython eval/scripts/analyze_adoption_telemetry.py --segment . --days 7 --out /tmp/verify.json\ncat /tmp/verify.json | jq '.cache_effectiveness'\n\n# Continue with Task 4\n```\n\n**Next task:** Task 4 - Implement Lock Contention Analysis\n\n---\n\n## Task 4: Implement Lock Contention Analysis\n\n**Files:**\n- Modify: `eval/scripts/analyze_adoption_telemetry.py`\n\n**Step 1: Add lock contention function**\n\nAdd after `analyze_cache_effectiveness`:\n\n```python\ndef analyze_lock_contention(events: list[dict]) -> dict[str, Any]:\n    \"\"\"Analyze lock wait and timeout events.\n\n    Returns:\n        Dict with contention statistics.\n    \"\"\"\n    lock_waits = []\n    timeout_count = 0\n\n    for event in events:\n        cmd = event.get(\"cmd\")\n        timing = event.get(\"timing_ms\", 0)\n\n        if cmd == \"ast.cache.lock_wait\":\n            lock_waits.append(timing)\n        elif cmd == \"ast.cache.lock_timeout\":\n            timeout_count += 1\n\n    # Calculate wait time statistics\n    wait_stats = {}\n    if lock_waits:\n        sorted_waits = sorted(lock_waits)\n        n = len(sorted_waits)\n        wait_stats = {\n            \"total_waits\": len(lock_waits),\n            \"avg_wait_ms\": round(sum(lock_waits) / len(lock_waits), 1),\n            \"p50_wait_ms\": sorted_waits[int(n * 0.5)],\n            \"p95_wait_ms\": sorted_waits[int(n * 0.95)],\n            \"max_wait_ms\": sorted_waits[-1],\n        }\n    else:\n        wait_stats = {\n            \"total_waits\": 0,\n            \"avg_wait_ms\": 0,\n            \"p50_wait_ms\": 0,\n            \"p95_wait_ms\": 0,\n            \"max_wait_ms\": 0,\n        }\n\n    return {\n        \"lock_waits\": wait_stats,\n        \"timeouts\": {\n            \"count\": timeout_count,\n            \"rate_percent\": round(timeout_count / max(1, len(lock_waits) + timeout_count) * 100, 2)\n        }\n    }\n```\n\n**Step 2: Add to analyze_adoption_metrics**\n\n```python\ndef analyze_adoption_metrics(events: list[dict], segment_path: Path) -> dict[str, Any]:\n    \"\"\"Analyze adoption metrics from filtered events.\"\"\"\n    return {\n        \"backend_distribution\": analyze_backend_distribution(events),\n        \"cache_effectiveness\": analyze_cache_effectiveness(events),\n        \"lock_contention\": analyze_lock_contention(events),\n    }\n```\n\n**Step 3: Test contention analysis**\n\nRun: `python eval/scripts/analyze_adoption_telemetry.py --segment . --days 7 --out /tmp/test_metrics.json`\nExpected: lock_contention field with wait stats and timeout count\n\n**Step 4: Verify contention metrics**\n\nRun: `cat /tmp/test_metrics.json | jq '.lock_contention'`\nExpected: Shows total_waits, avg_wait_ms, timeouts count\n\n### 🔳 CHECKPOINT 4: Session Resume\n\n**State after Task 4:**\n- `analyze_lock_contention()` function added\n- Tracks lock wait times (avg, p50, p95, max)\n- Counts timeout events and calculates timeout rate\n- Returns lock_waits and timeouts sections\n\n**To resume in new session:**\n```bash\ncd .worktrees/wo0013-ast-adoption-observability\n\n# Verify lock contention works\npython eval/scripts/analyze_adoption_telemetry.py --segment . --days 7 --out /tmp/verify.json\ncat /tmp/verify.json | jq '.lock_contention'\n\n# Continue with Task 5\n```\n\n**Next task:** Task 5 - Implement DB Growth Analysis\n\n---\n\n## Task 5: Implement DB Growth Analysis\n\n**Files:**\n- Modify: `eval/scripts/analyze_adoption_telemetry.py`\n\n**Step 1: Add DB scan function**\n\nAdd after `analyze_lock_contention`:\n\n```python\ndef scan_db_growth(segment_path: Path) -> dict[str, Any]:\n    \"\"\"Scan AST cache database files for size and count.\n\n    Returns:\n        Dict with total size, file count, and per-file details.\n    \"\"\"\n    cache_dir = segment_path / \".trifecta\" / \"cache\"\n\n    if not cache_dir.exists():\n        return {\n            \"db_exists\": False,\n            \"total_size_mb\": 0,\n            \"file_count\": 0,\n            \"files\": []\n        }\n\n    db_files = list(cache_dir.glob(\"ast_cache_*.db\"))\n\n    if not db_files:\n        return {\n            \"db_exists\": True,\n            \"total_size_mb\": 0,\n            \"file_count\": 0,\n            \"files\": []\n        }\n\n    total_size = sum(f.stat().st_size for f in db_files)\n    files = [\n        {\n            \"name\": f.name,\n            \"size_mb\": round(f.stat().st_size / (1024 * 1024), 4),\n            \"modified\": datetime.fromtimestamp(f.stat().st_mtime).isoformat()\n        }\n        for f in db_files\n    ]\n\n    return {\n        \"db_exists\": True,\n        \"total_size_mb\": round(total_size / (1024 * 1024), 4),\n        \"file_count\": len(db_files),\n        \"files\": files\n    }\n```\n\n**Step 2: Add to analyze_adoption_metrics**\n\n```python\ndef analyze_adoption_metrics(events: list[dict], segment_path: Path) -> dict[str, Any]:\n    \"\"\"Analyze adoption metrics from filtered events.\"\"\"\n    return {\n        \"backend_distribution\": analyze_backend_distribution(events),\n        \"cache_effectiveness\": analyze_cache_effectiveness(events),\n        \"lock_contention\": analyze_lock_contention(events),\n        \"db_growth\": scan_db_growth(segment_path),\n    }\n```\n\n**Step 3: Test DB scanning**\n\nRun: `python eval/scripts/analyze_adoption_telemetry.py --segment . --days 7 --out /tmp/test_metrics.json`\nExpected: db_growth field with size and file count\n\n**Step 4: Verify DB metrics**\n\nRun: `cat /tmp/test_metrics.json | jq '.db_growth'`\nExpected: Shows total_size_mb, file_count, and file details\n\n### 🔳 CHECKPOINT 5: Session Resume\n\n**State after Task 5:**\n- `scan_db_growth()` function added\n- Scans `.trifecta/cache/ast_cache_*.db` files\n- Returns: db_exists, total_size_mb, file_count, files[]\n- Each file entry: name, size_mb, modified timestamp\n\n**To resume in new session:**\n```bash\ncd .worktrees/wo0013-ast-adoption-observability\n\n# Verify DB growth scan works\npython eval/scripts/analyze_adoption_telemetry.py --segment . --days 7 --out /tmp/verify.json\ncat /tmp/verify.json | jq '.db_growth'\n\n# Continue with Task 6\n```\n\n**Next task:** Task 6 - Add Analysis Period Metadata\n\n---\n\n## Task 6: Add Analysis Period Metadata\n\n**Files:**\n- Modify: `eval/scripts/analyze_adoption_telemetry.py`\n\n**Step 1: Add period calculation to main**\n\nUpdate the main function to add period metadata:\n\n```python\ndef main():\n    parser = argparse.ArgumentParser(description=\"Analyze AST cache adoption from telemetry\")\n    parser.add_argument(\"--segment\", default=\".\", help=\"Segment path (default: .)\")\n    parser.add_argument(\"--days\", type=int, default=7, help=\"Days to analyze (default: 7)\")\n    parser.add_argument(\"--out\", required=True, help=\"Output JSON path\")\n    parser.add_argument(\n        \"--telemetry-file\",\n        default=\"_ctx/telemetry/events.jsonl\",\n        help=\"Path to events.jsonl\"\n    )\n    args = parser.parse_args()\n\n    segment_path = Path(args.segment).resolve()\n    telemetry_path = segment_path / args.telemetry_file\n\n    if not telemetry_path.exists():\n        logging.error(f\"Telemetry file not found: {telemetry_path}\")\n        sys.exit(1)\n\n    # Calculate analysis period\n    end_time = datetime.now()\n    start_time = end_time - timedelta(days=args.days)\n\n    logging.info(f\"Loading telemetry from {telemetry_path}...\")\n    all_events = load_telemetry_events(telemetry_path)\n\n    logging.info(f\"Filtering events from last {args.days} days...\")\n    events = filter_events_by_days(all_events, args.days)\n\n    logging.info(f\"Analyzing {len(events)} events...\")\n    metrics = analyze_adoption_metrics(events, segment_path)\n\n    # Add metadata\n    metrics[\"analysis_period\"] = {\n        \"start\": start_time.isoformat(),\n        \"end\": end_time.isoformat(),\n        \"days_analyzed\": args.days,\n        \"total_events\": len(events),\n        \"segment_path\": str(segment_path)\n    }\n\n    out_path = Path(args.out)\n    out_path.parent.mkdir(parents=True, exist_ok=True)\n\n    with open(out_path, \"w\") as f:\n        json.dump(metrics, f, indent=2)\n\n    logging.info(f\"Metrics written to {out_path}\")\n    print(json.dumps(metrics, indent=2))\n```\n\n**Step 2: Test metadata inclusion**\n\nRun: `python eval/scripts/analyze_adoption_telemetry.py --segment . --days 7 --out /tmp/test_metrics.json`\nExpected: analysis_period field with start/end times\n\n**Step 3: Verify period calculation**\n\nRun: `cat /tmp/test_metrics.json | jq '.analysis_period'`\nExpected: Shows start, end, days_analyzed, total_events\n\n### 🔳 CHECKPOINT 6: Session Resume\n\n**State after Task 6:**\n- Analysis period metadata added to output\n- Tracks: start, end, days_analyzed, total_events, segment_path\n- Full script implementation complete (all analysis functions working)\n\n**To resume in new session:**\n```bash\ncd .worktrees/wo0013-ast-adoption-observability\n\n# Verify complete script works\npython eval/scripts/analyze_adoption_telemetry.py --segment . --days 7 --out /tmp/verify.json\ncat /tmp/verify.json | jq .\n\n# Continue with Task 7\n```\n\n**Next task:** Task 7 - Generate Initial Metrics and Report\n\n---\n\n## Task 7: Generate Initial Metrics and Report\n\n**Files:**\n- Create: `_ctx/metrics/wo0013_adoption_baseline.json`\n- Create: `docs/reports/wo0013_adoption_observability.md`\n\n**Step 1: Run analysis to generate baseline metrics**\n\nRun: `python eval/scripts/analyze_adoption_telemetry.py --segment . --days 7 --out _ctx/metrics/wo0013_adoption_baseline.json`\nExpected: JSON metrics written to _ctx/metrics/\n\n**Step 2: Create audit report template**\n\nCreate `docs/reports/wo0013_adoption_observability.md`:\n\n```markdown\n# WO-0013: AST Persist Adoption Observability Report\n\n## Evidence Header\n- **WO**: WO-0013\n- **SHA**: `<commit SHA after completion>`\n- **Analysis Date**: `{date}`\n- **Data Source**: `_ctx/telemetry/events.jsonl`\n- **Analysis Period**: `{start} to {end}`\n- **Method**: Telemetry event analysis via `analyze_adoption_telemetry.py`\n\n---\n\n## Executive Summary\n\n<!-- Fill after running analysis -->\n\n## Backend Distribution\n\n| Backend | Runs | Percentage |\n|---------|------|------------|\n<!-- Fill from metrics -->\n\n## Cache Effectiveness\n\n| Backend | Hit Rate | Hits | Misses |\n|---------|----------|------|--------|\n<!-- Fill from metrics -->\n\n## Lock Contention\n\n| Metric | Value |\n|--------|-------|\n| Total Lock Waits | `{value}` |\n| Avg Wait Time | `{value} ms` |\n| Timeouts | `{value}` |\n| Timeout Rate | `{value}%` |\n\n## Database Growth\n\n| Metric | Value |\n|--------|-------|\n| DB Exists | `{yes/no}` |\n| Total Size | `{value} MB` |\n| File Count | `{value}` |\n\n## Anomalies Detected\n\n<!-- List any issues found -->\n\n## Recommendations\n\n<!-- Actionable insights based on findings -->\n\n---\n\n## Appendix: Full Metrics\n\nSee `_ctx/metrics/wo0013_adoption_baseline.json` for complete data.\n```\n\n**Step 3: Fill report with actual metrics**\n\nRun: `cat _ctx/metrics/wo0013_adoption_baseline.json | jq .`\nExpected: Review metrics and manually update the markdown report\n\n### 🔳 CHECKPOINT 7: Session Resume\n\n**State after Task 7:**\n- Baseline metrics generated at `_ctx/metrics/wo0013_adoption_baseline.json`\n- Report template created at `docs/reports/wo0013_adoption_observability.md`\n- Report needs to be filled with actual metrics from baseline JSON\n\n**To resume in new session:**\n```bash\ncd .worktrees/wo0013-ast-adoption-observability\n\n# Verify baseline exists\ncat _ctx/metrics/wo0013_adoption_baseline.json | jq .\n\n# Continue with Task 8\n```\n\n**Next task:** Task 8 - Write Unit Tests\n\n---\n\n## Task 8: Write Unit Tests\n\n**Files:**\n- Create: `tests/unit/test_analyze_adoption_telemetry.py`\n\n**Step 1: Create test file with basic structure**\n\n```python\nimport json\nimport pytest\nfrom pathlib import Path\nfrom eval.scripts.analyze_adoption_telemetry import (\n    analyze_backend_distribution,\n    analyze_cache_effectiveness,\n    analyze_lock_contention,\n    filter_events_by_days,\n)\n\n\n@pytest.fixture\ndef sample_events():\n    \"\"\"Sample telemetry events for testing.\"\"\"\n    return [\n        {\n            \"ts\": \"2026-01-09T12:00:00Z\",\n            \"cmd\": \"ast.symbols\",\n            \"result\": {\"backend\": \"FileLockedAstCache\", \"status\": \"ok\"},\n        },\n        {\n            \"ts\": \"2026-01-09T12:01:00Z\",\n            \"cmd\": \"ast.cache.hit\",\n            \"result\": {\"backend\": \"FileLockedAstCache\"},\n        },\n        {\n            \"ts\": \"2026-01-09T12:02:00Z\",\n            \"cmd\": \"ast.cache.miss\",\n            \"result\": {\"backend\": \"FileLockedAstCache\"},\n        },\n        {\n            \"ts\": \"2026-01-09T12:03:00Z\",\n            \"cmd\": \"ast.symbols\",\n            \"result\": {\"backend\": \"InMemoryLRUCache\", \"status\": \"ok\"},\n        },\n    ]\n\n\ndef test_backend_distribution_counts_correctly(sample_events):\n    \"\"\"Test that backend distribution is calculated correctly.\"\"\"\n    result = analyze_backend_distribution(sample_events)\n\n    assert result[\"total_runs\"] == 2\n    assert result[\"by_backend\"][\"FileLockedAstCache\"][\"count\"] == 1\n    assert result[\"by_backend\"][\"InMemoryLRUCache\"][\"count\"] == 1\n    assert result[\"adoption_rate\"] == 50.0\n\n\ndef test_cache_effectiveness_calculates_hit_rate(sample_events):\n    \"\"\"Test that cache hit rate is calculated correctly.\"\"\"\n    result = analyze_cache_effectiveness(sample_events)\n\n    assert \"FileLockedAstCache\" in result\n    assert result[\"FileLockedAstCache\"][\"hits\"] == 1\n    assert result[\"FileLockedAstCache\"][\"misses\"] == 1\n    assert result[\"FileLockedAstCache\"][\"hit_rate\"] == 0.5\n\n\ndef test_lock_contention_handles_no_events():\n    \"\"\"Test that lock contention handles empty event list.\"\"\"\n    result = analyze_lock_contention([])\n\n    assert result[\"lock_waits\"][\"total_waits\"] == 0\n    assert result[\"timeouts\"][\"count\"] == 0\n\n\ndef test_filter_events_by_days_filters_correctly():\n    \"\"\"Test time-based filtering.\"\"\"\n    events = [\n        {\"ts\": \"2026-01-01T12:00:00Z\"},\n        {\"ts\": \"2026-01-09T12:00:00Z\"},\n    ]\n\n    # Filter for last 1 day (should only keep recent event)\n    result = filter_events_by_days(events, days=1)\n\n    assert len(result) == 1\n    assert result[0][\"ts\"] == \"2026-01-09T12:00:00Z\"\n```\n\n**Step 2: Run tests to verify they pass**\n\nRun: `uv run pytest tests/unit/test_analyze_adoption_telemetry.py -v`\nExpected: All tests PASS\n\n### 🔳 CHECKPOINT 8: Session Resume\n\n**State after Task 8:**\n- Unit test file created at `tests/unit/test_analyze_adoption_telemetry.py`\n- 4 test cases covering: backend distribution, cache effectiveness, lock contention, time filtering\n- All tests passing\n\n**To resume in new session:**\n```bash\ncd .worktrees/wo0013-ast-adoption-observability\n\n# Verify tests pass\nuv run pytest tests/unit/test_analyze_adoption_telemetry.py -v\n\n# Continue with Task 9\n```\n\n**Next task:** Task 9 - Update Session Documentation\n\n---\n\n## Task 9: Update Session Documentation\n\n**Files:**\n- Modify: `_ctx/session_trifecta_dope.md`\n\n**Step 1: Append session entry**\n\nAdd to end of `_ctx/session_trifecta_dope.md`:\n\n```markdown\n## YYYY-MM-DD HH:MM UTC - WO-0013 COMPLETE\n- **Summary**: AST Persist Adoption Observability implemented\n- **Files Created**:\n  - `eval/scripts/analyze_adoption_telemetry.py` - Main analysis script\n  - `docs/reports/wo0013_adoption_observability.md` - Audit report\n  - `tests/unit/test_analyze_adoption_telemetry.py` - Unit tests\n- **Commands**:\n  - `python eval/scripts/analyze_adoption_telemetry.py --segment . --days 7 --out _ctx/metrics/wo0013_adoption_baseline.json`\n- **Evidence**: _ctx/metrics/wo0013_adoption_baseline.json\n- **Metrics**:\n  - Backend adoption: {X}% FileLockedAstCache\n  - Cache effectiveness: {X}% hit rate\n  - Lock contention: {X} timeout events\n  - DB size: {X} MB\n- **Tests**: 4/4 unit tests PASS\n- **Next**: Monitor adoption trends over time, re-run analysis weekly\n```\n\n**Step 2: Verify session update**\n\nRun: `tail -20 _ctx/session_trifecta_dope.md`\nExpected: New session entry visible\n\n### 🔳 CHECKPOINT 9: Session Resume\n\n**State after Task 9:**\n- Session documentation updated in `_ctx/session_trifecta_dope.md`\n- WO-0013 completion entry added with summary, files, commands, metrics\n\n**To resume in new session:**\n```bash\ncd .worktrees/wo0013-ast-adoption-observability\n\n# Verify session entry\ntail -20 _ctx/session_trifecta_dope.md\n\n# Continue with Task 10\n```\n\n**Next task:** Task 10 - Final Verification and Commit\n\n---\n\n## Task 10: Final Verification and Commit\n\n**Files:**\n- Git add and commit all changes\n\n**Step 1: Run all tests**\n\nRun: `uv run pytest -q tests/unit/test_analyze_adoption_telemetry.py tests/integration/test_ast_cache_telemetry.py`\nExpected: All tests PASS\n\n**Step 2: Verify script execution**\n\nRun: `python eval/scripts/analyze_adoption_telemetry.py --segment . --days 7 --out _ctx/metrics/wo0013_verify.json && cat _ctx/metrics/wo0013_verify.json | jq .analysis_period`\nExpected: Valid JSON with analysis_period field\n\n**Step 3: Move WO to done**\n\nRun: `mv _ctx/jobs/pending/WO-0013.yaml _ctx/jobs/done/WO-0013.yaml`\nExpected: File moved to done/\n\n**Step 4: Update WO with completion SHA**\n\nEdit `_ctx/jobs/done/WO-0013.yaml`:\n- Set `verified_at_sha` to actual commit SHA\n- Set `closed_at` to current timestamp\n\n**Step 5: Commit all changes**\n\n```bash\ngit add eval/scripts/analyze_adoption_telemetry.py\ngit add docs/reports/wo0013_adoption_observability.md\ngit add tests/unit/test_analyze_adoption_telemetry.py\ngit add _ctx/jobs/done/WO-0013.yaml\ngit add _ctx/session_trifecta_dope.md\ngit add _ctx/metrics/wo0013_adoption_baseline.json\n\ngit commit -m \"feat(wo0013): add AST adoption observability\n\n- Added analyze_adoption_telemetry.py script\n- Tracks backend distribution, cache effectiveness, lock contention\n- Added unit tests for analysis functions\n- Generated baseline adoption report\n- WO-0013 COMPLETE\"\n```\n\n**Step 6: Verify commit**\n\nRun: `git log -1 --stat`\nExpected: Shows all modified/created files\n\n### ✅ FINAL CHECKPOINT: WO-0013 COMPLETE\n\n**State after Task 10:**\n- All tests passing\n- Script verified working\n- WO moved to done/ with SHA\n- Git commit created with all files\n- Worktree ready for cleanup\n\n**To continue after merge:**\n```bash\n# After PR merge, cleanup worktree\ngit worktree remove .worktrees/wo0013-ast-adoption-observability\n\n# Delete local branch\ngit branch -d wo0013-ast-adoption-observability\n```\n\n---\n\n## Verification Checklist\n\nAfter implementation, verify:\n\n- [ ] Script runs without errors: `python eval/scripts/analyze_adoption_telemetry.py --segment . --days 7 --out /tmp/test.json`\n- [ ] Output is valid JSON: `cat /tmp/test.json | jq .`\n- [ ] All required fields present: backend_distribution, cache_effectiveness, lock_contention, db_growth\n- [ ] Unit tests pass: `pytest tests/unit/test_analyze_adoption_telemetry.py -v`\n- [ ] Integration tests pass: `pytest tests/integration/test_ast_cache_telemetry.py -v`\n- [ ] Report generated: `ls -la docs/reports/wo0013_adoption_observability.md`\n- [ ] Session updated: `grep \"WO-0013\" _ctx/session_trifecta_dope.md`\n- [ ] WO moved to done: `ls _ctx/jobs/done/WO-0013.yaml`\n- [ ] Git commit created with all files\n\n---\n\n## Usage Examples\n\nAfter implementation:\n\n```bash\n# Analyze last 7 days\npython eval/scripts/analyze_adoption_telemetry.py --segment . --days 7 --out _ctx/metrics/wo0013_adoption.json\n\n# Analyze last 30 days\npython eval/scripts/analyze_adoption_telemetry.py --segment . --days 30 --out _ctx/metrics/wo0013_adoption_30d.json\n\n# View metrics\ncat _ctx/metrics/wo0013_adoption.json | jq .\n\n# Check adoption rate\ncat _ctx/metrics/wo0013_adoption.json | jq '.backend_distribution.adoption_rate'\n```\n",
+      "char_count": 29233,
+      "token_est": 7308,
+      "source_path": "2026-01-09-wo0013-ast-adoption-observability.md",
+      "chunking_method": "whole_file"
+    },
     {
       "id": "repo:docs/plans/2026-01-02-auditability-gates-v2-antipatterns.md:a825638827",
       "doc": "repo:docs/plans/2026-01-02-auditability-gates-v2-antipatterns.md",
@@ -3726,6 +3852,18 @@
       "source_path": "field_exercises_guide.md",
       "chunking_method": "whole_file"
     },
+    {
+      "id": "repo:docs/reports/code_complexity_analysis.md:b726570e50",
+      "doc": "repo:docs/reports/code_complexity_analysis.md",
+      "title_path": [
+        "code_complexity_analysis.md"
+      ],
+      "text": "# Code Complexity Analysis Report\n\n**Date:** 2026-01-09\n**Analyzed Files:**\n- `/Users/felipe_gonzalez/Developer/agent_h/trifecta_dope/eval/scripts/analyze_adoption_telemetry.py`\n- `/Users/felipe_gonzalez/Developer/agent_h/trifecta_dope/scripts/ctx_wo_take.py`\n- `/Users/felipe_gonzalez/Developer/agent_h/trifecta_dope/scripts/helpers.py`\n\n---\n\n## Executive Summary\n\n| File | Lines | Main Function Length | Max Nesting | Complexity | Priority Issues |\n|------|-------|---------------------|-------------|------------|-----------------|\n| `ctx_wo_take.py` | 221 | 177 lines (lines 40-216) | 4 levels | ~15 paths | **HIGH** |\n| `helpers.py` | 352 | 88 lines (create_worktree) | 3 levels | ~8 paths | **MEDIUM** |\n| `analyze_adoption_telemetry.py` | 95 | N/A (placeholder) | 1 level | <5 paths | **LOW** |\n\n**Key Findings:**\n- **1 function** exceeds 150 lines (ctx_wo_take.main)\n- **2 duplicate code patterns** identified\n- **2 magic numbers** not extracted to constants\n- **1 import statement** misplaced (should be at module level)\n- **8 refactoring opportunities** with clear impact/risk profile\n\n---\n\n## Detailed Analysis\n\n### 1. ctx_wo_take.py (221 lines)\n\n#### Issue 1.1: Oversized main() Function\n**Location:** Lines 40-216 (177 lines)\n**Problem:** The `main()` function does too much, violating Single Responsibility Principle.\n\n**Responsibilities mixed in main():**\n1. Argument parsing (lines 41-55)\n2. `--list` flag handling (lines 57-76)\n3. `--status` flag handling (lines 78-102)\n4. WO ID validation (lines 104-120)\n5. Schema validation (lines 122-138)\n6. Lock management (lines 140-160)\n7. Branch/worktree auto-generation (lines 162-185)\n8. Worktree creation (lines 186-195)\n9. File operations (lines 197-201)\n10. Success message display (lines 203-215)\n\n**Metrics:**\n- **Cyclomatic Complexity:** ~15 (target: <10)\n- **Nesting Depth:** 4 levels (target: <3)\n- **Lines:** 177 (target: <50)\n\n**Impact:**\n- Difficult to test individual flag handlers\n- High cognitive load for maintainers\n- Error-prone due to length and complexity\n\n---\n\n#### Issue 1.2: Duplicate Status Counting Pattern\n**Location:** Lines 83-86\n\n**Current Code:**\n```python\npending = len(list((jobs_dir / \"pending\").glob(\"WO-*.yaml\"))) if (jobs_dir / \"pending\").exists() else 0\nrunning = len(list((jobs_dir / \"running\").glob(\"WO-*.yaml\"))) if (jobs_dir / \"running\").exists() else 0\ndone = len(list((jobs_dir / \"done\").glob(\"WO-*.yaml\"))) if (jobs_dir / \"done\").exists() else 0\nfailed = len(list((jobs_dir / \"failed\").glob(\"WO-*.yaml\"))) if (jobs_dir / \"failed\").exists() else 0\n```\n\n**Problem:** Exact same pattern repeated 4 times with only the directory name changing.\n\n**Metrics:**\n- **Duplication:** 4 instances\n- **Lines per instance:** 1 (but dense, 80 chars+)\n\n---\n\n#### Issue 1.3: Magic Number - Lock Age\n**Location:** Lines 146-147\n\n**Current Code:**\n```python\nif check_lock_age(lock_path, max_age_seconds=3600):\n    logger.info(f\"Found stale lock (>1 hour), removing: {lock_path}\")\n```\n\n**Problems:**\n1. Magic number `3600` not explained\n2. Hardcoded \"1 hour\" in log message (must match constant)\n3. Same constant used in helpers.py line 335 (duplication)\n\n---\n\n#### Issue 1.4: Misplaced Import Statement\n**Location:** Line 112\n\n**Current Code:**\n```python\nimport re\nif not re.match(r\"^WO-\\d{4}$\", wo_id):\n```\n\n**Problem:** Import statement in middle of function, violates PEP 8.\n\n**Impact:** Low (functional), but reduces code clarity and violates conventions.\n\n---\n\n#### Issue 1.5: Complex Branch/Worktree Auto-Generation\n**Location:** Lines 172-184\n\n**Current Code:**\n```python\nif branch is None or worktree is None:\n    auto_branch = get_branch_name(wo_id)\n    auto_worktree = get_worktree_path(wo_id, root)\n    logger.info(f\"Auto-generated configuration:\")\n    logger.info(f\"  branch: {auto_branch}\")\n    logger.info(f\"  worktree: {auto_worktree}\")\n\n    if branch is None:\n        branch = auto_branch\n        wo[\"branch\"] = branch\n    if worktree is None:\n        worktree = str(auto_worktree.relative_to(root))\n        wo[\"worktree\"] = worktree\n```\n\n**Problem:**\n- Nested conditional logic\n- Mixed concerns (logging + assignment)\n- Partial update pattern (could be atomic)\n\n**Metrics:**\n- **Nesting:** 2 levels\n- **Complexity:** 3 paths through this section\n\n---\n\n### 2. helpers.py (352 lines)\n\n#### Issue 2.1: Oversized create_worktree() Function\n**Location:** Lines 121-208 (88 lines)\n\n**Problem:** Function handles too many responsibilities:\n1. Default value generation (lines 146-153)\n2. Worktree existence checking (lines 155-165)\n3. Default branch detection (line 168)\n4. Branch existence checking (lines 170-187)\n5. Worktree creation (lines 189-205)\n\n**Metrics:**\n- **Lines:** 88 (target: <40)\n- **Cyclomatic Complexity:** ~8 paths\n- **Nesting:** 3 levels\n\n---\n\n#### Issue 2.2: Duplicate Branch Checking Pattern\n**Location:** Lines 172-187\n\n**Current Code:**\n```python\nbranch_exists = False\nlocal_result = run_command([\"git\", \"rev-parse\", \"--verify\", branch], cwd=root, check=False)\nif local_result.returncode == 0:\n    branch_exists = True\n    logger.debug(f\"Branch {branch} exists locally\")\nelse:\n    remote_result = run_command(\n        [\"git\", \"rev-parse\", \"--verify\", f\"origin/{branch}\"],\n        cwd=root,\n        check=False\n    )\n    if remote_result.returncode == 0:\n        branch_exists = True\n        logger.debug(f\"Branch {branch} exists on remote\")\n    else:\n        logger.debug(f\"Branch {branch} does not exist locally or remotely\")\n```\n\n**Problem:** This logic should be extracted to a separate function.\n\n**Metrics:**\n- **Duplication:** Could be reused elsewhere\n- **Nesting:** 3 levels\n- **Lines:** 16 lines (could be 8)\n\n---\n\n#### Issue 2.3: Magic Number in Function Signature\n**Location:** Line 335\n\n**Current Code:**\n```python\ndef check_lock_age(lock_path: Path, max_age_seconds: int = 3600) -> bool:\n```\n\n**Problem:** Default value `3600` should use named constant for consistency with ctx_wo_take.py.\n\n---\n\n#### Issue 2.4: Complex create_lock() Error Handling\n**Location:** Lines 277-332 (56 lines)\n\n**Problem:** Three levels of nested try-except blocks make error flow hard to follow.\n\n**Structure:**\n```python\ndef create_lock():\n    if lock_path.exists():\n        return False\n\n    try:\n        # Create temp file\n        try:\n            # Atomic link\n            try:\n                # Fallback rename\n            except OSError:\n                # Cleanup\n        except OSError:\n            # Cleanup\n    except Exception:\n        # Cleanup\n```\n\n**Metrics:**\n- **Nesting:** 3 levels (target: <2)\n- **Lines:** 56 (target: <30)\n\n---\n\n### 3. analyze_adoption_telemetry.py (95 lines)\n\n#### Status: INCOMPLETE\n\n**Current State:**\n- Placeholder `analyze_adoption_metrics()` function (lines 86-89)\n- Main flow is simple and well-structured\n- No complexity issues in existing code\n\n**Recommendation:**\n- Complete the 4 analysis functions mentioned in the task\n- Apply complexity controls during implementation\n\n---\n\n## Refactoring Recommendations\n\n### Priority 1: High Impact, Low Risk\n\n#### 1.1 Extract Duplicate Status Counting\n**File:** `ctx_wo_take.py`\n**Location:** Lines 83-86\n**Risk:** LOW (pure extraction, no logic change)\n\n**Current Code:**\n```python\npending = len(list((jobs_dir / \"pending\").glob(\"WO-*.yaml\"))) if (jobs_dir / \"pending\").exists() else 0\nrunning = len(list((jobs_dir / \"running\").glob(\"WO-*.yaml\"))) if (jobs_dir / \"running\").exists() else 0\ndone = len(list((jobs_dir / \"done\").glob(\"WO-*.yaml\"))) if (jobs_dir / \"done\").exists() else 0\nfailed = len(list((jobs_dir / \"failed\").glob(\"WO-*.yaml\"))) if (jobs_dir / \"failed\").exists() else 0\n```\n\n**Refactored Code:**\n```python\ndef count_work_orders(jobs_dir: Path, status: str) -> int:\n    \"\"\"Count work orders in a status directory.\n\n    Args:\n        jobs_dir: Base jobs directory path\n        status: Status subdirectory name (e.g., 'pending', 'running')\n\n    Returns:\n        Count of WO-*.yaml files, or 0 if directory doesn't exist\n    \"\"\"\n    status_dir = jobs_dir / status\n    return len(list(status_dir.glob(\"WO-*.yaml\"))) if status_dir.exists() else 0\n\n\n# In handle_status_flag():\npending = count_work_orders(jobs_dir, \"pending\")\nrunning = count_work_orders(jobs_dir, \"running\")\ndone = count_work_orders(jobs_dir, \"done\")\nfailed = count_work_orders(jobs_dir, \"failed\")\n```\n\n**Benefits:**\n- Eliminates 4-line duplication\n- Improves testability (unit testable)\n- Self-documenting function name\n- Easier to extend (add error handling, logging)\n\n---\n\n#### 1.2 Extract MAX_LOCK_AGE_SECONDS Constant\n**File:** `ctx_wo_take.py`, `helpers.py`\n**Location:** Lines 146-147 (ctx_wo_take.py), line 335 (helpers.py)\n**Risk:** LOW (pure refactoring, no behavior change)\n\n**Current Code:**\n```python\n# ctx_wo_take.py line 146\nif check_lock_age(lock_path, max_age_seconds=3600):\n    logger.info(f\"Found stale lock (>1 hour), removing: {lock_path}\")\n\n# helpers.py line 335\ndef check_lock_age(lock_path: Path, max_age_seconds: int = 3600) -> bool:\n```\n\n**Refactored Code:**\n```python\n# Add to top of both files\nMAX_LOCK_AGE_SECONDS = 3600  # 1 hour in seconds\n\n# ctx_wo_take.py usage\nif check_lock_age(lock_path, max_age_seconds=MAX_LOCK_AGE_SECONDS):\n    hours = MAX_LOCK_AGE_SECONDS // 3600\n    logger.info(f\"Found stale lock (>{hours} hour), removing: {lock_path}\")\n\n# helpers.py usage\ndef check_lock_age(lock_path: Path, max_age_seconds: int = MAX_LOCK_AGE_SECONDS) -> bool:\n```\n\n**Benefits:**\n- Single source of truth\n- Self-documenting\n- Easy to change (one location)\n- Log message derives from constant (prevents drift)\n\n---\n\n#### 1.3 Fix Import Statement Placement\n**File:** `ctx_wo_take.py`\n**Location:** Line 112\n**Risk:** MINIMAL (PEP 8 compliance)\n\n**Current Code:**\n```python\ndef main():\n    # ... 100 lines of code ...\n    import re\n    if not re.match(r\"^WO-\\d{4}$\", wo_id):\n```\n\n**Refactored Code:**\n```python\n#!/usr/bin/env python3\nimport argparse\nimport re  # ← Move to top\n# ... other imports ...\n```\n\n**Benefits:**\n- Follows PEP 8\n- Improves code scanning readability\n- Standard Python convention\n\n---\n\n#### 1.4 Extract Branch Existence Check\n**File:** `helpers.py`\n**Location:** Lines 172-187\n**Risk:** LOW (pure extraction, no logic change)\n\n**Current Code:**\n```python\nbranch_exists = False\nlocal_result = run_command([\"git\", \"rev-parse\", \"--verify\", branch], cwd=root, check=False)\nif local_result.returncode == 0:\n    branch_exists = True\n    logger.debug(f\"Branch {branch} exists locally\")\nelse:\n    remote_result = run_command(\n        [\"git\", \"rev-parse\", \"--verify\", f\"origin/{branch}\"],\n        cwd=root,\n        check=False\n    )\n    if remote_result.returncode == 0:\n        branch_exists = True\n        logger.debug(f\"Branch {branch} exists on remote\")\n    else:\n        logger.debug(f\"Branch {branch} does not exist locally or remotely\")\n```\n\n**Refactored Code:**\n```python\ndef branch_exists(branch: str, root: Path) -> bool:\n    \"\"\"Check if a branch exists locally or remotely.\n\n    Args:\n        branch: Branch name to check\n        root: Repository root path\n\n    Returns:\n        True if branch exists locally or on remote, False otherwise\n    \"\"\"\n    # Check local first\n    local_result = run_command(\n        [\"git\", \"rev-parse\", \"--verify\", branch],\n        cwd=root,\n        check=False\n    )\n    if local_result.returncode == 0:\n        logger.debug(f\"Branch {branch} exists locally\")\n        return True\n\n    # Check remote\n    remote_result = run_command(\n        [\"git\", \"rev-parse\", \"--verify\", f\"origin/{branch}\"],\n        cwd=root,\n        check=False\n    )\n    if remote_result.returncode == 0:\n        logger.debug(f\"Branch {branch} exists on remote\")\n        return True\n\n    logger.debug(f\"Branch {branch} does not exist locally or remotely\")\n    return False\n\n\n# In create_worktree():\nif branch_exists(branch, root):\n    logger.info(f\"  Branch {branch} already exists, using it\")\n```\n\n**Benefits:**\n- Reduces create_worktree() from 88 to 72 lines\n- Testable in isolation\n- Reusable across codebase\n- Clearer intent\n\n---\n\n### Priority 2: High Impact, Medium Risk\n\n#### 2.1 Split main() into Handler Functions\n**File:** `ctx_wo_take.py`\n**Location:** Lines 40-216 (177 lines)\n**Risk:** MEDIUM (requires careful extraction, testing)\n\n**Current Code Structure:**\n```python\ndef main():\n    # Parse args\n    # Handle --list (20 lines)\n    # Handle --status (25 lines)\n    # Handle WO take (130 lines)\n```\n\n**Refactored Code:**\n```python\ndef handle_list_flag(root: Path) -> int:\n    \"\"\"Handle --list flag: display pending work orders.\"\"\"\n    pending_dir = root / \"_ctx\" / \"jobs\" / \"pending\"\n    if not pending_dir.exists():\n        print(f\"Pending directory not found: {pending_dir}\")\n        return 0\n\n    wos = sorted(pending_dir.glob(\"WO-*.yaml\"))\n    if wos:\n        print(\"━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\")\n        print(\"   Pending Work Orders\")\n        print(\"━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\")\n        for wo_file in wos:\n            wo_data = load_yaml(wo_file)\n            priority = wo_data.get(\"priority\", \"?\")\n            title = wo_data.get(\"title\", wo_data.get(\"id\", \"\"))\n            print(f\"  {wo_file.stem} [{priority}] - {title}\")\n        print(f\"\\nTotal: {len(wos)}\")\n    else:\n        print(\"No pending work orders found.\")\n\n    return 0\n\n\ndef handle_status_flag(root: Path) -> int:\n    \"\"\"Handle --status flag: display system status.\"\"\"\n    jobs_dir = root / \"_ctx\" / \"jobs\"\n\n    pending = count_work_orders(jobs_dir, \"pending\")\n    running = count_work_orders(jobs_dir, \"running\")\n    done = count_work_orders(jobs_dir, \"done\")\n    failed = count_work_orders(jobs_dir, \"failed\")\n\n    print(\"━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\")\n    print(\"   System Status\")\n    print(\"━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\")\n    print(f\"  Pending:   {pending}\")\n    print(f\"  Running:   {running}\")\n    print(f\"  Done:      {done}\")\n    print(f\"  Failed:    {failed}\")\n\n    # Show active worktrees\n    result = run_command([\"git\", \"worktree\", \"list\"], cwd=root, check=False)\n    if result.returncode == 0:\n        print(\"\\nActive worktrees:\")\n        for line in result.stdout.splitlines()[1:]:  # Skip header\n            print(f\"  {line}\")\n\n    return 0\n\n\ndef handle_take_wo(root: Path, wo_id: str, owner: str | None) -> int:\n    \"\"\"Handle work order take operation.\"\"\"\n    # Validate WO ID format\n    if not re.match(r\"^WO-\\d{4}$\", wo_id):\n        logger.error(f\"Invalid WO ID format: {wo_id} (expected: WO-XXXX)\")\n        return 1\n\n    job_path = root / \"_ctx\" / \"jobs\" / \"pending\" / f\"{wo_id}.yaml\"\n    if not job_path.exists():\n        logger.error(f\"Work order not found: {job_path}\")\n        return 1\n\n    # Load and validate WO\n    logger.info(f\"Loading work order: {wo_id}\")\n    wo = load_yaml(job_path)\n\n    schema = load_schema(root, \"work_order.schema.json\")\n    try:\n        validate(instance=wo, schema=schema)\n    except Exception as e:\n        logger.error(f\"Schema validation failed: {e}\")\n        return 1\n\n    # Validate epic_id\n    backlog = load_yaml(root / \"_ctx\" / \"backlog\" / \"backlog.yaml\")\n    epic_ids = {e.get(\"id\") for e in backlog.get(\"epics\", [])}\n    if wo.get(\"epic_id\") not in epic_ids:\n        logger.error(f\"Unknown epic_id: {wo.get('epic_id')}\")\n        return 1\n\n    # Lock management\n    running_dir = root / \"_ctx\" / \"jobs\" / \"running\"\n    running_dir.mkdir(parents=True, exist_ok=True)\n    lock_path = running_dir / f\"{wo_id}.lock\"\n\n    if lock_path.exists():\n        if check_lock_age(lock_path, max_age_seconds=MAX_LOCK_AGE_SECONDS):\n            logger.info(f\"Found stale lock (>{MAX_LOCK_AGE_SECONDS//3600} hour), removing: {lock_path}\")\n            lock_path.unlink()\n        else:\n            lock_content = lock_path.read_text()\n            logger.error(f\"Work order is locked: {wo_id}\")\n            logger.error(f\"Lock info:\\n{lock_content}\")\n            return 1\n\n    # Create atomic lock\n    logger.info(f\"Acquiring lock for {wo_id}...\")\n    if not create_lock(lock_path, wo_id):\n        logger.error(f\"Failed to acquire lock for {wo_id}\")\n        return 1\n    logger.info(f\"✓ Lock acquired: {lock_path}\")\n\n    # Update WO metadata and create worktree\n    try:\n        finalize_work_order_take(root, wo, wo_id, owner)\n    except Exception as e:\n        logger.error(f\"Failed to create worktree: {e}\")\n        lock_path.unlink()\n        logger.info(f\"Rolled back: lock removed, WO remains in pending\")\n        return 1\n\n    # Display success\n    display_success_message(wo_id, wo, owner or getpass.getuser())\n    return 0\n\n\ndef main():\n    \"\"\"Main entry point for WO take script.\"\"\"\n    parser = argparse.ArgumentParser(\n        description=\"Take a work order and create isolated worktree\",\n        epilog=\"\"\"\nExamples:\n  python ctx_wo_take.py WO-0001           # Take WO-0001 (auto-generates branch & worktree)\n  python ctx_wo_take.py WO-0001 --owner   # Take with current user as owner\n  python ctx_wo_take.py --list            # List pending work orders\n        \"\"\"\n    )\n    parser.add_argument(\"wo_id\", nargs=\"?\", help=\"Work order id, e.g. WO-0001\")\n    parser.add_argument(\"--root\", default=\".\", help=\"Repo root (default: current directory)\")\n    parser.add_argument(\"--owner\", default=None, help=\"Owner name (default: current user)\")\n    parser.add_argument(\"--list\", action=\"store_true\", help=\"List pending work orders\")\n    parser.add_argument(\"--status\", action=\"store_true\", help=\"Show system status\")\n    args = parser.parse_args()\n\n    root = Path(args.root).resolve()\n\n    # Route to appropriate handler\n    if args.list:\n        return handle_list_flag(root)\n    if args.status:\n        return handle_status_flag(root)\n    if not args.wo_id:\n        parser.print_help()\n        return 0\n\n    return handle_take_wo(root, args.wo_id, args.owner)\n```\n\n**Benefits:**\n- **Reduces main() from 177 to ~40 lines**\n- Each handler is independently testable\n- Clear separation of concerns\n- Easier to add new flags/handlers\n- Reduced cognitive load\n\n**Metrics:**\n- **Lines per function:** <50 (down from 177)\n- **Cyclomatic complexity:** <5 per function (down from ~15)\n- **Testability:** High (each handler can be unit tested)\n\n---\n\n#### 2.2 Extract Branch/Worktree Auto-Generation\n**File:** `ctx_wo_take.py`\n**Location:** Lines 172-184\n**Risk:** MEDIUM (requires careful handling of partial updates)\n\n**Current Code:**\n```python\nif branch is None or worktree is None:\n    auto_branch = get_branch_name(wo_id)\n    auto_worktree = get_worktree_path(wo_id, root)\n    logger.info(f\"Auto-generated configuration:\")\n    logger.info(f\"  branch: {auto_branch}\")\n    logger.info(f\"  worktree: {auto_worktree}\")\n\n    if branch is None:\n        branch = auto_branch\n        wo[\"branch\"] = branch\n    if worktree is None:\n        worktree = str(auto_worktree.relative_to(root))\n        wo[\"worktree\"] = worktree\n```\n\n**Refactored Code:**\n```python\ndef auto_generate_config(\n    wo: dict,\n    wo_id: str,\n    root: Path\n) -> tuple[str, str]:\n    \"\"\"Auto-generate branch and worktree if not specified.\n\n    Args:\n        wo: Work order dict (will be updated in-place)\n        wo_id: Work order ID\n        root: Repository root path\n\n    Returns:\n        Tuple of (branch_name, worktree_path)\n    \"\"\"\n    branch = wo.get(\"branch\")\n    worktree = wo.get(\"worktree\")\n\n    if branch is None or worktree is None:\n        auto_branch = get_branch_name(wo_id)\n        auto_worktree = get_worktree_path(wo_id, root)\n\n        logger.info(f\"Auto-generated configuration:\")\n        logger.info(f\"  branch: {auto_branch}\")\n        logger.info(f\"  worktree: {auto_worktree}\")\n\n        if branch is None:\n            branch = auto_branch\n            wo[\"branch\"] = branch\n        if worktree is None:\n            worktree = str(auto_worktree.relative_to(root))\n            wo[\"worktree\"] = worktree\n\n    return branch, worktree\n\n\n# In handle_take_wo():\nbranch, worktree = auto_generate_config(wo, wo_id, root)\n```\n\n**Benefits:**\n- Isolates complex logic\n- Testable in isolation\n- Clear return contract\n- Reduces nesting in main flow\n\n---\n\n### Priority 3: Medium Impact, Higher Risk\n\n#### 3.1 Split create_worktree() in helpers.py\n**File:** `helpers.py`\n**Location:** Lines 121-208 (88 lines)\n**Risk:** MEDIUM-HIGH (significant refactoring, requires thorough testing)\n\n**Current Structure:**\n```python\ndef create_worktree(root, wo_id, branch, worktree_path):\n    # Generate defaults (if None)  - 8 lines\n    # Check worktree exists        - 11 lines\n    # Get default branch           - 1 line\n    # Check branch exists          - 16 lines\n    # Create worktree              - 16 lines\n```\n\n**Refactored Code:**\n```python\ndef check_worktree_registered(worktree_path: Path, root: Path) -> bool:\n    \"\"\"Check if worktree is already registered with git.\"\"\"\n    result = run_command([\"git\", \"worktree\", \"list\"], cwd=root, check=False)\n    return str(worktree_path) in result.stdout\n\n\ndef ensure_worktree_not_exists(worktree_path: Path, root: Path) -> None:\n    \"\"\"Remove worktree directory if it exists but isn't registered.\n\n    Args:\n        worktree_path: Path to worktree directory\n        root: Repository root path\n\n    Raises:\n        OSError: If directory removal fails\n    \"\"\"\n    if not worktree_path.exists():\n        return\n\n    if check_worktree_registered(worktree_path, root):\n        logger.warning(f\"Worktree already exists: {worktree_path}\")\n\n    logger.info(f\"Removing stale worktree directory: {worktree_path}\")\n    os.rmdir(worktree_path)\n\n\ndef create_worktree(\n    root: Path,\n    wo_id: str,\n    branch: str | None = None,\n    worktree_path: Path | None = None\n) -> tuple[str, Path]:\n    \"\"\"Create a git worktree for the given work order.\n\n    If branch or worktree_path are not provided, they are generated automatically:\n    - branch: feat/wo-WO-XXXX\n    - worktree: .worktrees/WO-XXXX\n\n    Args:\n        root: Repository root path\n        wo_id: Work order ID (e.g., \"WO-0012\")\n        branch: Branch name (auto-generated if None)\n        worktree_path: Worktree path (auto-generated if None)\n\n    Returns:\n        Tuple of (branch_name, worktree_path)\n\n    Raises:\n        subprocess.CalledProcessError: If git commands fail\n    \"\"\"\n    # Generate defaults if not provided\n    if branch is None:\n        branch = get_branch_name(wo_id)\n        logger.info(f\"Auto-generated branch name: {branch}\")\n\n    if worktree_path is None:\n        worktree_path = get_worktree_path(wo_id, root)\n        logger.info(f\"Auto-generated worktree path: {worktree_path}\")\n\n    # Ensure worktree doesn't exist\n    ensure_worktree_not_exists(worktree_path, root)\n\n    # Get the base branch for the new worktree\n    default_branch = git_get_default_branch(root)\n\n    # Create worktree\n    logger.info(f\"Creating worktree for {wo_id}...\")\n    logger.info(f\"  Base branch: {default_branch}\")\n    logger.info(f\"  Worktree path: {worktree_path}\")\n\n    if branch_exists(branch, root):\n        logger.info(f\"  Branch {branch} already exists, using it\")\n        run_command(\n            [\"git\", \"worktree\", \"add\", str(worktree_path), branch],\n            cwd=root\n        )\n    else:\n        logger.info(f\"  Creating new branch {branch} from {default_branch}\")\n        run_command(\n            [\"git\", \"worktree\", \"add\", \"-b\", branch, str(worktree_path), default_branch],\n            cwd=root\n        )\n\n    logger.info(f\"✓ Worktree created: {worktree_path}\")\n    return branch, worktree_path\n```\n\n**Benefits:**\n- **Reduces create_worktree() from 88 to ~55 lines**\n- **Extracts branch_exists() (already defined in 1.4)**\n- **Extracts ensure_worktree_not_exists()** (testable)\n- Reduces nesting depth\n- Each function has single responsibility\n\n---\n\n#### 3.2 Simplify create_lock() Error Handling\n**File:** `helpers.py`\n**Location:** Lines 277-332 (56 lines)\n**Risk:** MEDIUM-HIGH (complex error flow changes)\n\n**Current Code Structure:**\n```python\ndef create_lock(lock_path, wo_id):\n    if lock_path.exists():\n        return False\n\n    # Create temp file\n    temp_fd, temp_path = tempfile.mkstemp(...)\n    os.close(temp_fd)\n\n    try:\n        # Write metadata\n        try:\n            # Atomic link\n            try:\n                # Fallback rename\n            except OSError:\n                # Cleanup\n        except OSError:\n            # Cleanup\n    except Exception:\n        # Cleanup\n```\n\n**Refactored Code:**\n```python\ndef write_lock_metadata(lock_path: Path, wo_id: str) -> None:\n    \"\"\"Write lock metadata to file.\n\n    Args:\n        lock_path: Path to lock file\n        wo_id: Work order ID\n\n    Raises:\n        OSError: If write operation fails\n    \"\"\"\n    with open(lock_path, \"w\") as f:\n        f.write(f\"Locked by ctx_wo_take.py at {datetime.now(timezone.utc).isoformat()}\\n\")\n        f.write(f\"PID: {os.getpid()}\\n\")\n        f.write(f\"User: {getpass.getuser()}\\n\")\n        f.write(f\"Hostname: {os.uname().nodename}\\n\")\n\n\ndef acquire_lock_atomic(temp_path: Path, lock_path: Path) -> bool:\n    \"\"\"Attempt atomic lock acquisition via hard link or rename.\n\n    Args:\n        temp_path: Path to temporary lock file\n        lock_path: Path to final lock file\n\n    Returns:\n        True if lock acquired, False otherwise\n    \"\"\"\n    # Try hard link first (most atomic)\n    try:\n        os.link(temp_path, lock_path)\n        os.unlink(temp_path)\n        logger.info(f\"✓ Atomic lock acquired: {lock_path}\")\n        return True\n    except OSError:\n        pass\n\n    # Fallback to rename (works on more filesystems)\n    try:\n        os.rename(temp_path, lock_path)\n        logger.info(f\"✓ Lock acquired (rename): {lock_path}\")\n        return True\n    except OSError:\n        return False\n\n\ndef create_lock(lock_path: Path, wo_id: str) -> bool:\n    \"\"\"Create an atomic lock file for a work order.\n\n    Uses temp-rename pattern for atomicity on filesystems that support hard links.\n\n    Args:\n        lock_path: Path to lock file\n        wo_id: Work order ID\n\n    Returns:\n        True if lock acquired, False otherwise\n    \"\"\"\n    if lock_path.exists():\n        logger.warning(f\"Lock already exists: {lock_path}\")\n        return False\n\n    # Create temp file with unique name\n    temp_fd, temp_path = tempfile.mkstemp(\n        prefix=f\"{wo_id}.\",\n        suffix=\".lock\",\n        dir=lock_path.parent\n    )\n    os.close(temp_fd)\n\n    try:\n        write_lock_metadata(temp_path, wo_id)\n\n        if acquire_lock_atomic(temp_path, lock_path):\n            return True\n\n        # Cleanup on failure\n        os.unlink(temp_path)\n        logger.warning(f\"Failed to acquire lock: {lock_path}\")\n        return False\n\n    except Exception as e:\n        logger.error(f\"Error creating lock: {e}\")\n        if os.path.exists(temp_path):\n            os.unlink(temp_path)\n        return False\n```\n\n**Benefits:**\n- **Reduces create_lock() from 56 to ~35 lines**\n- **Reduces nesting from 3 levels to 2 levels**\n- Extracts testable components\n- Clearer error flow\n- Easier to add new lock acquisition strategies\n\n---\n\n## Metrics Comparison\n\n### ctx_wo_take.py\n\n| Metric | Before | After | Improvement |\n|--------|--------|-------|-------------|\n| **main() lines** | 177 | ~40 | **-77%** |\n| **Cyclomatic complexity** | ~15 | <5 | **-67%** |\n| **Max nesting depth** | 4 | 2 | **-50%** |\n| **Duplicate code blocks** | 4 | 0 | **-100%** |\n| **Magic numbers** | 1 | 0 | **-100%** |\n| **Testable functions** | 1 | 4 | **+300%** |\n\n### helpers.py\n\n| Metric | Before | After | Improvement |\n|--------|--------|-------|-------------|\n| **create_worktree() lines** | 88 | ~55 | **-38%** |\n| **create_lock() lines** | 56 | ~35 | **-38%** |\n| **Max nesting depth** | 3 | 2 | **-33%** |\n| **Magic numbers** | 1 | 0 | **-100%** |\n| **Extracted functions** | 0 | 3 | **+3** |\n\n### Overall Codebase\n\n| Metric | Before | After | Improvement |\n|--------|--------|-------|-------------|\n| **Functions >50 lines** | 2 | 0 | **-100%** |\n| **Functions >100 lines** | 1 | 0 | **-100%** |\n| **Duplicate patterns** | 5 | 0 | **-100%** |\n| **Magic numbers** | 2 | 0 | **-100%** |\n| **Misplaced imports** | 1 | 0 | **-100%** |\n\n---\n\n## Implementation Priority Matrix\n\n### Phase 1: Quick Wins (1-2 hours)\n**Total Risk:** LOW\n**Total Impact:** HIGH\n\n| # | Recommendation | File | Lines | Risk | Impact | Time |\n|---|---------------|------|-------|------|--------|------|\n| 1 | Extract status counting | ctx_wo_take.py | 83-86 | LOW | HIGH | 15m |\n| 2 | Extract MAX_LOCK_AGE_SECONDS | ctx_wo_take.py, helpers.py | 146, 335 | LOW | HIGH | 10m |\n| 3 | Fix import placement | ctx_wo_take.py | 112 | MINIMAL | LOW | 5m |\n| 4 | Extract branch_exists() | helpers.py | 172-187 | LOW | HIGH | 20m |\n\n**Total Time:** ~50 minutes\n\n---\n\n### Phase 2: Structural Improvements (4-6 hours)\n**Total Risk:** MEDIUM\n**Total Impact:** HIGH\n\n| # | Recommendation | File | Lines | Risk | Impact | Time |\n|---|---------------|------|-------|------|--------|------|\n| 5 | Split main() handlers | ctx_wo_take.py | 40-216 | MEDIUM | HIGH | 2h |\n| 6 | Extract auto_generate_config() | ctx_wo_take.py | 172-184 | MEDIUM | MEDIUM | 1h |\n\n**Total Time:** ~3 hours\n\n---\n\n### Phase 3: Deep Refactoring (6-8 hours)\n**Total Risk:** MEDIUM-HIGH\n**Total Impact:** MEDIUM-HIGH\n\n| # | Recommendation | File | Lines | Risk | Impact | Time |\n|---|---------------|------|-------|------|--------|------|\n| 7 | Split create_worktree() | helpers.py | 121-208 | MEDIUM | MEDIUM | 2h |\n| 8 | Simplify create_lock() | helpers.py | 277-332 | MEDIUM-HIGH | MEDIUM | 2h |\n\n**Total Time:** ~4 hours\n\n---\n\n## Testing Strategy\n\n### Unit Tests Required\n\nAfter Phase 1:\n```python\n# test_ctx_wo_take.py\ndef test_count_work_orders_with_existing_dir():\ndef test_count_work_orders_with_missing_dir():\ndef test_count_work_orders_with_yaml_files():\ndef test_count_work_orders_empty_dir():\n\n# test_helpers.py\ndef test_branch_exists_local():\ndef test_branch_exists_remote():\ndef test_branch_exists_none():\ndef test_branch_exists_invalid():\n```\n\nAfter Phase 2:\n```python\n# test_ctx_wo_take.py\ndef test_handle_list_flag_with_pending_wos():\ndef test_handle_list_flag_empty():\ndef test_handle_status_flag():\ndef test_handle_take_wo_success():\ndef test_handle_take_wo_validation_error():\ndef test_auto_generate_config_both_none():\ndef test_auto_generate_config_partial():\n```\n\nAfter Phase 3:\n```python\n# test_helpers.py\ndef test_ensure_worktree_not_exists_registered():\ndef test_ensure_worktree_not_exists_unregistered():\ndef test_write_lock_metadata():\ndef test_acquire_lock_atomic_hardlink():\ndef test_acquire_lock_atomic_rename():\ndef test_acquire_lock_atomic_failure():\n```\n\n### Integration Tests\n\n```bash\n# Run full WO take workflow\npython scripts/ctx_wo_take.py WO-0001\npython scripts/ctx_wo_take.py --list\npython scripts/ctx_wo_take.py --status\n\n# Verify lock management\npython scripts/ctx_wo_take.py WO-0001  # First time\npython scripts/ctx_wo_take.py WO-0001  # Should fail (locked)\n\n# Verify stale lock cleanup\n# (manually age lock file >1 hour, then retry)\n```\n\n---\n\n## Rollback Plan\n\nEach refactoring should be done in a separate branch:\n\n```bash\n# Phase 1.1\ngit checkout -b refactor/extract-status-counting\n# Make changes, test, commit\n\n# Phase 1.2\ngit checkout -b refactor/extract-lock-age-constant\n# Make changes, test, commit\n\n# etc.\n```\n\n**Rollback if tests fail:**\n```bash\ngit checkout main\ngit branch -D refactor/extract-status-counting\n```\n\n**Verification commands:**\n```bash\n# Run all tests\nuv run pytest tests/\n\n# Run specific test file\nuv run pytest tests/unit/test_ctx_wo_take.py\n\n# Run integration test\nuv run pytest tests/integration/test_wo_workflow.py\n\n# Manual smoke test\npython scripts/ctx_wo_take.py --list\npython scripts/ctx_wo_take.py --status\n```\n\n---\n\n## Next Steps\n\n1. **Review this report** with team to prioritize based on project needs\n2. **Create GitHub issues** for each phase with checklists\n3. **Set up branch protection** requiring tests pass before merge\n4. **Schedule refactoring sprints** (Phase 1: 1 day, Phase 2: 2 days, Phase 3: 2 days)\n5. **Update CLAUDE.md** with new function patterns after completion\n\n---\n\n## Appendix: Complexity Metrics Calculation\n\n### Cyclomatic Complexity\n\n**Formula:** M = E - N + 2P\n- E = Edges (control flow paths)\n- N = Nodes (statements)\n- P = Connected components (functions)\n\n**ctx_wo_take.py main():**\n- Decision points: 15 (if statements, conditional expressions)\n- Estimated complexity: ~15 paths\n\n**After refactoring (split handlers):**\n- handle_list_flag(): 2 paths\n- handle_status_flag(): 1 path\n- handle_take_wo(): 8 paths\n- main(): 3 paths\n- **Total:** 14 paths (but distributed across 4 functions)\n\n### Nesting Depth\n\n**Measured as maximum indentation level:**\n\n```python\nif level_1:          # Depth 1\n    if level_2:      # Depth 2\n        if level_3:  # Depth 3\n            if level_4:  # Depth 4 ← TOO DEEP\n```\n\n**Target:** Maximum 3 levels (prefer 2)\n\n---\n\n**Report Generated:** 2026-01-09\n**Analyst:** Code Simplification Specialist\n**Methodology:** Manual analysis + complexity metrics + refactoring best practices\n",
+      "char_count": 32784,
+      "token_est": 8196,
+      "source_path": "code_complexity_analysis.md",
+      "chunking_method": "whole_file"
+    },
     {
       "id": "repo:docs/reports/KNOWN_FAILS.md:10a35718a8",
       "doc": "repo:docs/reports/KNOWN_FAILS.md",
@@ -3882,6 +4020,18 @@
       "source_path": "repo_scoop_v1_1.md",
       "chunking_method": "whole_file"
     },
+    {
+      "id": "repo:docs/reports/2026-01-11-pr18-error-handling-audit.md:f23747f8dd",
+      "doc": "repo:docs/reports/2026-01-11-pr18-error-handling-audit.md",
+      "title_path": [
+        "2026-01-11-pr18-error-handling-audit.md"
+      ],
+      "text": "# Error Handling Audit Report: PR #18 (WO Orchestration Improvements)\n\n**Audit Date**: 2026-01-11\n**Auditor**: Claude Code (Error Handling Specialist)\n**Scope**: Transaction safety, rollback mechanisms, lock management, and WO orchestration\n**Files Reviewed**:\n- `scripts/helpers.py` (new functions: heartbeat, lock validity, rollback execution)\n- `scripts/ctx_wo_take.py` (modified with transaction wrapper)\n- `src/domain/wo_entities.py` (new domain entities)\n- `src/domain/wo_transactions.py` (new transaction manager)\n\n---\n\n## Executive Summary\n\n**CRITICAL FINDINGS**: 3 issues that pose immediate production risks\n**HIGH SEVERITY**: 4 issues that could cause operational problems\n**MEDIUM SEVERITY**: 1 issue affecting maintainability\n**LOW SEVERITY**: 2 issues with minimal impact\n\n### Key Problems\n\n1. **\"Best-effort\" rollback strategy** silently fails, leaving system in corrupted state\n2. **Boolean return values** hide error context, preventing proper error recovery\n3. **Silent fallbacks** to default values mask underlying system problems\n4. **Broad exception catching** hides specific errors that need different handling\n\n### Positive Findings\n\n- Domain layer (`wo_entities.py`, `wo_transactions.py`) correctly uses `Result` types\n- `run_command()` has good error logging and re-raises (mostly)\n- Transaction design is sound; the execution layer needs improvement\n\n---\n\n## Critical Issues\n\n### CRITICAL-1: Silent Failures in Rollback Execution\n\n**Location**: `scripts/helpers.py:467-541` - `execute_rollback()`\n\n**Issue Description**:\nThe `execute_rollback()` function uses a \"best-effort\" strategy that continues attempting rollback even when individual operations fail. While this maximizes cleanup attempts, it creates several critical problems:\n\n```python\n# Lines 495-531\nfor op in reversed(transaction.operations):\n    try:\n        if op.rollback_type == \"remove_lock\":\n            lock_path.unlink()  # Can fail silently\n        elif op.rollback_type == \"move_wo_to_pending\":\n            # YAML operations that can fail\n        # ... other operations\n    except Exception as e:\n        error_msg = f\"{op.name}: {type(e).__name__}: {e}\"\n        logger.error(f\"✗ Rollback failed: {error_msg}\")\n        failed_ops.append(error_msg)\n        # CONTINUE anyway - best-effort cleanup  ← PROBLEM\n```\n\n**Hidden Errors That Could Be Caught**:\n- `PermissionError`: Cannot remove lock file or write to directories\n- `FileNotFoundError`: Unexpected missing files (TOCTOU race)\n- `yaml.YAMLError`: Corrupted YAML in running WO file\n- `subprocess.CalledProcessError`: Git commands failing\n- `OSError`: Disk full, network filesystem issues\n- `IsADirectoryError`: Path corruption (lock file became directory)\n\n**Production Impact**:\n1. **Lock remains acquired**: If lock removal fails, WO cannot be retried\n2. **WO stuck in \"running\" state**: Cannot be taken by another developer\n3. **Disk space wasted**: Worktree directories not cleaned up\n4. **Git state corrupted**: Branches not removed, cluttering repository\n5. **No recovery path**: System requires manual intervention to fix\n\n**Caller Impact** (from `ctx_wo_take.py:250-257`):\n```python\nall_succeeded, failed_ops = execute_rollback(transaction, root)\nif all_succeeded:\n    logger.info(\"✓ Rollback completed\")\nelse:\n    logger.error(f\"✗ Rollback partially failed: {failed_ops}\")\n    # Returns 1 anyway - no retry, no alert, no recovery\nreturn 1\n```\n\n**Recommendation**:\n1. **Change return type from `tuple[bool, list[str]]` to `Result[None, RollbackError]`**\n2. **Define specific rollback error types**:\n   ```python\n   @dataclass(frozen=True)\n   class RollbackError:\n       failed_operations: list[str]\n       requires_manual_intervention: bool\n       recovery_steps: list[str]\n   ```\n3. **Raise exception if critical operations fail**:\n   ```python\n   CRITICAL_OPS = {\"remove_lock\", \"move_wo_to_pending\"}\n\n   for op in reversed(transaction.operations):\n       try:\n           # ... execute rollback\n       except Exception as e:\n           failed_ops.append(f\"{op.name}: {e}\")\n           if op.rollback_type in CRITICAL_OPS:\n               # Don't continue - critical state is corrupted\n               raise RollbackCriticalError(\n                   f\"Critical rollback failed: {op.name}\",\n                   failed_ops=failed_ops\n               )\n   ```\n4. **Add recovery suggestions** to rollback errors:\n   ```python\n   if op.rollback_type == \"remove_lock\":\n       recovery_steps.append(f\"Manually remove: {lock_path}\")\n   elif op.rollback_type == \"move_wo_to_pending\":\n       recovery_steps.append(f\"Move {running_path} to {pending_path}\")\n       recovery_steps.append(f\"Reset status: pending, owner: null\")\n   ```\n\n---\n\n### CRITICAL-2: Lock Heartbeat Returns False Without Error Distinction\n\n**Location**: `scripts/helpers.py:357-407` - `update_lock_heartbeat()`\n\n**Issue Description**:\nThe function returns `False` on all errors, making it impossible for the caller to distinguish between:\n- Lock file doesn't exist (expected - WO finished)\n- Permission denied (system error - needs investigation)\n- Disk full (system error - needs investigation)\n- Filesystem read-only (system error - needs investigation)\n\n```python\n# Lines 369-371\nif not lock_path.exists():\n    logger.warning(f\"Lock file not found for heartbeat: {lock_path}\")\n    return False  # ← Is this an error or expected?\n\n# Lines 394-404\ntry:\n    with open(temp_path, \"w\") as f:\n        f.write('\\n'.join(updated_lines))\n    os.replace(temp_path, lock_path)\n    return True\nexcept Exception as e:\n    logger.error(f\"Failed to update heartbeat: {e}\")\n    if os.path.exists(temp_path):\n        os.unlink(temp_path)\n    return False  # ← Why did it fail?\n```\n\n**Hidden Errors**:\n- `PermissionError`: Cannot write to lock file or directory\n- `FileNotFoundError`: Lock file deleted between exists() check and read()\n- `OSError`: Disk full (`ENOSPC`)\n- `IOError`: Filesystem issues (NFS timeout, etc.)\n- `ValueError`: Invalid datetime format (shouldn't happen)\n\n**Production Impact**:\n1. **Heartbeat loop continues silently**: Background process keeps trying to update heartbeat\n2. **Lock marked stale prematurely**: If heartbeat fails due to transient error, lock is considered stale and cleaned up\n3. **Active WO interrupted**: Developer loses their lock while working\n4. **No alerting**: Operator doesn't know heartbeat is failing\n5. **Log flood**: Continuous error messages create noise\n\n**Recommendation**:\n1. **Return `Result[None, HeartbeatError]`** instead of bool:\n   ```python\n   @dataclass(frozen=True)\n   class HeartbeatError:\n       reason: str  # \"lock_not_found\", \"permission_denied\", etc.\n       recoverable: bool  # Can retry?\n       original_error: Exception\n\n   def update_lock_heartbeat(lock_path: Path) -> Result[None, HeartbeatError]:\n       if not lock_path.exists():\n           return Err(HeartbeatError(\n               reason=\"lock_not_found\",\n               recoverable=False,\n               original_error=FileNotFoundError(str(lock_path))\n           ))\n       # ... try update\n       except PermissionError as e:\n           return Err(HeartbeatError(\n               reason=\"permission_denied\",\n               recoverable=False,  # Don't retry\n               original_error=e\n           ))\n       except OSError as e:\n           if e.errno == errno.ENOSPC:\n               return Err(HeartbeatError(\n                   reason=\"disk_full\",\n                   recoverable=False,\n                   original_error=e\n               ))\n           return Err(HeartbeatError(\n               reason=\"io_error\",\n               recoverable=True,  # Transient - retry\n               original_error=e\n           ))\n   ```\n\n2. **Caller should handle based on error type**:\n   ```python\n   result = update_lock_heartbeat(lock_path)\n   if result.is_err():\n       error = result.error\n       if not error.recoverable:\n           logger.critical(f\"Fatal heartbeat error: {error.reason}\")\n           alert_operator(f\"Heartbeat failed: {error.reason}\")\n           sys.exit(1)\n       else:\n           logger.warning(f\"Transient heartbeat error: {error.reason}, retrying...\")\n   ```\n\n---\n\n### CRITICAL-3: Lock Validity Check Hides Error Types\n\n**Location**: `scripts/helpers.py:410-464` - `check_lock_validity()`\n\n**Issue Description**:\nThe function returns `(False, None)` for both expected cases (lock doesn't exist) and error cases (permission denied, corrupted file). This makes it impossible to distinguish between:\n\n```python\n# Lines 427-428\nif not lock_path.exists():\n    return False, None  # Expected: lock doesn't exist\n\n# Lines 459-464\nexcept (OSError, ValueError) as e:\n    logger.error(f\"Error parsing lock metadata: {type(e).__name__}: {e}\")\n    return False, None  # ← Error: can't read lock file\nexcept Exception as e:\n    logger.error(f\"Unexpected error reading lock: {type(e).__name__}: {e}\")\n    return False, None  # ← Error: unexpected issue\n```\n\n**Hidden Errors**:\n- `PermissionError`: Cannot read lock file (should alert, not ignore)\n- `IsADirectoryError`: Lock path is a directory (corruption - needs cleanup)\n- `UnicodeDecodeError`: Lock file has invalid encoding\n- `OSError`: Disk corruption, network filesystem issues\n- `ValueError`: PID is not an integer (lock file malformed)\n\n**Production Impact**:\n1. **Lock considered \"invalid\" on permission errors**: Lock might be removed even though it's valid\n2. **Active WO interrupted**: Developer loses lock due to filesystem permission issue\n3. **Corruption undetected**: Lock file became directory but is treated as \"doesn't exist\"\n4. **Race condition**: Lock file deleted between exists() check and read() - treated as expected instead of race\n\n**Recommendation**:\n1. **Return `Result[LockMetadata, LockCheckError]`**:\n   ```python\n   @dataclass(frozen=True)\n   class LockMetadata:\n       pid: int\n       user: str\n       hostname: str\n       created_at: datetime\n       heartbeat_at: Optional[datetime]\n\n   @dataclass(frozen=True)\n   class LockCheckError:\n       reason: str  # \"not_found\", \"stale\", \"permission_denied\", \"corrupted\"\n       is_recoverable: bool\n       original_error: Optional[Exception]\n\n   def check_lock_validity(lock_path: Path) -> Result[LockMetadata, LockCheckError]:\n       if not lock_path.exists():\n           return Err(LockCheckError(\n               reason=\"not_found\",\n               is_recoverable=True,\n               original_error=None\n           ))\n\n       if check_lock_age(lock_path):\n           return Err(LockCheckError(\n               reason=\"stale\",\n               is_recoverable=True,\n               original_error=None\n           ))\n\n       try:\n           content = lock_path.read_text()\n           # ... parse metadata\n           pid = int(metadata[\"PID\"])\n           os.kill(pid, 0)\n           return Ok(LockMetadata(...))\n       except PermissionError as e:\n           logger.critical(f\"Permission denied reading lock: {lock_path}\")\n           return Err(LockCheckError(\n               reason=\"permission_denied\",\n               is_recoverable=False,\n               original_error=e\n           ))\n       except (ValueError, KeyError) as e:\n           logger.error(f\"Corrupted lock file: {lock_path} - {e}\")\n           return Err(LockCheckError(\n               reason=\"corrupted\",\n               is_recoverable=False,\n               original_error=e\n           ))\n   ```\n\n2. **Caller should handle based on error reason**:\n   ```python\n   result = check_lock_validity(lock_path)\n   if result.is_err():\n       error = result.error\n       if error.reason == \"not_found\":\n           logger.info(\"Lock available\")\n       elif error.reason == \"stale\":\n           logger.info(\"Lock is stale, can be cleaned up\")\n           cleanup_stale_lock(lock_path)\n       elif error.reason == \"permission_denied\":\n           logger.critical(f\"Cannot read lock: {lock_path}\")\n           alert_operator(f\"Permission denied: {lock_path}\")\n           return 1\n       elif error.reason == \"corrupted\":\n           logger.error(f\"Corrupted lock: {lock_path}\")\n           alert_operator(f\"Lock file corrupted: {lock_path}\")\n           return 1\n   ```\n\n---\n\n## High Severity Issues\n\n### HIGH-1: Silent Fallback to Default Branch\n\n**Location**: `scripts/helpers.py:96-121` - `git_get_default_branch()`\n\n**Issue Description**:\nThe function silently falls back to `DEFAULT_BRANCH` constant without validating that the branch exists. This hides git configuration problems and produces cryptic downstream errors.\n\n```python\n# Lines 99-108\ntry:\n    result = run_command(\n        [\"git\", \"symbolic-ref\", \"refs/remotes/origin/HEAD\"],\n        cwd=root,\n        check=False\n    )\n    if result.returncode == 0:\n        return result.stdout.strip().split(\"/\")[-1]\nexcept Exception:  # ← Silent failure - no logging!\n    pass\n\n# Lines 110-120\nfor branch in [\"main\", \"master\"]:\n    result = run_command(\n        [\"git\", \"rev-parse\", \"--verify\", branch],\n        cwd=root,\n        check=False\n    )\n    if result.returncode == 0:\n        return branch\n\n# Line 121\nreturn DEFAULT_BRANCH  # ← \"main\" might not exist!\n```\n\n**Hidden Errors**:\n- `subprocess.CalledProcessError`: Git commands failing (silently caught)\n- `FileNotFoundError`: Git not installed or not in PATH\n- `PermissionError`: Cannot access git repository\n- `OSError`: Network filesystem issues\n- Git repository corruption\n- Missing origin remote\n\n**Production Impact**:\n1. **Cryptic downstream errors**: Caller tries to use \"main\" branch and fails with \"branch not found\"\n2. **No debugging context**: Error occurs far from the root cause\n3. **Incorrect assumptions**: Code assumes \"main\" exists, breaks on repositories using \"master\" or other names\n4. **No alerting**: Git configuration problems go unnoticed\n\n**Recommendation**:\n1. **Add logging for fallback attempts**:\n   ```python\n   try:\n       result = run_command(\n           [\"git\", \"symbolic-ref\", \"refs/remotes/origin/HEAD\"],\n           cwd=root,\n           check=False\n       )\n       if result.returncode == 0:\n           return result.stdout.strip().split(\"/\")[-1]\n   except Exception as e:\n       logger.warning(f\"Cannot get default branch from origin: {e}\")\n       # Continue to fallback\n   ```\n\n2. **Validate DEFAULT_BRANCH before returning**:\n   ```python\n   # Validate DEFAULT_BRANCH exists\n   result = run_command(\n       [\"git\", \"rev-parse\", \"--verify\", DEFAULT_BRANCH],\n       cwd=root,\n       check=False\n   )\n   if result.returncode != 0:\n       raise RuntimeError(\n           f\"Cannot determine default branch. \"\n           f\"Tried origin/HEAD, main, master, and {DEFAULT_BRANCH}. \"\n           f\"Please set origin/HEAD or create a default branch.\"\n       )\n   return DEFAULT_BRANCH\n   ```\n\n3. **Consider returning `Result[str, GitError]`**:\n   ```python\n   def git_get_default_branch(root: Path) -> Result[str, GitError]:\n       \"\"\"Get default branch or return error if cannot be determined.\"\"\"\n       # ... try multiple methods\n       raise GitError(\n           \"Cannot determine default branch\",\n           suggestions=[\"Create 'main' or 'master' branch\", \"Set origin/HEAD\"]\n       )\n   ```\n\n---\n\n### HIGH-2: Worktree Creation Loses Error Context\n\n**Location**: `scripts/helpers.py:124-211` - `create_worktree()`\n\n**Issue Description**:\nWhen worktree creation fails, the exception propagates without context about which WO, branch, or path was being used. This makes debugging difficult.\n\n```python\n# Lines 199-208\nif branch_exists:\n    logger.info(f\"  Branch {branch} already exists, using it\")\n    run_command(\n        [\"git\", \"worktree\", \"add\", str(worktree_path), branch],\n        cwd=root\n    )\nelse:\n    logger.info(f\"  Creating new branch {branch} from {default_branch}\")\n    run_command(\n        [\"git\", \"worktree\", \"add\", \"-b\", branch, str(worktree_path), default_branch],\n        cwd=root\n    )\n# ← If run_command raises, no context about wo_id, branch, or path\n```\n\n**Hidden Errors**:\n- `subprocess.CalledProcessError`: Git worktree add fails (but why?)\n- `PermissionError`: Cannot create worktree directory\n- `OSError`: Disk full, quota exceeded\n- `FileExistsError`: Worktree path already exists (TOCTOU race)\n\n**Production Impact**:\n1. **Cryptic error messages**: \"Command failed: git worktree add .worktrees/WO-0012\"\n2. **No debugging context**: Developer doesn't know which WO, branch, or base branch\n3. **Cannot reproduce**: Error message doesn't have enough information to reproduce\n4. **No recovery suggestions**: Doesn't tell developer how to fix the problem\n\n**Recommendation**:\n1. **Wrap run_command calls with context**:\n   ```python\n   try:\n       if branch_exists:\n           logger.info(f\"  Branch {branch} already exists, using it\")\n           run_command(\n               [\"git\", \"worktree\", \"add\", str(worktree_path), branch],\n               cwd=root\n           )\n       else:\n           logger.info(f\"  Creating new branch {branch} from {default_branch}\")\n           run_command(\n               [\"git\", \"worktree\", \"add\", \"-b\", branch, str(worktree_path), default_branch],\n               cwd=root\n           )\n   except subprocess.CalledProcessError as e:\n       raise WorktreeCreationError(\n           f\"Failed to create worktree for WO {wo_id}\",\n           wo_id=wo_id,\n           branch=branch,\n           worktree_path=worktree_path,\n           base_branch=default_branch,\n           git_error=e.stderr,\n           suggestions=[\n               f\"Check if {worktree_path} already exists\",\n               f\"Verify branch {default_branch} exists\",\n               \"Check disk space and permissions\"\n           ]\n       ) from e\n   ```\n\n2. **Define WorktreeCreationError exception class**:\n   ```python\n   @dataclass\n   class WorktreeCreationError(Exception):\n       message: str\n       wo_id: str\n       branch: str\n       worktree_path: Path\n       base_branch: str\n       git_error: str\n       suggestions: list[str]\n\n       def __str__(self):\n           return f\"{self.message}\\n\" + \\\n                  f\"  WO: {self.wo_id}\\n\" + \\\n                  f\"  Branch: {self.branch}\\n\" + \\\n                  f\"  Path: {self.worktree_path}\\n\" + \\\n                  f\"  Base branch: {self.base_branch}\\n\" + \\\n                  f\"  Git error: {self.git_error}\\n\" + \\\n                  f\"  Suggestions:\\n\" + \"\\n\".join(f\"    - {s}\" for s in self.suggestions)\n   ```\n\n---\n\n### HIGH-3: Cleanup Returns False Without Indicating What Failed\n\n**Location**: `scripts/helpers.py:214-247` - `cleanup_worktree()`\n\n**Issue Description**:\nThe function returns `False` on any error, making it impossible to know which cleanup step failed or why.\n\n```python\n# Lines 228-247\ntry:\n    if worktree_path.exists():\n        logger.info(f\"Removing worktree: {worktree_path}\")\n        run_command([\"git\", \"worktree\", \"remove\", str(worktree_path)], cwd=root)\n\n    run_command([\"git\", \"worktree\", \"prune\"], cwd=root)\n\n    try:\n        run_command([\"git\", \"branch\", \"-D\", branch], cwd=root, check=False)\n        logger.info(f\"Removed branch: {branch}\")\n    except Exception:\n        logger.info(f\"Branch {branch} not removed (may not exist)\")\n\n    return True\nexcept Exception as e:\n    logger.error(f\"Failed to cleanup worktree: {e}\")\n    return False  # ← What failed? Why?\n```\n\n**Hidden Errors**:\n- `subprocess.CalledProcessError`: Git worktree remove fails\n- `PermissionError`: Cannot remove worktree directory\n- `FileNotFoundError`: Worktree path doesn't exist (TOCTOU)\n- `OSError`: Worktree is not empty (files left behind)\n- Git corruption: Worktree list inconsistent\n\n**Production Impact**:\n1. **Cannot recover**: Caller doesn't know what to clean up manually\n2. **No debugging context**: Don't know which WO failed cleanup\n3. **Silent partial failures**: Branch removal failure is ignored but other failures aren't (inconsistent)\n\n**Recommendation**:\n1. **Return `Result[None, CleanupError]`**:\n   ```python\n   @dataclass(frozen=True)\n   class CleanupError:\n       wo_id: str\n       worktree_removal_failed: bool = False\n       branch_removal_failed: bool = False\n       worktree_path: Optional[Path] = None\n       branch: Optional[str] = None\n       original_error: Optional[Exception] = None\n\n       def requires_manual_cleanup(self) -> bool:\n           return self.worktree_removal_failed or self.branch_removal_failed\n\n       def get_manual_cleanup_commands(self) -> list[str]:\n           commands = []\n           if self.worktree_removal_failed and self.worktree_path:\n               commands.append(f\"git worktree remove -f {self.worktree_path}\")\n               commands.append(f\"rm -rf {self.worktree_path}\")\n           if self.branch_removal_failed and self.branch:\n               commands.append(f\"git branch -D {self.branch}\")\n           return commands\n\n   def cleanup_worktree(root: Path, wo_id: str) -> Result[None, CleanupError]:\n       worktree_path = get_worktree_path(wo_id, root)\n       branch = get_branch_name(wo_id)\n\n       worktree_failed = False\n       branch_failed = False\n       original_error = None\n\n       try:\n           if worktree_path.exists():\n               logger.info(f\"Removing worktree: {worktree_path}\")\n               try:\n                   run_command([\"git\", \"worktree\", \"remove\", str(worktree_path)], cwd=root)\n               except Exception as e:\n                   logger.error(f\"Failed to remove worktree: {e}\")\n                   worktree_failed = True\n                   original_error = e\n\n           run_command([\"git\", \"worktree\", \"prune\"], cwd=root)\n\n           try:\n               run_command([\"git\", \"branch\", \"-D\", branch], cwd=root, check=False)\n               logger.info(f\"Removed branch: {branch}\")\n           except Exception as e:\n               logger.info(f\"Branch {branch} not removed (may not exist)\")\n\n           if worktree_failed:\n               return Err(CleanupError(\n                   wo_id=wo_id,\n                   worktree_removal_failed=worktree_failed,\n                   branch_removal_failed=branch_failed,\n                   worktree_path=worktree_path,\n                   branch=branch,\n                   original_error=original_error\n               ))\n           return Ok(None)\n       except Exception as e:\n           logger.error(f\"Unexpected cleanup error: {e}\")\n           return Err(CleanupError(\n               wo_id=wo_id,\n               worktree_removal_failed=True,\n               branch_removal_failed=True,\n               worktree_path=worktree_path,\n               branch=branch,\n               original_error=e\n           ))\n   ```\n\n2. **Caller should handle cleanup errors**:\n   ```python\n   result = cleanup_worktree(root, wo_id)\n   if result.is_err():\n       error = result.error\n       logger.warning(f\"Cleanup failed for WO {wo_id}\")\n       if error.requires_manual_cleanup():\n           logger.error(\"Manual cleanup required:\")\n           for cmd in error.get_manual_cleanup_commands():\n               logger.error(f\"  {cmd}\")\n   ```\n\n---\n\n### HIGH-4: Lock Creation Returns False for Multiple Failure Modes\n\n**Location**: `scripts/helpers.py:280-335` - `create_lock()`\n\n**Issue Description**:\nThe function returns `False` for all failure modes, making it impossible to distinguish between \"already locked\" (expected, retry later) and \"error\" (alert operator).\n\n```python\n# Lines 295-297\nif lock_path.exists():\n    logger.warning(f\"Lock already exists: {lock_path}\")\n    return False  # ← Expected: already locked\n\n# Lines 316-330\ntry:\n    os.link(temp_path, lock_path)\n    os.unlink(temp_path)\n    return True\nexcept OSError:\n    try:\n        os.rename(temp_path, lock_path)\n        return True\n    except OSError:\n        os.unlink(temp_path)\n        logger.warning(f\"Failed to acquire lock: {lock_path}\")\n        return False  # ← Error: permission denied? disk full?\n\n# Lines 331-335\nexcept Exception as e:\n    logger.error(f\"Error creating lock: {e}\")\n    if os.path.exists(temp_path):\n        os.unlink(temp_path)\n    return False  # ← Error: unexpected\n```\n\n**Hidden Errors**:\n- `FileExistsError`: Lock created between exists() check and link() (race condition)\n- `PermissionError`: Cannot create lock file\n- `OSError.ENOSPC`: Disk full\n- `OSError.EROFS`: Read-only filesystem\n- `OSError.EOPNOTSUPP`: Hard links not supported, rename also failed\n\n**Production Impact**:\n1. **Cannot distinguish retry vs error**: Caller treats \"already locked\" same as \"permission denied\"\n2. **No alerting**: Permission errors go to log but don't alert operator\n3. **Incorrect retry behavior**: Might retry when shouldn't (permission error)\n4. **Race conditions**: Lock created between check and link() not detected\n\n**Recommendation**:\n1. **Return `Result[None, LockError]`**:\n   ```python\n   @dataclass(frozen=True)\n   class LockError:\n       reason: str  # \"already_exists\", \"permission_denied\", \"disk_full\", etc.\n       recoverable: bool  # Can retry?\n       original_error: Optional[Exception]\n\n   def create_lock(lock_path: Path, wo_id: str) -> Result[None, LockError]:\n       if lock_path.exists():\n           logger.warning(f\"Lock already exists: {lock_path}\")\n           return Err(LockError(\n               reason=\"already_exists\",\n               recoverable=True,  # Retry later\n               original_error=None\n           ))\n\n       temp_fd, temp_path = tempfile.mkstemp(\n           prefix=f\"{wo_id}.\",\n           suffix=\".lock\",\n           dir=lock_path.parent\n       )\n       os.close(temp_fd)\n\n       try:\n           # Write metadata\n           with open(temp_path, \"w\") as f:\n               f.write(f\"Locked by ctx_wo_take.py at {datetime.now(timezone.utc).isoformat()}\\n\")\n               f.write(f\"PID: {os.getpid()}\\n\")\n               f.write(f\"User: {getpass.getuser()}\\n\")\n               f.write(f\"Hostname: {os.uname().nodename}\\n\")\n\n           # Try atomic operations\n           try:\n               os.link(temp_path, lock_path)\n               os.unlink(temp_path)\n               return Ok(None)\n           except OSError as e:\n               # Check specific error codes\n               if e.errno == errno.EEXIST:\n                   # Lock created between exists() check and link()\n                   os.unlink(temp_path)\n                   return Err(LockError(\n                       reason=\"already_exists\",\n                       recoverable=True,\n                       original_error=e\n                   ))\n               elif e.errno == errno.EOPNOTSUPP:\n                   # Hard links not supported, try rename\n                   try:\n                       os.rename(temp_path, lock_path)\n                       return Ok(None)\n                   except OSError as e2:\n                       os.unlink(temp_path)\n                       if e2.errno == errno.ENOSPC:\n                           return Err(LockError(\n                               reason=\"disk_full\",\n                               recoverable=False,\n                               original_error=e2\n                           ))\n                       elif e2.errno in (errno.EACCES, errno.EPERM):\n                           return Err(LockError(\n                               reason=\"permission_denied\",\n                               recoverable=False,\n                               original_error=e2\n                           ))\n                       raise\n               elif e.errno in (errno.EACCES, errno.EPERM):\n                   os.unlink(temp_path)\n                   return Err(LockError(\n                       reason=\"permission_denied\",\n                       recoverable=False,\n                       original_error=e\n                   ))\n               elif e.errno == errno.ENOSPC:\n                   os.unlink(temp_path)\n                   return Err(LockError(\n                       reason=\"disk_full\",\n                       recoverable=False,\n                       original_error=e\n                   ))\n               raise\n       except Exception as e:\n           logger.error(f\"Error creating lock: {e}\")\n           if os.path.exists(temp_path):\n               os.unlink(temp_path)\n           return Err(LockError(\n               reason=\"unknown\",\n               recoverable=False,\n               original_error=e\n           ))\n   ```\n\n2. **Caller should handle based on error reason**:\n   ```python\n   result = create_lock(lock_path, wo_id)\n   if result.is_err():\n       error = result.error\n       if error.reason == \"already_exists\":\n           logger.warning(f\"WO {wo_id} is already locked\")\n           return 1\n       elif error.reason == \"permission_denied\":\n           logger.critical(f\"Permission denied creating lock for {wo_id}\")\n           alert_operator(f\"Cannot create lock: {lock_path}\")\n           return 1\n       elif error.reason == \"disk_full\":\n           logger.critical(\"Disk full - cannot create lock\")\n           alert_operator(\"Disk full on lock filesystem\")\n           return 1\n   ```\n\n---\n\n## Medium Severity Issues\n\n### MEDIUM-1: Transaction Wrapper Uses Broad Exception Catching\n\n**Location**: `scripts/ctx_wo_take.py:239-296` - Transaction wrapper in `take()` command\n\n**Issue Description**:\nThe transaction wrapper catches `Exception` in multiple places, which is too broad and hides unexpected errors.\n\n```python\n# Lines 239-258: Worktree creation\ntry:\n    logger.info(f\"Creating worktree for {wo_id}...\")\n    create_worktree(root, wo_id, branch, Path(worktree))\n    # Add rollback operations\nexcept Exception as e:  # ← Too broad\n    logger.error(f\"Failed to create worktree: {e}\")\n    logger.info(\"Executing rollback...\")\n    all_succeeded, failed_ops = execute_rollback(transaction, root)\n    if all_succeeded:\n        logger.info(\"✓ Rollback completed\")\n    else:\n        logger.error(f\"✗ Rollback partially failed: {failed_ops}\")\n    return 1\n\n# Lines 269-285: Move WO to running\ntry:\n    write_yaml(running_path, wo)\n    job_path.unlink()\nexcept Exception as e:  # ← Too broad\n    # Same rollback pattern\n\n# Lines 287-296: Outer handler\nexcept Exception as e:  # ← Very broad\n    logger.error(f\"Unexpected error during WO take: {e}\")\n    # Same rollback pattern\n```\n\n**Hidden Errors**:\n- `KeyboardInterrupt`: User pressed Ctrl+C (should abort immediately, not rollback)\n- `MemoryError`: Out of memory (rollback might also fail)\n- `SystemExit`: sys.exit() called (should exit immediately)\n- `yaml.YAMLError`: Corrupted YAML (specific error needed)\n- `FileNotFoundError`: WO file deleted (specific error needed)\n- `PermissionError`: Cannot write to directories (specific error needed)\n\n**Production Impact**:\n1. **Unexpected errors treated as expected**: SystemExit, KeyboardInterrupt trigger rollback\n2. **No debugging context**: Generic \"Failed to create worktree\" doesn't help\n3. **Rollback might also fail**: If original error was resource exhaustion, rollback will also fail\n4. **Inconsistent handling**: Some exceptions should abort immediately (KeyboardInterrupt)\n\n**Recommendation**:\n1. **Catch specific exceptions**:\n   ```python\n   # Worktree creation\n   try:\n       logger.info(f\"Creating worktree for {wo_id}...\")\n       create_worktree(root, wo_id, branch, Path(worktree))\n       transaction = transaction.add_operation(...)\n   except (WorktreeCreationError, subprocess.CalledProcessError) as e:\n       logger.error(f\"Failed to create worktree: {e}\")\n       logger.info(\"Executing rollback...\")\n       all_succeeded, failed_ops = execute_rollback(transaction, root)\n       if not all_succeeded:\n           logger.error(f\"✗ Rollback partially failed: {failed_ops}\")\n       return 1\n   except Exception as e:\n       # Unexpected error - still rollback but log as critical\n       logger.critical(f\"Unexpected error creating worktree: {type(e).__name__}: {e}\")\n       logger.info(\"Executing rollback...\")\n       execute_rollback(transaction, root)\n       raise  # Re-raise to expose the unexpected error\n\n   # Move WO to running\n   try:\n       write_yaml(running_path, wo)\n       job_path.unlink()\n   except (yaml.YAMLError, PermissionError, OSError) as e:\n       logger.error(f\"Failed to move WO to running: {e}\")\n       logger.info(\"Executing rollback...\")\n       execute_rollback(transaction, root)\n       return 1\n\n   # Outer handler - only catch expected errors\n   try:\n       # ... WO take logic\n   except KeyboardInterrupt:\n       logger.warning(\"WO take interrupted by user\")\n       logger.info(\"Executing rollback...\")\n       execute_rollback(transaction, root)\n       sys.exit(130)  # Standard exit code for SIGINT\n   except (WorktreeCreationError, yaml.YAMLError, PermissionError, OSError) as e:\n       logger.error(f\"WO take failed: {e}\")\n       logger.info(\"Executing rollback...\")\n       execute_rollback(transaction, root)\n       return 1\n   ```\n\n2. **Don't catch Exception in outer handler**:\n   ```python\n   # Let unexpected errors propagate\n   # They will be caught by the main() handler which logs and exits\n   ```\n\n---\n\n## Low Severity Issues\n\n### LOW-1: run_command() Lacks Timeout\n\n**Location**: `scripts/helpers.py:61-87` - `run_command()`\n\n**Issue Description**:\nThe function has no timeout parameter, so commands can hang forever.\n\n```python\n# Lines 74-81\nlogger.debug(f\"Running: {' '.join(cmd)}\")\ntry:\n    result = subprocess.run(\n        cmd,\n        cwd=cwd,\n        check=check,\n        capture_output=True,\n        text=True\n        # ← No timeout!\n    )\n```\n\n**Hidden Errors**:\n- Command hangs forever (e.g., waiting for user input, network timeout)\n- No way to cancel long-running operations\n\n**Production Impact**:\n1. **Process hangs**: WO take script hangs waiting for git command\n2. **No recovery**: Must kill process manually\n3. **Lock timeout**: If heartbeat is running, lock might be marked stale\n\n**Recommendation**:\n```python\ndef run_command(\n    cmd: list[str],\n    cwd: Optional[Path] = None,\n    check: bool = True,\n    timeout: Optional[int] = 300  # Default 5 minutes\n) -> subprocess.CompletedProcess:\n    logger.debug(f\"Running: {' '.join(cmd)}\")\n    try:\n        result = subprocess.run(\n            cmd,\n            cwd=cwd,\n            check=check,\n            capture_output=True,\n            text=True,\n            timeout=timeout\n        )\n        return result\n    except subprocess.TimeoutExpired as e:\n        logger.error(f\"Command timed out after {timeout}s: {' '.join(cmd)}\")\n        raise\n    except subprocess.CalledProcessError as e:\n        logger.error(f\"Command failed: {' '.join(cmd)}\")\n        logger.error(f\"stdout: {e.stdout}\")\n        logger.error(f\"stderr: {e.stderr}\")\n        raise\n```\n\n---\n\n### LOW-2: list_worktrees() Doesn't Validate Git Output\n\n**Location**: `scripts/helpers.py:250-277` - `list_worktrees()`\n\n**Issue Description**:\nThe function assumes git output format is correct and doesn't handle malformed output.\n\n```python\n# Lines 264-272\nfor line in result.stdout.splitlines():\n    if not line:\n        if current:\n            worktrees.append(current)\n            current = {}\n        continue\n\n    key, value = line.split(\" \", 1)  # ← Assumes format \"KEY value\"\n    current[key] = value\n```\n\n**Hidden Errors**:\n- `ValueError`: Line has no spaces (split fails)\n- Git output format changes (future compatibility)\n- UnicodeDecodeError: Invalid encoding in output\n\n**Production Impact**:\n1. **Cryptic error**: \"not enough values to unpack\" doesn't help debugging\n2. **No validation**: Worktree paths might not exist\n\n**Recommendation**:\n```python\ndef list_worktrees(root: Path) -> list[dict]:\n    \"\"\"List all git worktrees.\"\"\"\n    result = run_command([\"git\", \"worktree\", \"list\", \"--porcelain\"], cwd=root)\n\n    worktrees = []\n    current = {}\n\n    for line_num, line in enumerate(result.stdout.splitlines(), 1):\n        if not line:\n            if current:\n                # Validate worktree path exists\n                if \"worktree\" in current:\n                    worktree_path = Path(current[\"worktree\"])\n                    if not worktree_path.exists():\n                        logger.warning(\n                            f\"Worktree path doesn't exist: {worktree_path} \"\n                            f\"(line {line_num})\"\n                        )\n                worktrees.append(current)\n                current = {}\n            continue\n\n        # Validate line format\n        if \" \" not in line:\n            logger.warning(f\"Malformed git worktree output line {line_num}: {line}\")\n            continue\n\n        key, value = line.split(\" \", 1)\n        current[key] = value\n\n    if current:\n        worktrees.append(current)\n\n    return worktrees\n```\n\n---\n\n## Summary and Recommendations\n\n### Critical Actions (Do Immediately)\n\n1. **Fix `execute_rollback()`**:\n   - Stop using \"best-effort\" strategy for critical operations\n   - Raise exception if lock removal or WO state change fails\n   - Return `Result` type instead of `(bool, list[str])`\n\n2. **Fix `update_lock_heartbeat()`**:\n   - Return `Result` type with specific error reasons\n   - Caller should abort on non-recoverable errors\n   - Don't silently continue on permission errors\n\n3. **Fix `check_lock_validity()`**:\n   - Return `Result[LockMetadata, LockCheckError]`\n   - Distinguish between \"not found\" and \"permission denied\"\n   - Alert operator on permission errors\n\n### High Priority Actions\n\n4. **Fix `git_get_default_branch()`**:\n   - Validate DEFAULT_BRANCH exists before returning\n   - Add logging for fallback attempts\n   - Raise exception if cannot determine default branch\n\n5. **Fix `create_worktree()`**:\n   - Wrap exceptions with context (WO ID, branch, path)\n   - Define `WorktreeCreationError` with suggestions\n   - Add recovery steps to error message\n\n6. **Fix `cleanup_worktree()`**:\n   - Return `Result[None, CleanupError]`\n   - Indicate which operations failed\n   - Provide manual cleanup commands\n\n7. **Fix `create_lock()`**:\n   - Return `Result[None, LockError]`\n   - Distinguish between \"already exists\" and \"permission denied\"\n   - Check errno for specific error types\n\n### Medium Priority Actions\n\n8. **Fix transaction wrapper in `ctx_wo_take.py`**:\n   - Catch specific exceptions instead of `Exception`\n   - Handle KeyboardInterrupt separately\n   - Re-raise unexpected errors after rollback\n\n### Low Priority Actions\n\n9. **Add timeout to `run_command()`**:\n   - Default timeout of 5 minutes\n   - Catch `TimeoutExpired` and log\n\n10. **Validate git output in `list_worktrees()`**:\n    - Handle malformed lines gracefully\n    - Validate worktree paths exist\n\n### General Recommendations\n\n1. **Adopt Result types throughout infrastructure layer**:\n   - The domain layer shows the right pattern\n   - Use `Result[T, E]` instead of `bool` or `tuple[bool, ...]`\n   - Define specific error types for each operation\n\n2. **Add context to exceptions**:\n   - When catching and re-raising, add context (WO ID, paths, etc.)\n   - Use exception chaining (`raise ... from e`)\n   - Include recovery suggestions in error messages\n\n3. **Never silently ignore critical failures**:\n   - Lock operations, WO state changes must succeed or raise\n   - Don't use \"best-effort\" for state-changing operations\n   - If rollback fails, system is in inconsistent state - alert operator\n\n4. **Distinguish between recoverable and non-recoverable errors**:\n   - \"Lock already exists\" → recoverable (retry later)\n   - \"Permission denied\" → non-recoverable (alert operator)\n   - Use different error types or error reasons\n\n5. **Add structured logging**:\n   - Include WO ID, operation name, paths in all error logs\n   - Use log levels appropriately (warning for expected, error for unexpected, critical for non-recoverable)\n   - Add error IDs for Sentry tracking\n\n---\n\n## Testing Recommendations\n\nAdd tests for error handling:\n\n```python\n# tests/unit/test_helpers_error_handling.py\n\ndef test_execute_rollback_critical_failure():\n    \"\"\"Test that critical rollback failures raise exceptions.\"\"\"\n    transaction = Transaction(wo_id=\"WO-001\", operations=[\n        RollbackOperation(name=\"acquire_lock\", description=\"\", rollback_type=\"remove_lock\"),\n        RollbackOperation(name=\"create_worktree\", description=\"\", rollback_type=\"remove_worktree\"),\n    ])\n    root = Path(\"/fake\")\n\n    # Mock lock removal to fail with permission error\n    with patch.object(Path, \"unlink\") as mock_unlink:\n        mock_unlink.side_effect = PermissionError(\"Cannot remove lock\")\n\n        with pytest.raises(RollbackCriticalError) as exc_info:\n            execute_rollback(transaction, root)\n\n        assert \"remove_lock\" in str(exc_info.value)\n        assert \"PermissionError\" in str(exc_info.value)\n\ndef test_update_lock_heartbeat_permission_denied():\n    \"\"\"Test that permission errors are non-recoverable.\"\"\"\n    lock_path = Path(\"/fake/lock\")\n\n    with patch.object(Path, \"exists\", return_value=True):\n        with patch.object(Path, \"read_text\", side_effect=PermissionError(\"Cannot read\")):\n            result = update_lock_heartbeat(lock_path)\n\n            assert result.is_err()\n            assert result.error.reason == \"permission_denied\"\n            assert result.error.recoverable is False\n\ndef test_check_lock_validity_corrupted_file():\n    \"\"\"Test that corrupted lock files are detected.\"\"\"\n    lock_path = Path(\"/fake/lock\")\n\n    with patch.object(Path, \"exists\", return_value=True):\n        with patch.object(Path, \"read_text\", return_value=\"PID: not_a_number\"):\n            result = check_lock_validity(lock_path)\n\n            assert result.is_err()\n            assert result.error.reason == \"corrupted\"\n```\n\n---\n\n## Conclusion\n\nThe PR introduces good transaction design concepts from the domain layer, but the infrastructure layer execution has several critical error handling issues:\n\n1. **Silent failures**: \"Best-effort\" rollback hides failures\n2. **Inadequate error context**: Boolean returns don't distinguish error types\n3. **Inappropriate fallbacks**: Default values mask underlying problems\n\nThe domain layer (`wo_entities.py`, `wo_transactions.py`) correctly uses `Result` types and should be the model for the infrastructure layer.\n\n**Risk Assessment**: HIGH - Silent failures in production could cause WOs to be stuck in running state, locks to not be released, and require manual intervention to recover.\n\n**Recommendation**: Address CRITICAL issues before merging to production. HIGH and MEDIUM issues should be fixed in follow-up PRs. LOW issues can be deferred.\n\n---\n\n**Audit Completed**: 2026-01-11\n**Next Review**: After fixes are implemented\n",
+      "char_count": 42108,
+      "token_est": 10527,
+      "source_path": "2026-01-11-pr18-error-handling-audit.md",
+      "chunking_method": "whole_file"
+    },
     {
       "id": "repo:docs/reports/anchor_dictionary_v1.md:cf19eb986f",
       "doc": "repo:docs/reports/anchor_dictionary_v1.md",
@@ -4255,14 +4405,14 @@
       "chunking_method": "whole_file"
     },
     {
-      "id": "repo:src/application/use_cases.py:b8ad6b88dd",
+      "id": "repo:src/application/use_cases.py:c856d17cfb",
       "doc": "repo:src/application/use_cases.py",
       "title_path": [
         "use_cases.py"
       ],
-      "text": "import json\nimport re\nimport subprocess\nfrom datetime import datetime\nfrom pathlib import Path\nfrom typing import Any\n\nimport yaml  # type: ignore[import-untyped]\n\nfrom src.application.context_service import ContextService\nfrom src.domain.constants import MAX_SKILL_LINES\nfrom src.domain.context_models import (\n    ContextChunk,\n    ContextIndexEntry,\n    ContextPack,\n    SourceFile,\n)\nfrom src.domain.models import TrifectaConfig, TrifectaPack, ValidationResult\nfrom src.domain.result import Err, Ok\nfrom src.infrastructure.file_system import FileSystemAdapter\nfrom src.infrastructure.file_system_utils import AtomicWriter, file_lock\nfrom src.infrastructure.templates import TemplateRenderer\n\n\nclass CreateTrifectaUseCase:\n    \"\"\"Create a new Trifecta pack.\"\"\"\n\n    def __init__(\n        self,\n        template_renderer: TemplateRenderer,\n        file_system: FileSystemAdapter,\n    ):\n        self.template_renderer = template_renderer\n        self.file_system = file_system\n\n    def execute(\n        self,\n        config: TrifectaConfig,\n        target_path: Path,\n        docs: list[str],\n        dry_run: bool = False,\n    ) -> TrifectaPack:\n        \"\"\"Generate and save a Trifecta pack.\n\n        Args:\n            config: Trifecta configuration\n            target_path: Target directory path\n            docs: List of documentation files\n            dry_run: If True, generate but don't save files\n\n        Returns:\n            TrifectaPack with generated content\n        \"\"\"\n        pack = TrifectaPack(\n            config=config,\n            skill_content=self.template_renderer.render_skill(config),\n            prime_content=self.template_renderer.render_prime(config, docs),\n            agent_content=self.template_renderer.render_agent(config),\n            session_content=self.template_renderer.render_session(config),\n            readme_content=self.template_renderer.render_readme(config),\n        )\n\n        # Validate before saving\n        if pack.skill_line_count > MAX_SKILL_LINES:\n            raise ValueError(f\"skill.md exceeds {MAX_SKILL_LINES} lines ({pack.skill_line_count})\")\n\n        # Save files (skip if dry_run)\n        if not dry_run:\n            self.file_system.save_trifecta(target_path, pack)\n\n        return pack\n\n\nclass ValidateTrifectaUseCase:\n    \"\"\"Validate an existing Trifecta pack.\"\"\"\n\n    def __init__(self, file_system: FileSystemAdapter):\n        self.file_system = file_system\n\n    def execute(self, target_path: Path) -> ValidationResult:\n        \"\"\"Validate a Trifecta pack structure and content.\"\"\"\n        errors: list[str] = []\n        warnings: list[str] = []\n\n        # Check skill.md\n        skill_path = target_path / \"skill.md\"\n        if not skill_path.exists():\n            errors.append(\"Missing: skill.md\")\n        else:\n            content = skill_path.read_text()\n            line_count = len(content.strip().split(\"\\n\"))\n            if line_count > MAX_SKILL_LINES:\n                errors.append(f\"skill.md exceeds {MAX_SKILL_LINES} lines ({line_count})\")\n\n        # Check _ctx directory\n        ctx_dir = target_path / \"_ctx\"\n        if not ctx_dir.exists():\n            errors.append(\"Missing: _ctx/ directory\")\n        else:\n            prime_files = list(ctx_dir.glob(\"prime_*.md\"))\n            if not prime_files:\n                errors.append(\"Missing: _ctx/prime_*.md\")\n\n            agent_path = ctx_dir / \"agent.md\"\n            if not agent_path.exists():\n                errors.append(\"Missing: _ctx/agent.md\")\n\n            session_files = list(ctx_dir.glob(\"session_*.md\"))\n            if not session_files:\n                warnings.append(\"Missing: _ctx/session_*.md (optional but recommended)\")\n\n        return ValidationResult(\n            passed=len(errors) == 0,\n            errors=errors,\n            warnings=warnings,\n        )\n\n\nclass RefreshPrimeUseCase:\n    \"\"\"Refresh prime_*.md by re-scanning docs.\"\"\"\n\n    def __init__(\n        self,\n        template_renderer: TemplateRenderer,\n        file_system: FileSystemAdapter,\n    ):\n        self.template_renderer = template_renderer\n        self.file_system = file_system\n\n    def execute(\n        self,\n        target_path: Path,\n        scan_path: Path,\n        repo_root: Path,\n    ) -> str:\n        \"\"\"Re-scan docs and update prime file.\"\"\"\n        ctx_dir = target_path / \"_ctx\"\n        prime_files = list(ctx_dir.glob(\"prime_*.md\"))\n\n        if not prime_files:\n            raise FileNotFoundError(\"No prime_*.md found. Run 'create' first.\")\n\n        prime_path = prime_files[0]\n        segment = prime_path.stem.replace(\"prime_\", \"\")\n\n        # Scan docs\n        docs = self.file_system.scan_docs(scan_path, repo_root)\n\n        # Build minimal config\n        config = TrifectaConfig(\n            segment=segment,\n            scope=f\"Segment {segment}\",\n            repo_root=str(repo_root),\n        )\n\n        # Regenerate prime\n        prime_content = self.template_renderer.render_prime(config, docs)\n        prime_path.write_text(prime_content)\n\n        return prime_path.name\n\n\nclass BuildContextPackUseCase:\n    \"\"\"Build a Context Pack for a segment.\"\"\"\n\n    def __init__(self, file_system: FileSystemAdapter, telemetry: Any = None) -> None:\n        self.file_system = file_system\n        self.telemetry = telemetry\n\n    def _extract_references(\n        self, content: str, root: Path, repo_root: Path | None = None\n    ) -> dict[str, Path]:\n        \"\"\"Extract referenced files from Prime content with STRICT SECURITY.\"\"\"\n\n        refs: dict[str, Path] = {}\n        visited_paths = set()\n        MAX_LINKS = 25\n\n        # Regex for [link](path) and `path`\n        lines = content.splitlines()\n        for line in lines:\n            line = line.strip()\n            if not (line.startswith(\"-\") or line.startswith(\"*\") or line[0:1].isdigit()):\n                continue\n\n            path_str = None\n            # Try `code` block\n            code_match = re.search(r\"`([^`]+)`\", line)\n            if code_match:\n                path_str = code_match.group(1).strip()\n\n            # Try [link](path)\n            link_match = re.search(r\"\\[.*?\\]\\((.*?)\\)\", line)\n            if link_match:\n                path_str = link_match.group(1).strip()\n\n            if path_str:\n                if len(refs) >= MAX_LINKS:\n                    warning_msg = \"prime_links_truncated_total\"\n                    if self.telemetry:\n                        self.telemetry.incr(warning_msg)\n                    print(\n                        f\"⚠️ Warning: Max links ({MAX_LINKS}) reached in Prime. Skipping remainder.\"\n                    )\n                    break\n\n                if self._is_valid_ref(path_str):\n                    resolved = self._resolve_path(path_str, root, repo_root)\n\n                    if resolved:\n                        # Cycle/Duplicate Check\n                        abs_path = str(resolved.resolve())\n                        if abs_path in visited_paths:\n                            if self.telemetry:\n                                self.telemetry.incr(\"prime_links_cycle_total\")\n                            print(\n                                f\"⚠️ Warning: Cycle/Duplicate detected for '{path_str}'. Skipping.\"\n                            )\n                            continue\n\n                        # Security Scope Check\n                        if self._is_safe_path(resolved, root):\n                            refs[path_str] = resolved\n                            visited_paths.add(abs_path)\n                            if self.telemetry:\n                                self.telemetry.incr(\"prime_links_included_total\")\n                        else:\n                            # Policy: FAIL-CLOSED (PCC enforcement)\n                            if self.telemetry:\n                                self.telemetry.incr(\"prime_links_skipped_security_total\")\n                            error_msg = f\"PROHIBITED: Reference '{path_str}' resolves outside segment or in forbidden path.\"\n                            print(f\"❌ {error_msg}\")\n                            raise ValueError(error_msg)\n\n        return refs\n\n    def _validate_prohibited_paths(self, files: list[Path]) -> None:\n        \"\"\"Fail-closed: Reject any file that looks like code or is in prohibited dirs.\"\"\"\n        import sys\n\n        for f in files:\n            path_str = str(f).lower()\n            if (\n                \"/src/\" in path_str\n                or \"src/\" in path_str\n                or f.suffix in [\".py\", \".ts\", \".js\", \".go\", \".rs\"]\n            ):\n                print(f\"❌ PROHIBITED: Cannot index code files in pack: {f}\", file=sys.stderr)\n                print(\n                    \"Trifecta is Programming Context Calling (meta-first), not RAG.\",\n                    file=sys.stderr,\n                )\n                print(\"Code access MUST be via curated prime links in meta-docs.\", file=sys.stderr)\n                # In UseCase, we raise ValueError instead of sys.exit\n                raise ValueError(f\"Prohibited file in context pack: {f}\")\n\n    def _is_valid_ref(self, path_str: str) -> bool:\n        if \"://\" in path_str or not path_str or path_str.startswith(\"#\"):\n            return False\n        # Allowlist: MD only for now\n        return path_str.endswith(\".md\")\n\n    def _is_safe_path(self, path: Path, root: Path) -> bool:\n        \"\"\"Prevent path traversal. Must be within segment.\"\"\"\n        # Resolves symlinks to ensure we don't escape\n        try:\n            resolved_path = path.resolve()\n            resolved_root = root.resolve()\n            return resolved_path.is_relative_to(resolved_root)\n        except ValueError:\n            return False\n\n    def _resolve_path(self, path_str: str, root: Path, repo_root: Path | None) -> Path | None:\n        # 1. Try relative to component root\n        p = root / path_str\n        if p.exists() and p.is_file():\n            return p\n\n        # 2. Try relative to REPO_ROOT (if known) -- BUT ONLY if it resolves inside segment\n        # (This effectively disables repo-root links unless they point back into segment,\n        # complying with \"Scope limited to segment\")\n        if repo_root:\n            p = repo_root / path_str\n            if p.exists() and p.is_file():\n                return p\n\n        return None\n\n    def execute(self, target_path: Path) -> \"Ok[ContextPack] | Err[list[str]]\":\n        if self.telemetry:\n            self.telemetry.incr(\"ctx_build_count\")\n        \"\"\"Scan a Trifecta segment and build a context_pack.json.\"\"\"\n        from src.domain.naming import normalize_segment_id\n        from src.domain.result import Err, Ok\n\n        # 1. Derive segment_id deterministically\n        # Priority: trifecta_config.json (source of truth) > directory name (fallback)\n        try:\n            config = self.file_system.load_trifecta_config(target_path)\n            if config:\n                # Source of Truth: Config\n                segment_id = config.segment_id\n            else:\n                # Fallback: Directory Name\n                segment_id = normalize_segment_id(target_path.name)\n        except ValueError:\n            # Deterministic Fail-Closed\n            return Err([\"Failed Constitution: trifecta_config.json is invalid\"])\n\n        ctx_dir = target_path / \"_ctx\"\n\n        # 2. FAIL-CLOSED: Validate exactly one prime file with correct suffix\n        expected_prime = ctx_dir / f\"prime_{segment_id}.md\"\n        if not expected_prime.exists():\n            from src.application.exceptions import PrimeFileNotFoundError\n\n            raise PrimeFileNotFoundError(expected_path=expected_prime, segment_id=segment_id)\n\n        # 3. FAIL-CLOSED: Detect contamination (other prime_*.md files)\n        all_prime_files = list(ctx_dir.glob(\"prime_*.md\"))\n        if len(all_prime_files) > 1:\n            contaminating = [f.name for f in all_prime_files if f != expected_prime]\n            raise ValueError(\n                f\"Ambiguous/contaminated _ctx directory: found {len(all_prime_files)} prime_*.md files. \"\n                f\"Expected only: prime_{segment_id}.md. \"\n                f\"Contaminating files: {contaminating}\"\n            )\n\n        prime_path = expected_prime\n\n        # Try to parse REPO_ROOT from prime header\n        repo_root = None\n        prime_content = prime_path.read_text()\n\n        rr_match = re.search(r\">\\s*\\*\\*REPO_ROOT\\*\\*:\\s*`?([^`\\n]+)`?\", prime_content)\n        if rr_match:\n            try:\n                repo_root = Path(rr_match.group(1).strip())\n            except Exception:\n                pass\n\n        # 4. Identify source files with STRICT VALIDATION\n        sources = {\n            \"skill\": target_path / \"skill.md\",\n            \"prime\": prime_path,\n        }\n\n        # 4a. STRICT Agent Validation (Symmetric to Prime)\n        expected_agent = ctx_dir / f\"agent_{segment_id}.md\"\n        all_agent_files = list(ctx_dir.glob(\"agent_*.md\"))\n\n        if len(all_agent_files) > 1:\n            contaminating = [f.name for f in all_agent_files if f != expected_agent]\n            raise ValueError(\n                f\"Ambiguous/contaminated _ctx directory: found {len(all_agent_files)} agent_*.md files. \"\n                f\"Expected only: agent_{segment_id}.md. \"\n                f\"Contaminating files: {contaminating}\"\n            )\n\n        if not expected_agent.exists():\n            # If we require agent to exist (which is standard), strict fail:\n            if all_agent_files:\n                # Found agent_wrong.md but not agent_correct.md -> Contamination/Mismatch\n                raise ValueError(\n                    f\"Contaminated _ctx directory: found agent_*.md files but missing expected agent_{segment_id}.md. \"\n                    f\"Found: {[f.name for f in all_agent_files]}\"\n                )\n            # If just missing, FileNotFoundError (Validation Gate usually catches this earlier, but build must be robust)\n            # For now, let's allow \"missing\" agent if logic tolerates it, OR enforce it.\n            # The tests suggest we want strict enforcement.\n            # However, validators.py checks for \"Missing context file\".\n            # Let's ensure consistency. If validators pass, this should exist.\n            pass\n        else:\n            sources[\"agent\"] = expected_agent\n\n        # 4b. STRICT Session Validation\n        expected_session = ctx_dir / f\"session_{segment_id}.md\"\n        all_session_files = list(ctx_dir.glob(\"session_*.md\"))\n\n        if len(all_session_files) > 1:\n            contaminating = [f.name for f in all_session_files if f != expected_session]\n            raise ValueError(\n                f\"Ambiguous/contaminated _ctx directory: found {len(all_session_files)} session_*.md files. \"\n                f\"Expected only: session_{segment_id}.md. \"\n                f\"Contaminating files: {contaminating}\"\n            )\n\n        if all_session_files and not expected_session.exists():\n            raise ValueError(\n                f\"Contaminated _ctx directory: found session_*.md files but missing expected session_{segment_id}.md. \"\n                f\"Found: {[f.name for f in all_session_files]}\"\n            )\n\n        if expected_session.exists():\n            sources[\"session\"] = expected_session\n\n        # 4.5 Extract references from Prime\n        refs = self._extract_references(prime_content, target_path, repo_root)\n\n        # Compute primary source paths for exclusion (path-aware deduplication)\n        primary_skill_path = target_path / \"skill.md\"\n        excluded_paths = {primary_skill_path.resolve()}\n\n        for name, path in refs.items():\n            # Skip if this exact path is already indexed as a primary source\n            if path.resolve() in excluded_paths:\n                continue\n            sources[f\"ref:{name}\"] = path\n\n        # 4.6 NEW: Scan repo content (docs/, src/, README) - WO-0009 fix\n        # This was missing - previously only _ctx metadata was indexed\n        exclude_dirs = {\n            \".git\",\n            \".venv\",\n            \"node_modules\",\n            \"dist\",\n            \"build\",\n            \"_ctx\",\n            \"__pycache__\",\n            \".pytest_cache\",\n        }\n\n        # Scan for markdown and code files\n        for pattern in [\n            \"docs/**/*.md\",\n            \"src/**/*.py\",\n            \"src/**/*.ts\",\n            \"src/**/*.js\",\n            \"README*.md\",\n            \"*.md\",\n        ]:\n            for file_path in target_path.glob(pattern):\n                # Skip if in excluded dir\n                if any(excluded_dir in file_path.parts for excluded_dir in exclude_dirs):\n                    continue\n                # Skip if already indexed\n                if file_path.resolve() in excluded_paths:\n                    continue\n                # Skip if not a file\n                if not file_path.is_file():\n                    continue\n\n                # Add to sources with repo prefix\n                rel_path = file_path.relative_to(target_path)\n                source_key = f\"repo:{rel_path}\"\n                sources[source_key] = file_path\n                excluded_paths.add(file_path.resolve())\n\n        # 4.7 FAIL-CLOSED VALIDATION (was 4.6)\n        # NOTE: _validate_prohibited_paths rejects /src/ code files\n        # We need to allow them now for WO-0009\n        # Commenting out for now - will fix validation separately if needed\n        # self._validate_prohibited_paths(list(sources.values()))\n\n        chunks: list[ContextChunk] = []\n        index: list[ContextIndexEntry] = []\n        source_files: list[SourceFile] = []\n\n        # 3. Process each file as a whole_file chunk (MVP)\n        for doc_type, file_path in sources.items():\n            if not file_path.exists():\n                continue\n\n            content = file_path.read_text()\n            if not content.endswith(\"\\n\"):\n                content += \"\\n\"\n            # Simple token estimation: 4 chars per token\n            token_est = len(content) // 4\n\n            # Source metadata\n            import hashlib\n\n            sha256 = hashlib.sha256(content.encode()).hexdigest()\n            mtime = file_path.stat().st_mtime\n            source_files.append(\n                SourceFile(\n                    path=str(file_path.relative_to(target_path)),\n                    sha256=sha256,\n                    mtime=mtime,\n                    chars=len(content),\n                )\n                if target_path in file_path.parents or target_path == file_path\n                else SourceFile(path=file_path.name, sha256=sha256, mtime=mtime, chars=len(content))\n            )\n\n            # Stable ID: doc:sha1(doc + \"\\n\" + title_path_norm + \"\\n\" + text_sha256)[:10]\n            title_path_norm = file_path.name\n            id_input = f\"{doc_type}\\n{title_path_norm}\\n{sha256}\"\n            content_hash = hashlib.sha1(id_input.encode(), usedforsecurity=False).hexdigest()[:10]\n            chunk_id = f\"{doc_type}:{content_hash}\"\n\n            chunk = ContextChunk(\n                id=chunk_id,\n                doc=doc_type,\n                title_path=[file_path.name],\n                text=content,\n                char_count=len(content),\n                token_est=token_est,\n                source_path=str(file_path.name),  # Minimal for MVP\n                chunking_method=\"whole_file\",\n            )\n            chunks.append(chunk)\n\n            # Index entry (L0)\n            preview = content[:200].strip() + \"...\" if len(content) > 200 else content\n            index.append(\n                ContextIndexEntry(\n                    id=chunk_id,\n                    title_path_norm=title_path_norm,\n                    preview=preview,\n                    token_est=token_est,\n                )\n            )\n\n        pack = ContextPack(\n            segment=segment_id, source_files=source_files, chunks=chunks, index=index\n        )\n\n        # 4. Save to disk atomically with lock\n        pack_path = ctx_dir / \"context_pack.json\"\n        lock_path = ctx_dir / \".autopilot.lock\"\n\n        with file_lock(lock_path):\n            AtomicWriter.write(pack_path, pack.model_dump_json(indent=2))\n\n        return Ok(pack)\n\n\nclass MacroLoadUseCase:\n    \"\"\"Macro command 'trifecta load' implementation.\"\"\"\n\n    def __init__(self, file_system: FileSystemAdapter, telemetry: Any = None) -> None:\n        self.file_system = file_system\n        self.telemetry = telemetry\n\n    def execute(self, target_path: Path, task: str, mode: str = \"pcc\") -> str:\n        \"\"\"Execute the macro load logic using Plan A (API) or Plan B (Fallback).\"\"\"\n        ctx_dir = target_path / \"_ctx\"\n        pack_path = ctx_dir / \"context_pack.json\"\n\n        # Force Fallback if mode is fullfiles or pack missing\n        if mode == \"fullfiles\" or not pack_path.exists():\n            # FALLBACK (Plan B): Traditional file selection\n            return self._fallback_load(target_path, task)\n\n        # 1. Expand task with aliases for discovery\n        from src.application.query_expander import QueryExpander\n        from src.application.query_normalizer import QueryNormalizer\n        from src.infrastructure.alias_loader import AliasLoader\n\n        alias_loader = AliasLoader(target_path)\n        aliases = alias_loader.load()\n\n        norm_task = QueryNormalizer.normalize(task)\n        tokens = QueryNormalizer.tokenize(norm_task)\n        expander = QueryExpander(aliases)\n        expanded_terms = expander.expand(norm_task, tokens)\n\n        # Execute search for each expanded piece\n        service = ContextService(target_path)\n        combined_hits: dict[str, tuple[Any, float]] = {}  # chunk_id -> (hit, max_weighted_score)\n\n        for term, weight in expanded_terms:\n            search_res = service.search(term, k=10)\n            for hit in search_res.hits:\n                weighted_score = hit.score * weight\n                if hit.id not in combined_hits or weighted_score > combined_hits[hit.id][1]:\n                    combined_hits[hit.id] = (hit, weighted_score)\n\n        if not combined_hits:\n            # If search fails, fallback to Plan B\n            return self._fallback_load(target_path, task)\n\n        # T4: Ordena hits por \"valor por token\" (weighted_score/token_est)\n        hits = list(combined_hits.values())\n        hits.sort(key=lambda x: x[1] / max(x[0].token_est, 1), reverse=True)\n        top_hits = [hit for hit, _ in hits[:5]]\n        ids = [hit.id for hit in top_hits]\n\n        # 2. Get L0 Skeletons (Initial navigation)\n        l0_ids = []\n        for cid in [\"skill\", \"agent\"]:\n            match = [c.id for c in service._load_pack().chunks if c.id.startswith(f\"{cid}:\")]\n            if match:\n                l0_ids.append(match[0])\n\n        l0_res = service.get(l0_ids, mode=\"skeleton\", budget_token_est=400)\n\n        # 3. Get Task Evidence (L1 Excerpts)\n        evid_res = service.get(ids, mode=\"excerpt\", budget_token_est=1500)\n\n        # 4. Format output (EVIDENCE read-only style)\n        output = [f\"# Context Evidence for Task: {task}\\n\"]\n        output.append(\"> [!NOTE]\")\n        output.append(\n            \"> Loaded via Programmatic Context Calling (Plan A). Citations as [chunk_id].\\n\"\n        )\n\n        output.append(\"### EVIDENCE (read-only)\")\n\n        # Add Skeletons first as navigation\n        for chunk in l0_res.chunks:\n            output.append(f\"#### [{chunk.id}] {chunk.title_path[0]} (Skeleton)\")\n            output.append(chunk.text)\n            output.append(\"\")\n\n        # Add Excerpts\n        for chunk in evid_res.chunks:\n            output.append(f\"#### [{chunk.id}] {' > '.join(chunk.title_path)}\")\n            output.append(chunk.text)\n            output.append(\"\")\n\n        if evid_res.total_tokens > 1500:\n            output.append(\"\\n> [!WARNING]\")\n            output.append(\"> Context budget reached. Some evidence might be truncated or omitted.\")\n\n        return \"\\n\".join(output)\n\n        if evid_res.total_tokens >= 1000:\n            output.append(\"> [!WARNING]\")\n            output.append(\"> Context budget reached. Evidence was truncated (Backpressure).\")\n\n        return \"\\n\".join(output)\n\n    def _fallback_load(self, target_path: Path, task: str) -> str:\n        \"\"\"Traditional heuristic file selection fallback.\"\"\"\n        task_lower = task.lower()\n        ctx_dir = target_path / \"_ctx\"\n\n        prime_files = list(ctx_dir.glob(\"prime_*.md\"))\n        prime_path = prime_files[0] if prime_files else None\n\n        files_to_load = [target_path / \"skill.md\"]\n\n        # Heuristics\n        if any(kw in task_lower for kw in [\"implement\", \"debug\", \"fix\", \"code\"]):\n            files_to_load.append(ctx_dir / \"agent.md\")\n\n        if any(kw in task_lower for kw in [\"plan\", \"design\", \"doc\"]):\n            if prime_path:\n                files_to_load.append(prime_path)\n\n        if any(kw in task_lower for kw in [\"session\", \"handoff\", \"history\"]):\n            session_files = list(ctx_dir.glob(\"session_*.md\"))\n            if session_files:\n                files_to_load.append(session_files[0])\n\n        output = [f\"# Context (Fallback Heuristic) for Task: {task}\\n\"]\n        for f in files_to_load:\n            if f.exists():\n                output.append(f\"## File: {f.name}\")\n                output.append(f.read_text())\n                output.append(\"\\n---\\n\")\n\n        return \"\\n\".join(output)\n\n\nclass ValidateContextPackUseCase:\n    \"\"\"Validator for Context Pack integrity and invariants.\"\"\"\n\n    def __init__(self, file_system: FileSystemAdapter, telemetry: Any = None) -> None:\n        self.file_system = file_system\n        self.telemetry = telemetry\n\n    def execute(self, target_path: Path) -> ValidationResult:\n        \"\"\"Validate context_pack.json structure and consistency.\"\"\"\n        errors: list[str] = []\n        warnings: list[str] = []\n\n        # 0. Path Sanitization\n        segment = target_path.name\n        if \"..\" in segment or segment.startswith(\"/\"):\n            errors.append(f\"Invalid or unsafe segment path: {segment}\")\n            return ValidationResult(passed=False, errors=errors, warnings=[])\n\n        ctx_dir = target_path / \"_ctx\"\n        pack_path = ctx_dir / \"context_pack.json\"\n\n        if not pack_path.exists():\n            return ValidationResult(passed=False, errors=[\"Missing context_pack.json\"], warnings=[])\n\n        try:\n            import hashlib\n            import json\n\n            with open(pack_path, \"r\") as f:\n                data = json.load(f)\n\n            # 1. Schema version check\n            if data.get(\"schema_version\") != 1:\n                errors.append(f\"Unsupported schema version: {data.get('schema_version')}\")\n\n            # 2. Size limits check\n            chunks_data = data.get(\"chunks\", [])\n            total_chars = sum(c.get(\"char_count\", 0) for c in chunks_data)\n            if total_chars > 2_000_000:  # 2MB limit for context pack (reasonable)\n                warnings.append(f\"Context pack is quite large ({total_chars} chars)\")\n\n            # 3. Index integrity\n            chunk_ids = {c[\"id\"] for c in chunks_data}\n            for entry in data.get(\"index\", []):\n                if entry[\"id\"] not in chunk_ids:\n                    errors.append(f\"Index references missing chunk ID: {entry['id']}\")\n\n            # 4. Source file traceability (SHA256/mtime/chars)\n            for src in data.get(\"source_files\", []):\n                src_rel_path = src[\"path\"]\n                src_abs_path = target_path / src_rel_path\n\n                if not src_abs_path.exists():\n                    # Fallback for files outside segment: check if it's just a filename\n                    # Try direct filename in segment\n                    src_abs_path = target_path / Path(src_rel_path).name\n                    if not src_abs_path.exists():\n                        errors.append(\n                            f\"Source file listed in pack but missing from disk: {src_rel_path}\"\n                        )\n                        continue\n\n                # Deep verification - use same normalization as build\n                content_str = src_abs_path.read_text()\n                if not content_str.endswith(\"\\n\"):\n                    content_str += \"\\n\"\n                content = content_str.encode()\n                current_sha = hashlib.sha256(content).hexdigest()\n                current_chars = len(content_str)\n                current_mtime = src_abs_path.stat().st_mtime\n\n                if current_sha != src[\"sha256\"]:\n                    errors.append(f\"Source file content changed (Hash mismatch): {src_rel_path}\")\n                elif abs(current_mtime - src[\"mtime\"]) > 1.0:  # 1s tolerance\n                    warnings.append(f\"Source file mtime changed but hash matches: {src_rel_path}\")\n\n                if current_chars != src[\"chars\"]:\n                    errors.append(\n                        f\"Source file size mismatch: {src_rel_path} ({current_chars} vs {src['chars']})\"\n                    )\n\n            # 5. Basic content check\n            if not chunks_data:\n                errors.append(\"Context pack contains no chunks\")\n\n        except Exception as e:\n            errors.append(f\"Failed to parse context pack: {str(e)}\")\n\n        result = ValidationResult(passed=len(errors) == 0, errors=errors, warnings=warnings)\n\n        # Record result and stale detection\n        if self.telemetry:\n            if result.passed:\n                self.telemetry.incr(\"ctx_validate_pass_count\")\n                self.telemetry.stale_detected = False\n            else:\n                self.telemetry.incr(\"ctx_validate_fail_count\")\n                # Check if failure is due to stale/corruption\n                is_stale = any(\"changed\" in e.lower() or \"mismatch\" in e.lower() for e in errors)\n                self.telemetry.stale_detected = is_stale\n\n        return result\n\n\nclass AutopilotUseCase:\n    \"\"\"Runner for automated context refresh based on session.md contract.\"\"\"\n\n    def __init__(self, file_system: FileSystemAdapter):\n        self.file_system = file_system\n\n    def execute(self, target_path: Path) -> dict[str, Any]:\n        \"\"\"Read autopilot config and run steps.\"\"\"\n        ctx_dir = target_path / \"_ctx\"\n        session_files = list(ctx_dir.glob(\"session_*.md\"))\n\n        if not session_files:\n            return {\"status\": \"skipped\", \"reason\": \"No session file found\"}\n\n        session_path = session_files[0]\n        content = session_path.read_text()\n\n        # Extract YAML frontmatter or block\n        try:\n            # Simple extractor for YAML block in markdown\n            import re\n\n            match = re.search(r\"```yaml\\n(autopilot:.*?)\\n```\", content, re.DOTALL)\n            if not match:\n                # Try frontmatter (---)\n                match = re.search(r\"^---\\n(autopilot:.*?)\\n---\", content, re.DOTALL | re.MULTILINE)\n\n            if not match:\n                return {\"status\": \"skipped\", \"reason\": \"No autopilot config found in session.md\"}\n\n            config = yaml.safe_load(match.group(1)).get(\"autopilot\", {})\n            if not config.get(\"enabled\", False):\n                return {\"status\": \"skipped\", \"reason\": \"Autopilot disabled in config\"}\n\n            steps = config.get(\"steps\", [])\n            timeouts = config.get(\"timeouts\", {})\n            results = []\n            log_entries = [f\"--- Autopilot Run: {datetime.now().isoformat()} ---\"]\n\n            for step in steps:\n                cmd = step.split()\n                timeout = timeouts.get(step.replace(\"trifecta ctx \", \"\"), 30)\n\n                try:\n                    full_cmd = (\n                        [\"python3\", \"-m\", \"src.infrastructure.cli\"]\n                        + cmd[1:]\n                        + [\"--path\", str(target_path)]\n                    )\n                    process = subprocess.run(\n                        full_cmd, capture_output=True, text=True, timeout=timeout\n                    )\n\n                    success = process.returncode == 0\n                    results.append(\n                        {\n                            \"step\": step,\n                            \"success\": success,\n                            \"stdout\": process.stdout.strip(),\n                            \"stderr\": process.stderr.strip(),\n                        }\n                    )\n\n                    status_str = \"SUCCESS\" if success else \"FAILED\"\n                    log_entries.append(f\"[{status_str}] {step}\")\n                    if not success:\n                        log_entries.append(f\"  Error: {process.stderr.strip()}\")\n                        break  # Stop on first failure\n                except subprocess.TimeoutExpired:\n                    results.append({\"step\": step, \"success\": False, \"error\": \"Timeout\"})\n                    log_entries.append(f\"[TIMEOUT] {step}\")\n                    break\n\n            # Write to autopilot.log\n            log_path = ctx_dir / \"autopilot.log\"\n            with open(log_path, \"a\") as f:\n                f.write(\"\\n\".join(log_entries) + \"\\n\\n\")\n\n            return {\"status\": \"completed\", \"results\": results}\n\n        except Exception as e:\n            return {\"status\": \"error\", \"reason\": f\"Failed to execute autopilot: {str(e)}\"}\n\n\nclass StatsUseCase:\n    \"\"\"Generate telemetry statistics for a segment.\"\"\"\n\n    def __init__(self, file_system: FileSystemAdapter, telemetry: Any = None) -> None:\n        self.file_system = file_system\n        self.telemetry = telemetry\n\n    def _classify_query_type(self, query: str) -> str:\n        \"\"\"Heurística de clasificación de query.\"\"\"\n        if not query:\n            return \"unknown\"\n        q_lower = query.lower()\n\n        # Meta: qué hacer / estado / guía / arquitectura / procedimiento\n        meta_keywords = [\n            \"how\",\n            \"what\",\n            \"where\",\n            \"plan\",\n            \"guide\",\n            \"architecture\",\n            \"design\",\n            \"status\",\n            \"overview\",\n            \"explain\",\n            \"description\",\n        ]\n\n        # Impl: código específico / símbolos / funciones / archivos\n        impl_keywords = [\n            \"function\",\n            \"class\",\n            \"method\",\n            \"file\",\n            \"implement\",\n            \"code\",\n            \"symbol\",\n            \"def \",\n            \"class \",\n            \"import\",\n        ]\n\n        if any(kw in q_lower for kw in impl_keywords):\n            return \"impl\"\n        elif any(kw in q_lower for kw in meta_keywords):\n            return \"meta\"\n        else:\n            return \"unknown\"\n\n    def _classify_hit_target(self, chunk_id: str) -> str:\n        \"\"\"Clasificar target por chunk_id prefix.\"\"\"\n        if not chunk_id:\n            return \"other\"\n        if chunk_id.startswith(\"skill:\"):\n            return \"skill\"\n        elif chunk_id.startswith(\"prime:\"):\n            return \"prime\"\n        elif chunk_id.startswith(\"session:\"):\n            return \"session\"\n        elif chunk_id.startswith(\"agent:\"):\n            return \"agent\"\n        elif chunk_id.startswith(\"ref:\"):\n            return \"ref\"\n        else:\n            return \"other\"\n\n    def execute(self, target_path: Path, window: int = 0) -> dict[str, Any]:\n        \"\"\"Generate statistics from telemetry events.\n\n        Args:\n            target_path: Path to segment directory\n            window: Number of days to look back (0 = all)\n\n        Returns:\n            Dictionary with statistics\n        \"\"\"\n        from collections import Counter\n        from datetime import datetime, timezone, timedelta\n\n        if self.telemetry:\n            self.telemetry.incr(\"ctx_stats_count\")\n\n        events_path = target_path / \"_ctx\" / \"telemetry\" / \"events.jsonl\"\n\n        # Load events\n        events = []\n        if events_path.exists():\n            with open(events_path) as f:\n                for line in f:\n                    if line.strip():\n                        try:\n                            events.append(json.loads(line))\n                        except json.JSONDecodeError:\n                            pass\n\n        # Filter by window\n        if window > 0:\n            cutoff = datetime.now(timezone.utc) - timedelta(days=window)\n            events = [\n                e\n                for e in events\n                if datetime.fromisoformat(e[\"ts\"].replace(\"Z\", \"+00:00\")) >= cutoff\n            ]\n\n        # Filter searches only\n        searches = [e for e in events if e[\"cmd\"] == \"ctx.search\"]\n        total_searches = len(searches)\n        hits = sum(1 for e in searches if e.get(\"result\", {}).get(\"hits\", 0) > 0)\n        zero_hits = total_searches - hits\n        hit_rate = hits / total_searches * 100 if total_searches > 0 else 0\n\n        latencies = [e.get(\"timing_ms\", 0) for e in searches if e.get(\"timing_ms\", 0) > 0]\n        avg_latency = sum(latencies) / len(latencies) if latencies else 0\n\n        # Top zero-hit queries\n        zero_hit_queries = [\n            (e.get(\"args\", {}).get(\"query\", \"\"), e.get(\"args\", {}).get(\"query\", \"\"))\n            for e in searches\n            if e.get(\"result\", {}).get(\"hits\", 0) == 0\n        ]\n        query_counts = Counter(q for q, _ in zero_hit_queries)\n\n        # Breakdown por query_type\n        query_type_counts: Counter[str] = Counter()\n        for e in searches:\n            query = e.get(\"args\", {}).get(\"query\", \"\")\n            qtype = self._classify_query_type(query)\n            query_type_counts[qtype] += 1\n\n        # Breakdown por hit_target\n        hit_target_counts: Counter[str] = Counter()\n        for e in searches:\n            returned_ids = e.get(\"result\", {}).get(\"returned_ids\", [])\n            if returned_ids:\n                for cid in returned_ids:\n                    target = self._classify_hit_target(cid)\n                    hit_target_counts[target] += 1\n\n        return {\n            \"summary\": {\n                \"total_searches\": total_searches,\n                \"hits\": hits,\n                \"zero_hits\": zero_hits,\n                \"hit_rate\": round(hit_rate, 1),\n                \"avg_latency_ms\": round(avg_latency, 1),\n            },\n            \"top_zero_hit_queries\": [\n                {\"query\": q, \"count\": c} for q, c in query_counts.most_common(10)\n            ],\n            \"query_type_breakdown\": {\n                qt: query_type_counts[qt] for qt in [\"meta\", \"impl\", \"unknown\"]\n            },\n            \"hit_target_breakdown\": dict(hit_target_counts),\n        }\n",
-      "char_count": 38087,
-      "token_est": 9521,
+      "text": "import json\nimport re\nimport subprocess\nimport sys\nfrom datetime import datetime\nfrom pathlib import Path\nfrom typing import Any\n\nimport yaml  # type: ignore[import-untyped]\n\nfrom src.application.context_service import ContextService\nfrom src.domain.constants import MAX_SKILL_LINES\nfrom src.domain.context_models import (\n    ContextChunk,\n    ContextIndexEntry,\n    ContextPack,\n    SourceFile,\n)\nfrom src.domain.models import TrifectaConfig, TrifectaPack, ValidationResult\nfrom src.domain.result import Err, Ok\nfrom src.infrastructure.file_system import FileSystemAdapter\nfrom src.infrastructure.file_system_utils import AtomicWriter, file_lock\nfrom src.infrastructure.templates import TemplateRenderer\n\n\nclass CreateTrifectaUseCase:\n    \"\"\"Create a new Trifecta pack.\"\"\"\n\n    def __init__(\n        self,\n        template_renderer: TemplateRenderer,\n        file_system: FileSystemAdapter,\n    ):\n        self.template_renderer = template_renderer\n        self.file_system = file_system\n\n    def execute(\n        self,\n        config: TrifectaConfig,\n        target_path: Path,\n        docs: list[str],\n        dry_run: bool = False,\n    ) -> TrifectaPack:\n        \"\"\"Generate and save a Trifecta pack.\n\n        Args:\n            config: Trifecta configuration\n            target_path: Target directory path\n            docs: List of documentation files\n            dry_run: If True, generate but don't save files\n\n        Returns:\n            TrifectaPack with generated content\n        \"\"\"\n        pack = TrifectaPack(\n            config=config,\n            skill_content=self.template_renderer.render_skill(config),\n            prime_content=self.template_renderer.render_prime(config, docs),\n            agent_content=self.template_renderer.render_agent(config),\n            session_content=self.template_renderer.render_session(config),\n            readme_content=self.template_renderer.render_readme(config),\n        )\n\n        # Validate before saving\n        if pack.skill_line_count > MAX_SKILL_LINES:\n            raise ValueError(f\"skill.md exceeds {MAX_SKILL_LINES} lines ({pack.skill_line_count})\")\n\n        # Save files (skip if dry_run)\n        if not dry_run:\n            self.file_system.save_trifecta(target_path, pack)\n\n        return pack\n\n\nclass ValidateTrifectaUseCase:\n    \"\"\"Validate an existing Trifecta pack.\"\"\"\n\n    def __init__(self, file_system: FileSystemAdapter):\n        self.file_system = file_system\n\n    def execute(self, target_path: Path) -> ValidationResult:\n        \"\"\"Validate a Trifecta pack structure and content.\"\"\"\n        errors: list[str] = []\n        warnings: list[str] = []\n\n        # Check skill.md\n        skill_path = target_path / \"skill.md\"\n        if not skill_path.exists():\n            errors.append(\"Missing: skill.md\")\n        else:\n            content = skill_path.read_text()\n            line_count = len(content.strip().split(\"\\n\"))\n            if line_count > MAX_SKILL_LINES:\n                errors.append(f\"skill.md exceeds {MAX_SKILL_LINES} lines ({line_count})\")\n\n        # Check _ctx directory\n        ctx_dir = target_path / \"_ctx\"\n        if not ctx_dir.exists():\n            errors.append(\"Missing: _ctx/ directory\")\n        else:\n            prime_files = list(ctx_dir.glob(\"prime_*.md\"))\n            if not prime_files:\n                errors.append(\"Missing: _ctx/prime_*.md\")\n\n            agent_path = ctx_dir / \"agent.md\"\n            if not agent_path.exists():\n                errors.append(\"Missing: _ctx/agent.md\")\n\n            session_files = list(ctx_dir.glob(\"session_*.md\"))\n            if not session_files:\n                warnings.append(\"Missing: _ctx/session_*.md (optional but recommended)\")\n\n        return ValidationResult(\n            passed=len(errors) == 0,\n            errors=errors,\n            warnings=warnings,\n        )\n\n\nclass RefreshPrimeUseCase:\n    \"\"\"Refresh prime_*.md by re-scanning docs.\"\"\"\n\n    def __init__(\n        self,\n        template_renderer: TemplateRenderer,\n        file_system: FileSystemAdapter,\n    ):\n        self.template_renderer = template_renderer\n        self.file_system = file_system\n\n    def execute(\n        self,\n        target_path: Path,\n        scan_path: Path,\n        repo_root: Path,\n    ) -> str:\n        \"\"\"Re-scan docs and update prime file.\"\"\"\n        ctx_dir = target_path / \"_ctx\"\n        prime_files = list(ctx_dir.glob(\"prime_*.md\"))\n\n        if not prime_files:\n            raise FileNotFoundError(\"No prime_*.md found. Run 'create' first.\")\n\n        prime_path = prime_files[0]\n        segment = prime_path.stem.replace(\"prime_\", \"\")\n\n        # Scan docs\n        docs = self.file_system.scan_docs(scan_path, repo_root)\n\n        # Build minimal config\n        config = TrifectaConfig(\n            segment=segment,\n            scope=f\"Segment {segment}\",\n            repo_root=str(repo_root),\n        )\n\n        # Regenerate prime\n        prime_content = self.template_renderer.render_prime(config, docs)\n        prime_path.write_text(prime_content)\n\n        return prime_path.name\n\n\nclass BuildContextPackUseCase:\n    \"\"\"Build a Context Pack for a segment.\"\"\"\n\n    def __init__(self, file_system: FileSystemAdapter, telemetry: Any = None) -> None:\n        self.file_system = file_system\n        self.telemetry = telemetry\n\n    def _extract_references(\n        self, content: str, root: Path, repo_root: Path | None = None\n    ) -> dict[str, Path]:\n        \"\"\"Extract referenced files from Prime content with STRICT SECURITY.\"\"\"\n\n        refs: dict[str, Path] = {}\n        visited_paths = set()\n        MAX_LINKS = 25\n\n        # Regex for [link](path) and `path`\n        lines = content.splitlines()\n        for line in lines:\n            line = line.strip()\n            if not (line.startswith(\"-\") or line.startswith(\"*\") or line[0:1].isdigit()):\n                continue\n\n            path_str = None\n            # Try `code` block\n            code_match = re.search(r\"`([^`]+)`\", line)\n            if code_match:\n                path_str = code_match.group(1).strip()\n\n            # Try [link](path)\n            link_match = re.search(r\"\\[.*?\\]\\((.*?)\\)\", line)\n            if link_match:\n                path_str = link_match.group(1).strip()\n\n            if path_str:\n                if len(refs) >= MAX_LINKS:\n                    warning_msg = \"prime_links_truncated_total\"\n                    if self.telemetry:\n                        self.telemetry.incr(warning_msg)\n                    sys.stderr.write(\n                        f\"⚠️ Warning: Max links ({MAX_LINKS}) reached in Prime. Skipping remainder.\\n\"\n                    )\n                    break\n\n                if self._is_valid_ref(path_str):\n                    resolved = self._resolve_path(path_str, root, repo_root)\n\n                    if resolved:\n                        # Cycle/Duplicate Check\n                        abs_path = str(resolved.resolve())\n                        if abs_path in visited_paths:\n                            if self.telemetry:\n                                self.telemetry.incr(\"prime_links_cycle_total\")\n                            sys.stderr.write(\n                                f\"⚠️ Warning: Cycle/Duplicate detected for '{path_str}'. Skipping.\\n\"\n                            )\n                            continue\n\n                        # Security Scope Check\n                        if self._is_safe_path(resolved, root):\n                            refs[path_str] = resolved\n                            visited_paths.add(abs_path)\n                            if self.telemetry:\n                                self.telemetry.incr(\"prime_links_included_total\")\n                        else:\n                            # Policy: FAIL-CLOSED (PCC enforcement)\n                            if self.telemetry:\n                                self.telemetry.incr(\"prime_links_skipped_security_total\")\n                            error_msg = f\"PROHIBITED: Reference '{path_str}' resolves outside segment or in forbidden path.\"\n                            sys.stderr.write(f\"❌ {error_msg}\\n\")\n                            raise ValueError(error_msg)\n\n        return refs\n\n    def _validate_prohibited_paths(self, files: list[Path]) -> None:\n        \"\"\"Fail-closed: Reject any file that looks like code or is in prohibited dirs.\"\"\"\n        import sys\n\n        for f in files:\n            path_str = str(f).lower()\n            if (\n                \"/src/\" in path_str\n                or \"src/\" in path_str\n                or f.suffix in [\".py\", \".ts\", \".js\", \".go\", \".rs\"]\n            ):\n                sys.stderr.write(f\"❌ PROHIBITED: Cannot index code files in pack: {f}\\n\")\n                sys.stderr.write(\"Trifecta is Programming Context Calling (meta-first), not RAG.\\n\")\n                sys.stderr.write(\"Code access MUST be via curated prime links in meta-docs.\\n\")\n                # In UseCase, we raise ValueError instead of sys.exit\n                raise ValueError(f\"Prohibited file in context pack: {f}\")\n\n    def _is_valid_ref(self, path_str: str) -> bool:\n        if \"://\" in path_str or not path_str or path_str.startswith(\"#\"):\n            return False\n        # Allowlist: MD only for now\n        return path_str.endswith(\".md\")\n\n    def _is_safe_path(self, path: Path, root: Path) -> bool:\n        \"\"\"Prevent path traversal. Must be within segment.\"\"\"\n        # Resolves symlinks to ensure we don't escape\n        try:\n            resolved_path = path.resolve()\n            resolved_root = root.resolve()\n            return resolved_path.is_relative_to(resolved_root)\n        except ValueError:\n            return False\n\n    def _resolve_path(self, path_str: str, root: Path, repo_root: Path | None) -> Path | None:\n        # 1. Try relative to component root\n        p = root / path_str\n        if p.exists() and p.is_file():\n            return p\n\n        # 2. Try relative to REPO_ROOT (if known) -- BUT ONLY if it resolves inside segment\n        # (This effectively disables repo-root links unless they point back into segment,\n        # complying with \"Scope limited to segment\")\n        if repo_root:\n            p = repo_root / path_str\n            if p.exists() and p.is_file():\n                return p\n\n        return None\n\n    def execute(self, target_path: Path) -> \"Ok[ContextPack] | Err[list[str]]\":\n        if self.telemetry:\n            self.telemetry.incr(\"ctx_build_count\")\n        \"\"\"Scan a Trifecta segment and build a context_pack.json.\"\"\"\n        from src.domain.naming import normalize_segment_id\n        from src.domain.result import Err, Ok\n\n        # 1. Derive segment_id deterministically\n        # Priority: trifecta_config.json (source of truth) > directory name (fallback)\n        try:\n            config = self.file_system.load_trifecta_config(target_path)\n            if config:\n                # Source of Truth: Config\n                segment_id = config.segment_id\n            else:\n                # Fallback: Directory Name\n                segment_id = normalize_segment_id(target_path.name)\n        except ValueError:\n            # Deterministic Fail-Closed\n            return Err([\"Failed Constitution: trifecta_config.json is invalid\"])\n\n        ctx_dir = target_path / \"_ctx\"\n\n        # 2. FAIL-CLOSED: Validate exactly one prime file with correct suffix\n        expected_prime = ctx_dir / f\"prime_{segment_id}.md\"\n        if not expected_prime.exists():\n            from src.application.exceptions import PrimeFileNotFoundError\n\n            raise PrimeFileNotFoundError(expected_path=expected_prime, segment_id=segment_id)\n\n        # 3. FAIL-CLOSED: Detect contamination (other prime_*.md files)\n        all_prime_files = list(ctx_dir.glob(\"prime_*.md\"))\n        if len(all_prime_files) > 1:\n            contaminating = [f.name for f in all_prime_files if f != expected_prime]\n            raise ValueError(\n                f\"Ambiguous/contaminated _ctx directory: found {len(all_prime_files)} prime_*.md files. \"\n                f\"Expected only: prime_{segment_id}.md. \"\n                f\"Contaminating files: {contaminating}\"\n            )\n\n        prime_path = expected_prime\n\n        # Try to parse REPO_ROOT from prime header\n        repo_root = None\n        prime_content = prime_path.read_text()\n\n        rr_match = re.search(r\">\\s*\\*\\*REPO_ROOT\\*\\*:\\s*`?([^`\\n]+)`?\", prime_content)\n        if rr_match:\n            try:\n                repo_root = Path(rr_match.group(1).strip())\n            except Exception:\n                pass\n\n        # 4. Identify source files with STRICT VALIDATION\n        sources = {\n            \"skill\": target_path / \"skill.md\",\n            \"prime\": prime_path,\n        }\n\n        # 4a. STRICT Agent Validation (Symmetric to Prime)\n        expected_agent = ctx_dir / f\"agent_{segment_id}.md\"\n        all_agent_files = list(ctx_dir.glob(\"agent_*.md\"))\n\n        if len(all_agent_files) > 1:\n            contaminating = [f.name for f in all_agent_files if f != expected_agent]\n            raise ValueError(\n                f\"Ambiguous/contaminated _ctx directory: found {len(all_agent_files)} agent_*.md files. \"\n                f\"Expected only: agent_{segment_id}.md. \"\n                f\"Contaminating files: {contaminating}\"\n            )\n\n        if not expected_agent.exists():\n            # If we require agent to exist (which is standard), strict fail:\n            if all_agent_files:\n                # Found agent_wrong.md but not agent_correct.md -> Contamination/Mismatch\n                raise ValueError(\n                    f\"Contaminated _ctx directory: found agent_*.md files but missing expected agent_{segment_id}.md. \"\n                    f\"Found: {[f.name for f in all_agent_files]}\"\n                )\n            # If just missing, FileNotFoundError (Validation Gate usually catches this earlier, but build must be robust)\n            # For now, let's allow \"missing\" agent if logic tolerates it, OR enforce it.\n            # The tests suggest we want strict enforcement.\n            # However, validators.py checks for \"Missing context file\".\n            # Let's ensure consistency. If validators pass, this should exist.\n            pass\n        else:\n            sources[\"agent\"] = expected_agent\n\n        # 4b. STRICT Session Validation\n        expected_session = ctx_dir / f\"session_{segment_id}.md\"\n        all_session_files = list(ctx_dir.glob(\"session_*.md\"))\n\n        if len(all_session_files) > 1:\n            contaminating = [f.name for f in all_session_files if f != expected_session]\n            raise ValueError(\n                f\"Ambiguous/contaminated _ctx directory: found {len(all_session_files)} session_*.md files. \"\n                f\"Expected only: session_{segment_id}.md. \"\n                f\"Contaminating files: {contaminating}\"\n            )\n\n        if all_session_files and not expected_session.exists():\n            raise ValueError(\n                f\"Contaminated _ctx directory: found session_*.md files but missing expected session_{segment_id}.md. \"\n                f\"Found: {[f.name for f in all_session_files]}\"\n            )\n\n        if expected_session.exists():\n            sources[\"session\"] = expected_session\n\n        # 4.5 Extract references from Prime\n        refs = self._extract_references(prime_content, target_path, repo_root)\n\n        # Compute primary source paths for exclusion (path-aware deduplication)\n        primary_skill_path = target_path / \"skill.md\"\n        excluded_paths = {primary_skill_path.resolve()}\n\n        for name, path in refs.items():\n            # Skip if this exact path is already indexed as a primary source\n            if path.resolve() in excluded_paths:\n                continue\n            sources[f\"ref:{name}\"] = path\n\n        # 4.6 NEW: Scan repo content (docs/, src/, README) - WO-0009 fix\n        # This was missing - previously only _ctx metadata was indexed\n        exclude_dirs = {\n            \".git\",\n            \".venv\",\n            \"node_modules\",\n            \"dist\",\n            \"build\",\n            \"_ctx\",\n            \"__pycache__\",\n            \".pytest_cache\",\n        }\n\n        # Scan for markdown and code files\n        for pattern in [\n            \"docs/**/*.md\",\n            \"src/**/*.py\",\n            \"src/**/*.ts\",\n            \"src/**/*.js\",\n            \"README*.md\",\n            \"*.md\",\n        ]:\n            for file_path in target_path.glob(pattern):\n                # Skip if in excluded dir\n                if any(excluded_dir in file_path.parts for excluded_dir in exclude_dirs):\n                    continue\n                # Skip if already indexed\n                if file_path.resolve() in excluded_paths:\n                    continue\n                # Skip if not a file\n                if not file_path.is_file():\n                    continue\n\n                # Add to sources with repo prefix\n                rel_path = file_path.relative_to(target_path)\n                source_key = f\"repo:{rel_path}\"\n                sources[source_key] = file_path\n                excluded_paths.add(file_path.resolve())\n\n        # 4.7 FAIL-CLOSED VALIDATION (was 4.6)\n        # NOTE: _validate_prohibited_paths rejects /src/ code files\n        # We need to allow them now for WO-0009\n        # Commenting out for now - will fix validation separately if needed\n        # self._validate_prohibited_paths(list(sources.values()))\n\n        chunks: list[ContextChunk] = []\n        index: list[ContextIndexEntry] = []\n        source_files: list[SourceFile] = []\n\n        # 3. Process each file as a whole_file chunk (MVP)\n        for doc_type, file_path in sources.items():\n            if not file_path.exists():\n                continue\n\n            content = file_path.read_text()\n            if not content.endswith(\"\\n\"):\n                content += \"\\n\"\n            # Simple token estimation: 4 chars per token\n            token_est = len(content) // 4\n\n            # Source metadata\n            import hashlib\n\n            sha256 = hashlib.sha256(content.encode()).hexdigest()\n            mtime = file_path.stat().st_mtime\n            source_files.append(\n                SourceFile(\n                    path=str(file_path.relative_to(target_path)),\n                    sha256=sha256,\n                    mtime=mtime,\n                    chars=len(content),\n                )\n                if target_path in file_path.parents or target_path == file_path\n                else SourceFile(path=file_path.name, sha256=sha256, mtime=mtime, chars=len(content))\n            )\n\n            # Stable ID: doc:sha1(doc + \"\\n\" + title_path_norm + \"\\n\" + text_sha256)[:10]\n            title_path_norm = file_path.name\n            id_input = f\"{doc_type}\\n{title_path_norm}\\n{sha256}\"\n            content_hash = hashlib.sha1(id_input.encode(), usedforsecurity=False).hexdigest()[:10]\n            chunk_id = f\"{doc_type}:{content_hash}\"\n\n            chunk = ContextChunk(\n                id=chunk_id,\n                doc=doc_type,\n                title_path=[file_path.name],\n                text=content,\n                char_count=len(content),\n                token_est=token_est,\n                source_path=str(file_path.name),  # Minimal for MVP\n                chunking_method=\"whole_file\",\n            )\n            chunks.append(chunk)\n\n            # Index entry (L0)\n            preview = content[:200].strip() + \"...\" if len(content) > 200 else content\n            index.append(\n                ContextIndexEntry(\n                    id=chunk_id,\n                    title_path_norm=title_path_norm,\n                    preview=preview,\n                    token_est=token_est,\n                )\n            )\n\n        pack = ContextPack(\n            segment=segment_id, source_files=source_files, chunks=chunks, index=index\n        )\n\n        # 4. Save to disk atomically with lock\n        pack_path = ctx_dir / \"context_pack.json\"\n        lock_path = ctx_dir / \".autopilot.lock\"\n\n        with file_lock(lock_path):\n            AtomicWriter.write(pack_path, pack.model_dump_json(indent=2))\n\n        return Ok(pack)\n\n\nclass MacroLoadUseCase:\n    \"\"\"Macro command 'trifecta load' implementation.\"\"\"\n\n    def __init__(self, file_system: FileSystemAdapter, telemetry: Any = None) -> None:\n        self.file_system = file_system\n        self.telemetry = telemetry\n\n    def execute(self, target_path: Path, task: str, mode: str = \"pcc\") -> str:\n        \"\"\"Execute the macro load logic using Plan A (API) or Plan B (Fallback).\"\"\"\n        ctx_dir = target_path / \"_ctx\"\n        pack_path = ctx_dir / \"context_pack.json\"\n\n        # Force Fallback if mode is fullfiles or pack missing\n        if mode == \"fullfiles\" or not pack_path.exists():\n            # FALLBACK (Plan B): Traditional file selection\n            return self._fallback_load(target_path, task)\n\n        # 1. Expand task with aliases for discovery\n        from src.application.query_expander import QueryExpander\n        from src.application.query_normalizer import QueryNormalizer\n        from src.infrastructure.alias_loader import AliasLoader\n\n        alias_loader = AliasLoader(target_path)\n        aliases = alias_loader.load()\n\n        norm_task = QueryNormalizer.normalize(task)\n        tokens = QueryNormalizer.tokenize(norm_task)\n        expander = QueryExpander(aliases)\n        expanded_terms = expander.expand(norm_task, tokens)\n\n        # Execute search for each expanded piece\n        service = ContextService(target_path)\n        combined_hits: dict[str, tuple[Any, float]] = {}  # chunk_id -> (hit, max_weighted_score)\n\n        for term, weight in expanded_terms:\n            search_res = service.search(term, k=10)\n            for hit in search_res.hits:\n                weighted_score = hit.score * weight\n                if hit.id not in combined_hits or weighted_score > combined_hits[hit.id][1]:\n                    combined_hits[hit.id] = (hit, weighted_score)\n\n        if not combined_hits:\n            # If search fails, fallback to Plan B\n            return self._fallback_load(target_path, task)\n\n        # T4: Ordena hits por \"valor por token\" (weighted_score/token_est)\n        hits = list(combined_hits.values())\n        hits.sort(key=lambda x: x[1] / max(x[0].token_est, 1), reverse=True)\n        top_hits = [hit for hit, _ in hits[:5]]\n        ids = [hit.id for hit in top_hits]\n\n        # 2. Get L0 Skeletons (Initial navigation)\n        l0_ids = []\n        for cid in [\"skill\", \"agent\"]:\n            match = [c.id for c in service._load_pack().chunks if c.id.startswith(f\"{cid}:\")]\n            if match:\n                l0_ids.append(match[0])\n\n        l0_res = service.get(l0_ids, mode=\"skeleton\", budget_token_est=400)\n\n        # 3. Get Task Evidence (L1 Excerpts)\n        evid_res = service.get(ids, mode=\"excerpt\", budget_token_est=1500)\n\n        # 4. Format output (EVIDENCE read-only style)\n        output = [f\"# Context Evidence for Task: {task}\\n\"]\n        output.append(\"> [!NOTE]\")\n        output.append(\n            \"> Loaded via Programmatic Context Calling (Plan A). Citations as [chunk_id].\\n\"\n        )\n\n        output.append(\"### EVIDENCE (read-only)\")\n\n        # Add Skeletons first as navigation\n        for chunk in l0_res.chunks:\n            output.append(f\"#### [{chunk.id}] {chunk.title_path[0]} (Skeleton)\")\n            output.append(chunk.text)\n            output.append(\"\")\n\n        # Add Excerpts\n        for chunk in evid_res.chunks:\n            output.append(f\"#### [{chunk.id}] {' > '.join(chunk.title_path)}\")\n            output.append(chunk.text)\n            output.append(\"\")\n\n        if evid_res.total_tokens > 1500:\n            output.append(\"\\n> [!WARNING]\")\n            output.append(\"> Context budget reached. Some evidence might be truncated or omitted.\")\n\n        return \"\\n\".join(output)\n\n        if evid_res.total_tokens >= 1000:\n            output.append(\"> [!WARNING]\")\n            output.append(\"> Context budget reached. Evidence was truncated (Backpressure).\")\n\n        return \"\\n\".join(output)\n\n    def _fallback_load(self, target_path: Path, task: str) -> str:\n        \"\"\"Traditional heuristic file selection fallback.\"\"\"\n        task_lower = task.lower()\n        ctx_dir = target_path / \"_ctx\"\n\n        prime_files = list(ctx_dir.glob(\"prime_*.md\"))\n        prime_path = prime_files[0] if prime_files else None\n\n        files_to_load = [target_path / \"skill.md\"]\n\n        # Heuristics\n        if any(kw in task_lower for kw in [\"implement\", \"debug\", \"fix\", \"code\"]):\n            files_to_load.append(ctx_dir / \"agent.md\")\n\n        if any(kw in task_lower for kw in [\"plan\", \"design\", \"doc\"]):\n            if prime_path:\n                files_to_load.append(prime_path)\n\n        if any(kw in task_lower for kw in [\"session\", \"handoff\", \"history\"]):\n            session_files = list(ctx_dir.glob(\"session_*.md\"))\n            if session_files:\n                files_to_load.append(session_files[0])\n\n        output = [f\"# Context (Fallback Heuristic) for Task: {task}\\n\"]\n        for f in files_to_load:\n            if f.exists():\n                output.append(f\"## File: {f.name}\")\n                output.append(f.read_text())\n                output.append(\"\\n---\\n\")\n\n        return \"\\n\".join(output)\n\n\nclass ValidateContextPackUseCase:\n    \"\"\"Validator for Context Pack integrity and invariants.\"\"\"\n\n    def __init__(self, file_system: FileSystemAdapter, telemetry: Any = None) -> None:\n        self.file_system = file_system\n        self.telemetry = telemetry\n\n    def execute(self, target_path: Path) -> ValidationResult:\n        \"\"\"Validate context_pack.json structure and consistency.\"\"\"\n        errors: list[str] = []\n        warnings: list[str] = []\n\n        # 0. Path Sanitization\n        segment = target_path.name\n        if \"..\" in segment or segment.startswith(\"/\"):\n            errors.append(f\"Invalid or unsafe segment path: {segment}\")\n            return ValidationResult(passed=False, errors=errors, warnings=[])\n\n        ctx_dir = target_path / \"_ctx\"\n        pack_path = ctx_dir / \"context_pack.json\"\n\n        if not pack_path.exists():\n            return ValidationResult(passed=False, errors=[\"Missing context_pack.json\"], warnings=[])\n\n        try:\n            import hashlib\n            import json\n\n            with open(pack_path, \"r\") as f:\n                data = json.load(f)\n\n            # 1. Schema version check\n            if data.get(\"schema_version\") != 1:\n                errors.append(f\"Unsupported schema version: {data.get('schema_version')}\")\n\n            # 2. Size limits check\n            chunks_data = data.get(\"chunks\", [])\n            total_chars = sum(c.get(\"char_count\", 0) for c in chunks_data)\n            if total_chars > 2_000_000:  # 2MB limit for context pack (reasonable)\n                warnings.append(f\"Context pack is quite large ({total_chars} chars)\")\n\n            # 3. Index integrity\n            chunk_ids = {c[\"id\"] for c in chunks_data}\n            for entry in data.get(\"index\", []):\n                if entry[\"id\"] not in chunk_ids:\n                    errors.append(f\"Index references missing chunk ID: {entry['id']}\")\n\n            # 4. Source file traceability (SHA256/mtime/chars)\n            for src in data.get(\"source_files\", []):\n                src_rel_path = src[\"path\"]\n                src_abs_path = target_path / src_rel_path\n\n                if not src_abs_path.exists():\n                    # Fallback for files outside segment: check if it's just a filename\n                    # Try direct filename in segment\n                    src_abs_path = target_path / Path(src_rel_path).name\n                    if not src_abs_path.exists():\n                        errors.append(\n                            f\"Source file listed in pack but missing from disk: {src_rel_path}\"\n                        )\n                        continue\n\n                # Deep verification - use same normalization as build\n                content_str = src_abs_path.read_text()\n                if not content_str.endswith(\"\\n\"):\n                    content_str += \"\\n\"\n                content = content_str.encode()\n                current_sha = hashlib.sha256(content).hexdigest()\n                current_chars = len(content_str)\n                current_mtime = src_abs_path.stat().st_mtime\n\n                if current_sha != src[\"sha256\"]:\n                    errors.append(f\"Source file content changed (Hash mismatch): {src_rel_path}\")\n                elif abs(current_mtime - src[\"mtime\"]) > 1.0:  # 1s tolerance\n                    warnings.append(f\"Source file mtime changed but hash matches: {src_rel_path}\")\n\n                if current_chars != src[\"chars\"]:\n                    errors.append(\n                        f\"Source file size mismatch: {src_rel_path} ({current_chars} vs {src['chars']})\"\n                    )\n\n            # 5. Basic content check\n            if not chunks_data:\n                errors.append(\"Context pack contains no chunks\")\n\n        except Exception as e:\n            errors.append(f\"Failed to parse context pack: {str(e)}\")\n\n        result = ValidationResult(passed=len(errors) == 0, errors=errors, warnings=warnings)\n\n        # Record result and stale detection\n        if self.telemetry:\n            if result.passed:\n                self.telemetry.incr(\"ctx_validate_pass_count\")\n                self.telemetry.stale_detected = False\n            else:\n                self.telemetry.incr(\"ctx_validate_fail_count\")\n                # Check if failure is due to stale/corruption\n                is_stale = any(\"changed\" in e.lower() or \"mismatch\" in e.lower() for e in errors)\n                self.telemetry.stale_detected = is_stale\n\n        return result\n\n\nclass AutopilotUseCase:\n    \"\"\"Runner for automated context refresh based on session.md contract.\"\"\"\n\n    def __init__(self, file_system: FileSystemAdapter):\n        self.file_system = file_system\n\n    def execute(self, target_path: Path) -> dict[str, Any]:\n        \"\"\"Read autopilot config and run steps.\"\"\"\n        ctx_dir = target_path / \"_ctx\"\n        session_files = list(ctx_dir.glob(\"session_*.md\"))\n\n        if not session_files:\n            return {\"status\": \"skipped\", \"reason\": \"No session file found\"}\n\n        session_path = session_files[0]\n        content = session_path.read_text()\n\n        # Extract YAML frontmatter or block\n        try:\n            # Simple extractor for YAML block in markdown\n            import re\n\n            match = re.search(r\"```yaml\\n(autopilot:.*?)\\n```\", content, re.DOTALL)\n            if not match:\n                # Try frontmatter (---)\n                match = re.search(r\"^---\\n(autopilot:.*?)\\n---\", content, re.DOTALL | re.MULTILINE)\n\n            if not match:\n                return {\"status\": \"skipped\", \"reason\": \"No autopilot config found in session.md\"}\n\n            config = yaml.safe_load(match.group(1)).get(\"autopilot\", {})\n            if not config.get(\"enabled\", False):\n                return {\"status\": \"skipped\", \"reason\": \"Autopilot disabled in config\"}\n\n            steps = config.get(\"steps\", [])\n            timeouts = config.get(\"timeouts\", {})\n            results = []\n            log_entries = [f\"--- Autopilot Run: {datetime.now().isoformat()} ---\"]\n\n            for step in steps:\n                cmd = step.split()\n                timeout = timeouts.get(step.replace(\"trifecta ctx \", \"\"), 30)\n\n                try:\n                    full_cmd = (\n                        [\"python3\", \"-m\", \"src.infrastructure.cli\"]\n                        + cmd[1:]\n                        + [\"--path\", str(target_path)]\n                    )\n                    process = subprocess.run(\n                        full_cmd, capture_output=True, text=True, timeout=timeout\n                    )\n\n                    success = process.returncode == 0\n                    results.append(\n                        {\n                            \"step\": step,\n                            \"success\": success,\n                            \"stdout\": process.stdout.strip(),\n                            \"stderr\": process.stderr.strip(),\n                        }\n                    )\n\n                    status_str = \"SUCCESS\" if success else \"FAILED\"\n                    log_entries.append(f\"[{status_str}] {step}\")\n                    if not success:\n                        log_entries.append(f\"  Error: {process.stderr.strip()}\")\n                        break  # Stop on first failure\n                except subprocess.TimeoutExpired:\n                    results.append({\"step\": step, \"success\": False, \"error\": \"Timeout\"})\n                    log_entries.append(f\"[TIMEOUT] {step}\")\n                    break\n\n            # Write to autopilot.log\n            log_path = ctx_dir / \"autopilot.log\"\n            with open(log_path, \"a\") as f:\n                f.write(\"\\n\".join(log_entries) + \"\\n\\n\")\n\n            return {\"status\": \"completed\", \"results\": results}\n\n        except Exception as e:\n            return {\"status\": \"error\", \"reason\": f\"Failed to execute autopilot: {str(e)}\"}\n\n\nclass StatsUseCase:\n    \"\"\"Generate telemetry statistics for a segment.\"\"\"\n\n    def __init__(self, file_system: FileSystemAdapter, telemetry: Any = None) -> None:\n        self.file_system = file_system\n        self.telemetry = telemetry\n\n    def _classify_query_type(self, query: str) -> str:\n        \"\"\"Heurística de clasificación de query.\"\"\"\n        if not query:\n            return \"unknown\"\n        q_lower = query.lower()\n\n        # Meta: qué hacer / estado / guía / arquitectura / procedimiento\n        meta_keywords = [\n            \"how\",\n            \"what\",\n            \"where\",\n            \"plan\",\n            \"guide\",\n            \"architecture\",\n            \"design\",\n            \"status\",\n            \"overview\",\n            \"explain\",\n            \"description\",\n        ]\n\n        # Impl: código específico / símbolos / funciones / archivos\n        impl_keywords = [\n            \"function\",\n            \"class\",\n            \"method\",\n            \"file\",\n            \"implement\",\n            \"code\",\n            \"symbol\",\n            \"def \",\n            \"class \",\n            \"import\",\n        ]\n\n        if any(kw in q_lower for kw in impl_keywords):\n            return \"impl\"\n        elif any(kw in q_lower for kw in meta_keywords):\n            return \"meta\"\n        else:\n            return \"unknown\"\n\n    def _classify_hit_target(self, chunk_id: str) -> str:\n        \"\"\"Clasificar target por chunk_id prefix.\"\"\"\n        if not chunk_id:\n            return \"other\"\n        if chunk_id.startswith(\"skill:\"):\n            return \"skill\"\n        elif chunk_id.startswith(\"prime:\"):\n            return \"prime\"\n        elif chunk_id.startswith(\"session:\"):\n            return \"session\"\n        elif chunk_id.startswith(\"agent:\"):\n            return \"agent\"\n        elif chunk_id.startswith(\"ref:\"):\n            return \"ref\"\n        else:\n            return \"other\"\n\n    def execute(self, target_path: Path, window: int = 0) -> dict[str, Any]:\n        \"\"\"Generate statistics from telemetry events.\n\n        Args:\n            target_path: Path to segment directory\n            window: Number of days to look back (0 = all)\n\n        Returns:\n            Dictionary with statistics\n        \"\"\"\n        from collections import Counter\n        from datetime import datetime, timezone, timedelta\n\n        if self.telemetry:\n            self.telemetry.incr(\"ctx_stats_count\")\n\n        events_path = target_path / \"_ctx\" / \"telemetry\" / \"events.jsonl\"\n\n        # Load events\n        events = []\n        if events_path.exists():\n            with open(events_path) as f:\n                for line in f:\n                    if line.strip():\n                        try:\n                            events.append(json.loads(line))\n                        except json.JSONDecodeError:\n                            pass\n\n        # Filter by window\n        if window > 0:\n            cutoff = datetime.now(timezone.utc) - timedelta(days=window)\n            events = [\n                e\n                for e in events\n                if datetime.fromisoformat(e[\"ts\"].replace(\"Z\", \"+00:00\")) >= cutoff\n            ]\n\n        # Filter searches only\n        searches = [e for e in events if e[\"cmd\"] == \"ctx.search\"]\n        total_searches = len(searches)\n        hits = sum(1 for e in searches if e.get(\"result\", {}).get(\"hits\", 0) > 0)\n        zero_hits = total_searches - hits\n        hit_rate = hits / total_searches * 100 if total_searches > 0 else 0\n\n        latencies = [e.get(\"timing_ms\", 0) for e in searches if e.get(\"timing_ms\", 0) > 0]\n        avg_latency = sum(latencies) / len(latencies) if latencies else 0\n\n        # Top zero-hit queries\n        zero_hit_queries = [\n            (e.get(\"args\", {}).get(\"query\", \"\"), e.get(\"args\", {}).get(\"query\", \"\"))\n            for e in searches\n            if e.get(\"result\", {}).get(\"hits\", 0) == 0\n        ]\n        query_counts = Counter(q for q, _ in zero_hit_queries)\n\n        # Breakdown por query_type\n        query_type_counts: Counter[str] = Counter()\n        for e in searches:\n            query = e.get(\"args\", {}).get(\"query\", \"\")\n            qtype = self._classify_query_type(query)\n            query_type_counts[qtype] += 1\n\n        # Breakdown por hit_target\n        hit_target_counts: Counter[str] = Counter()\n        for e in searches:\n            returned_ids = e.get(\"result\", {}).get(\"returned_ids\", [])\n            if returned_ids:\n                for cid in returned_ids:\n                    target = self._classify_hit_target(cid)\n                    hit_target_counts[target] += 1\n\n        return {\n            \"summary\": {\n                \"total_searches\": total_searches,\n                \"hits\": hits,\n                \"zero_hits\": zero_hits,\n                \"hit_rate\": round(hit_rate, 1),\n                \"avg_latency_ms\": round(avg_latency, 1),\n            },\n            \"top_zero_hit_queries\": [\n                {\"query\": q, \"count\": c} for q, c in query_counts.most_common(10)\n            ],\n            \"query_type_breakdown\": {\n                qt: query_type_counts[qt] for qt in [\"meta\", \"impl\", \"unknown\"]\n            },\n            \"hit_target_breakdown\": dict(hit_target_counts),\n        }\n",
+      "char_count": 38066,
+      "token_est": 9516,
       "source_path": "use_cases.py",
       "chunking_method": "whole_file"
     },
@@ -4423,14 +4573,14 @@
       "chunking_method": "whole_file"
     },
     {
-      "id": "repo:src/application/obsidian_sync_use_case.py:1624323f39",
+      "id": "repo:src/application/obsidian_sync_use_case.py:2bfd345dab",
       "doc": "repo:src/application/obsidian_sync_use_case.py",
       "title_path": [
         "obsidian_sync_use_case.py"
       ],
-      "text": "\"\"\"Obsidian sync use case.\n\nThis module orchestrates the end-to-end sync of findings to Obsidian,\nfollowing Trifecta's Clean Architecture use case pattern.\n\nFollowing Trifecta Clean Architecture:\n- Application layer: orchestrates business logic\n- Uses domain models from src.domain.obsidian_models\n- Delegates to infrastructure for I/O\n- Delegates to application services for transformation\n\"\"\"\n\nfrom __future__ import annotations\n\nimport time\nfrom dataclasses import dataclass, field\nfrom pathlib import Path\nfrom typing import TYPE_CHECKING, Literal\n\nfrom src.domain.obsidian_models import (\n    Finding,\n    ObsidianConfig,\n    SyncResult,\n    ValidationResult,\n)\nfrom src.application.hookify_extractor import HookifyExtractor\nfrom src.application.obsidian_renderer import NoteRenderer\nfrom src.infrastructure.hookify_logger import HookifyEvidenceLogger\nfrom src.infrastructure.obsidian_config import ObsidianConfigManager\nfrom src.infrastructure.obsidian_writer import ObsidianWriter\n\nif TYPE_CHECKING:\n    from collections.abc import Mapping\n\n\n@dataclass\nclass SyncToObsidianUseCase:\n    \"\"\"Use case for syncing findings to Obsidian vault.\n\n    This is the main orchestration layer that coordinates:\n    1. Loading configuration\n    2. Extracting findings from various sources\n    3. Filtering by priority\n    4. Rendering notes\n    5. Writing to vault (or preview if dry-run)\n\n    Usage:\n        use_case = SyncToObsidianUseCase(config)\n        result = use_case.execute(\n            segment_path=Path(\".\"),\n            min_priority=\"P2\",\n            dry_run=False,\n            sources={\"hookify\": True, \"telemetry\": False}\n        )\n    \"\"\"\n\n    config: ObsidianConfig\n    renderer: NoteRenderer = field(init=False)\n    writer: ObsidianWriter = field(init=False)\n    config_manager: ObsidianConfigManager = field(init=False)\n\n    def __post_init__(self):\n        \"\"\"Initialize dependencies after config is set.\"\"\"\n        self.renderer = NoteRenderer(date_format=self.config.date_format)\n        self.writer = ObsidianWriter(self.config)\n        self.config_manager = ObsidianConfigManager()\n\n    def execute(\n        self,\n        segment_path: Path,\n        min_priority: Literal[\"P0\", \"P1\", \"P2\", \"P3\", \"P4\", \"P5\"] = \"P5\",\n        dry_run: bool = False,\n        sources: Mapping[str, bool] | None = None,\n    ) -> SyncResult:\n        \"\"\"Execute the sync use case.\n\n        Args:\n            segment_path: Path to segment root\n            min_priority: Minimum priority to sync (P1-P5)\n            dry_run: If True, preview without writing\n            sources: Which sources to include (default: all)\n\n        Returns:\n            SyncResult with summary\n        \"\"\"\n        start_time = time.time()\n\n        # Default sources\n        if sources is None:\n            sources = {\n                \"hookify\": True,\n                \"telemetry\": True,\n                \"micro_audit\": True,\n            }\n\n        # Validate vault\n        validation = self.writer.validate_vault()\n        if not validation.valid:\n            raise RuntimeError(f\"Vault validation failed: {validation.error}\")\n\n        # Extract findings from all enabled sources\n        all_findings: list[Finding] = []\n        active_sources: list[str] = []\n\n        if sources.get(\"hookify\", False):\n            hookify_findings = self._extract_hookify_findings(segment_path, min_priority)\n            all_findings.extend(hookify_findings)\n            if hookify_findings:\n                active_sources.append(\"hookify\")\n\n        if sources.get(\"telemetry\", False):\n            # TODO: Implement telemetry extraction\n            pass\n\n        if sources.get(\"micro_audit\", False):\n            # TODO: Implement micro-audit extraction\n            pass\n\n        # Get existing note IDs to avoid duplicates\n        existing_ids = self.writer.get_existing_note_ids()\n\n        # Filter out already-synced findings\n        new_findings = [f for f in all_findings if f.id not in existing_ids]\n\n        # Render notes\n        notes = [self.renderer.render(f, self.config.vault_path) for f in new_findings]\n\n        # Track results\n        notes_created = 0\n        notes_updated = 0\n        notes_skipped = len(all_findings) - len(new_findings)\n\n        previews: list[dict] = []\n\n        if dry_run:\n            # Generate previews\n            for note in notes:\n                previews.append(\n                    {\n                        \"path\": str(note.path),\n                        \"content\": note.render()[:500] + \"...\",\n                        \"finding_id\": note.finding_id,\n                    }\n                )\n        else:\n            # Write notes\n            batch_result = self.writer.write_batch(notes)\n            notes_created = batch_result.created\n            notes_updated = batch_result.updated\n\n            if batch_result.failed > 0:\n                # Log errors but don't fail the sync\n                for error in batch_result.errors:\n                    print(f\"Warning: {error}\")\n\n        duration_ms = int((time.time() - start_time) * 1000)\n\n        return SyncResult(\n            total_findings=len(all_findings),\n            notes_created=notes_created,\n            notes_updated=notes_updated,\n            notes_skipped=notes_skipped,\n            active_sources=active_sources,\n            duration_ms=duration_ms,\n            previews=previews,\n        )\n\n    def _extract_hookify_findings(\n        self,\n        segment_path: Path,\n        min_priority: Literal[\"P0\", \"P1\", \"P2\", \"P3\", \"P4\", \"P5\"],\n    ) -> list[Finding]:\n        \"\"\"Extract findings from hookify violations.\n\n        Args:\n            segment_path: Path to segment root\n            min_priority: Minimum priority to include\n\n        Returns:\n            List of Finding objects\n        \"\"\"\n        # Initialize logger\n        logger = HookifyEvidenceLogger(segment_path)\n\n        # Get violations\n        violations = logger.get_violations()\n\n        # Extract findings\n        extractor = HookifyExtractor(segment_path)\n        findings = extractor.extract(violations, min_priority)\n\n        return findings\n\n    def validate_vault(self) -> ValidationResult:\n        \"\"\"Validate the Obsidian vault configuration.\n\n        Convenience method that delegates to the writer.\n\n        Returns:\n            ValidationResult with outcome\n        \"\"\"\n        return self.writer.validate_vault()\n\n    def show_config(self) -> str:\n        \"\"\"Show current configuration.\n\n        Convenience method that delegates to the config manager.\n\n        Returns:\n            Formatted configuration string\n        \"\"\"\n        return self.config_manager.show()\n\n\ndef create_sync_use_case(\n    vault_path: Path | None = None,\n    min_priority: Literal[\"P0\", \"P1\", \"P2\", \"P3\", \"P4\", \"P5\"] = \"P5\",\n) -> SyncToObsidianUseCase:\n    \"\"\"Factory function to create a sync use case.\n\n    Loads configuration with proper precedence and creates\n    the use case with all dependencies.\n\n    Args:\n        vault_path: Optional vault path override\n        min_priority: Optional min priority override\n\n    Returns:\n        Configured SyncToObsidianUseCase\n    \"\"\"\n    config_manager = ObsidianConfigManager()\n    config = config_manager.load(vault_path=vault_path, min_priority=min_priority)\n\n    return SyncToObsidianUseCase(config=config)\n",
-      "char_count": 7280,
-      "token_est": 1820,
+      "text": "\"\"\"Obsidian sync use case.\n\nThis module orchestrates the end-to-end sync of findings to Obsidian,\nfollowing Trifecta's Clean Architecture use case pattern.\n\nFollowing Trifecta Clean Architecture:\n- Application layer: orchestrates business logic\n- Uses domain models from src.domain.obsidian_models\n- Delegates to infrastructure for I/O\n- Delegates to application services for transformation\n\"\"\"\n\nfrom __future__ import annotations\n\nimport sys\nimport time\nfrom dataclasses import dataclass, field\nfrom pathlib import Path\nfrom typing import TYPE_CHECKING, Literal\n\nfrom src.domain.obsidian_models import (\n    Finding,\n    ObsidianConfig,\n    SyncResult,\n    ValidationResult,\n)\nfrom src.application.hookify_extractor import HookifyExtractor\nfrom src.application.obsidian_renderer import NoteRenderer\nfrom src.infrastructure.hookify_logger import HookifyEvidenceLogger\nfrom src.infrastructure.obsidian_config import ObsidianConfigManager\nfrom src.infrastructure.obsidian_writer import ObsidianWriter\n\nif TYPE_CHECKING:\n    from collections.abc import Mapping\n\n\n@dataclass\nclass SyncToObsidianUseCase:\n    \"\"\"Use case for syncing findings to Obsidian vault.\n\n    This is the main orchestration layer that coordinates:\n    1. Loading configuration\n    2. Extracting findings from various sources\n    3. Filtering by priority\n    4. Rendering notes\n    5. Writing to vault (or preview if dry-run)\n\n    Usage:\n        use_case = SyncToObsidianUseCase(config)\n        result = use_case.execute(\n            segment_path=Path(\".\"),\n            min_priority=\"P2\",\n            dry_run=False,\n            sources={\"hookify\": True, \"telemetry\": False}\n        )\n    \"\"\"\n\n    config: ObsidianConfig\n    renderer: NoteRenderer = field(init=False)\n    writer: ObsidianWriter = field(init=False)\n    config_manager: ObsidianConfigManager = field(init=False)\n\n    def __post_init__(self):\n        \"\"\"Initialize dependencies after config is set.\"\"\"\n        self.renderer = NoteRenderer(date_format=self.config.date_format)\n        self.writer = ObsidianWriter(self.config)\n        self.config_manager = ObsidianConfigManager()\n\n    def execute(\n        self,\n        segment_path: Path,\n        min_priority: Literal[\"P0\", \"P1\", \"P2\", \"P3\", \"P4\", \"P5\"] = \"P5\",\n        dry_run: bool = False,\n        sources: Mapping[str, bool] | None = None,\n    ) -> SyncResult:\n        \"\"\"Execute the sync use case.\n\n        Args:\n            segment_path: Path to segment root\n            min_priority: Minimum priority to sync (P1-P5)\n            dry_run: If True, preview without writing\n            sources: Which sources to include (default: all)\n\n        Returns:\n            SyncResult with summary\n        \"\"\"\n        start_time = time.time()\n\n        # Default sources\n        if sources is None:\n            sources = {\n                \"hookify\": True,\n                \"telemetry\": True,\n                \"micro_audit\": True,\n            }\n\n        # Validate vault\n        validation = self.writer.validate_vault()\n        if not validation.valid:\n            raise RuntimeError(f\"Vault validation failed: {validation.error}\")\n\n        # Extract findings from all enabled sources\n        all_findings: list[Finding] = []\n        active_sources: list[str] = []\n\n        if sources.get(\"hookify\", False):\n            hookify_findings = self._extract_hookify_findings(segment_path, min_priority)\n            all_findings.extend(hookify_findings)\n            if hookify_findings:\n                active_sources.append(\"hookify\")\n\n        if sources.get(\"telemetry\", False):\n            # TODO: Implement telemetry extraction\n            pass\n\n        if sources.get(\"micro_audit\", False):\n            # TODO: Implement micro-audit extraction\n            pass\n\n        # Get existing note IDs to avoid duplicates\n        existing_ids = self.writer.get_existing_note_ids()\n\n        # Filter out already-synced findings\n        new_findings = [f for f in all_findings if f.id not in existing_ids]\n\n        # Render notes\n        notes = [self.renderer.render(f, self.config.vault_path) for f in new_findings]\n\n        # Track results\n        notes_created = 0\n        notes_updated = 0\n        notes_skipped = len(all_findings) - len(new_findings)\n\n        previews: list[dict] = []\n\n        if dry_run:\n            # Generate previews\n            for note in notes:\n                previews.append(\n                    {\n                        \"path\": str(note.path),\n                        \"content\": note.render()[:500] + \"...\",\n                        \"finding_id\": note.finding_id,\n                    }\n                )\n        else:\n            # Write notes\n            batch_result = self.writer.write_batch(notes)\n            notes_created = batch_result.created\n            notes_updated = batch_result.updated\n\n            if batch_result.failed > 0:\n                # Log errors but don't fail the sync\n                for error in batch_result.errors:\n                    sys.stderr.write(f\"Warning: {error}\\n\")\n\n        duration_ms = int((time.time() - start_time) * 1000)\n\n        return SyncResult(\n            total_findings=len(all_findings),\n            notes_created=notes_created,\n            notes_updated=notes_updated,\n            notes_skipped=notes_skipped,\n            active_sources=active_sources,\n            duration_ms=duration_ms,\n            previews=previews,\n        )\n\n    def _extract_hookify_findings(\n        self,\n        segment_path: Path,\n        min_priority: Literal[\"P0\", \"P1\", \"P2\", \"P3\", \"P4\", \"P5\"],\n    ) -> list[Finding]:\n        \"\"\"Extract findings from hookify violations.\n\n        Args:\n            segment_path: Path to segment root\n            min_priority: Minimum priority to include\n\n        Returns:\n            List of Finding objects\n        \"\"\"\n        # Initialize logger\n        logger = HookifyEvidenceLogger(segment_path)\n\n        # Get violations\n        violations = logger.get_violations()\n\n        # Extract findings\n        extractor = HookifyExtractor(segment_path)\n        findings = extractor.extract(violations, min_priority)\n\n        return findings\n\n    def validate_vault(self) -> ValidationResult:\n        \"\"\"Validate the Obsidian vault configuration.\n\n        Convenience method that delegates to the writer.\n\n        Returns:\n            ValidationResult with outcome\n        \"\"\"\n        return self.writer.validate_vault()\n\n    def show_config(self) -> str:\n        \"\"\"Show current configuration.\n\n        Convenience method that delegates to the config manager.\n\n        Returns:\n            Formatted configuration string\n        \"\"\"\n        return self.config_manager.show()\n\n\ndef create_sync_use_case(\n    vault_path: Path | None = None,\n    min_priority: Literal[\"P0\", \"P1\", \"P2\", \"P3\", \"P4\", \"P5\"] = \"P5\",\n) -> SyncToObsidianUseCase:\n    \"\"\"Factory function to create a sync use case.\n\n    Loads configuration with proper precedence and creates\n    the use case with all dependencies.\n\n    Args:\n        vault_path: Optional vault path override\n        min_priority: Optional min priority override\n\n    Returns:\n        Configured SyncToObsidianUseCase\n    \"\"\"\n    config_manager = ObsidianConfigManager()\n    config = config_manager.load(vault_path=vault_path, min_priority=min_priority)\n\n    return SyncToObsidianUseCase(config=config)\n",
+      "char_count": 7304,
+      "token_est": 1826,
       "source_path": "obsidian_sync_use_case.py",
       "chunking_method": "whole_file"
     },
@@ -4447,14 +4597,14 @@
       "chunking_method": "whole_file"
     },
     {
-      "id": "repo:src/application/search_get_usecases.py:a218ecc485",
+      "id": "repo:src/application/search_get_usecases.py:af8ae18020",
       "doc": "repo:src/application/search_get_usecases.py",
       "title_path": [
         "search_get_usecases.py"
       ],
-      "text": "\"\"\"Use case wrappers for Search and Get with telemetry.\"\"\"\n\nimport hashlib\nfrom pathlib import Path\nfrom typing import Any, Literal, Optional\n\nfrom src.application.context_service import ContextService, GetResult\nfrom src.infrastructure.file_system import FileSystemAdapter\nfrom src.domain.query_linter import LinterPlan\n\n\nclass SearchUseCase:\n    \"\"\"Wrapper for ctx.search with telemetry.\"\"\"\n\n    def __init__(self, file_system: FileSystemAdapter, telemetry: Any = None) -> None:\n        self.file_system = file_system\n        self.telemetry = telemetry\n\n    def execute(\n        self, target_path: Path, query: str, limit: int = 5, enable_lint: bool = False\n    ) -> str:\n        \"\"\"Execute search with query linting, alias expansion and format output.\n\n        Pipeline:\n        1. Normalize query (lowercase, strip, collapse whitespace)\n        2. Linter (if enabled): classify + anchor expansion for vague queries\n        3. Tokenize FINAL query (after linter decision) - CRITICAL ORDER\n        4. Alias expansion (synonym-based via _ctx/aliases.yaml)\n        5. Search: execute weighted search across all terms\n\n        Args:\n            target_path: Segment path to search\n            query: Raw search query\n            limit: Max results to return\n            enable_lint: If True, apply query linter for anchor guidance (default: False)\n\n        Returns:\n            Formatted search results string\n        \"\"\"\n        from src.infrastructure.alias_loader import AliasLoader\n        from src.application.query_normalizer import QueryNormalizer\n        from src.application.query_expander import QueryExpander\n        from src.infrastructure.segment_utils import resolve_segment_root\n        from src.infrastructure.config_loader import ConfigLoader\n        from src.domain.query_linter import lint_query\n\n        # Load aliases\n        alias_loader = AliasLoader(target_path)\n        aliases = alias_loader.load()\n\n        # Normalize query\n        normalized_query = QueryNormalizer.normalize(query)\n\n        # Apply Query Linter (anchor-based classification + expansion)\n        if enable_lint:\n            repo_root = resolve_segment_root(target_path)\n            anchors_cfg = ConfigLoader.load_anchors(repo_root)\n            aliases_cfg = ConfigLoader.load_linter_aliases(repo_root)\n\n            lint_plan: LinterPlan = lint_query(normalized_query, anchors_cfg, aliases_cfg)\n\n            # If config missing, force disabled state\n            if anchors_cfg.get(\"_missing_config\") or aliases_cfg.get(\"_missing_config\"):\n                lint_plan[\"query_class\"] = \"disabled_missing_config\"\n                lint_plan[\"changed\"] = False\n                lint_plan[\"changes\"] = {\"added_strong\": [], \"added_weak\": [], \"reasons\": []}\n                query_for_expander = normalized_query\n            else:\n                query_for_expander = (\n                    lint_plan[\"expanded_query\"] if lint_plan[\"changed\"] else normalized_query\n                )\n        else:\n            lint_plan: LinterPlan = {\n                \"original_query\": normalized_query,\n                \"query_class\": \"disabled\",\n                \"token_count\": 0,\n                \"anchors_detected\": {\"strong\": [], \"weak\": [], \"aliases_matched\": []},\n                \"expanded_query\": normalized_query,\n                \"changed\": False,\n                \"changes\": {\"added_strong\": [], \"added_weak\": [], \"reasons\": []},\n            }\n            query_for_expander = normalized_query\n\n        # CRITICAL: Tokenize AFTER linter decides final query\n        tokens = QueryNormalizer.tokenize(query_for_expander)\n\n        # Expand query with aliases\n        expander = QueryExpander(aliases)\n        expanded_terms = expander.expand(query_for_expander, tokens)\n\n        # Execute search for each term and combine results\n        service = ContextService(target_path)\n        combined_results: dict[str, tuple[Any, float]] = {}  # chunk_id -> (hit, max_score)\n\n        for term, weight in expanded_terms:\n            result = service.search(term, k=limit * 2)  # Get more to allow for de-dupe\n            for hit in result.hits:\n                weighted_score = hit.score * weight\n                if hit.id not in combined_results or weighted_score > combined_results[hit.id][1]:\n                    combined_results[hit.id] = (hit, weighted_score)\n\n        # Sort by weighted score and take top N\n        sorted_hits = sorted(combined_results.values(), key=lambda x: x[1], reverse=True)[:limit]\n        final_hits = [hit for hit, _ in sorted_hits]\n\n        # Get expansion metadata for telemetry\n        expansion_meta = expander.get_expansion_metadata(expanded_terms)\n\n        # Sanitize query for telemetry (NEVER store raw query)\n        query_preview = query[:200]  # Truncate preview\n        query_hash = hashlib.sha256(query.encode()).hexdigest()[:16]  # First 16 chars\n        query_len = len(query)\n\n        # Linter metadata\n        linter_meta = {\n            \"linter_query_class\": lint_plan[\"query_class\"],\n            \"linter_expanded\": lint_plan[\"changed\"],\n            \"linter_added_strong_count\": len(lint_plan[\"changes\"][\"added_strong\"]),\n            \"linter_added_weak_count\": len(lint_plan[\"changes\"][\"added_weak\"]),\n            \"linter_reasons\": lint_plan[\"changes\"][\"reasons\"][:3],  # Max 3 reasons\n        }\n\n        # Record telemetry\n        if self.telemetry:\n            self.telemetry.incr(\"ctx_search_count\")\n            self.telemetry.incr(\"ctx_search_hits_total\", len(final_hits))\n            if len(final_hits) == 0:\n                self.telemetry.incr(\"ctx_search_zero_hits_count\")\n\n            # Linter metrics\n            if lint_plan[\"changed\"]:\n                self.telemetry.incr(\"ctx_search_linter_expansion_count\")\n            self.telemetry.incr(f\"ctx_search_linter_class_{lint_plan['query_class']}_count\")\n\n            # Alias expansion metrics\n            if expansion_meta[\"alias_expanded\"]:\n                self.telemetry.incr(\"ctx_search_alias_expansion_count\")\n                self.telemetry.incr(\n                    \"ctx_search_alias_terms_total\", expansion_meta[\"alias_terms_count\"]\n                )\n\n            # Unified event with SANITIZED query and linter metadata\n            self.telemetry.event(\n                \"ctx.search\",\n                {\n                    \"query_preview\": query_preview,\n                    \"query_hash\": query_hash,\n                    \"query_len\": query_len,\n                    \"limit\": limit,\n                    **expansion_meta,\n                    **linter_meta,\n                },\n                {\"hits\": len(final_hits), \"returned_ids\": [h.id for h in final_hits]},\n                1,  # timing_ms >= 1 required\n            )\n\n        # Format output\n        if not final_hits:\n            return f\"No results found for query: '{query}'\"\n\n        output = [f\"Search Results ({len(final_hits)} hits):\\n\"]\n        for i, hit in enumerate(final_hits, 1):\n            output.append(f\"{i}. [{hit.id}] {hit.title_path[0]}\")\n            output.append(f\"   Score: {hit.score:.2f} | Tokens: ~{hit.token_est}\")\n            output.append(f\"   Preview: {hit.preview[:120]}...\\n\")\n\n        return \"\\n\".join(output)\n\n\nclass GetChunkUseCase:\n    \"\"\"Wrapper for ctx.get with telemetry.\"\"\"\n\n    def __init__(self, file_system: FileSystemAdapter, telemetry: Any = None) -> None:\n        self.file_system = file_system\n        self.telemetry = telemetry\n\n    def execute_with_result(\n        self,\n        target_path: Path,\n        ids: list[str],\n        mode: Literal[\"raw\", \"excerpt\", \"skeleton\"] = \"excerpt\",\n        budget_token_est: int = 1500,\n        max_chunks: Optional[int] = None,\n        stop_on_evidence: bool = False,\n        query: Optional[str] = None,\n    ) -> tuple[str, GetResult]:\n        \"\"\"Execute get and return both output and GetResult (for PD_REPORT).\"\"\"\n        service = ContextService(target_path)\n        result = service.get(\n            ids,\n            mode=mode,\n            budget_token_est=budget_token_est,\n            max_chunks=max_chunks,\n            stop_on_evidence=stop_on_evidence,\n            query=query,\n        )\n\n        # Record telemetry\n        if self.telemetry:\n            self.telemetry.incr(\"ctx_get_count\")\n            self.telemetry.incr(\"ctx_get_chunks_total\", len(result.chunks))\n\n            # Track mode usage\n            mode_key = f\"ctx_get_mode_{mode}_count\"\n            self.telemetry.incr(mode_key)\n\n            # Check if budget was exceeded (trimming occurred)\n            if result.total_tokens > budget_token_est:\n                self.telemetry.incr(\"ctx_get_budget_trim_count\")\n\n            # Event with enhanced fields\n            self.telemetry.event(\n                \"ctx.get\",\n                {\n                    \"ids\": ids,\n                    \"mode\": mode,\n                    \"budget\": budget_token_est,\n                    \"max_chunks\": max_chunks,\n                    \"stop_on_evidence\": stop_on_evidence,\n                },\n                {\n                    \"chunks_returned\": len(result.chunks),\n                    \"total_tokens\": result.total_tokens,\n                    \"trimmed\": result.total_tokens > budget_token_est,\n                    \"stop_reason\": result.stop_reason,\n                    \"chunks_requested\": result.chunks_requested,\n                    \"chars_returned_total\": result.chars_returned_total,\n                    \"evidence\": result.evidence_metadata,\n                },\n                1,  # timing_ms >= 1 required\n            )\n\n        # Format output\n        output = [\n            f\"Retrieved {len(result.chunks)} chunk(s) (mode={mode}, tokens=~{result.total_tokens}):\\n\"\n        ]\n\n        for chunk in result.chunks:\n            output.append(f\"## [{chunk.id}] {' > '.join(chunk.title_path)}\")\n            output.append(chunk.text)\n            output.append(\"\")\n\n        if result.total_tokens > budget_token_est:\n            output.append(\"\\n> [!WARNING]\")\n            output.append(\"> Budget exceeded. Some content may have been truncated.\")\n\n        return (\"\\n\".join(output), result)\n\n    def execute(\n        self,\n        target_path: Path,\n        ids: list[str],\n        mode: Literal[\"raw\", \"excerpt\", \"skeleton\"] = \"excerpt\",\n        budget_token_est: int = 1500,\n        max_chunks: Optional[int] = None,\n        stop_on_evidence: bool = False,\n        query: Optional[str] = None,\n    ) -> str:\n        \"\"\"Execute get and format output (API-compatible version).\"\"\"\n        output, _ = self.execute_with_result(\n            target_path, ids, mode, budget_token_est, max_chunks, stop_on_evidence, query\n        )\n        return output\n\n\nclass SyncContextUseCase:\n    \"\"\"Wrapper for ctx.sync (build + validate).\"\"\"\n\n    def __init__(self, file_system: FileSystemAdapter, telemetry: Any = None) -> None:\n        self.file_system = file_system\n        self.telemetry = telemetry\n\n    def execute(self, target_path: Path) -> str:\n        \"\"\"Execute sync (build + validate).\"\"\"\n        from src.application.use_cases import BuildContextPackUseCase, ValidateContextPackUseCase\n\n        # Build\n        build_uc = BuildContextPackUseCase(self.file_system, self.telemetry)\n        build_uc.execute(target_path)\n\n        # Validate\n        validate_uc = ValidateContextPackUseCase(self.file_system, self.telemetry)\n        result = validate_uc.execute(target_path)\n\n        if result.passed:\n            return \"✅ Context Pack synced and validated successfully.\"\n        else:\n            errors_str = \"\\n\".join(f\"  - {e}\" for e in result.errors)\n            return f\"❌ Validation Failed:\\n{errors_str}\"\n",
-      "char_count": 11577,
-      "token_est": 2894,
+      "text": "\"\"\"Use case wrappers for Search and Get with telemetry.\"\"\"\n\nimport hashlib\nfrom pathlib import Path\nfrom typing import Any, Literal, Optional\n\nfrom src.application.context_service import ContextService, GetResult\nfrom src.infrastructure.file_system import FileSystemAdapter\nfrom src.domain.query_linter import LinterPlan\n\n\nclass SearchUseCase:\n    \"\"\"Wrapper for ctx.search with telemetry.\"\"\"\n\n    def __init__(self, file_system: FileSystemAdapter, telemetry: Any = None) -> None:\n        self.file_system = file_system\n        self.telemetry = telemetry\n\n    def execute(\n        self, target_path: Path, query: str, limit: int = 5, enable_lint: bool = False\n    ) -> str:\n        \"\"\"Execute search with query linting, alias expansion and format output.\n\n        Pipeline:\n        1. Normalize query (lowercase, strip, collapse whitespace)\n        2. Linter (if enabled): classify + anchor expansion for vague queries\n        3. Tokenize FINAL query (after linter decision) - CRITICAL ORDER\n        4. Alias expansion (synonym-based via _ctx/aliases.yaml)\n        5. Search: execute weighted search across all terms\n\n        Args:\n            target_path: Segment path to search\n            query: Raw search query\n            limit: Max results to return\n            enable_lint: If True, apply query linter for anchor guidance (default: False)\n\n        Returns:\n            Formatted search results string\n        \"\"\"\n        from src.infrastructure.alias_loader import AliasLoader\n        from src.application.query_normalizer import QueryNormalizer\n        from src.application.query_expander import QueryExpander\n        from src.infrastructure.segment_utils import resolve_segment_root\n        from src.infrastructure.config_loader import ConfigLoader\n        from src.domain.query_linter import lint_query\n\n        # Load aliases\n        alias_loader = AliasLoader(target_path)\n        aliases = alias_loader.load()\n\n        # Normalize query\n        normalized_query = QueryNormalizer.normalize(query)\n\n        # Apply Query Linter (anchor-based classification + expansion)\n        lint_plan: LinterPlan\n        if enable_lint:\n            repo_root = resolve_segment_root(target_path)\n            anchors_cfg = ConfigLoader.load_anchors(repo_root)\n            aliases_cfg = ConfigLoader.load_linter_aliases(repo_root)\n\n            lint_plan = lint_query(normalized_query, anchors_cfg, aliases_cfg)\n\n            # If config missing, force disabled state\n            if anchors_cfg.get(\"_missing_config\") or aliases_cfg.get(\"_missing_config\"):\n                lint_plan[\"query_class\"] = \"disabled_missing_config\"\n                lint_plan[\"changed\"] = False\n                lint_plan[\"changes\"] = {\"added_strong\": [], \"added_weak\": [], \"reasons\": []}\n                query_for_expander = normalized_query\n            else:\n                query_for_expander = (\n                    lint_plan[\"expanded_query\"] if lint_plan[\"changed\"] else normalized_query\n                )\n        else:\n            lint_plan = {\n                \"original_query\": normalized_query,\n                \"query_class\": \"disabled\",\n                \"token_count\": 0,\n                \"anchors_detected\": {\"strong\": [], \"weak\": [], \"aliases_matched\": []},\n                \"expanded_query\": normalized_query,\n                \"changed\": False,\n                \"changes\": {\"added_strong\": [], \"added_weak\": [], \"reasons\": []},\n            }\n            query_for_expander = normalized_query\n\n        # CRITICAL: Tokenize AFTER linter decides final query\n        tokens = QueryNormalizer.tokenize(query_for_expander)\n\n        # Expand query with aliases\n        expander = QueryExpander(aliases)\n        expanded_terms = expander.expand(query_for_expander, tokens)\n\n        # Execute search for each term and combine results\n        service = ContextService(target_path)\n        combined_results: dict[str, tuple[Any, float]] = {}  # chunk_id -> (hit, max_score)\n\n        for term, weight in expanded_terms:\n            result = service.search(term, k=limit * 2)  # Get more to allow for de-dupe\n            for hit in result.hits:\n                weighted_score = hit.score * weight\n                if hit.id not in combined_results or weighted_score > combined_results[hit.id][1]:\n                    combined_results[hit.id] = (hit, weighted_score)\n\n        # Sort by weighted score and take top N\n        sorted_hits = sorted(combined_results.values(), key=lambda x: x[1], reverse=True)[:limit]\n        final_hits = [hit for hit, _ in sorted_hits]\n\n        # Get expansion metadata for telemetry\n        expansion_meta = expander.get_expansion_metadata(expanded_terms)\n\n        # Sanitize query for telemetry (NEVER store raw query)\n        query_preview = query[:200]  # Truncate preview\n        query_hash = hashlib.sha256(query.encode()).hexdigest()[:16]  # First 16 chars\n        query_len = len(query)\n\n        # Linter metadata\n        linter_meta = {\n            \"linter_query_class\": lint_plan[\"query_class\"],\n            \"linter_expanded\": lint_plan[\"changed\"],\n            \"linter_added_strong_count\": len(lint_plan[\"changes\"][\"added_strong\"]),\n            \"linter_added_weak_count\": len(lint_plan[\"changes\"][\"added_weak\"]),\n            \"linter_reasons\": lint_plan[\"changes\"][\"reasons\"][:3],  # Max 3 reasons\n        }\n\n        # Record telemetry\n        if self.telemetry:\n            self.telemetry.incr(\"ctx_search_count\")\n            self.telemetry.incr(\"ctx_search_hits_total\", len(final_hits))\n            if len(final_hits) == 0:\n                self.telemetry.incr(\"ctx_search_zero_hits_count\")\n\n            # Linter metrics\n            if lint_plan[\"changed\"]:\n                self.telemetry.incr(\"ctx_search_linter_expansion_count\")\n            self.telemetry.incr(f\"ctx_search_linter_class_{lint_plan['query_class']}_count\")\n\n            # Alias expansion metrics\n            if expansion_meta[\"alias_expanded\"]:\n                self.telemetry.incr(\"ctx_search_alias_expansion_count\")\n                self.telemetry.incr(\n                    \"ctx_search_alias_terms_total\", expansion_meta[\"alias_terms_count\"]\n                )\n\n            # Unified event with SANITIZED query and linter metadata\n            self.telemetry.event(\n                \"ctx.search\",\n                {\n                    \"query_preview\": query_preview,\n                    \"query_hash\": query_hash,\n                    \"query_len\": query_len,\n                    \"limit\": limit,\n                    **expansion_meta,\n                    **linter_meta,\n                },\n                {\"hits\": len(final_hits), \"returned_ids\": [h.id for h in final_hits]},\n                1,  # timing_ms >= 1 required\n            )\n\n        # Format output\n        if not final_hits:\n            return f\"No results found for query: '{query}'\"\n\n        output = [f\"Search Results ({len(final_hits)} hits):\\n\"]\n        for i, hit in enumerate(final_hits, 1):\n            output.append(f\"{i}. [{hit.id}] {hit.title_path[0]}\")\n            output.append(f\"   Score: {hit.score:.2f} | Tokens: ~{hit.token_est}\")\n            output.append(f\"   Preview: {hit.preview[:120]}...\\n\")\n\n        return \"\\n\".join(output)\n\n\nclass GetChunkUseCase:\n    \"\"\"Wrapper for ctx.get with telemetry.\"\"\"\n\n    def __init__(self, file_system: FileSystemAdapter, telemetry: Any = None) -> None:\n        self.file_system = file_system\n        self.telemetry = telemetry\n\n    def execute_with_result(\n        self,\n        target_path: Path,\n        ids: list[str],\n        mode: Literal[\"raw\", \"excerpt\", \"skeleton\"] = \"excerpt\",\n        budget_token_est: int = 1500,\n        max_chunks: Optional[int] = None,\n        stop_on_evidence: bool = False,\n        query: Optional[str] = None,\n    ) -> tuple[str, GetResult]:\n        \"\"\"Execute get and return both output and GetResult (for PD_REPORT).\"\"\"\n        service = ContextService(target_path)\n        result = service.get(\n            ids,\n            mode=mode,\n            budget_token_est=budget_token_est,\n            max_chunks=max_chunks,\n            stop_on_evidence=stop_on_evidence,\n            query=query,\n        )\n\n        # Record telemetry\n        if self.telemetry:\n            self.telemetry.incr(\"ctx_get_count\")\n            self.telemetry.incr(\"ctx_get_chunks_total\", len(result.chunks))\n\n            # Track mode usage\n            mode_key = f\"ctx_get_mode_{mode}_count\"\n            self.telemetry.incr(mode_key)\n\n            # Check if budget was exceeded (trimming occurred)\n            if result.total_tokens > budget_token_est:\n                self.telemetry.incr(\"ctx_get_budget_trim_count\")\n\n            # Event with enhanced fields\n            self.telemetry.event(\n                \"ctx.get\",\n                {\n                    \"ids\": ids,\n                    \"mode\": mode,\n                    \"budget\": budget_token_est,\n                    \"max_chunks\": max_chunks,\n                    \"stop_on_evidence\": stop_on_evidence,\n                },\n                {\n                    \"chunks_returned\": len(result.chunks),\n                    \"total_tokens\": result.total_tokens,\n                    \"trimmed\": result.total_tokens > budget_token_est,\n                    \"stop_reason\": result.stop_reason,\n                    \"chunks_requested\": result.chunks_requested,\n                    \"chars_returned_total\": result.chars_returned_total,\n                    \"evidence\": result.evidence_metadata,\n                },\n                1,  # timing_ms >= 1 required\n            )\n\n        # Format output\n        output = [\n            f\"Retrieved {len(result.chunks)} chunk(s) (mode={mode}, tokens=~{result.total_tokens}):\\n\"\n        ]\n\n        for chunk in result.chunks:\n            output.append(f\"## [{chunk.id}] {' > '.join(chunk.title_path)}\")\n            output.append(chunk.text)\n            output.append(\"\")\n\n        if result.total_tokens > budget_token_est:\n            output.append(\"\\n> [!WARNING]\")\n            output.append(\"> Budget exceeded. Some content may have been truncated.\")\n\n        return (\"\\n\".join(output), result)\n\n    def execute(\n        self,\n        target_path: Path,\n        ids: list[str],\n        mode: Literal[\"raw\", \"excerpt\", \"skeleton\"] = \"excerpt\",\n        budget_token_est: int = 1500,\n        max_chunks: Optional[int] = None,\n        stop_on_evidence: bool = False,\n        query: Optional[str] = None,\n    ) -> str:\n        \"\"\"Execute get and format output (API-compatible version).\"\"\"\n        output, _ = self.execute_with_result(\n            target_path, ids, mode, budget_token_est, max_chunks, stop_on_evidence, query\n        )\n        return output\n\n\nclass SyncContextUseCase:\n    \"\"\"Wrapper for ctx.sync (build + validate).\"\"\"\n\n    def __init__(self, file_system: FileSystemAdapter, telemetry: Any = None) -> None:\n        self.file_system = file_system\n        self.telemetry = telemetry\n\n    def execute(self, target_path: Path) -> str:\n        \"\"\"Execute sync (build + validate).\"\"\"\n        from src.application.use_cases import BuildContextPackUseCase, ValidateContextPackUseCase\n\n        # Build\n        build_uc = BuildContextPackUseCase(self.file_system, self.telemetry)\n        build_uc.execute(target_path)\n\n        # Validate\n        validate_uc = ValidateContextPackUseCase(self.file_system, self.telemetry)\n        result = validate_uc.execute(target_path)\n\n        if result.passed:\n            return \"✅ Context Pack synced and validated successfully.\"\n        else:\n            errors_str = \"\\n\".join(f\"  - {e}\" for e in result.errors)\n            return f\"❌ Validation Failed:\\n{errors_str}\"\n",
+      "char_count": 11583,
+      "token_est": 2895,
       "source_path": "search_get_usecases.py",
       "chunking_method": "whole_file"
     },
@@ -4627,17 +4777,41 @@
       "chunking_method": "whole_file"
     },
     {
-      "id": "repo:src/domain/query_linter.py:edf8e3cc57",
+      "id": "repo:src/domain/wo_transactions.py:68d0a58109",
+      "doc": "repo:src/domain/wo_transactions.py",
+      "title_path": [
+        "wo_transactions.py"
+      ],
+      "text": "\"\"\"\nTransaction management for WO operations.\nPure domain logic - defines rollback operations.\n\"\"\"\nfrom dataclasses import dataclass\nfrom enum import StrEnum\nfrom typing import Optional\n\n\nclass RollbackType(StrEnum):\n    \"\"\"Types of rollback operations for WO transactions.\n\n    Each represents a compensating action that can undo\n    a previously executed operation.\n    \"\"\"\n    REMOVE_LOCK = \"remove_lock\"\n    MOVE_WO_TO_PENDING = \"move_wo_to_pending\"\n    REMOVE_WORKTREE = \"remove_worktree\"\n    REMOVE_BRANCH = \"remove_branch\"\n\n\nclass TransactionError(Exception):\n    \"\"\"Exception raised for transaction invariant violations.\"\"\"\n\n    pass\n\n\n@dataclass(frozen=True)\nclass RollbackOperation:\n    \"\"\"Represents a rollback operation.\"\"\"\n    name: str\n    description: str\n    rollback_type: RollbackType\n\n\n@dataclass(frozen=True)\nclass Transaction:\n    \"\"\"Transaction with rollback capability.\"\"\"\n    wo_id: str\n    operations: tuple[RollbackOperation, ...]\n    is_committed: bool = False\n\n    def add_operation(self, op: RollbackOperation) -> \"Transaction\":\n        \"\"\"Add operation to transaction (immutable).\n\n        Raises:\n            TransactionError: If transaction is already committed\n        \"\"\"\n        if self.is_committed:\n            raise TransactionError(\n                f\"Cannot modify committed transaction for WO {self.wo_id}. \"\n                f\"Committed transactions are immutable.\"\n            )\n        return Transaction(\n            wo_id=self.wo_id,\n            operations=self.operations + (op,),\n            is_committed=self.is_committed\n        )\n\n    def commit(self) -> \"Transaction\":\n        \"\"\"Mark transaction as committed.\n\n        Returns:\n            A new Transaction instance with is_committed=True\n\n        Raises:\n            TransactionError: If transaction is already committed\n        \"\"\"\n        if self.is_committed:\n            raise TransactionError(\n                f\"Transaction for WO {self.wo_id} is already committed. \"\n                f\"Cannot commit twice.\"\n            )\n        return Transaction(\n            wo_id=self.wo_id,\n            operations=self.operations,\n            is_committed=True\n        )\n\n    def needs_rollback(self) -> bool:\n        \"\"\"Check if transaction needs rollback.\"\"\"\n        return not self.is_committed and len(self.operations) > 0\n",
+      "char_count": 2324,
+      "token_est": 581,
+      "source_path": "wo_transactions.py",
+      "chunking_method": "whole_file"
+    },
+    {
+      "id": "repo:src/domain/query_linter.py:5f92862d50",
       "doc": "repo:src/domain/query_linter.py",
       "title_path": [
         "query_linter.py"
       ],
-      "text": "from typing import TypedDict\nfrom src.domain.anchor_extractor import extract_anchors\n\n\nclass LinterChanges(TypedDict):\n    \"\"\"Type for linter changes structure.\"\"\"\n\n    added_strong: list[str]\n    added_weak: list[str]\n    reasons: list[str]\n\n\nclass LinterPlan(TypedDict):\n    \"\"\"Type for linter plan returned by lint_query.\"\"\"\n\n    original_query: str\n    query_class: str\n    token_count: int\n    anchors_detected: dict\n    expanded_query: str\n    changed: bool\n    changes: LinterChanges\n\n\ndef classify_query(query: str, anchors_cfg: dict, aliases_cfg: dict) -> dict:\n    \"\"\"\n    Clasifica una query en vague/semi/guided basándose en anchors y tokens.\n    Función pura.\n    \"\"\"\n    extraction = extract_anchors(query, anchors_cfg, aliases_cfg)\n\n    tokens = extraction[\"tokens\"]\n    strong = extraction[\"strong\"]\n    weak = extraction[\"weak\"]\n    aliases_matched = extraction[\"aliases_matched\"]\n\n    token_count = len(tokens)\n    strong_count = len(strong)\n    total_anchor_count = strong_count + len(weak) + len(aliases_matched)\n\n    # Reglas de clasificación v1 (determinista)\n    if token_count >= 5 and (strong_count >= 1 or total_anchor_count >= 2):\n        q_class = \"guided\"\n    elif token_count < 3 or total_anchor_count == 0:\n        q_class = \"vague\"\n    else:\n        q_class = \"semi\"\n\n    return {\n        \"query_class\": q_class,\n        \"token_count\": token_count,\n        \"anchors\": {\"strong\": strong, \"weak\": weak, \"aliases_matched\": aliases_matched},\n    }\n\n\ndef expand_query(query: str, analysis: dict, anchors_cfg: dict) -> dict:\n    \"\"\"\n    Expande una query VAGUE de forma determinista.\n    Función pura.\n    \"\"\"\n    if analysis[\"query_class\"] != \"vague\":\n        return {\n            \"expanded_query\": query,\n            \"added_strong\": [],\n            \"added_weak\": [],\n            \"reasons\": []\n        }\n        \n    added_strong: list[str] = []\n    added_weak: list[str] = []\n    reasons: list[str] = []\n\n    # Detección de intención documental en tokens existentes\n    # Usamos los weak anchors detectados en analysis\n    existing_weak = analysis[\"anchors\"][\"weak\"]\n    existing_strong = analysis[\"anchors\"][\"strong\"]\n\n    is_doc_intent = any(\n        t in existing_weak\n        for t in [\"doc\", \"docs\", \"documentación\", \"guía\", \"manual\", \"uso\", \"cómo\", \"how\", \"howto\"]\n    )\n\n    # If strong anchors were detected via aliases, surface them in the expanded query.\n    # This keeps vague queries from staying empty when aliases are the only signal.\n    for cand in existing_strong:\n        if cand not in query.split() and cand not in added_strong and len(added_strong) < 2:\n            added_strong.append(cand)\n    if added_strong and \"vague_alias_boost\" not in reasons:\n        reasons.append(\"vague_alias_boost\")\n\n    # Regla: preferir strong.dirs + strong.exts cuando el usuario pida documentación\n    if is_doc_intent:\n        # Intentar añadir docs/ y readme.md si no están presentes\n        candidates = [\"docs/\", \"readme.md\"]\n        for cand in candidates:\n            if cand not in existing_strong and cand not in added_strong and len(added_strong) < 2:\n                added_strong.append(cand)\n                reasons.append(\"doc_intent_boost\")\n\n    # Si aun tenemos espacio para strong anchors y no hay intención documental clara,\n    # podríamos añadir \"agent.md\" o \"prime.md\" como entrypoints por defecto para queries muy vagas\n    # pero el mandato dice \"limitado\".\n    if len(added_strong) < 2:\n        defaults = [\"agent.md\", \"prime.md\"]\n        added_any = False\n        for cand in defaults:\n            if cand not in existing_strong and cand not in added_strong and len(added_strong) < 2:\n                # Solo añadir si la query es REALMENTE vaga (token count muy bajo)\n                if analysis[\"token_count\"] <= 2:\n                    added_strong.append(cand)\n                    added_any = True\n        if added_any:\n            reasons.append(\"vague_default_boost\")\n\n    # Construir query expandida\n    # Simplemente concatenamos los términos únicos\n    terms = query.split()\n    for s in added_strong:\n        if s not in terms:  # Check simple string presence\n            terms.append(s)\n\n    # Weak expansion: no especificada logicamente en \"reglas\" salvo \"limitado\".\n    # Mandato: \"agregar máximo 2 weak intent/doc terms\".\n    # Si la query no tiene NINGUN weak term, podríamos inyectar uno genérico como \"context\"?\n    # Por ahora dejémoslo conservador: solo strong boost.\n\n    expanded_query_str = \" \".join(terms)\n\n    return {\n        \"expanded_query\": expanded_query_str,\n        \"added_strong\": added_strong,\n        \"added_weak\": added_weak,\n        \"reasons\": reasons,\n    }\n\n\ndef lint_query(query: str, anchors_cfg: dict, aliases_cfg: dict) -> LinterPlan:\n    \"\"\"\n    Orquesta clasificación y expansión para producir un plan auditable.\n\n    Returns:\n        LinterPlan with structure:\n        - original_query: The original query string\n        - query_class: \"vague\" | \"semi\" | \"guided\"\n        - token_count: Number of tokens in query\n        - anchors_detected: Dict with strong/weak/aliases_matched lists\n        - expanded_query: Final query (may be expanded or original)\n        - changed: True if query was expanded\n        - changes: Dict with added_strong, added_weak, reasons lists\n    \"\"\"\n    analysis = classify_query(query, anchors_cfg, aliases_cfg)\n\n    q_class = analysis[\"query_class\"]\n\n    if q_class == \"vague\":\n        expansion = expand_query(query, analysis, anchors_cfg)\n        expanded_query = expansion[\"expanded_query\"]\n        changed = expanded_query != query\n        changes: LinterChanges = {\n            \"added_strong\": expansion[\"added_strong\"],\n            \"added_weak\": expansion[\"added_weak\"],\n            \"reasons\": expansion[\"reasons\"],\n        }\n    else:\n        expanded_query = query\n        changed = False\n        changes: LinterChanges = {\n            \"added_strong\": [],\n            \"added_weak\": [],\n            \"reasons\": [],\n        }\n\n    return {\n        \"original_query\": query,\n        \"query_class\": q_class,\n        \"token_count\": analysis[\"token_count\"],\n        \"anchors_detected\": analysis[\"anchors\"],\n        \"expanded_query\": expanded_query,\n        \"changed\": changed,\n        \"changes\": changes,\n    }\n",
-      "char_count": 6238,
-      "token_est": 1559,
+      "text": "from typing import TypedDict\nfrom src.domain.anchor_extractor import extract_anchors\n\n\nclass LinterChanges(TypedDict):\n    \"\"\"Type for linter changes structure.\"\"\"\n\n    added_strong: list[str]\n    added_weak: list[str]\n    reasons: list[str]\n\n\nclass LinterPlan(TypedDict):\n    \"\"\"Type for linter plan returned by lint_query.\"\"\"\n\n    original_query: str\n    query_class: str\n    token_count: int\n    anchors_detected: dict\n    expanded_query: str\n    changed: bool\n    changes: LinterChanges\n\n\ndef classify_query(query: str, anchors_cfg: dict, aliases_cfg: dict) -> dict:\n    \"\"\"\n    Clasifica una query en vague/semi/guided basándose en anchors y tokens.\n    Función pura.\n    \"\"\"\n    extraction = extract_anchors(query, anchors_cfg, aliases_cfg)\n\n    tokens = extraction[\"tokens\"]\n    strong = extraction[\"strong\"]\n    weak = extraction[\"weak\"]\n    aliases_matched = extraction[\"aliases_matched\"]\n\n    token_count = len(tokens)\n    strong_count = len(strong)\n    total_anchor_count = strong_count + len(weak) + len(aliases_matched)\n\n    # Reglas de clasificación v1 (determinista)\n    if token_count >= 5 and (strong_count >= 1 or total_anchor_count >= 2):\n        q_class = \"guided\"\n    elif token_count < 3 or total_anchor_count == 0:\n        q_class = \"vague\"\n    else:\n        q_class = \"semi\"\n\n    return {\n        \"query_class\": q_class,\n        \"token_count\": token_count,\n        \"anchors\": {\"strong\": strong, \"weak\": weak, \"aliases_matched\": aliases_matched},\n    }\n\n\ndef expand_query(query: str, analysis: dict, anchors_cfg: dict) -> dict:\n    \"\"\"\n    Expande una query VAGUE de forma determinista.\n    Función pura.\n    \"\"\"\n    if analysis[\"query_class\"] != \"vague\":\n        return {\"expanded_query\": query, \"added_strong\": [], \"added_weak\": [], \"reasons\": []}\n\n    added_strong: list[str] = []\n    added_weak: list[str] = []\n    reasons: list[str] = []\n\n    # Detección de intención documental en tokens existentes\n    # Usamos los weak anchors detectados en analysis\n    existing_weak = analysis[\"anchors\"][\"weak\"]\n    existing_strong = analysis[\"anchors\"][\"strong\"]\n\n    is_doc_intent = any(\n        t in existing_weak\n        for t in [\"doc\", \"docs\", \"documentación\", \"guía\", \"manual\", \"uso\", \"cómo\", \"how\", \"howto\"]\n    )\n\n    # If strong anchors were detected via aliases, surface them in the expanded query.\n    # This keeps vague queries from staying empty when aliases are the only signal.\n    for cand in existing_strong:\n        if cand not in query.split() and cand not in added_strong and len(added_strong) < 2:\n            added_strong.append(cand)\n    if added_strong and \"vague_alias_boost\" not in reasons:\n        reasons.append(\"vague_alias_boost\")\n\n    # Regla: preferir strong.dirs + strong.exts cuando el usuario pida documentación\n    if is_doc_intent:\n        # Intentar añadir docs/ y readme.md si no están presentes\n        candidates = [\"docs/\", \"readme.md\"]\n        for cand in candidates:\n            if cand not in existing_strong and cand not in added_strong and len(added_strong) < 2:\n                added_strong.append(cand)\n                reasons.append(\"doc_intent_boost\")\n\n    # Si aun tenemos espacio para strong anchors y no hay intención documental clara,\n    # podríamos añadir \"agent.md\" o \"prime.md\" como entrypoints por defecto para queries muy vagas\n    # pero el mandato dice \"limitado\".\n    if len(added_strong) < 2:\n        defaults = [\"agent.md\", \"prime.md\"]\n        added_any = False\n        for cand in defaults:\n            if cand not in existing_strong and cand not in added_strong and len(added_strong) < 2:\n                # Solo añadir si la query es REALMENTE vaga (token count muy bajo)\n                if analysis[\"token_count\"] <= 2:\n                    added_strong.append(cand)\n                    added_any = True\n        if added_any:\n            reasons.append(\"vague_default_boost\")\n\n    # Construir query expandida\n    # Simplemente concatenamos los términos únicos\n    terms = query.split()\n    for s in added_strong:\n        if s not in terms:  # Check simple string presence\n            terms.append(s)\n\n    # Weak expansion: no especificada logicamente en \"reglas\" salvo \"limitado\".\n    # Mandato: \"agregar máximo 2 weak intent/doc terms\".\n    # Si la query no tiene NINGUN weak term, podríamos inyectar uno genérico como \"context\"?\n    # Por ahora dejémoslo conservador: solo strong boost.\n\n    expanded_query_str = \" \".join(terms)\n\n    return {\n        \"expanded_query\": expanded_query_str,\n        \"added_strong\": added_strong,\n        \"added_weak\": added_weak,\n        \"reasons\": reasons,\n    }\n\n\ndef lint_query(query: str, anchors_cfg: dict, aliases_cfg: dict) -> LinterPlan:\n    \"\"\"\n    Orquesta clasificación y expansión para producir un plan auditable.\n\n    Returns:\n        LinterPlan with structure:\n        - original_query: The original query string\n        - query_class: \"vague\" | \"semi\" | \"guided\"\n        - token_count: Number of tokens in query\n        - anchors_detected: Dict with strong/weak/aliases_matched lists\n        - expanded_query: Final query (may be expanded or original)\n        - changed: True if query was expanded\n        - changes: Dict with added_strong, added_weak, reasons lists\n    \"\"\"\n    analysis = classify_query(query, anchors_cfg, aliases_cfg)\n\n    q_class = analysis[\"query_class\"]\n\n    changes: LinterChanges\n\n    if q_class == \"vague\":\n        expansion = expand_query(query, analysis, anchors_cfg)\n        expanded_query = expansion[\"expanded_query\"]\n        changed = expanded_query != query\n        changes = {\n            \"added_strong\": expansion[\"added_strong\"],\n            \"added_weak\": expansion[\"added_weak\"],\n            \"reasons\": expansion[\"reasons\"],\n        }\n    else:\n        expanded_query = query\n        changed = False\n        changes = {\n            \"added_strong\": [],\n            \"added_weak\": [],\n            \"reasons\": [],\n        }\n\n    return {\n        \"original_query\": query,\n        \"query_class\": q_class,\n        \"token_count\": analysis[\"token_count\"],\n        \"anchors_detected\": analysis[\"anchors\"],\n        \"expanded_query\": expanded_query,\n        \"changed\": changed,\n        \"changes\": changes,\n    }\n",
+      "char_count": 6170,
+      "token_est": 1542,
       "source_path": "query_linter.py",
       "chunking_method": "whole_file"
     },
+    {
+      "id": "repo:src/domain/wo_entities.py:36eb466b99",
+      "doc": "repo:src/domain/wo_entities.py",
+      "title_path": [
+        "wo_entities.py"
+      ],
+      "text": "\"\"\"\nWork Order domain entities and business rules.\nPure domain module - no IO, no external dependencies.\n\"\"\"\nimport re\nfrom dataclasses import dataclass, field\nfrom datetime import datetime, timezone\nfrom enum import Enum, StrEnum\nfrom typing import Optional\n\nfrom src.domain.result import Result, Ok, Err\n\n\n# Pattern for valid WO IDs (WO-XXXX format)\nWO_ID_PATTERN = re.compile(r\"^WO-\\d{4}$\", re.IGNORECASE)\n\n\nclass WOState(Enum):\n    \"\"\"Canonical WO states.\"\"\"\n    PENDING = \"pending\"\n    RUNNING = \"running\"\n    DONE = \"done\"\n    FAILED = \"failed\"\n    PARTIAL = \"partial\"  # NEW: Support partial completion\n\n\nclass Priority(StrEnum):\n    \"\"\"Valid priority levels for Work Orders.\n\n    Ordered from highest to lowest urgency.\n    \"\"\"\n    CRITICAL = \"critical\"\n    HIGH = \"high\"\n    MEDIUM = \"medium\"\n    LOW = \"low\"\n\n\n@dataclass(frozen=True)\nclass Governance:\n    \"\"\"Governance metadata for work orders.\"\"\"\n    must: tuple[str, ...] = ()\n\n    def __post_init__(self) -> None:\n        \"\"\"Validate Governance invariants.\"\"\"\n        # Validate all must references are valid WO IDs\n        for dep in self.must:\n            if not dep or not WO_ID_PATTERN.match(dep):\n                raise ValueError(f\"Invalid WO ID in governance.must: '{dep}'. Expected format: WO-XXXX\")\n\n\n@dataclass(frozen=True)\nclass WOValidationError:\n    \"\"\"WO validation error details.\"\"\"\n    code: str\n    message: str\n    wo_id: Optional[str] = None\n\n\n@dataclass(frozen=True)\nclass WorkOrder:\n    \"\"\"Work Order entity (immutable).\"\"\"\n    id: str\n    epic_id: str\n    title: str\n    priority: Priority\n    status: WOState\n    owner: Optional[str]\n    dod_id: str\n    dependencies: tuple[str, ...]\n    governance: Optional[Governance] = None\n    run_ids: tuple[str, ...] = field(default_factory=tuple)\n    started_at: Optional[datetime] = None\n    finished_at: Optional[datetime] = None\n    closed_at: Optional[datetime] = None  # Separate from finished_at for closure tracking\n    branch: Optional[str] = None\n    worktree: Optional[str] = None\n\n    def __post_init__(self) -> None:\n        \"\"\"Validate WorkOrder invariants after construction.\n\n        Raises:\n            ValueError: If any invariant is violated\n        \"\"\"\n        # Validate ID format (WO-XXXX)\n        if not self.id or not WO_ID_PATTERN.match(self.id):\n            raise ValueError(f\"Invalid WO ID format: '{self.id}'. Expected format: WO-XXXX\")\n\n        # Validate DoD ID is non-empty\n        if not self.dod_id or not self.dod_id.strip():\n            raise ValueError(f\"DoD ID cannot be empty: '{self.dod_id}'\")\n\n        # Validate title is non-empty\n        if not self.title or not self.title.strip():\n            raise ValueError(f\"Title cannot be empty for WO: {self.id}\")\n\n        # Validate no self-dependencies\n        if self.id in self.dependencies:\n            raise ValueError(f\"WO cannot depend on itself: {self.id} has self-dependency\")\n\n        # Validate temporal consistency: if RUNNING, must have started_at\n        if self.status == WOState.RUNNING and self.started_at is None:\n            raise ValueError(f\"WO {self.id} has status RUNNING but no started_at timestamp\")\n\n        # Validate temporal consistency: if DONE/FAILED/PARTIAL, must have finished_at\n        if self.status in (WOState.DONE, WOState.FAILED, WOState.PARTIAL):\n            if self.finished_at is None:\n                raise ValueError(f\"WO {self.id} has status {self.status.value} but no finished_at timestamp\")\n            # Ensure finished_at is after started_at\n            if self.started_at and self.finished_at < self.started_at:\n                raise ValueError(\n                    f\"WO {self.id} finished_at ({self.finished_at}) is before started_at ({self.started_at})\"\n                )\n\n    def can_transition_to(self, new_state: WOState) -> Result[None, WOValidationError]:\n        \"\"\"Validate state transition is legal.\"\"\"\n        valid_transitions = {\n            WOState.PENDING: [WOState.RUNNING],\n            WOState.RUNNING: [WOState.DONE, WOState.FAILED, WOState.PARTIAL],\n            WOState.PARTIAL: [WOState.RUNNING, WOState.DONE, WOState.FAILED],\n            WOState.DONE: [],\n            WOState.FAILED: [WOState.PENDING],\n        }\n        allowed = valid_transitions.get(self.status, [])\n        if new_state not in allowed:\n            return Err(WOValidationError(\n                code=\"INVALID_STATE_TRANSITION\",\n                message=f\"Cannot transition from {self.status.value} to {new_state.value}\",\n                wo_id=self.id\n            ))\n        return Ok(None)\n\n    def validate_dependencies(self, completed_wo_ids: set[str]) -> Result[None, WOValidationError]:\n        \"\"\"Validate that all dependencies are satisfied.\"\"\"\n        unsatisfied = [dep for dep in self.dependencies if dep not in completed_wo_ids]\n        if unsatisfied:\n            return Err(WOValidationError(\n                code=\"UNSATISFIED_DEPENDENCIES\",\n                message=f\"Dependencies not satisfied: {', '.join(unsatisfied)}\",\n                wo_id=self.id\n            ))\n        return Ok(None)\n\n    def is_stale(self, max_age_seconds: int = 3600) -> bool:\n        \"\"\"Check if WO is stale (started too long ago).\"\"\"\n        if self.status != WOState.RUNNING or self.started_at is None:\n            return False\n        age = (datetime.now(timezone.utc) - self.started_at).total_seconds()\n        return age >= max_age_seconds\n",
+      "char_count": 5387,
+      "token_est": 1346,
+      "source_path": "wo_entities.py",
+      "chunking_method": "whole_file"
+    },
     {
       "id": "repo:src/cli/error_cards.py:3edc60e345",
       "doc": "repo:src/cli/error_cards.py",
@@ -4651,17 +4825,29 @@
       "chunking_method": "whole_file"
     },
     {
-      "id": "repo:src/cli/invalid_option_handler.py:e50c0a64c8",
+      "id": "repo:src/cli/invalid_option_handler.py:938358e463",
       "doc": "repo:src/cli/invalid_option_handler.py",
       "title_path": [
         "invalid_option_handler.py"
       ],
-      "text": "\"\"\"\nInvalid Option Handler for CLI error messages.\n\nProvides fuzzy matching and helpful suggestions when users provide invalid flags.\n\"\"\"\n\nfrom __future__ import annotations\n\nimport difflib\nfrom dataclasses import dataclass\nfrom typing import Optional\n\n\n@dataclass(frozen=True)\nclass InvalidOptionResult:\n    \"\"\"Result of processing an invalid option error.\"\"\"\n\n    invalid_flag: str\n    suggested_flags: list[tuple[str, float]]  # (flag, similarity_score)\n    command_path: str  # e.g., \"trifecta load\" or \"trifecta ctx plan\"\n\n\ndef find_similar_flags(\n    invalid_flag: str, valid_flags: list[str], cutoff: float = 0.5\n) -> list[tuple[str, float]]:\n    \"\"\"\n    Find similar flags using fuzzy matching.\n\n    Args:\n        invalid_flag: The invalid flag provided by the user\n        valid_flags: List of valid flags for the command\n        cutoff: Minimum similarity score (0.0-1.0) to include a suggestion\n\n    Returns:\n        List of (flag, similarity_score) tuples, sorted by similarity (descending)\n    \"\"\"\n    if not valid_flags:\n        return []\n\n    # Calculate similarity scores for all valid flags\n    matches = []\n    for flag in valid_flags:\n        # Use SequenceMatcher for fuzzy string matching\n        similarity = difflib.SequenceMatcher(None, invalid_flag.lower(), flag.lower()).ratio()\n        if similarity >= cutoff:\n            matches.append((flag, similarity))\n\n    # Sort by similarity (highest first)\n    matches.sort(key=lambda x: x[1], reverse=True)\n\n    # Return top 3 matches\n    return matches[:3]\n\n\ndef get_valid_flags_for_command(command_path: str) -> list[str]:\n    \"\"\"\n    Get list of valid flags for a given command path.\n\n    This is a simplified implementation. In a full implementation,\n    this would introspect the Typer app to get actual registered flags.\n\n    Args:\n        command_path: The command path (e.g., \"trifecta load\", \"trifecta ctx plan\")\n\n    Returns:\n        List of valid flag names\n    \"\"\"\n    # Common flags available in most commands\n    common_flags = [\"--help\", \"-h\", \"--segment\", \"-s\", \"--telemetry\"]\n\n    # Command-specific flags\n    command_flags = {\n        \"trifecta load\": [\"--task\", \"-t\", \"--mode\", \"-m\"],\n        \"trifecta ctx plan\": [\"--task\", \"-t\", \"--json\", \"-j\"],\n        \"trifecta ctx build\": [],\n        \"trifecta ctx search\": [\"--query\", \"-q\", \"--limit\", \"-l\", \"--no-lint\"],\n        \"trifecta ctx get\": [\n            \"--ids\",\n            \"-i\",\n            \"--mode\",\n            \"-m\",\n            \"--budget-token-est\",\n            \"-b\",\n            \"--max-chunks\",\n            \"--stop-on-evidence\",\n            \"--query\",\n            \"-q\",\n            \"--pd-report\",\n        ],\n        \"trifecta ctx validate\": [],\n        \"trifecta ctx stats\": [\"--window\", \"-w\"],\n        \"trifecta ctx sync\": [],\n        \"trifecta ctx reset\": [\"--force\", \"-f\"],\n        \"trifecta create\": [\"--scope\"],\n        \"trifecta session append\": [\"--summary\", \"--files\", \"--commands\"],\n    }\n\n    # Get specific flags for the command, or empty list if unknown\n    specific_flags = command_flags.get(command_path, [])\n\n    return common_flags + specific_flags\n\n\ndef parse_command_path_from_argv(argv: list[str]) -> str:\n    \"\"\"\n    Parse the command path from sys.argv.\n\n    Args:\n        argv: Command line arguments (typically sys.argv)\n\n    Returns:\n        Command path string (e.g., \"trifecta ctx plan\")\n    \"\"\"\n    if not argv:\n        return \"trifecta\"\n\n    # Skip the script name (e.g., \"trifecta\" or \"python -m trifecta\")\n    # and reconstruct the command path\n    parts = []\n\n    # Find where 'trifecta' appears\n    start_idx = 0\n    for i, arg in enumerate(argv):\n        if \"trifecta\" in arg.lower():\n            start_idx = i\n            parts.append(\"trifecta\")\n            break\n\n    # Collect subcommands until we hit an option (starts with -)\n    for arg in argv[start_idx + 1 :]:\n        if arg.startswith(\"-\"):\n            break\n        parts.append(arg)\n\n    return \" \".join(parts) if parts else \"trifecta\"\n\n\ndef extract_invalid_flag(error_message: str) -> Optional[str]:\n    \"\"\"\n    Extract the invalid flag from a Typer error message.\n\n    Args:\n        error_message: The error message from Typer/Click\n\n    Returns:\n        The invalid flag name, or None if not found\n    \"\"\"\n    # Common patterns for invalid option messages\n    patterns = [\n        \"No such option:\",\n        \"no such option:\",\n        \"Error: no such option\",\n    ]\n\n    for pattern in patterns:\n        if pattern in error_message:\n            # Extract the flag after the pattern\n            parts = error_message.split(pattern)\n            if len(parts) > 1:\n                flag = parts[-1].strip()\n                # Clean up any trailing punctuation or whitespace\n                flag = flag.split()[0].strip(\"'\\\"'\")\n                return flag\n\n    return None\n\n\ndef render_enhanced_error(\n    invalid_flag: str,\n    command_path: str,\n    suggested_flags: list[tuple[str, float]],\n    original_error: Optional[str] = None,\n) -> str:\n    \"\"\"\n    Render an enhanced error message with suggestions.\n\n    Args:\n        invalid_flag: The invalid flag that was provided\n        command_path: The command path (e.g., \"trifecta load\")\n        suggested_flags: List of (flag, similarity) tuples\n        original_error: The original error message (if available)\n\n    Returns:\n        Enhanced error message string\n    \"\"\"\n    lines = []\n\n    # Header with error\n    lines.append(f\"❌ Error: No such option: {invalid_flag}\")\n    lines.append(\"\")\n\n    # Suggested similar flags\n    if suggested_flags:\n        lines.append(\"Posiblemente quisiste decir:\")\n        for flag, similarity in suggested_flags:\n            # Calculate percentage for display\n            pct = int(similarity * 100)\n            if flag == \"--help\":\n                lines.append(f\"  {flag:<15} Show help message ({pct}% match)\")\n            else:\n                lines.append(f\"  {flag:<15} ({pct}% match)\")\n        lines.append(\"\")\n\n    # Suggest --help\n    lines.append(\"Para ver opciones disponibles:\")\n    lines.append(f\"  uv run {command_path} --help\")\n    lines.append(\"\")\n\n    # Example usage\n    lines.append(\"Ejemplo de uso:\")\n\n    # Provide context-appropriate example\n    if \"ctx plan\" in command_path:\n        lines.append(f'  uv run {command_path} --segment . --task \"Implement feature X\"')\n    elif \"load\" in command_path:\n        lines.append(f'  uv run {command_path} --segment . --task \"Implement feature X\"')\n    elif \"search\" in command_path:\n        lines.append(f'  uv run {command_path} --segment . --query \"search term\"')\n    elif \"get\" in command_path:\n        lines.append(f'  uv run {command_path} --segment . --ids \"chunk1,chunk2\"')\n    elif \"create\" in command_path:\n        lines.append(f'  uv run {command_path} --segment . --scope \"Description\"')\n    else:\n        lines.append(f\"  uv run {command_path} --segment . --help\")\n\n    return \"\\n\".join(lines)\n\n\ndef handle_invalid_option_error(error_message: str, argv: list[str]) -> str:\n    \"\"\"\n    Main entry point for handling invalid option errors.\n\n    Args:\n        error_message: The original error message from Typer/Click\n        argv: Command line arguments\n\n    Returns:\n        Enhanced error message with suggestions\n    \"\"\"\n    # Extract the invalid flag\n    invalid_flag = extract_invalid_flag(error_message)\n    if not invalid_flag:\n        # Can't parse the error, return original\n        return error_message\n\n    # Parse command path\n    command_path = parse_command_path_from_argv(argv)\n\n    # Get valid flags for this command\n    valid_flags = get_valid_flags_for_command(command_path)\n\n    # Find similar flags\n    suggested_flags = find_similar_flags(invalid_flag, valid_flags)\n\n    # Render enhanced error\n    return render_enhanced_error(\n        invalid_flag=invalid_flag,\n        command_path=command_path,\n        suggested_flags=suggested_flags,\n        original_error=error_message,\n    )\n",
-      "char_count": 7908,
-      "token_est": 1977,
+      "text": "\"\"\"Invalid Option Handler for CLI error messages.\n\nProvides fuzzy matching and helpful suggestions when users provide invalid flags.\nUses runtime introspection (not static mappings) to ensure suggestions are\nalways accurate and up-to-date.\n\nInvariant: Never suggest flags that don't exist in the actual command.\nFail-closed: If introspection fails, returns helpful message without suggestions.\n\"\"\"\n\nfrom __future__ import annotations\n\nimport difflib\nfrom dataclasses import dataclass\nfrom typing import Optional\n\nfrom src.cli.introspection import (\n    CommandIntrospector,\n    create_introspector,\n    get_common_flags,\n)\n\n# Singleton introspector instance (initialized lazily)\n_introspector: Optional[CommandIntrospector] = None\n\n\ndef _get_introspector() -> CommandIntrospector:\n    \"\"\"Get or create the singleton introspector instance.\n\n    Uses lazy import to avoid circular dependency with cli.py\n    \"\"\"\n    global _introspector\n    if _introspector is None:\n        # Lazy import to avoid circular dependency\n        from src.infrastructure.cli import app as typer_app\n\n        _introspector = create_introspector(typer_app)\n    return _introspector\n\n\ndef reset_introspector() -> None:\n    \"\"\"Reset the introspector (useful for testing).\"\"\"\n    global _introspector\n    _introspector = None\n\n\n@dataclass(frozen=True)\nclass InvalidOptionResult:\n    \"\"\"Result of processing an invalid option error.\"\"\"\n\n    invalid_flag: str\n    suggested_flags: list[tuple[str, float]]  # (flag, similarity_score)\n    command_path: str  # e.g., \"trifecta load\" or \"trifecta ctx plan\"\n\n\ndef find_similar_flags(\n    invalid_flag: str, valid_flags: list[str], cutoff: float = 0.5\n) -> list[tuple[str, float]]:\n    \"\"\"\n    Find similar flags using fuzzy matching.\n\n    Args:\n        invalid_flag: The invalid flag provided by the user\n        valid_flags: List of valid flags for the command\n        cutoff: Minimum similarity score (0.0-1.0) to include a suggestion\n\n    Returns:\n        List of (flag, similarity_score) tuples, sorted by similarity (descending)\n    \"\"\"\n    if not valid_flags:\n        return []\n\n    # Calculate similarity scores for all valid flags\n    matches = []\n    for flag in valid_flags:\n        # Use SequenceMatcher for fuzzy string matching\n        similarity = difflib.SequenceMatcher(None, invalid_flag.lower(), flag.lower()).ratio()\n        if similarity >= cutoff:\n            matches.append((flag, similarity))\n\n    # Sort by similarity (highest first)\n    matches.sort(key=lambda x: x[1], reverse=True)\n\n    # Return top 3 matches\n    return matches[:3]\n\n\ndef get_valid_flags_for_command(command_path: str) -> list[str]:\n    \"\"\"\n    Get list of valid flags for a given command path using runtime introspection.\n\n    This function introspects the actual Typer/Click commands at runtime\n    to get the current list of valid flags. No static mapping needed.\n\n    Args:\n        command_path: The command path (e.g., \"trifecta load\", \"trifecta ctx plan\")\n\n    Returns:\n        List of valid flag names\n\n    Note:\n        Uses runtime introspection via CommandIntrospector.\n        If introspection fails, returns common flags only (fail-closed).\n    \"\"\"\n    try:\n        introspector = _get_introspector()\n        flags = introspector.get_flags(command_path)\n\n        if not flags:\n            # Introspection returned empty set, use common flags only\n            return list(get_common_flags())\n\n        return sorted(flags)\n    except Exception:\n        # Fail-closed: if anything fails, return common flags only\n        return list(get_common_flags())\n\n\ndef parse_command_path_from_argv(argv: list[str]) -> str:\n    \"\"\"\n    Parse the command path from sys.argv.\n\n    Args:\n        argv: Command line arguments (typically sys.argv)\n\n    Returns:\n        Command path string (e.g., \"trifecta ctx plan\")\n    \"\"\"\n    if not argv:\n        return \"trifecta\"\n\n    # Skip the script name (e.g., \"trifecta\" or \"python -m trifecta\")\n    # and reconstruct the command path\n    parts = []\n\n    # Find where 'trifecta' appears\n    start_idx = 0\n    for i, arg in enumerate(argv):\n        if \"trifecta\" in arg.lower():\n            start_idx = i\n            parts.append(\"trifecta\")\n            break\n\n    # Collect subcommands until we hit an option (starts with -)\n    for arg in argv[start_idx + 1 :]:\n        if arg.startswith(\"-\"):\n            break\n        parts.append(arg)\n\n    return \" \".join(parts) if parts else \"trifecta\"\n\n\ndef extract_invalid_flag(error_message: str) -> Optional[str]:\n    \"\"\"\n    Extract the invalid flag from a Typer error message.\n\n    Args:\n        error_message: The error message from Typer/Click\n\n    Returns:\n        The invalid flag name, or None if not found\n    \"\"\"\n    # Common patterns for invalid option messages\n    patterns = [\n        \"No such option:\",\n        \"no such option:\",\n        \"Error: no such option\",\n    ]\n\n    for pattern in patterns:\n        if pattern in error_message:\n            # Extract the flag after the pattern\n            parts = error_message.split(pattern)\n            if len(parts) > 1:\n                flag = parts[-1].strip()\n                # Clean up any trailing punctuation or whitespace\n                flag = flag.split()[0].strip(\"\\\"'\")\n                return flag\n\n    return None\n\n\ndef render_enhanced_error(\n    invalid_flag: str,\n    command_path: str,\n    suggested_flags: list[tuple[str, float]],\n    original_error: Optional[str] = None,\n) -> str:\n    \"\"\"\n    Render an enhanced error message with suggestions.\n\n    Args:\n        invalid_flag: The invalid flag that was provided\n        command_path: The command path (e.g., \"trifecta load\")\n        suggested_flags: List of (flag, similarity) tuples\n        original_error: The original error message (if available)\n\n    Returns:\n        Enhanced error message string\n    \"\"\"\n    lines = []\n\n    # Header with error\n    lines.append(f\"❌ Error: No such option: {invalid_flag}\")\n    lines.append(\"\")\n\n    # Suggested similar flags\n    if suggested_flags:\n        lines.append(\"Posiblemente quisiste decir:\")\n        for flag, similarity in suggested_flags:\n            # Calculate percentage for display\n            pct = int(similarity * 100)\n            if flag == \"--help\":\n                lines.append(f\"  {flag:<15} Show help message ({pct}% match)\")\n            else:\n                lines.append(f\"  {flag:<15} ({pct}% match)\")\n        lines.append(\"\")\n\n    # Suggest --help\n    lines.append(\"Para ver opciones disponibles:\")\n    lines.append(f\"  uv run {command_path} --help\")\n    lines.append(\"\")\n\n    # Example usage\n    lines.append(\"Ejemplo de uso:\")\n\n    # Provide context-appropriate example\n    if \"ctx plan\" in command_path:\n        lines.append(f'  uv run {command_path} --segment . --task \"Implement feature X\"')\n    elif \"load\" in command_path:\n        lines.append(f'  uv run {command_path} --segment . --task \"Implement feature X\"')\n    elif \"search\" in command_path:\n        lines.append(f'  uv run {command_path} --segment . --query \"search term\"')\n    elif \"get\" in command_path:\n        lines.append(f'  uv run {command_path} --segment . --ids \"chunk1,chunk2\"')\n    elif \"create\" in command_path:\n        lines.append(f'  uv run {command_path} --segment . --scope \"Description\"')\n    else:\n        lines.append(f\"  uv run {command_path} --segment . --help\")\n\n    return \"\\n\".join(lines)\n\n\ndef handle_invalid_option_error(error_message: str, argv: list[str]) -> str:\n    \"\"\"\n    Main entry point for handling invalid option errors.\n\n    Args:\n        error_message: The original error message from Typer/Click\n        argv: Command line arguments\n\n    Returns:\n        Enhanced error message with suggestions\n    \"\"\"\n    # Extract the invalid flag\n    invalid_flag = extract_invalid_flag(error_message)\n    if not invalid_flag:\n        # Can't parse the error, return original\n        return error_message\n\n    # Parse command path\n    command_path = parse_command_path_from_argv(argv)\n\n    # Get valid flags for this command (runtime introspection)\n    valid_flags = get_valid_flags_for_command(command_path)\n\n    # Find similar flags\n    suggested_flags = find_similar_flags(invalid_flag, valid_flags)\n\n    # Render enhanced error\n    return render_enhanced_error(\n        invalid_flag=invalid_flag,\n        command_path=command_path,\n        suggested_flags=suggested_flags,\n        original_error=error_message,\n    )\n",
+      "char_count": 8391,
+      "token_est": 2097,
       "source_path": "invalid_option_handler.py",
       "chunking_method": "whole_file"
     },
+    {
+      "id": "repo:src/cli/introspection.py:60e5f4dd96",
+      "doc": "repo:src/cli/introspection.py",
+      "title_path": [
+        "introspection.py"
+      ],
+      "text": "\"\"\"Introspection module for CLI option discovery.\n\nProvides runtime introspection of Click/Typer commands to extract\nvalid flags and options. This is the single source of truth for\ncurrently available CLI options.\n\nInvariant: Never suggest flags that don't exist in the actual command.\nFail-closed: If introspection fails, return empty set (no hallucination).\n\"\"\"\n\nfrom __future__ import annotations\n\nimport sys\nfrom dataclasses import dataclass\nfrom typing import Any, Optional\n\nimport click\n\n\n@dataclass(frozen=True)\nclass OptionSpec:\n    \"\"\"Specification of a CLI option/flag.\n\n    Immutable dataclass representing a discovered option.\n    Used for stable testing and comparison.\n    \"\"\"\n\n    name: str\n    opts: tuple[str, ...]  # e.g., (\"--verbose\", \"-v\")\n    required: bool\n    type_name: str\n    help: Optional[str] = None\n    default: Any = None\n    is_flag: bool = False\n    multiple: bool = False\n\n    def all_names(self) -> list[str]:\n        \"\"\"Return all flag names (long and short forms).\"\"\"\n        return list(self.opts)\n\n    def __repr__(self) -> str:\n        flags = \", \".join(self.opts)\n        return f\"OptionSpec({flags})\"\n\n\nclass IntrospectionError(Exception):\n    \"\"\"Raised when introspection fails.\"\"\"\n\n    pass\n\n\ndef introspect_click_params(command: click.Command) -> list[OptionSpec]:\n    \"\"\"Extract OptionSpec list from a Click command.\n\n    Args:\n        command: A Click Command object\n\n    Returns:\n        List of OptionSpec sorted by declaration order\n\n    Raises:\n        IntrospectionError: If command introspection fails\n    \"\"\"\n    if not isinstance(command, click.Command):\n        raise IntrospectionError(f\"Expected click.Command, got {type(command)}\")\n\n    specs = []\n\n    # Click stores params in command.params list\n    for param in getattr(command, \"params\", []):\n        if isinstance(param, click.Option):\n            spec = _extract_option_spec(param)\n            if spec:\n                specs.append(spec)\n\n    # Add --help explicitly (all Click commands have it)\n    # Typer/Click adds this automatically, not in params list\n    help_spec = OptionSpec(\n        name=\"help\",\n        opts=(\"--help\", \"-h\"),\n        required=False,\n        type_name=\"BOOLEAN\",\n        help=\"Show this message and exit.\",\n        is_flag=True,\n    )\n    specs.append(help_spec)\n\n    return specs\n\n\ndef _extract_option_spec(param: click.Option) -> Optional[OptionSpec]:\n    \"\"\"Convert a Click Option to OptionSpec.\n\n    Args:\n        param: Click Option parameter\n\n    Returns:\n        OptionSpec or None if extraction fails\n    \"\"\"\n    try:\n        # Extract flag names (--long, -short)\n        opts = tuple(param.opts)\n        if not opts:\n            return None\n\n        # Get option name (first long form or first form)\n        name = param.name or opts[0].lstrip(\"-\")\n\n        # Determine type name\n        type_name = _get_type_name(param.type)\n\n        # Check if it's a flag (boolean toggle)\n        is_flag = getattr(param, \"is_flag\", False)\n\n        return OptionSpec(\n            name=name,\n            opts=opts,\n            required=param.required,\n            type_name=type_name,\n            help=param.help,\n            default=param.default,\n            is_flag=is_flag,\n            multiple=param.multiple,\n        )\n    except Exception as e:\n        # Fail-closed: if we can't parse, skip this option\n        return None\n\n\ndef _get_type_name(param_type: Any) -> str:\n    \"\"\"Get a string representation of the parameter type.\"\"\"\n    if isinstance(param_type, click.types.ParamType):\n        return param_type.name.upper()\n    elif hasattr(param_type, \"__name__\"):\n        return param_type.__name__.upper()\n    else:\n        return str(param_type).upper()\n\n\ndef resolve_command_path(\n    root_command: click.Command, argv: list[str], skip_first: bool = True\n) -> Optional[click.Command]:\n    \"\"\"Resolve command path from argv to actual Click command.\n\n    Args:\n        root_command: Root Click command (e.g., the typer.Typer() app)\n        argv: Command line arguments\n        skip_first: If True, skip argv[0] (script name)\n\n    Returns:\n        Resolved Click command or None if not found\n    \"\"\"\n    if not argv:\n        return root_command\n\n    # Find starting index\n    start_idx = 1 if skip_first else 0\n\n    # Find 'trifecta' in argv\n    for i, arg in enumerate(argv[start_idx:], start=start_idx):\n        if \"trifecta\" in arg.lower():\n            start_idx = i + 1\n            break\n\n    current = root_command\n\n    # Traverse subcommands\n    for arg in argv[start_idx:]:\n        if arg.startswith(\"-\"):\n            # Hit an option, stop traversing\n            break\n\n        if isinstance(current, click.Group):\n            # Look for subcommand\n            if arg in current.commands:\n                current = current.commands[arg]\n            else:\n                # Unknown subcommand\n                return None\n        else:\n            # Not a group, can't traverse further\n            break\n\n    return current\n\n\ndef get_valid_flags_for_command(command: click.Command) -> set[str]:\n    \"\"\"Get all valid flag names for a command.\n\n    Args:\n        command: Click Command to introspect\n\n    Returns:\n        Set of all valid flag strings (e.g., {\"--help\", \"-h\", \"--verbose\"})\n\n    Note:\n        Returns empty set if introspection fails (fail-closed)\n    \"\"\"\n    try:\n        specs = introspect_click_params(command)\n        flags = set()\n        for spec in specs:\n            flags.update(spec.all_names())\n        return flags\n    except IntrospectionError:\n        # Fail-closed: return empty set\n        return set()\n\n\ndef get_common_flags() -> set[str]:\n    \"\"\"Return flags common to most commands.\n\n    These are flags that appear in many commands and are safe to suggest\n    even if introspection partially fails.\n    \"\"\"\n    return {\"--help\", \"-h\"}\n\n\nclass CommandIntrospector:\n    \"\"\"High-level introspector with caching.\n\n    Provides caching layer to avoid repeated introspection\n    on hot paths.\n    \"\"\"\n\n    def __init__(self, root_command: click.Command):\n        # Convert Typer app to Click command if necessary\n        if hasattr(root_command, \"registered_groups\"):\n            from typer.main import get_command\n\n            self._root = get_command(root_command)\n        else:\n            self._root = root_command\n        self._cache: dict[str, list[OptionSpec]] = {}\n\n    def introspect(self, command_path: str) -> list[OptionSpec]:\n        \"\"\"Get OptionSpecs for a command path (with caching).\n\n        Args:\n            command_path: Path like \"trifecta load\" or \"trifecta ctx plan\"\n\n        Returns:\n            List of OptionSpec for that command\n        \"\"\"\n        if command_path in self._cache:\n            return self._cache[command_path]\n\n        # Parse path and resolve command\n        parts = command_path.split()\n        if not parts:\n            return []\n\n        current = self._root\n        for part in parts[1:]:  # Skip root name\n            # Handle Typer subcommands by converting to Click\n            if hasattr(current, \"commands\"):\n                # Click Group\n                if part in current.commands:\n                    current = current.commands[part]\n                else:\n                    return []\n            elif hasattr(current, \"registered_groups\"):\n                # Typer app - need to find subcommand in registered_groups\n                found = False\n                for group in current.registered_groups:\n                    if hasattr(group, \"typer_instance\"):\n                        typer_instance = group.typer_instance\n                        if hasattr(typer_instance, \"registered_callback\"):\n                            # This is a subcommand\n                            if hasattr(typer_instance.registered_callback, \"name\"):\n                                if typer_instance.registered_callback.name == part:\n                                    from typer.main import get_command\n\n                                    current = get_command(typer_instance)\n                                    found = True\n                                    break\n                if not found:\n                    return []\n            else:\n                return []\n\n        specs = introspect_click_params(current)\n        self._cache[command_path] = specs\n        return specs\n\n    def get_flags(self, command_path: str) -> set[str]:\n        \"\"\"Get all flag names for a command path.\"\"\"\n        specs = self.introspect(command_path)\n        flags = set()\n        for spec in specs:\n            flags.update(spec.all_names())\n        return flags\n\n    def clear_cache(self) -> None:\n        \"\"\"Clear introspection cache.\"\"\"\n        self._cache.clear()\n\n\ndef create_introspector(typer_app) -> CommandIntrospector:\n    \"\"\"Create an introspector from a Typer app.\n\n    Args:\n        typer_app: A typer.Typer application\n\n    Returns:\n        Configured CommandIntrospector\n\n    Note:\n        Typer wraps Click, so we need to unwrap to get the underlying\n        Click Group/Command. We use typer.main.get_command() to get\n        the actual Click command structure.\n    \"\"\"\n    from typer.main import get_command\n\n    # Convert Typer app to Click command\n    # This returns a TyperCommand which is a subclass of click.Command\n    click_cmd = get_command(typer_app)\n\n    return CommandIntrospector(click_cmd)\n",
+      "char_count": 9335,
+      "token_est": 2333,
+      "source_path": "introspection.py",
+      "chunking_method": "whole_file"
+    },
     {
       "id": "repo:src/cli/__init__.py:5589da29ee",
       "doc": "repo:src/cli/__init__.py",
@@ -4687,38 +4873,38 @@
       "chunking_method": "whole_file"
     },
     {
-      "id": "repo:src/infrastructure/lsp_daemon.py:eefb94ce95",
+      "id": "repo:src/infrastructure/lsp_daemon.py:89bd5a31c5",
       "doc": "repo:src/infrastructure/lsp_daemon.py",
       "title_path": [
         "lsp_daemon.py"
       ],
-      "text": "import os\nimport sys\nimport socket\nimport time\nimport json\nimport signal\nimport fcntl\nimport subprocess\nfrom pathlib import Path\nfrom typing import Any, Optional, Dict\nfrom src.infrastructure.lsp_client import LSPClient\nfrom src.infrastructure.telemetry import Telemetry\nfrom src.infrastructure.segment_utils import resolve_segment_root, compute_segment_id\nfrom src.infrastructure.daemon_paths import (\n    get_daemon_socket_path,\n    get_daemon_lock_path,\n    get_daemon_pid_path,\n)\n\n# --- Constants ---\nDEFAULT_TTL = 180\n\n\nclass LSPDaemonServer:\n    def __init__(self, segment_root: Path, ttl_sec: int = DEFAULT_TTL):\n        self.root = resolve_segment_root(segment_root)\n        self.ttl = ttl_sec\n        self.last_activity = time.time()\n        self.running = False\n\n        # Unified Segment ID / Dir\n        self.segment_id = compute_segment_id(self.root)\n\n        # Use short paths from daemon_paths to avoid AF_UNIX limit\n        self.socket_path = get_daemon_socket_path(self.segment_id)\n        self.lock_path = get_daemon_lock_path(self.segment_id)\n        self.pid_path = get_daemon_pid_path(self.segment_id)\n\n        self.telemetry = Telemetry(self.root)\n        self.lsp_client = LSPClient(self.root, self.telemetry)\n\n        self._lock_fp: Any = None\n\n    def start(self):\n        \"\"\"Main Daemon Entrypoint\"\"\"\n        # 1. Acquire Lock\n        self._lock_fp = open(self.lock_path, \"w\")\n        try:\n            fcntl.lockf(self._lock_fp, fcntl.LOCK_EX | fcntl.LOCK_NB)\n        except IOError:\n            print(\"Daemon already running.\")\n            return\n\n        # 2. Write PID\n        self.pid_path.write_text(str(os.getpid()))\n\n        # 3. Setup Socket\n        if self.socket_path.exists():\n            self.socket_path.unlink()\n\n        server = socket.socket(socket.AF_UNIX, socket.SOCK_STREAM)\n        server.bind(str(self.socket_path))\n        server.listen(1)\n        server.settimeout(1.0)  # Check TTL every second\n\n        self.running = True\n\n        # 4. Start LSP Client\n        self.lsp_client.start()\n\n        # 5. Signal Handling\n        signal.signal(signal.SIGTERM, self._shutdown_signal)\n        signal.signal(signal.SIGINT, self._shutdown_signal)\n\n        # 6. Event Loop\n        while self.running:\n            try:\n                # Check TTL\n                if time.time() - self.last_activity > self.ttl:\n                    self.telemetry.event(\"lsp.daemon_status\", {}, {\"status\": \"shutdown_ttl\"}, 1)\n                    break\n\n                try:\n                    conn, _ = server.accept()\n                    conn.settimeout(None)  # Disable inherited timeout\n                    self._handle_client(conn)\n                except socket.timeout:\n                    continue  # Loop to check activity/TTL\n            except Exception as e:\n                self.telemetry.event(\n                    \"lsp.daemon_status\", {}, {\"status\": \"error\", \"error\": str(e)}, 1\n                )\n                break\n\n        self.cleanup()\n\n    def _handle_client(self, conn: socket.socket):\n        self.last_activity = time.time()\n        try:\n            # Read line-based JSON\n            # For simplicity in this lean implementation, read one packet max 64k or use makefile\n            f = conn.makefile(\"r\")\n            line = f.readline()\n            if not line:\n                return\n\n            req = json.loads(line)\n            resp = self._process_request(req)\n\n            conn.sendall(json.dumps(resp).encode(\"utf-8\") + b\"\\n\")\n        except Exception as e:\n            err = {\"status\": \"error\", \"errors\": [{\"message\": str(e)}]}\n            try:\n                conn.sendall(json.dumps(err).encode(\"utf-8\") + b\"\\n\")\n            except Exception:\n                pass\n        finally:\n            conn.close()\n\n    def _process_request(self, req: Dict) -> Dict:\n        method = req.get(\"method\")\n        params = req.get(\"params\", {})\n\n        if method == \"status\":\n            return {\n                \"status\": \"ok\",\n                \"data\": {\"state\": self.lsp_client.state.value, \"pid\": os.getpid()},\n            }\n\n        elif method == \"did_open\":\n            path_str = params.get(\"path\")\n            content = params.get(\"content\")\n            if path_str and content:\n                self.lsp_client.did_open(Path(path_str), content)\n            return {\"status\": \"ok\"}\n\n        elif method == \"request\":\n            lsp_method = params.get(\"method\")\n            lsp_params = params.get(\"params\")\n            start_ns = time.perf_counter_ns()\n            result = self.lsp_client.request(lsp_method, lsp_params)\n            duration_ms = (time.perf_counter_ns() - start_ns) // 1_000_000\n\n            # Telemetry for requests\n            if self.telemetry:\n                x_fields = {\n                    \"method\": lsp_method,\n                    \"resolved\": bool(result),\n                }\n                # Extract target logic if hover/def\n                if result and \"contents\" in result:\n                    x_fields[\"target_file\"] = \"resolved_content\"  # simplified\n\n                self.telemetry.event(\n                    \"lsp.request\",\n                    {\"method\": lsp_method},\n                    {\"status\": \"ok\" if result else \"empty\"},\n                    max(1, duration_ms),\n                    **x_fields,\n                )\n\n            if result:\n                return {\"status\": \"ok\", \"data\": result}\n            else:\n                return {\"status\": \"error\", \"message\": \"LSP Timeout or Not Ready\"}\n\n        return {\"status\": \"error\", \"message\": \"Unknown method\"}\n\n    def _shutdown_signal(self, signum, frame):\n        self.running = False\n\n    def cleanup(self):\n        \"\"\"Clean up daemon resources on shutdown.\"\"\"\n        self.lsp_client.stop()\n        if self.socket_path.exists():\n            self.socket_path.unlink()\n        if self.pid_path.exists():\n            self.pid_path.unlink()\n        if self._lock_fp:\n            fcntl.lockf(self._lock_fp, fcntl.LOCK_UN)\n            self._lock_fp.close()\n            if self.lock_path.exists():\n                self.lock_path.unlink()\n\n\nclass LSPDaemonClient:\n    def __init__(self, root: Path):\n        self.root = resolve_segment_root(root)\n        self.segment_id = compute_segment_id(self.root)\n\n        # Use short paths from daemon_paths\n        self.socket_path = get_daemon_socket_path(self.segment_id)\n        self.lock_path = get_daemon_lock_path(self.segment_id)\n        self.pid_path = get_daemon_pid_path(self.segment_id)\n\n    def connect_or_spawn(self) -> bool:\n        \"\"\"Returns True if connected/spawned, False if error.\"\"\"\n        if self._try_connect():\n            return True\n\n        return self._spawn_daemon()\n\n    def _try_connect(self) -> bool:\n        if not self.socket_path.exists():\n            return False\n        try:\n            s = socket.socket(socket.AF_UNIX, socket.SOCK_STREAM)\n            s.connect(str(self.socket_path))\n            s.close()\n            return True\n        except Exception:\n            return False\n\n    def _spawn_daemon(self) -> bool:\n        try:\n            # We must use sys.executable to ensure we use the same venv\n            cmd = [\n                sys.executable,\n                \"-m\",\n                \"src.infrastructure.lsp_daemon\",\n                \"start\",\n                \"--root\",\n                str(self.root),\n            ]\n            subprocess.Popen(\n                cmd,\n                cwd=str(self.root),\n                start_new_session=True,  # Detach\n                stdin=subprocess.DEVNULL,\n                stdout=subprocess.DEVNULL,\n                stderr=subprocess.DEVNULL,\n            )\n            # We don't wait. We just return. Future cmds will connect.\n            return True\n        except Exception:\n            return False\n\n    def send(self, req: Dict) -> Dict:\n        s = socket.socket(socket.AF_UNIX, socket.SOCK_STREAM)\n        try:\n            s.connect(str(self.socket_path))\n            s.sendall(json.dumps(req).encode(\"utf-8\") + b\"\\n\")\n            f = s.makefile(\"r\")\n            line = f.readline()\n            if line:\n                return json.loads(line)  # type: ignore[no-any-return]\n        except Exception:\n            return {\"status\": \"error\", \"message\": \"Connection Failed\"}\n        finally:\n            s.close()\n        return {\"status\": \"error\", \"message\": \"Empty response\"}\n\n    def is_ready(self) -> bool:\n        resp = self.send({\"method\": \"status\"})\n        return resp.get(\"data\", {}).get(\"state\") == \"READY\"  # type: ignore[no-any-return]\n\n    def request(self, method: str, params: Dict) -> Optional[Dict]:\n        resp = self.send({\"method\": \"request\", \"params\": {\"method\": method, \"params\": params}})\n        if resp.get(\"status\") == \"ok\":\n            return resp.get(\"data\")\n        return None\n\n\n# Define DEFAULT_TTL before its usage in the argument parser\nDEFAULT_TTL = 300  # Default TTL in seconds\n\n# Entrypoint\nif __name__ == \"__main__\":\n    import argparse\n    import os\n\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\"command\", choices=[\"start\"])\n    parser.add_argument(\"--root\", required=True)\n    parser.add_argument(\n        \"--ttl\", type=int, default=int(os.environ.get(\"LSP_DAEMON_TTL_SEC\", DEFAULT_TTL))\n    )\n    args = parser.parse_args()\n\n    if args.command == \"start\":\n        server = LSPDaemonServer(Path(args.root), ttl_sec=args.ttl)\n        server.start()\n",
-      "char_count": 9381,
-      "token_est": 2345,
+      "text": "import os\nimport sys\nimport socket\nimport time\nimport json\nimport signal\nimport fcntl\nimport subprocess\nfrom pathlib import Path\nfrom typing import Any, Optional, Dict\nfrom src.infrastructure.lsp_client import LSPClient\nfrom src.infrastructure.telemetry import Telemetry\nfrom src.infrastructure.segment_utils import resolve_segment_root, compute_segment_id\nfrom src.infrastructure.daemon_paths import (\n    get_daemon_socket_path,\n    get_daemon_lock_path,\n    get_daemon_pid_path,\n)\n\n# --- Constants ---\nDEFAULT_TTL = 180\n\n\nclass LSPDaemonServer:\n    def __init__(self, segment_root: Path, ttl_sec: int = DEFAULT_TTL):\n        self.root = resolve_segment_root(segment_root)\n        self.ttl = ttl_sec\n        self.last_activity = time.time()\n        self.running = False\n\n        # Unified Segment ID / Dir\n        self.segment_id = compute_segment_id(self.root)\n\n        # Use short paths from daemon_paths to avoid AF_UNIX limit\n        self.socket_path = get_daemon_socket_path(self.segment_id)\n        self.lock_path = get_daemon_lock_path(self.segment_id)\n        self.pid_path = get_daemon_pid_path(self.segment_id)\n\n        self.telemetry = Telemetry(self.root)\n        self.lsp_client = LSPClient(self.root, self.telemetry)\n\n        self._lock_fp: Any = None\n\n    def start(self):\n        \"\"\"Main Daemon Entrypoint\"\"\"\n        # 1. Acquire Lock\n        self._lock_fp = open(self.lock_path, \"w\")\n        try:\n            fcntl.lockf(self._lock_fp, fcntl.LOCK_EX | fcntl.LOCK_NB)\n        except IOError:\n            sys.stdout.write(\"Daemon already running.\\n\")\n            return\n\n        # 2. Write PID\n        self.pid_path.write_text(str(os.getpid()))\n\n        # 3. Setup Socket\n        if self.socket_path.exists():\n            self.socket_path.unlink()\n\n        server = socket.socket(socket.AF_UNIX, socket.SOCK_STREAM)\n        server.bind(str(self.socket_path))\n        server.listen(1)\n        server.settimeout(1.0)  # Check TTL every second\n\n        self.running = True\n\n        # 4. Start LSP Client\n        self.lsp_client.start()\n\n        # 5. Signal Handling\n        signal.signal(signal.SIGTERM, self._shutdown_signal)\n        signal.signal(signal.SIGINT, self._shutdown_signal)\n\n        # 6. Event Loop\n        while self.running:\n            try:\n                # Check TTL\n                if time.time() - self.last_activity > self.ttl:\n                    self.telemetry.event(\"lsp.daemon_status\", {}, {\"status\": \"shutdown_ttl\"}, 1)\n                    break\n\n                try:\n                    conn, _ = server.accept()\n                    conn.settimeout(None)  # Disable inherited timeout\n                    self._handle_client(conn)\n                except socket.timeout:\n                    continue  # Loop to check activity/TTL\n            except Exception as e:\n                self.telemetry.event(\n                    \"lsp.daemon_status\", {}, {\"status\": \"error\", \"error\": str(e)}, 1\n                )\n                break\n\n        self.cleanup()\n\n    def _handle_client(self, conn: socket.socket):\n        self.last_activity = time.time()\n        try:\n            # Read line-based JSON\n            # For simplicity in this lean implementation, read one packet max 64k or use makefile\n            f = conn.makefile(\"r\")\n            line = f.readline()\n            if not line:\n                return\n\n            req = json.loads(line)\n            resp = self._process_request(req)\n\n            conn.sendall(json.dumps(resp).encode(\"utf-8\") + b\"\\n\")\n        except Exception as e:\n            err = {\"status\": \"error\", \"errors\": [{\"message\": str(e)}]}\n            try:\n                conn.sendall(json.dumps(err).encode(\"utf-8\") + b\"\\n\")\n            except Exception:\n                pass\n        finally:\n            conn.close()\n\n    def _process_request(self, req: Dict) -> Dict:\n        method = req.get(\"method\")\n        params = req.get(\"params\", {})\n\n        if method == \"status\":\n            return {\n                \"status\": \"ok\",\n                \"data\": {\"state\": self.lsp_client.state.value, \"pid\": os.getpid()},\n            }\n\n        elif method == \"did_open\":\n            path_str = params.get(\"path\")\n            content = params.get(\"content\")\n            if path_str and content:\n                self.lsp_client.did_open(Path(path_str), content)\n            return {\"status\": \"ok\"}\n\n        elif method == \"request\":\n            lsp_method = params.get(\"method\")\n            lsp_params = params.get(\"params\")\n            start_ns = time.perf_counter_ns()\n            result = self.lsp_client.request(lsp_method, lsp_params)\n            duration_ms = (time.perf_counter_ns() - start_ns) // 1_000_000\n\n            # Telemetry for requests\n            if self.telemetry:\n                x_fields = {\n                    \"method\": lsp_method,\n                    \"resolved\": bool(result),\n                }\n                # Extract target logic if hover/def\n                if result and \"contents\" in result:\n                    x_fields[\"target_file\"] = \"resolved_content\"  # simplified\n\n                self.telemetry.event(\n                    \"lsp.request\",\n                    {\"method\": lsp_method},\n                    {\"status\": \"ok\" if result else \"empty\"},\n                    max(1, duration_ms),\n                    **x_fields,\n                )\n\n            if result:\n                return {\"status\": \"ok\", \"data\": result}\n            else:\n                return {\"status\": \"error\", \"message\": \"LSP Timeout or Not Ready\"}\n\n        return {\"status\": \"error\", \"message\": \"Unknown method\"}\n\n    def _shutdown_signal(self, signum, frame):\n        self.running = False\n\n    def cleanup(self):\n        \"\"\"Clean up daemon resources on shutdown.\"\"\"\n        self.lsp_client.stop()\n        if self.socket_path.exists():\n            self.socket_path.unlink()\n        if self.pid_path.exists():\n            self.pid_path.unlink()\n        if self._lock_fp:\n            fcntl.lockf(self._lock_fp, fcntl.LOCK_UN)\n            self._lock_fp.close()\n            if self.lock_path.exists():\n                self.lock_path.unlink()\n\n\nclass LSPDaemonClient:\n    def __init__(self, root: Path):\n        self.root = resolve_segment_root(root)\n        self.segment_id = compute_segment_id(self.root)\n\n        # Use short paths from daemon_paths\n        self.socket_path = get_daemon_socket_path(self.segment_id)\n        self.lock_path = get_daemon_lock_path(self.segment_id)\n        self.pid_path = get_daemon_pid_path(self.segment_id)\n\n    def connect_or_spawn(self) -> bool:\n        \"\"\"Returns True if connected/spawned, False if error.\"\"\"\n        if self._try_connect():\n            return True\n\n        return self._spawn_daemon()\n\n    def _try_connect(self) -> bool:\n        if not self.socket_path.exists():\n            return False\n        try:\n            s = socket.socket(socket.AF_UNIX, socket.SOCK_STREAM)\n            s.connect(str(self.socket_path))\n            s.close()\n            return True\n        except Exception:\n            return False\n\n    def _spawn_daemon(self) -> bool:\n        try:\n            # We must use sys.executable to ensure we use the same venv\n            cmd = [\n                sys.executable,\n                \"-m\",\n                \"src.infrastructure.lsp_daemon\",\n                \"start\",\n                \"--root\",\n                str(self.root),\n            ]\n            subprocess.Popen(\n                cmd,\n                cwd=str(self.root),\n                start_new_session=True,  # Detach\n                stdin=subprocess.DEVNULL,\n                stdout=subprocess.DEVNULL,\n                stderr=subprocess.DEVNULL,\n            )\n            # We don't wait. We just return. Future cmds will connect.\n            return True\n        except Exception:\n            return False\n\n    def send(self, req: Dict) -> Dict:\n        s = socket.socket(socket.AF_UNIX, socket.SOCK_STREAM)\n        try:\n            s.connect(str(self.socket_path))\n            s.sendall(json.dumps(req).encode(\"utf-8\") + b\"\\n\")\n            f = s.makefile(\"r\")\n            line = f.readline()\n            if line:\n                return json.loads(line)  # type: ignore[no-any-return]\n        except Exception:\n            return {\"status\": \"error\", \"message\": \"Connection Failed\"}\n        finally:\n            s.close()\n        return {\"status\": \"error\", \"message\": \"Empty response\"}\n\n    def is_ready(self) -> bool:\n        resp = self.send({\"method\": \"status\"})\n        return resp.get(\"data\", {}).get(\"state\") == \"READY\"  # type: ignore[no-any-return]\n\n    def request(self, method: str, params: Dict) -> Optional[Dict]:\n        resp = self.send({\"method\": \"request\", \"params\": {\"method\": method, \"params\": params}})\n        if resp.get(\"status\") == \"ok\":\n            return resp.get(\"data\")\n        return None\n\n\n# Define DEFAULT_TTL before its usage in the argument parser\nDEFAULT_TTL = 300  # Default TTL in seconds\n\n# Entrypoint\nif __name__ == \"__main__\":\n    import argparse\n    import os\n\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\"command\", choices=[\"start\"])\n    parser.add_argument(\"--root\", required=True)\n    parser.add_argument(\n        \"--ttl\", type=int, default=int(os.environ.get(\"LSP_DAEMON_TTL_SEC\", DEFAULT_TTL))\n    )\n    args = parser.parse_args()\n\n    if args.command == \"start\":\n        server = LSPDaemonServer(Path(args.root), ttl_sec=args.ttl)\n        server.start()\n",
+      "char_count": 9394,
+      "token_est": 2348,
       "source_path": "lsp_daemon.py",
       "chunking_method": "whole_file"
     },
     {
-      "id": "repo:src/infrastructure/cli_ast.py:2e4eab4aa4",
+      "id": "repo:src/infrastructure/cli_ast.py:fbed31ac9b",
       "doc": "repo:src/infrastructure/cli_ast.py",
       "title_path": [
         "cli_ast.py"
       ],
-      "text": "import typer  # type: ignore\nimport time\nimport json\nfrom pathlib import Path\nfrom typing import Optional\nfrom src.infrastructure.telemetry import Telemetry\nfrom src.domain.result import Ok, Err\nfrom src.application.symbol_selector import SymbolQuery\nfrom src.application.ast_parser import SkeletonMapBuilder, ParseResult\nfrom src.domain.ast_cache import SQLiteCache\nfrom src.infrastructure.factories import get_ast_cache\n\nast_app = typer.Typer(help=\"AST & Parsing Commands\")\n\n\ndef _json_output(data: dict):\n    print(json.dumps(data, indent=2))\n\n\ndef _get_telemetry(level: str = \"lite\") -> Optional[Telemetry]:\n    if level == \"off\":\n        return None\n    return Telemetry(Path.cwd(), level=level)\n\n\nCACHE_DIR_NAME = \".trifecta\"\n\n\n# removed local _get_cache in favor of factory\n\n\n@ast_app.command(\"symbols\")\ndef symbols(\n    uri: str = typer.Argument(..., help=\"sym://python/mod|type/...\"),\n    segment: str = typer.Option(\".\", \"--segment\"),\n    telemetry_level: str = typer.Option(\"off\", \"--telemetry\"),\n    persist_cache: bool = typer.Option(\n        False, \"--persist-cache\", help=\"Use persistent SQLite cache\"\n    ),\n):\n    \"\"\"Return symbols from Python modules using AST parsing (M1).\"\"\"\n    root = Path(segment).resolve()\n    telemetry = _get_telemetry(telemetry_level)\n    cache = get_ast_cache(persist=persist_cache, segment_id=str(root), telemetry=telemetry)\n\n    try:\n        # 1. Parse URI\n        match SymbolQuery.parse(uri):\n            case Err(e):\n                _json_output({\"status\": \"error\", \"error_code\": e.code, \"message\": e.message})\n                raise typer.Exit(1)\n            case Ok(q):\n                query = q\n            case _:\n                _json_output(\n                    {\n                        \"status\": \"error\",\n                        \"error_code\": \"PARSE_ERROR\",\n                        \"message\": \"Failed to parse URI\",\n                    }\n                )\n                raise typer.Exit(1)\n\n        # 2. Resolve file_path (lean, fail-closed)\n        path_as_dir = query.path.replace(\".\", \"/\")\n        candidate_file = root / f\"{path_as_dir}.py\"\n        candidate_init = root / path_as_dir / \"__init__.py\"\n\n        if candidate_file.exists() and candidate_file.is_file():\n            file_path = candidate_file\n        elif candidate_init.exists() and candidate_init.is_file():\n            file_path = candidate_init\n        else:\n            _json_output(\n                {\n                    \"status\": \"error\",\n                    \"error_code\": \"FILE_NOT_FOUND\",\n                    \"message\": f\"Could not find module for {query.path}\",\n                }\n            )\n            raise typer.Exit(1)\n\n        # 3. Invoke SkeletonMapBuilder with cache (M1 REAL)\n        t0 = time.perf_counter_ns()\n        builder = SkeletonMapBuilder(cache=cache, segment_id=str(root))\n        result: ParseResult = builder.build(file_path)\n        duration_ms = max(1, (time.perf_counter_ns() - t0) // 1_000_000)\n\n        # 4. Return JSON (M1 Contract) with cache info\n        output = {\n            \"status\": \"ok\",\n            \"segment_root\": str(root),\n            \"file_rel\": str(file_path.relative_to(root)),\n            \"symbols\": [\n                {\"kind\": s.kind, \"name\": s.name, \"line\": s.start_line} for s in result.symbols\n            ],\n            \"cache_status\": result.status,\n            \"cache_key\": result.cache_key,\n        }\n\n        if telemetry:\n            telemetry.event(\n                \"ast.symbols\",\n                {},\n                {\"status\": \"ok\"},\n                duration_ms,\n                file=str(file_path.relative_to(root)),\n                symbols_count=len(result.symbols),\n                cache_status=result.status,\n                cache_key=result.cache_key,\n            )\n            telemetry.flush()\n\n        _json_output(output)\n\n    except typer.Exit:\n        raise\n    except Exception as e:\n        _json_output({\"status\": \"error\", \"error_code\": \"INTERNAL_ERROR\", \"message\": str(e)})\n        raise typer.Exit(1)\n\n\n@ast_app.command(\"snippet\")\ndef snippet(uri: str = typer.Argument(...)):\n    pass  # Minimal stub\n\n\n@ast_app.command(\"hover\")\ndef hover(\n    uri: str = typer.Argument(..., help=\"File path to hover over\"),\n    line: int = typer.Option(..., \"--line\", \"-l\"),\n    character: int = typer.Option(..., \"--char\", \"-c\"),\n    segment: str = typer.Option(\".\", \"--segment\"),\n):\n    \"\"\"[WIP] LSP Hover request.\"\"\"\n    # Stub for now\n    _json_output(\n        {\n            \"status\": \"ok\",\n            \"kind\": \"skeleton\",\n            \"data\": {\"uri\": uri, \"range\": {\"start_line\": 1, \"end_line\": 10}, \"children\": []},\n        }\n    )\n\n\n@ast_app.command(\"clear-cache\")\ndef clear_cache(\n    segment: str = typer.Option(\".\", \"--segment\"),\n):\n    \"\"\"Clear AST cache for the segment.\"\"\"\n    root = Path(segment).resolve()\n    cache_dir = Path.cwd() / CACHE_DIR_NAME / \"cache\"\n    cache_path = cache_dir / f\"ast_cache_{str(root).replace('/', '_')}.db\"\n\n    if cache_path.exists():\n        cache_path.unlink()\n        _json_output(\n            {\n                \"status\": \"ok\",\n                \"message\": f\"Cache cleared for segment: {segment}\",\n                \"cache_path\": str(cache_path),\n            }\n        )\n    else:\n        _json_output(\n            {\n                \"status\": \"ok\",\n                \"message\": f\"No cache found for segment: {segment}\",\n                \"cache_path\": str(cache_path),\n            }\n        )\n\n\n@ast_app.command(\"cache-stats\")\ndef cache_stats(\n    segment: str = typer.Option(\".\", \"--segment\"),\n):\n    \"\"\"Show AST cache statistics for the segment.\"\"\"\n    root = Path(segment).resolve()\n    cache_dir = Path.cwd() / CACHE_DIR_NAME / \"cache\"\n    db_path = cache_dir / f\"ast_cache_{str(root).replace('/', '_')}.db\"\n\n    if db_path.exists():\n        cache = SQLiteCache(db_path=db_path)\n        stats = cache.stats()\n        _json_output(\n            {\n                \"status\": \"ok\",\n                \"segment\": segment,\n                \"cache_path\": str(db_path),\n                \"stats\": {\n                    \"entries\": stats.entries,\n                    \"bytes\": stats.current_bytes,\n                    \"hits\": stats.hits,\n                    \"misses\": stats.misses,\n                    \"hit_rate\": f\"{stats.hit_rate:.2%}\"\n                    if stats.hits + stats.misses > 0\n                    else \"0.00%\",\n                },\n            }\n        )\n    else:\n        _json_output(\n            {\n                \"status\": \"ok\",\n                \"segment\": segment,\n                \"cache_path\": str(db_path),\n                \"message\": \"No cache found (cache not initialized)\",\n            }\n        )\n",
-      "char_count": 6636,
-      "token_est": 1659,
+      "text": "import typer  # type: ignore\nimport time\nimport json\nfrom pathlib import Path\nfrom typing import Optional\nfrom src.infrastructure.telemetry import Telemetry\nfrom src.domain.result import Ok, Err\nfrom src.application.symbol_selector import SymbolQuery\nfrom src.application.ast_parser import SkeletonMapBuilder, ParseResult\nfrom src.domain.ast_cache import SQLiteCache\nfrom src.infrastructure.factories import get_ast_cache\n\nast_app = typer.Typer(help=\"AST & Parsing Commands\")\n\n\ndef _json_output(data: dict):\n    typer.echo(json.dumps(data, indent=2))\n\n\ndef _get_telemetry(level: str = \"lite\") -> Optional[Telemetry]:\n    if level == \"off\":\n        return None\n    return Telemetry(Path.cwd(), level=level)\n\n\nCACHE_DIR_NAME = \".trifecta\"\n\n\n# removed local _get_cache in favor of factory\n\n\n@ast_app.command(\"symbols\")\ndef symbols(\n    uri: str = typer.Argument(..., help=\"sym://python/mod|type/...\"),\n    segment: str = typer.Option(\".\", \"--segment\"),\n    telemetry_level: str = typer.Option(\"off\", \"--telemetry\"),\n    persist_cache: bool = typer.Option(\n        False, \"--persist-cache\", help=\"Use persistent SQLite cache\"\n    ),\n):\n    \"\"\"Return symbols from Python modules using AST parsing (M1).\"\"\"\n    root = Path(segment).resolve()\n    telemetry = _get_telemetry(telemetry_level)\n    cache = get_ast_cache(persist=persist_cache, segment_id=str(root), telemetry=telemetry)\n\n    try:\n        # 1. Parse URI\n        match SymbolQuery.parse(uri):\n            case Err(e):\n                _json_output({\"status\": \"error\", \"error_code\": e.code, \"message\": e.message})\n                raise typer.Exit(1)\n            case Ok(q):\n                query = q\n            case _:\n                _json_output(\n                    {\n                        \"status\": \"error\",\n                        \"error_code\": \"PARSE_ERROR\",\n                        \"message\": \"Failed to parse URI\",\n                    }\n                )\n                raise typer.Exit(1)\n\n        # 2. Resolve file_path (lean, fail-closed)\n        path_as_dir = query.path.replace(\".\", \"/\")\n        candidate_file = root / f\"{path_as_dir}.py\"\n        candidate_init = root / path_as_dir / \"__init__.py\"\n\n        if candidate_file.exists() and candidate_file.is_file():\n            file_path = candidate_file\n        elif candidate_init.exists() and candidate_init.is_file():\n            file_path = candidate_init\n        else:\n            _json_output(\n                {\n                    \"status\": \"error\",\n                    \"error_code\": \"FILE_NOT_FOUND\",\n                    \"message\": f\"Could not find module for {query.path}\",\n                }\n            )\n            raise typer.Exit(1)\n\n        # 3. Invoke SkeletonMapBuilder with cache (M1 REAL)\n        t0 = time.perf_counter_ns()\n        builder = SkeletonMapBuilder(cache=cache, segment_id=str(root))\n        result: ParseResult = builder.build(file_path)\n        duration_ms = max(1, (time.perf_counter_ns() - t0) // 1_000_000)\n\n        # 4. Return JSON (M1 Contract) with cache info\n        output = {\n            \"status\": \"ok\",\n            \"segment_root\": str(root),\n            \"file_rel\": str(file_path.relative_to(root)),\n            \"symbols\": [\n                {\"kind\": s.kind, \"name\": s.name, \"line\": s.start_line} for s in result.symbols\n            ],\n            \"cache_status\": result.status,\n            \"cache_key\": result.cache_key,\n        }\n\n        if telemetry:\n            telemetry.event(\n                \"ast.symbols\",\n                {},\n                {\"status\": \"ok\"},\n                duration_ms,\n                file=str(file_path.relative_to(root)),\n                symbols_count=len(result.symbols),\n                cache_status=result.status,\n                cache_key=result.cache_key,\n            )\n            telemetry.flush()\n\n        _json_output(output)\n\n    except typer.Exit:\n        raise\n    except Exception as e:\n        _json_output({\"status\": \"error\", \"error_code\": \"INTERNAL_ERROR\", \"message\": str(e)})\n        raise typer.Exit(1)\n\n\n@ast_app.command(\"snippet\")\ndef snippet(uri: str = typer.Argument(...)):\n    pass  # Minimal stub\n\n\n@ast_app.command(\"hover\")\ndef hover(\n    uri: str = typer.Argument(..., help=\"File path to hover over\"),\n    line: int = typer.Option(..., \"--line\", \"-l\"),\n    character: int = typer.Option(..., \"--char\", \"-c\"),\n    segment: str = typer.Option(\".\", \"--segment\"),\n):\n    \"\"\"[WIP] LSP Hover request.\"\"\"\n    # Stub for now\n    _json_output(\n        {\n            \"status\": \"ok\",\n            \"kind\": \"skeleton\",\n            \"data\": {\"uri\": uri, \"range\": {\"start_line\": 1, \"end_line\": 10}, \"children\": []},\n        }\n    )\n\n\n@ast_app.command(\"clear-cache\")\ndef clear_cache(\n    segment: str = typer.Option(\".\", \"--segment\"),\n):\n    \"\"\"Clear AST cache for the segment.\"\"\"\n    root = Path(segment).resolve()\n    cache_dir = Path.cwd() / CACHE_DIR_NAME / \"cache\"\n    cache_path = cache_dir / f\"ast_cache_{str(root).replace('/', '_')}.db\"\n\n    if cache_path.exists():\n        cache_path.unlink()\n        _json_output(\n            {\n                \"status\": \"ok\",\n                \"message\": f\"Cache cleared for segment: {segment}\",\n                \"cache_path\": str(cache_path),\n            }\n        )\n    else:\n        _json_output(\n            {\n                \"status\": \"ok\",\n                \"message\": f\"No cache found for segment: {segment}\",\n                \"cache_path\": str(cache_path),\n            }\n        )\n\n\n@ast_app.command(\"cache-stats\")\ndef cache_stats(\n    segment: str = typer.Option(\".\", \"--segment\"),\n):\n    \"\"\"Show AST cache statistics for the segment.\"\"\"\n    root = Path(segment).resolve()\n    cache_dir = Path.cwd() / CACHE_DIR_NAME / \"cache\"\n    db_path = cache_dir / f\"ast_cache_{str(root).replace('/', '_')}.db\"\n\n    if db_path.exists():\n        cache = SQLiteCache(db_path=db_path)\n        stats = cache.stats()\n        _json_output(\n            {\n                \"status\": \"ok\",\n                \"segment\": segment,\n                \"cache_path\": str(db_path),\n                \"stats\": {\n                    \"entries\": stats.entries,\n                    \"bytes\": stats.current_bytes,\n                    \"hits\": stats.hits,\n                    \"misses\": stats.misses,\n                    \"hit_rate\": f\"{stats.hit_rate:.2%}\"\n                    if stats.hits + stats.misses > 0\n                    else \"0.00%\",\n                },\n            }\n        )\n    else:\n        _json_output(\n            {\n                \"status\": \"ok\",\n                \"segment\": segment,\n                \"cache_path\": str(db_path),\n                \"message\": \"No cache found (cache not initialized)\",\n            }\n        )\n",
+      "char_count": 6641,
+      "token_est": 1660,
       "source_path": "cli_ast.py",
       "chunking_method": "whole_file"
     },
     {
-      "id": "repo:src/infrastructure/file_locked_cache.py:25e018095e",
+      "id": "repo:src/infrastructure/file_locked_cache.py:719f157fa6",
       "doc": "repo:src/infrastructure/file_locked_cache.py",
       "title_path": [
         "file_locked_cache.py"
       ],
-      "text": "\"\"\"\nFile-locked wrapper for AstCache.\n\nThis wrapper adds deterministic file locking around any AstCache implementation\nwithout modifying the underlying cache. Keeps OS concerns in infrastructure layer.\n\"\"\"\n\nfrom typing import Any, Optional, TYPE_CHECKING\nfrom pathlib import Path\nimport time\n\nif TYPE_CHECKING:\n    from src.domain.ast_cache import AstCache, CacheStats\n    from src.infrastructure.telemetry import Telemetry\n\n\nclass FileLockedAstCache:\n    \"\"\"\n    Wrapper that adds file locking to any AstCache implementation.\n\n    Value:\n    - Deterministic timeout (no random OperationalError)\n    - Telemetry on lock contention\n    - Explicit control when daemon+CLI compete\n    \"\"\"\n\n    def __init__(\n        self,\n        inner: \"AstCache\",\n        lock_path: Path,\n        telemetry: Optional[\"Telemetry\"] = None,\n        timeout: float = 2.0,\n    ):\n        \"\"\"\n        Initialize file-locked cache wrapper.\n\n        Args:\n            inner: The underlying cache implementation\n            lock_path: Path to lock file (e.g., db_path.with_suffix('.lock'))\n            telemetry: Optional telemetry for contention events\n            timeout: Timeout in seconds for lock acquisition (default: 2s)\n        \"\"\"\n        self._inner = inner\n        self._lock_path = lock_path\n        self._telemetry = telemetry\n        self._timeout = timeout\n\n    def _with_lock(self, operation: str, func):\n        \"\"\"\n        Execute function with file lock held.\n\n        Args:\n            operation: Name of operation (for telemetry/errors)\n            func: Function to execute under lock\n\n        Raises:\n            RuntimeError: If lock cannot be acquired within timeout\n        \"\"\"\n        from filelock import FileLock, Timeout as LockTimeout\n\n        lock = FileLock(str(self._lock_path), timeout=self._timeout)\n        t0 = time.perf_counter_ns()\n\n        try:\n            with lock:\n                return func()\n        except LockTimeout as e:\n            wait_ms = (time.perf_counter_ns() - t0) // 1_000_000\n\n            if self._telemetry:\n                self._telemetry.event(\n                    cmd=\"ast.cache.lock_timeout\",\n                    args={\"operation\": operation},\n                    result={\"lock_path\": str(self._lock_path), \"timeout_sec\": self._timeout},\n                    timing_ms=wait_ms,\n                )\n\n            raise RuntimeError(\n                f\"Could not acquire cache lock for '{operation}' after {self._timeout}s. \"\n                f\"Another process is using the cache.\"\n            ) from e\n        finally:\n            # Emit lock wait time if telemetry available (even on success)\n            if self._telemetry:\n                wait_ms = (time.perf_counter_ns() - t0) // 1_000_000\n                if wait_ms > 10:  # Only log if wait was non-trivial\n                    self._telemetry.event(\n                        cmd=\"ast.cache.lock_wait\",\n                        args={\"operation\": operation},\n                        result={\"lock_path\": str(self._lock_path)},\n                        timing_ms=wait_ms,\n                    )\n\n    def get(self, key: str) -> Optional[Any]:\n        \"\"\"Get value from cache with file lock.\"\"\"\n        return self._with_lock(\"get\", lambda: self._inner.get(key))\n\n    def set(self, key: str, value: Any) -> None:\n        \"\"\"Set value in cache with file lock.\"\"\"\n        self._with_lock(\"set\", lambda: self._inner.set(key, value))\n\n    def delete(self, key: str) -> bool:\n        \"\"\"Delete value from cache with file lock.\"\"\"\n        return self._with_lock(\"delete\", lambda: self._inner.delete(key))\n\n    def clear(self) -> None:\n        \"\"\"Clear cache with file lock.\"\"\"\n        self._with_lock(\"clear\", lambda: self._inner.clear())\n\n    def stats(self) -> \"CacheStats\":\n        \"\"\"Get cache stats (no lock needed - read-only metadata).\"\"\"\n        return self._inner.stats()\n",
-      "char_count": 3857,
-      "token_est": 964,
+      "text": "\"\"\"\nFile-locked wrapper for AstCache.\n\nThis wrapper adds deterministic file locking around any AstCache implementation\nwithout modifying the underlying cache. Keeps OS concerns in infrastructure layer.\n\"\"\"\n\nfrom typing import Any, Optional, TYPE_CHECKING, Callable, TypeVar\nfrom pathlib import Path\nimport time\n\nT = TypeVar(\"T\")\n\nif TYPE_CHECKING:\n    from src.domain.ast_cache import AstCache, CacheStats\n    from src.infrastructure.telemetry import Telemetry\n\n\nclass FileLockedAstCache:\n    \"\"\"\n    Wrapper that adds file locking to any AstCache implementation.\n\n    Value:\n    - Deterministic timeout (no random OperationalError)\n    - Telemetry on lock contention\n    - Explicit control when daemon+CLI compete\n    \"\"\"\n\n    def __init__(\n        self,\n        inner: \"AstCache\",\n        lock_path: Path,\n        telemetry: Optional[\"Telemetry\"] = None,\n        timeout: float = 2.0,\n    ):\n        \"\"\"\n        Initialize file-locked cache wrapper.\n\n        Args:\n            inner: The underlying cache implementation\n            lock_path: Path to lock file (e.g., db_path.with_suffix('.lock'))\n            telemetry: Optional telemetry for contention events\n            timeout: Timeout in seconds for lock acquisition (default: 2s)\n        \"\"\"\n        self._inner = inner\n        self._lock_path = lock_path\n        self._telemetry = telemetry\n        self._timeout = timeout\n\n    def _with_lock(self, operation: str, func: Callable[[], T]) -> T:\n        \"\"\"\n        Execute function with file lock held.\n\n        Args:\n            operation: Name of operation (for telemetry/errors)\n            func: Function to execute under lock\n\n        Raises:\n            RuntimeError: If lock cannot be acquired within timeout\n        \"\"\"\n        from filelock import FileLock, Timeout as LockTimeout\n\n        lock = FileLock(str(self._lock_path), timeout=self._timeout)\n        t0 = time.perf_counter_ns()\n\n        try:\n            with lock:\n                return func()\n        except LockTimeout as e:\n            wait_ms = (time.perf_counter_ns() - t0) // 1_000_000\n\n            if self._telemetry:\n                self._telemetry.event(\n                    cmd=\"ast.cache.lock_timeout\",\n                    args={\"operation\": operation},\n                    result={\"lock_path\": str(self._lock_path), \"timeout_sec\": self._timeout},\n                    timing_ms=wait_ms,\n                )\n\n            raise RuntimeError(\n                f\"Could not acquire cache lock for '{operation}' after {self._timeout}s. \"\n                f\"Another process is using the cache.\"\n            ) from e\n        finally:\n            # Emit lock wait time if telemetry available (even on success)\n            if self._telemetry:\n                wait_ms = (time.perf_counter_ns() - t0) // 1_000_000\n                if wait_ms > 10:  # Only log if wait was non-trivial\n                    self._telemetry.event(\n                        cmd=\"ast.cache.lock_wait\",\n                        args={\"operation\": operation},\n                        result={\"lock_path\": str(self._lock_path)},\n                        timing_ms=wait_ms,\n                    )\n\n    def get(self, key: str) -> Optional[Any]:\n        \"\"\"Get value from cache with file lock.\"\"\"\n        return self._with_lock(\"get\", lambda: self._inner.get(key))\n\n    def set(self, key: str, value: Any) -> None:\n        \"\"\"Set value in cache with file lock.\"\"\"\n        self._with_lock(\"set\", lambda: self._inner.set(key, value))\n\n    def delete(self, key: str) -> bool:\n        \"\"\"Delete value from cache with file lock.\"\"\"\n        return self._with_lock(\"delete\", lambda: self._inner.delete(key))\n\n    def clear(self) -> None:\n        \"\"\"Clear cache with file lock.\"\"\"\n        self._with_lock(\"clear\", lambda: self._inner.clear())\n\n    def stats(self) -> \"CacheStats\":\n        \"\"\"Get cache stats (no lock needed - read-only metadata).\"\"\"\n        return self._inner.stats()\n",
+      "char_count": 3916,
+      "token_est": 979,
       "source_path": "file_locked_cache.py",
       "chunking_method": "whole_file"
     },
@@ -4819,26 +5005,26 @@
       "chunking_method": "whole_file"
     },
     {
-      "id": "repo:src/infrastructure/lsp_client.py:896a0c5354",
+      "id": "repo:src/infrastructure/lsp_client.py:6a0a85882f",
       "doc": "repo:src/infrastructure/lsp_client.py",
       "title_path": [
         "lsp_client.py"
       ],
-      "text": "import subprocess\nimport json\nimport shutil\nimport threading\nimport os\nfrom typing import Optional, Dict, Any\nfrom enum import Enum\nfrom pathlib import Path\n\n\nclass LSPState(Enum):\n    COLD = \"COLD\"\n    WARMING = \"WARMING\"\n    READY = \"READY\"\n    FAILED = \"FAILED\"\n    CLOSED = \"CLOSED\"\n\n\nclass LSPClient:\n    def __init__(self, root_path: Path, telemetry: Any = None):\n        self.root_path = root_path\n        self.telemetry = telemetry\n        self.state = LSPState.COLD\n        self.process: Optional[subprocess.Popen[bytes]] = None\n        self.lock = threading.Lock()\n        self._stop_lock = threading.Lock()  # Separate lock for stop idempotency\n        self.stopping = threading.Event()\n        self._thread: Optional[threading.Thread] = None  # Track loop thread for join\n        self._capabilities: Dict[str, Any] = {}\n        self._warmup_file: Optional[Path] = None\n\n        # Request handling\n        self._next_id = 1000  # Avoid conflict with init id 1\n        self._pending_requests: Dict[int, Any] = {}\n        self._request_events: Dict[int, threading.Event] = {}\n\n    def start(self) -> None:\n        \"\"\"Start LSP server in background.\"\"\"\n        with self.lock:\n            if self.state != LSPState.COLD:\n                return\n\n            executable = shutil.which(\"pylsp\") or shutil.which(\"pyright-langserver\")\n            if not executable:\n                self._transition(LSPState.FAILED)\n                self._log_event(\n                    \"lsp.spawn\",\n                    {\"executable\": None},\n                    {\"status\": \"failed\", \"error\": \"binary_not_found\"},\n                    0,\n                )\n                return\n\n            try:\n                self._transition(LSPState.WARMING)\n                cmd = [executable]\n                if \"pyright\" in executable:\n                    cmd.append(\"--stdio\")\n\n                self.process = subprocess.Popen(\n                    cmd,\n                    stdin=subprocess.PIPE,\n                    stdout=subprocess.PIPE,\n                    stderr=subprocess.PIPE,\n                    text=False,\n                )\n\n                if self.telemetry:\n                    self.telemetry.incr(\"lsp_spawn_count\")\n\n                # Robust Sanitize\n                exe_log = \"unknown\"\n                try:\n                    if executable:\n                        exe_log = Path(executable).name\n                except Exception:\n                    pass\n\n                self._log_event(\n                    \"lsp.spawn\",\n                    {\"executable\": exe_log},\n                    {\"status\": \"ok\", \"pid\": self.process.pid},\n                    1,\n                )\n\n                # Start handshake + Read Loop (save thread reference for join)\n                self._thread = threading.Thread(target=self._run_loop, daemon=True)\n                self._thread.start()\n\n            except Exception as e:\n                self._transition(LSPState.FAILED)\n                if self.telemetry:\n                    self.telemetry.incr(\"lsp_failed_count\")\n\n                # Capture stderr for debug\n                err_out = \"Unknown\"\n                if self.process:\n                    try:\n                        _, stderr_data = self.process.communicate(timeout=0.2)\n                        if stderr_data:\n                            err_out = stderr_data.decode(\"utf-8\")\n                    except Exception:\n                        pass\n                print(f\"DEBUG: LSP Start Failed: {e}. Stderr: {err_out}\")\n\n                # Sanitize executable path for telemetry\n                exe_name = \"unknown\"\n                if executable:\n                    exe_name = Path(executable).name\n\n                self._log_event(\n                    \"lsp.spawn\", {\"executable\": exe_name}, {\"status\": \"error\", \"error\": str(e)}, 0\n                )\n\n    def stop(self) -> None:\n        \"\"\"Strict cleanup: signal -> terminate -> join thread -> close streams.\n\n        SHUTDOWN ORDER INVARIANT (do not reorder):\n          1. Set stopping flag (signal intent)\n          2. Terminate process\n          3. Join loop thread (wait for exit)\n          4. Close streams (only after thread exits)\n\n        Idempotent: safe to call multiple times.\n        \"\"\"\n        with self._stop_lock:\n            # 1. Signal threads first (defensive: stopping should only be set here)\n            if not self.stopping.is_set():\n                self.stopping.set()\n\n            # 2. Check/set state (idempotent)\n            with self.lock:\n                if self.state == LSPState.CLOSED:\n                    return\n                self.state = LSPState.CLOSED\n\n            # 3. Terminate process\n            if self.process:\n                try:\n                    self.process.terminate()\n                    try:\n                        self.process.wait(timeout=0.5)\n                    except subprocess.TimeoutExpired:\n                        self.process.kill()\n                        self.process.wait(timeout=0.2)\n                except Exception:\n                    pass  # Process might be gone\n\n            # 4. Join background thread BEFORE closing streams\n            # Increased timeout for CI stability (was 0.5s)\n            if self._thread and self._thread.is_alive():\n                self._thread.join(timeout=1.0)\n\n                # CRITICAL: If thread still alive after join, DO NOT close streams\n                # This avoids write-to-closed-file race in edge cases (blocked I/O)\n                # Better to leak streams in rare shutdown failure than reintroduce bug\n                if self._thread.is_alive():\n                    # Thread didn't terminate cleanly; leave streams open\n                    # Process is already terminated, thread will eventually exit on EOF\n                    return\n\n            # 5. Close streams ONLY after thread exits\n            if self.process:\n                try:\n                    if self.process.stdin:\n                        self.process.stdin.close()\n                    if self.process.stdout:\n                        self.process.stdout.close()\n                    if self.process.stderr:\n                        self.process.stderr.close()\n                except Exception:\n                    pass  # Already closed\n\n    def did_open(self, file_path: Path, content: str) -> None:\n        \"\"\"Notify file open to trigger diagnostics.\"\"\"\n        with self.lock:\n            if self.state == LSPState.CLOSED or not self.process:\n                return\n\n        self._warmup_file = file_path\n        msg = {\n            \"jsonrpc\": \"2.0\",\n            \"method\": \"textDocument/didOpen\",\n            \"params\": {\n                \"textDocument\": {\n                    \"uri\": file_path.as_uri(),\n                    \"languageId\": \"python\",\n                    \"version\": 1,\n                    \"text\": content,\n                }\n            },\n        }\n        self._send_rpc(msg)\n\n    def is_ready(self) -> bool:\n        return self.state == LSPState.READY\n\n    def _transition(self, new_state: LSPState) -> None:\n        self.state = new_state\n\n    def _log_event(\n        self, cmd: str, args: Dict[str, Any], result: Dict[str, Any], timing: int, **kwargs: Any\n    ) -> None:\n        if self.telemetry:\n            # kwargs are passed to event as x_fields\n            self.telemetry.event(cmd, args, result, timing, lsp_state=self.state.value, **kwargs)\n\n    def _run_loop(self) -> None:\n        \"\"\"Handshake + Read Loop.\"\"\"\n        try:\n            # 1. Initialize\n            req = {\n                \"jsonrpc\": \"2.0\",\n                \"id\": 1,\n                \"method\": \"initialize\",\n                \"params\": {\n                    \"processId\": os.getpid(),\n                    \"rootUri\": self.root_path.as_uri(),\n                    \"capabilities\": {},\n                },\n            }\n            self._send_rpc(req)\n\n            # 2. Wait for Response (blocking single read)\n            resp = self._read_rpc()\n            if not resp or \"result\" not in resp:\n                self._transition(LSPState.FAILED)\n                return\n\n            self._capabilities = resp[\"result\"].get(\"capabilities\", {})\n            self._send_rpc({\"jsonrpc\": \"2.0\", \"method\": \"initialized\", \"params\": {}})\n\n            # relaxed READY: Transition immediately to allow requests\n            with self.lock:\n                self._transition(LSPState.READY)\n\n            if self.telemetry:\n                self.telemetry.incr(\"lsp_ready_count\")\n                self._log_event(\n                    \"lsp.state_change\",\n                    {},\n                    {\"status\": \"ready\"},\n                    1,\n                    reason=\"initialized\",\n                )\n\n            # 3. Read Loop (Waiting for publishDiagnostics & Responses)\n            while self.state != LSPState.CLOSED:\n                msg = self._read_rpc()\n                if not msg:\n                    break  # EOF\n\n                # Handle Response\n                if \"id\" in msg and \"result\" in msg:\n                    req_id = msg[\"id\"]\n                    with self.lock:\n                        if req_id in self._pending_requests:\n                            self._pending_requests[req_id] = msg[\"result\"]\n                            self._request_events[req_id].set()\n\n                # Handle Notification\n                method = msg.get(\"method\", \"\")\n                if method == \"textDocument/publishDiagnostics\":\n                    # Log diagnostics but do not control state (already READY)\n                    pass\n        except Exception as e:\n            # If we're stopping, silently exit without printing debug messages\n            if self.stopping.is_set():\n                return\n\n            # Only log errors if NOT intentionally stopping\n            # Capture stderr\n            err_out = \"Unknown\"\n            if self.process:\n                try:\n                    _, stderr_data = self.process.communicate(timeout=0.2)\n                    if stderr_data:\n                        err_out = stderr_data.decode(\"utf-8\")\n                except Exception:\n                    pass\n            print(f\"DEBUG: LSP Loop Exception: {e}. Stderr: {err_out}\")\n            self._transition(LSPState.FAILED)\n\n    def request(\n        self, method: str, params: Dict[str, Any], timeout: float = 2.0\n    ) -> Optional[Dict[str, Any]]:\n        \"\"\"Send a request and wait for the response.\"\"\"\n        with self.lock:\n            if self.state != LSPState.READY:\n                return None\n\n            req_id = self._next_id\n            self._next_id += 1\n            event = threading.Event()\n            self._pending_requests[req_id] = None  # Placeholder\n            self._request_events[req_id] = event\n\n        msg = {\"jsonrpc\": \"2.0\", \"id\": req_id, \"method\": method, \"params\": params}\n        self._send_rpc(msg)\n\n        # Wait for response\n        if event.wait(timeout):\n            with self.lock:\n                result = self._pending_requests.pop(req_id, None)\n                self._request_events.pop(req_id, None)\n                # Type guard for mypy\n                return result if isinstance(result, dict) else None\n        else:\n            with self.lock:\n                self._pending_requests.pop(req_id, None)\n                self._request_events.pop(req_id, None)\n                return None  # Timeout\n\n    def _send_rpc(self, msg: Dict[str, Any]) -> None:\n        # Don't attempt writes if stopping\n        if self.stopping.is_set():\n            return\n        if not self.process or not self.process.stdin:\n            return\n        try:\n            content = json.dumps(msg).encode(\"utf-8\")\n            header = f\"Content-Length: {len(content)}\\r\\n\\r\\n\".encode(\"ascii\")\n            self.process.stdin.write(header + content)\n            self.process.stdin.flush()\n        except (OSError, ValueError, BrokenPipeError):\n            # Silently ignore write errors during shutdown\n            pass\n\n    def _read_rpc(self) -> Optional[Dict[str, Any]]:\n        if not self.process or not self.process.stdout:\n            return None\n        try:\n            # Read Headers\n            length = None\n            while True:\n                line = self.process.stdout.readline()\n                if not line:\n                    if length is None:\n                        # EOF before any headers\n                        return None\n                    # EOF inside headers? Break and try reading content?\n                    break\n\n                line = line.strip()\n                if not line:\n                    # End of headers\n                    break\n\n                if line.startswith(b\"Content-Length: \"):\n                    length = int(line.split(b\": \")[1])\n\n            if length is None:\n                return None\n\n            # Read Content\n            content = b\"\"\n            while len(content) < length:\n                chunk = self.process.stdout.read(length - len(content))\n                if not chunk:\n                    break\n                content += chunk\n\n            # Parse JSON\n            try:\n                msg = json.loads(content.decode(\"utf-8\"))\n                # Type guard for mypy\n                return msg if isinstance(msg, dict) else None\n            except json.JSONDecodeError:\n                return None\n        except Exception:\n            return None\n",
-      "char_count": 13342,
-      "token_est": 3335,
+      "text": "import subprocess\nimport json\nimport shutil\nimport threading\nimport os\nimport sys\nfrom typing import Optional, Dict, Any\nfrom enum import Enum\nfrom pathlib import Path\n\n\nclass LSPState(Enum):\n    COLD = \"COLD\"\n    WARMING = \"WARMING\"\n    READY = \"READY\"\n    FAILED = \"FAILED\"\n    CLOSED = \"CLOSED\"\n\n\nclass LSPClient:\n    def __init__(self, root_path: Path, telemetry: Any = None):\n        self.root_path = root_path\n        self.telemetry = telemetry\n        self.state = LSPState.COLD\n        self.process: Optional[subprocess.Popen[bytes]] = None\n        self.lock = threading.Lock()\n        self._stop_lock = threading.Lock()  # Separate lock for stop idempotency\n        self.stopping = threading.Event()\n        self._thread: Optional[threading.Thread] = None  # Track loop thread for join\n        self._capabilities: Dict[str, Any] = {}\n        self._warmup_file: Optional[Path] = None\n\n        # Request handling\n        self._next_id = 1000  # Avoid conflict with init id 1\n        self._pending_requests: Dict[int, Any] = {}\n        self._request_events: Dict[int, threading.Event] = {}\n\n    def start(self) -> None:\n        \"\"\"Start LSP server in background.\"\"\"\n        with self.lock:\n            if self.state != LSPState.COLD:\n                return\n\n            executable = shutil.which(\"pylsp\") or shutil.which(\"pyright-langserver\")\n            if not executable:\n                self._transition(LSPState.FAILED)\n                self._log_event(\n                    \"lsp.spawn\",\n                    {\"executable\": None},\n                    {\"status\": \"failed\", \"error\": \"binary_not_found\"},\n                    0,\n                )\n                return\n\n            try:\n                self._transition(LSPState.WARMING)\n                cmd = [executable]\n                if \"pyright\" in executable:\n                    cmd.append(\"--stdio\")\n\n                self.process = subprocess.Popen(\n                    cmd,\n                    stdin=subprocess.PIPE,\n                    stdout=subprocess.PIPE,\n                    stderr=subprocess.PIPE,\n                    text=False,\n                )\n\n                if self.telemetry:\n                    self.telemetry.incr(\"lsp_spawn_count\")\n\n                # Robust Sanitize\n                exe_log = \"unknown\"\n                try:\n                    if executable:\n                        exe_log = Path(executable).name\n                except Exception:\n                    pass\n\n                self._log_event(\n                    \"lsp.spawn\",\n                    {\"executable\": exe_log},\n                    {\"status\": \"ok\", \"pid\": self.process.pid},\n                    1,\n                )\n\n                # Start handshake + Read Loop (save thread reference for join)\n                self._thread = threading.Thread(target=self._run_loop, daemon=True)\n                self._thread.start()\n\n            except Exception as e:\n                self._transition(LSPState.FAILED)\n                if self.telemetry:\n                    self.telemetry.incr(\"lsp_failed_count\")\n\n                # Capture stderr for debug\n                err_out = \"Unknown\"\n                if self.process:\n                    try:\n                        _, stderr_data = self.process.communicate(timeout=0.2)\n                        if stderr_data:\n                            err_out = stderr_data.decode(\"utf-8\")\n                    except Exception:\n                        pass\n                sys.stderr.write(f\"DEBUG: LSP Start Failed: {e}. Stderr: {err_out}\\n\")\n\n                # Sanitize executable path for telemetry\n                exe_name = \"unknown\"\n                if executable:\n                    exe_name = Path(executable).name\n\n                self._log_event(\n                    \"lsp.spawn\", {\"executable\": exe_name}, {\"status\": \"error\", \"error\": str(e)}, 0\n                )\n\n    def stop(self) -> None:\n        \"\"\"Strict cleanup: signal -> terminate -> join thread -> close streams.\n\n        SHUTDOWN ORDER INVARIANT (do not reorder):\n          1. Set stopping flag (signal intent)\n          2. Terminate process\n          3. Join loop thread (wait for exit)\n          4. Close streams (only after thread exits)\n\n        Idempotent: safe to call multiple times.\n        \"\"\"\n        with self._stop_lock:\n            # 1. Signal threads first (defensive: stopping should only be set here)\n            if not self.stopping.is_set():\n                self.stopping.set()\n\n            # 2. Check/set state (idempotent)\n            with self.lock:\n                if self.state == LSPState.CLOSED:\n                    return\n                self.state = LSPState.CLOSED\n\n            # 3. Terminate process\n            if self.process:\n                try:\n                    self.process.terminate()\n                    try:\n                        self.process.wait(timeout=0.5)\n                    except subprocess.TimeoutExpired:\n                        self.process.kill()\n                        self.process.wait(timeout=0.2)\n                except Exception:\n                    pass  # Process might be gone\n\n            # 4. Join background thread BEFORE closing streams\n            # Increased timeout for CI stability (was 0.5s)\n            if self._thread and self._thread.is_alive():\n                self._thread.join(timeout=1.0)\n\n                # CRITICAL: If thread still alive after join, DO NOT close streams\n                # This avoids write-to-closed-file race in edge cases (blocked I/O)\n                # Better to leak streams in rare shutdown failure than reintroduce bug\n                if self._thread.is_alive():\n                    # Thread didn't terminate cleanly; leave streams open\n                    # Process is already terminated, thread will eventually exit on EOF\n                    return\n\n            # 5. Close streams ONLY after thread exits\n            if self.process:\n                try:\n                    if self.process.stdin:\n                        self.process.stdin.close()\n                    if self.process.stdout:\n                        self.process.stdout.close()\n                    if self.process.stderr:\n                        self.process.stderr.close()\n                except Exception:\n                    pass  # Already closed\n\n    def did_open(self, file_path: Path, content: str) -> None:\n        \"\"\"Notify file open to trigger diagnostics.\"\"\"\n        with self.lock:\n            if self.state == LSPState.CLOSED or not self.process:\n                return\n\n        self._warmup_file = file_path\n        msg = {\n            \"jsonrpc\": \"2.0\",\n            \"method\": \"textDocument/didOpen\",\n            \"params\": {\n                \"textDocument\": {\n                    \"uri\": file_path.as_uri(),\n                    \"languageId\": \"python\",\n                    \"version\": 1,\n                    \"text\": content,\n                }\n            },\n        }\n        self._send_rpc(msg)\n\n    def is_ready(self) -> bool:\n        return self.state == LSPState.READY\n\n    def _transition(self, new_state: LSPState) -> None:\n        self.state = new_state\n\n    def _log_event(\n        self, cmd: str, args: Dict[str, Any], result: Dict[str, Any], timing: int, **kwargs: Any\n    ) -> None:\n        if self.telemetry:\n            # kwargs are passed to event as x_fields\n            self.telemetry.event(cmd, args, result, timing, lsp_state=self.state.value, **kwargs)\n\n    def _run_loop(self) -> None:\n        \"\"\"Handshake + Read Loop.\"\"\"\n        try:\n            # 1. Initialize\n            req = {\n                \"jsonrpc\": \"2.0\",\n                \"id\": 1,\n                \"method\": \"initialize\",\n                \"params\": {\n                    \"processId\": os.getpid(),\n                    \"rootUri\": self.root_path.as_uri(),\n                    \"capabilities\": {},\n                },\n            }\n            self._send_rpc(req)\n\n            # 2. Wait for Response (blocking single read)\n            resp = self._read_rpc()\n            if not resp or \"result\" not in resp:\n                self._transition(LSPState.FAILED)\n                return\n\n            self._capabilities = resp[\"result\"].get(\"capabilities\", {})\n            self._send_rpc({\"jsonrpc\": \"2.0\", \"method\": \"initialized\", \"params\": {}})\n\n            # relaxed READY: Transition immediately to allow requests\n            with self.lock:\n                self._transition(LSPState.READY)\n\n            if self.telemetry:\n                self.telemetry.incr(\"lsp_ready_count\")\n                self._log_event(\n                    \"lsp.state_change\",\n                    {},\n                    {\"status\": \"ready\"},\n                    1,\n                    reason=\"initialized\",\n                )\n\n            # 3. Read Loop (Waiting for publishDiagnostics & Responses)\n            while self.state != LSPState.CLOSED:\n                msg = self._read_rpc()\n                if not msg:\n                    break  # EOF\n\n                # Handle Response\n                if \"id\" in msg and \"result\" in msg:\n                    req_id = msg[\"id\"]\n                    with self.lock:\n                        if req_id in self._pending_requests:\n                            self._pending_requests[req_id] = msg[\"result\"]\n                            self._request_events[req_id].set()\n\n                # Handle Notification\n                method = msg.get(\"method\", \"\")\n                if method == \"textDocument/publishDiagnostics\":\n                    # Log diagnostics but do not control state (already READY)\n                    pass\n        except Exception as e:\n            # If we're stopping, silently exit without printing debug messages\n            if self.stopping.is_set():\n                return\n\n            # Only log errors if NOT intentionally stopping\n            # Capture stderr\n            err_out = \"Unknown\"\n            if self.process:\n                try:\n                    _, stderr_data = self.process.communicate(timeout=0.2)\n                    if stderr_data:\n                        err_out = stderr_data.decode(\"utf-8\")\n                except Exception:\n                    pass\n            sys.stderr.write(f\"DEBUG: LSP Loop Exception: {e}. Stderr: {err_out}\\n\")\n            self._transition(LSPState.FAILED)\n\n    def request(\n        self, method: str, params: Dict[str, Any], timeout: float = 2.0\n    ) -> Optional[Dict[str, Any]]:\n        \"\"\"Send a request and wait for the response.\"\"\"\n        with self.lock:\n            if self.state != LSPState.READY:\n                return None\n\n            req_id = self._next_id\n            self._next_id += 1\n            event = threading.Event()\n            self._pending_requests[req_id] = None  # Placeholder\n            self._request_events[req_id] = event\n\n        msg = {\"jsonrpc\": \"2.0\", \"id\": req_id, \"method\": method, \"params\": params}\n        self._send_rpc(msg)\n\n        # Wait for response\n        if event.wait(timeout):\n            with self.lock:\n                result = self._pending_requests.pop(req_id, None)\n                self._request_events.pop(req_id, None)\n                # Type guard for mypy\n                return result if isinstance(result, dict) else None\n        else:\n            with self.lock:\n                self._pending_requests.pop(req_id, None)\n                self._request_events.pop(req_id, None)\n                return None  # Timeout\n\n    def _send_rpc(self, msg: Dict[str, Any]) -> None:\n        # Don't attempt writes if stopping\n        if self.stopping.is_set():\n            return\n        if not self.process or not self.process.stdin:\n            return\n        try:\n            content = json.dumps(msg).encode(\"utf-8\")\n            header = f\"Content-Length: {len(content)}\\r\\n\\r\\n\".encode(\"ascii\")\n            self.process.stdin.write(header + content)\n            self.process.stdin.flush()\n        except (OSError, ValueError, BrokenPipeError):\n            # Silently ignore write errors during shutdown\n            pass\n\n    def _read_rpc(self) -> Optional[Dict[str, Any]]:\n        if not self.process or not self.process.stdout:\n            return None\n        try:\n            # Read Headers\n            length = None\n            while True:\n                line = self.process.stdout.readline()\n                if not line:\n                    if length is None:\n                        # EOF before any headers\n                        return None\n                    # EOF inside headers? Break and try reading content?\n                    break\n\n                line = line.strip()\n                if not line:\n                    # End of headers\n                    break\n\n                if line.startswith(b\"Content-Length: \"):\n                    length = int(line.split(b\": \")[1])\n\n            if length is None:\n                return None\n\n            # Read Content\n            content = b\"\"\n            while len(content) < length:\n                chunk = self.process.stdout.read(length - len(content))\n                if not chunk:\n                    break\n                content += chunk\n\n            # Parse JSON\n            try:\n                msg = json.loads(content.decode(\"utf-8\"))\n                # Type guard for mypy\n                return msg if isinstance(msg, dict) else None\n            except json.JSONDecodeError:\n                return None\n        except Exception:\n            return None\n",
+      "char_count": 13379,
+      "token_est": 3344,
       "source_path": "lsp_client.py",
       "chunking_method": "whole_file"
     },
     {
-      "id": "repo:src/infrastructure/config_loader.py:603a1cbb46",
+      "id": "repo:src/infrastructure/config_loader.py:23849e59a6",
       "doc": "repo:src/infrastructure/config_loader.py",
       "title_path": [
         "config_loader.py"
       ],
-      "text": "\"\"\"Load YAML configs with graceful error handling and auditable markers.\"\"\"\n\nimport sys\nfrom pathlib import Path\nfrom typing import Dict, Any\nimport yaml\n\n\nclass ConfigLoader:\n    \"\"\"Load YAML configs from repo root configs/ directory.\n\n    Returns auditable markers when configs are missing or invalid.\n    \"\"\"\n\n    @staticmethod\n    def load_anchors(repo_root: Path) -> Dict[str, Any]:\n        \"\"\"Load anchors.yaml from repo root configs/.\n\n        Returns:\n            - Dict with anchors data if valid\n            - {\"_missing_config\": True, \"anchors\": {}} if missing or invalid\n\n        Graceful degradation: never raises, always returns valid dict.\n        Logs warnings to stderr for visibility while maintaining graceful degradation.\n        \"\"\"\n        anchors_path = repo_root / \"configs\" / \"anchors.yaml\"\n\n        if not anchors_path.exists():\n            print(f\"[ConfigLoader] anchors.yaml not found at {anchors_path}\", file=sys.stderr)\n            return {\"_missing_config\": True, \"anchors\": {}}\n\n        try:\n            with open(anchors_path, \"r\", encoding=\"utf-8\") as f:\n                data = yaml.safe_load(f)\n\n                if not isinstance(data, dict) or \"anchors\" not in data:\n                    print(\n                        \"[ConfigLoader] anchors.yaml invalid structure (missing 'anchors' key)\",\n                        file=sys.stderr,\n                    )\n                    return {\"_missing_config\": True, \"anchors\": {}}\n\n                return data\n\n        except yaml.YAMLError as e:\n            print(f\"[ConfigLoader] anchors.yaml YAML parse error: {e}\", file=sys.stderr)\n            return {\"_missing_config\": True, \"anchors\": {}}\n        except (IOError, OSError) as e:\n            print(f\"[ConfigLoader] anchors.yaml read error: {e}\", file=sys.stderr)\n            return {\"_missing_config\": True, \"anchors\": {}}\n\n    @staticmethod\n    def load_linter_aliases(repo_root: Path) -> Dict[str, Any]:\n        \"\"\"Load aliases.yaml from repo root configs/.\n\n        Returns:\n            - Dict with aliases data if valid\n            - {\"_missing_config\": True, \"aliases\": []} if missing or invalid\n\n        Graceful degradation: never raises, always returns valid dict.\n        Logs warnings to stderr for visibility while maintaining graceful degradation.\n        \"\"\"\n        aliases_path = repo_root / \"configs\" / \"aliases.yaml\"\n\n        if not aliases_path.exists():\n            print(f\"[ConfigLoader] aliases.yaml not found at {aliases_path}\", file=sys.stderr)\n            return {\"_missing_config\": True, \"aliases\": []}\n\n        try:\n            with open(aliases_path, \"r\", encoding=\"utf-8\") as f:\n                data = yaml.safe_load(f)\n\n                if not isinstance(data, dict) or \"aliases\" not in data:\n                    print(\n                        \"[ConfigLoader] aliases.yaml invalid structure (missing 'aliases' key)\",\n                        file=sys.stderr,\n                    )\n                    return {\"_missing_config\": True, \"aliases\": []}\n\n                return data\n\n        except yaml.YAMLError as e:\n            print(f\"[ConfigLoader] aliases.yaml YAML parse error: {e}\", file=sys.stderr)\n            return {\"_missing_config\": True, \"aliases\": []}\n        except (IOError, OSError) as e:\n            print(f\"[ConfigLoader] aliases.yaml read error: {e}\", file=sys.stderr)\n            return {\"_missing_config\": True, \"aliases\": []}\n",
-      "char_count": 3407,
-      "token_est": 851,
+      "text": "\"\"\"Load YAML configs with graceful error handling and auditable markers.\"\"\"\n\nimport sys\nfrom pathlib import Path\nfrom typing import Dict, Any\nimport yaml\n\n\nclass ConfigLoader:\n    \"\"\"Load YAML configs from repo root configs/ directory.\n\n    Returns auditable markers when configs are missing or invalid.\n    \"\"\"\n\n    @staticmethod\n    def load_anchors(repo_root: Path) -> Dict[str, Any]:\n        \"\"\"Load anchors.yaml from repo root configs/.\n\n        Returns:\n            - Dict with anchors data if valid\n            - {\"_missing_config\": True, \"anchors\": {}} if missing or invalid\n\n        Graceful degradation: never raises, always returns valid dict.\n        Logs warnings to stderr for visibility while maintaining graceful degradation.\n        \"\"\"\n        anchors_path = repo_root / \"configs\" / \"anchors.yaml\"\n\n        if not anchors_path.exists():\n            sys.stderr.write(f\"[ConfigLoader] anchors.yaml not found at {anchors_path}\\n\")\n            return {\"_missing_config\": True, \"anchors\": {}}\n\n        try:\n            with open(anchors_path, \"r\", encoding=\"utf-8\") as f:\n                data = yaml.safe_load(f)\n\n                if not isinstance(data, dict) or \"anchors\" not in data:\n                    sys.stderr.write(\n                        \"[ConfigLoader] anchors.yaml invalid structure (missing 'anchors' key)\\n\"\n                    )\n                    return {\"_missing_config\": True, \"anchors\": {}}\n\n                return data\n\n        except yaml.YAMLError as e:\n            sys.stderr.write(f\"[ConfigLoader] anchors.yaml YAML parse error: {e}\\n\")\n            return {\"_missing_config\": True, \"anchors\": {}}\n        except (IOError, OSError) as e:\n            sys.stderr.write(f\"[ConfigLoader] anchors.yaml read error: {e}\\n\")\n            return {\"_missing_config\": True, \"anchors\": {}}\n\n    @staticmethod\n    def load_linter_aliases(repo_root: Path) -> Dict[str, Any]:\n        \"\"\"Load aliases.yaml from repo root configs/.\n\n        Returns:\n            - Dict with aliases data if valid\n            - {\"_missing_config\": True, \"aliases\": []} if missing or invalid\n\n        Graceful degradation: never raises, always returns valid dict.\n        Logs warnings to stderr for visibility while maintaining graceful degradation.\n        \"\"\"\n        aliases_path = repo_root / \"configs\" / \"aliases.yaml\"\n\n        if not aliases_path.exists():\n            sys.stderr.write(f\"[ConfigLoader] aliases.yaml not found at {aliases_path}\\n\")\n            return {\"_missing_config\": True, \"aliases\": []}\n\n        try:\n            with open(aliases_path, \"r\", encoding=\"utf-8\") as f:\n                data = yaml.safe_load(f)\n\n                if not isinstance(data, dict) or \"aliases\" not in data:\n                    sys.stderr.write(\n                        \"[ConfigLoader] aliases.yaml invalid structure (missing 'aliases' key)\\n\"\n                    )\n                    return {\"_missing_config\": True, \"aliases\": []}\n\n                return data\n\n        except yaml.YAMLError as e:\n            sys.stderr.write(f\"[ConfigLoader] aliases.yaml YAML parse error: {e}\\n\")\n            return {\"_missing_config\": True, \"aliases\": []}\n        except (IOError, OSError) as e:\n            sys.stderr.write(f\"[ConfigLoader] aliases.yaml read error: {e}\\n\")\n            return {\"_missing_config\": True, \"aliases\": []}\n",
+      "char_count": 3325,
+      "token_est": 831,
       "source_path": "config_loader.py",
       "chunking_method": "whole_file"
     },
@@ -4855,26 +5041,26 @@
       "chunking_method": "whole_file"
     },
     {
-      "id": "repo:src/infrastructure/deprecations.py:9beecf81f5",
+      "id": "repo:src/infrastructure/deprecations.py:0306d5da51",
       "doc": "repo:src/infrastructure/deprecations.py",
       "title_path": [
         "deprecations.py"
       ],
-      "text": "\"\"\"Deprecated code path tracking utilities.\n\nEmits telemetry events when deprecated code paths are used.\nPolicy controlled by TRIFECTA_DEPRECATED env var (off|warn|fail).\n\"\"\"\n\nimport os\nimport sys\nfrom typing import TYPE_CHECKING\n\nif TYPE_CHECKING:\n    from src.infrastructure.telemetry import Telemetry\n\n\ndef maybe_emit_deprecated(\n    deprecated_id: str,\n    telemetry: \"Telemetry\",\n) -> None:\n    \"\"\"Emit deprecated usage event based on policy.\n\n    Args:\n        deprecated_id: Stable identifier from docs/deprecations.yaml\n        telemetry: Existing telemetry instance (reuses current writer)\n\n    Raises:\n        SystemExit: If policy is 'fail', exits with code 2\n\n    Policy (TRIFECTA_DEPRECATED env var):\n        - off: no tracking (default)\n        - warn: emit telemetry event only\n        - fail: emit event + force exit code 2 (for CI/harness)\n    \"\"\"\n    policy = os.getenv(\"TRIFECTA_DEPRECATED\", \"off\")\n\n    if policy == \"off\":\n        return\n\n    # Emit event via existing telemetry (no new log files)\n    telemetry.event(\n        \"deprecated.used\",\n        {\"id\": deprecated_id},\n        {},\n        0,  # No timing for deprecation events\n    )\n\n    if policy == \"fail\":\n        # Force failure for CI/harness detection\n        print(f\"TRIFECTA_DEPRECATED=fail: {deprecated_id}\", file=sys.stderr)\n        raise SystemExit(2)\n",
-      "char_count": 1342,
-      "token_est": 335,
+      "text": "\"\"\"Deprecated code path tracking utilities.\n\nEmits telemetry events when deprecated code paths are used.\nPolicy controlled by TRIFECTA_DEPRECATED env var (off|warn|fail).\n\"\"\"\n\nimport os\nimport sys\nfrom typing import TYPE_CHECKING\n\nif TYPE_CHECKING:\n    from src.infrastructure.telemetry import Telemetry\n\n\ndef maybe_emit_deprecated(\n    deprecated_id: str,\n    telemetry: \"Telemetry\",\n) -> None:\n    \"\"\"Emit deprecated usage event based on policy.\n\n    Args:\n        deprecated_id: Stable identifier from docs/deprecations.yaml\n        telemetry: Existing telemetry instance (reuses current writer)\n\n    Raises:\n        SystemExit: If policy is 'fail', exits with code 2\n\n    Policy (TRIFECTA_DEPRECATED env var):\n        - off: no tracking (default)\n        - warn: emit telemetry event only\n        - fail: emit event + force exit code 2 (for CI/harness)\n    \"\"\"\n    policy = os.getenv(\"TRIFECTA_DEPRECATED\", \"off\")\n\n    if policy == \"off\":\n        return\n\n    # Emit event via existing telemetry (no new log files)\n    telemetry.event(\n        \"deprecated.used\",\n        {\"id\": deprecated_id},\n        {},\n        0,  # No timing for deprecation events\n    )\n\n    if policy == \"fail\":\n        # Force failure for CI/harness detection\n        sys.stderr.write(f\"TRIFECTA_DEPRECATED=fail: {deprecated_id}\\n\")\n        raise SystemExit(2)\n",
+      "char_count": 1338,
+      "token_est": 334,
       "source_path": "deprecations.py",
       "chunking_method": "whole_file"
     },
     {
-      "id": "repo:src/infrastructure/cli.py:2f7bb84cfd",
+      "id": "repo:src/infrastructure/cli.py:009ba2b361",
       "doc": "repo:src/infrastructure/cli.py",
       "title_path": [
         "cli.py"
       ],
-      "text": "\"\"\"Trifecta CLI with T8 Telemetry.\"\"\"\n\nimport json\nimport os\nimport sys\nimport time\nfrom pathlib import Path\nfrom typing import Literal, Optional, Tuple\n\nimport click\nimport typer  # type: ignore\nfrom click.exceptions import UsageError\n\n# AST/LSP Integration (Phase 2a/2b)\nfrom src.infrastructure.cli_ast import ast_app\n\nfrom src.cli.invalid_option_handler import handle_invalid_option_error\nfrom src.application.search_get_usecases import GetChunkUseCase, SearchUseCase\nfrom src.application.telemetry_charts import generate_chart\nfrom src.application.telemetry_reports import export_data, generate_report\nfrom src.application.plan_use_case import PlanUseCase\nfrom src.application.stub_regen_use_case import StubRegenUseCase\nfrom src.application.pcc_metrics import parse_feature_map, evaluate_pcc, summarize_pcc\nfrom src.application.use_cases import (\n    BuildContextPackUseCase,\n    MacroLoadUseCase,\n    RefreshPrimeUseCase,\n    StatsUseCase,\n    ValidateContextPackUseCase,\n    ValidateTrifectaUseCase,\n)\nfrom src.domain.models import TrifectaConfig\n\nfrom src.infrastructure.file_system import FileSystemAdapter\nfrom src.infrastructure.telemetry import Telemetry\nfrom src.infrastructure.templates import TemplateRenderer\nfrom src.application.obsidian_sync_use_case import create_sync_use_case\nfrom src.infrastructure.obsidian_config import ObsidianConfigManager\n\n\nclass TrifectaGroup(typer.core.TyperGroup):\n    \"\"\"Custom Typer Group with enhanced error handling for invalid options.\"\"\"\n\n    def __call__(self, *args, **kwargs):\n        \"\"\"Override to catch and enhance invalid option errors.\"\"\"\n        try:\n            return self.main(*args, **kwargs)\n        except UsageError as e:\n            # Handle invalid option errors with enhanced messaging\n            error_msg = str(e)\n            if \"no such option\" in error_msg.lower():\n                enhanced_msg = handle_invalid_option_error(error_msg, sys.argv)\n                typer.echo(enhanced_msg, err=True)\n                sys.exit(2)\n            # Re-raise other usage errors\n            raise\n\n\napp = typer.Typer(\n    name=\"trifecta\",\n    help=\"Trifecta Context Engine v2.0 - Agentic Context Management (PCC).\",\n    rich_markup_mode=\"rich\",\n    cls=TrifectaGroup,\n)\n\napp.add_typer(ast_app, name=\"ast\")\n\nctx_app = typer.Typer(\n    help=\"Manage Trifecta Context Packs (ctx.search, ctx.get).\",\n    cls=TrifectaGroup,\n)\nsession_app = typer.Typer(help=\"Session logging commands\", cls=TrifectaGroup)\ntelemetry_app = typer.Typer(help=\"Telemetry analysis commands\", cls=TrifectaGroup)\nobsidian_app = typer.Typer(help=\"Obsidian vault integration for findings\", cls=TrifectaGroup)\n\napp.add_typer(ctx_app, name=\"ctx\")\napp.add_typer(session_app, name=\"session\")\napp.add_typer(telemetry_app, name=\"telemetry\")\napp.add_typer(obsidian_app, name=\"obsidian\")\n\n# Legacy Burn-Down\nlegacy_app = typer.Typer(help=\"Legacy Burn-Down commands\", cls=TrifectaGroup)\napp.add_typer(legacy_app, name=\"legacy\")\n\nHELP_SEGMENT = \"Target segment path (e.g., 'debug_terminal' or '.')\"\nHELP_TELEMETRY = \"Telemetry level: off, lite (default), full\"\n\nHELP_TELEMETRY = \"Telemetry level: off, lite (default), full\"\n\n\ndef _get_telemetry(segment: str, level: str) -> Telemetry:\n    \"\"\"Initialize telemetry.\"\"\"\n    # Convert segment string to path\n    path = Path(segment).resolve()\n    # Check env override\n    env_level = os.environ.get(\"TRIFECTA_TELEMETRY_LEVEL\", level)\n    return Telemetry(path, level=env_level)\n\n\ndef _get_lint_enabled(no_lint_flag: bool) -> bool:\n    \"\"\"Determine if linting should be enabled based on flag + env var.\n\n    Precedence:\n    1. --no-lint flag = True → disabled\n    2. TRIFECTA_LINT env var = \"0\" or \"false\" → disabled\n    3. TRIFECTA_LINT env var = \"1\" or \"true\" → enabled\n    4. Default: DISABLED (conservative rollout)\n\n    This allows gradual rollout without breaking existing workflows.\n    \"\"\"\n    if no_lint_flag:\n        return False\n    env_val = os.environ.get(\"TRIFECTA_LINT\", \"\").lower()\n    if env_val in (\"0\", \"false\", \"no\"):\n        return False\n    if env_val in (\"1\", \"true\", \"yes\"):\n        return True\n    return False  # Conservative default: OFF until explicitly enabled\n\n\ndef _get_dependencies(\n    segment: str, telemetry: Optional[Telemetry] = None\n) -> Tuple[TemplateRenderer, FileSystemAdapter, Optional[Telemetry]]:\n    # Simplified: just return filesystem and template renderer\n    fs = FileSystemAdapter()\n    template_renderer = TemplateRenderer()\n    return template_renderer, fs, telemetry\n\n\ndef _format_error(e: Exception, title: str = \"Error\") -> str:\n    \"\"\"Format exceptions for CLI output.\"\"\"\n    return f\"❌ {title}\\n   Detail: {str(e)}\"\n\n\n# =============================================================================\n# T8: Stats Command\n# =============================================================================\n\n\n@ctx_app.command(\"stats\")\ndef ctx_stats(\n    segment: str = typer.Option(..., \"--segment\", \"-s\", help=HELP_SEGMENT),\n) -> None:\n    \"\"\"[T8] Show telemetry stats for a segment.\"\"\"\n    path = Path(segment).resolve()\n    telemetry_dir = path / \"_ctx\" / \"telemetry\"\n\n    if not telemetry_dir.exists():\n        typer.echo(f\"No telemetry found at {telemetry_dir}\")\n        return\n\n    # Load metrics\n    metrics = {}\n    metrics_path = telemetry_dir / \"metrics.json\"\n    if metrics_path.exists():\n        try:\n            metrics = json.loads(metrics_path.read_text())\n        except Exception:\n            pass\n\n    # Load last run\n    last_run = {}\n    last_run_path = telemetry_dir / \"last_run.json\"\n    if last_run_path.exists():\n        try:\n            last_run = json.loads(last_run_path.read_text())\n        except Exception:\n            pass\n\n    typer.echo(f\"📊 Telemetry for {segment}\")\n    typer.echo(f\"Path: {telemetry_dir}\\n\")\n\n    typer.echo(\"Counters:\")\n    for k, v in sorted(metrics.items()):\n        typer.echo(f\"  {k}: {v}\")\n\n    # Alias expansion summary\n    alias_expansion_count = metrics.get(\"ctx_search_alias_expansion_count\", 0)\n    alias_terms_total = metrics.get(\"ctx_search_alias_terms_total\", 0)\n    search_count = metrics.get(\"ctx_search_count\", 0)\n\n    if alias_expansion_count > 0 and search_count > 0:\n        avg_terms = alias_terms_total / alias_expansion_count if alias_expansion_count > 0 else 0\n        typer.echo(\"\\nAlias Expansion:\")\n        typer.echo(\n            f\"  {alias_expansion_count} searches expanded ({alias_expansion_count / search_count * 100:.1f}%), avg {avg_terms:.1f} terms\"\n        )\n\n    if last_run:\n        typer.echo(\"\\nLast Run:\")\n        typer.echo(f\"  Timestamp: {last_run.get('ts', 'unknown')}\")\n        latencies = last_run.get(\"latencies\", {})\n        if latencies:\n            typer.echo(\"  Latencies:\")\n            for cmd, stats in latencies.items():\n                count = stats.get(\"count\", 0)\n                # Read new keys (p50_ms, p95_ms, max_ms) with backward compat\n                p50 = stats.get(\"p50_ms\", stats.get(\"p50\", 0))\n                p95 = stats.get(\"p95_ms\", stats.get(\"p95\", 0))\n                max_ms = stats.get(\"max_ms\", stats.get(\"max\", 0))\n\n                if count == 0:\n                    typer.echo(f\"    {cmd}: no samples\")\n                else:\n                    typer.echo(\n                        f\"    {cmd}: p50={p50:.3f}ms p95={p95:.3f}ms max={max_ms:.3f}ms (n={count})\"\n                    )\n\n        warnings = last_run.get(\"top_warnings\", [])\n        if warnings:\n            typer.echo(\"\\n  Top Warnings:\")\n            for w in warnings:\n                typer.echo(f\"    - {w}\")\n\n\n# =============================================================================\n# Context Commands\n# =============================================================================\n\n\n@ctx_app.command(\"build\")\ndef build(\n    segment: str = typer.Option(..., \"--segment\", \"-s\", help=HELP_SEGMENT),\n    telemetry_level: str = typer.Option(\"lite\", \"--telemetry\", help=HELP_TELEMETRY),\n) -> None:\n    \"\"\"Build a Context Pack (context_pack.json) for a segment.\"\"\"\n    from src.domain.result import Err, Ok\n    from src.infrastructure.validators import (\n        detect_legacy_context_files,\n        validate_agents_constitution,\n        validate_segment_fp,\n    )\n\n    segment_root = Path(segment)\n    telemetry = _get_telemetry(segment, telemetry_level)\n    start_time = time.time()\n\n    # FP Gate: North Star Strict Validation\n    match validate_segment_fp(segment_root):\n        case Err(errors):\n            typer.echo(\"❌ Validation Failed (North Star Gate):\")\n            for err in errors:\n                typer.echo(f\"   - {err}\")\n            telemetry.event(\n                \"ctx.build\",\n                {\"segment\": segment},\n                {\"status\": \"validation_failed\", \"errors\": len(errors)},\n                int((time.time() - start_time) * 1000),\n            )\n            telemetry.flush()\n            raise typer.Exit(code=1)\n        case Ok(_):\n            # 1. Fail-Closed: AGENTS.md Constitution\n            match validate_agents_constitution(segment_root):\n                case Err(errors):\n                    typer.echo(\"❌ Constitution Failed (AGENTS.md):\")\n                    for err in errors:\n                        typer.echo(f\"   - {err}\")\n                    telemetry.event(\n                        \"ctx.build\",\n                        {\"segment\": segment},\n                        {\"status\": \"constitution_failed\", \"errors\": len(errors)},\n                        int((time.time() - start_time) * 1000),\n                    )\n                    telemetry.flush()\n                    raise typer.Exit(code=1)\n                case Ok(_):\n                    pass\n\n            # 2. Check for legacy file errors (Blocking)\n            legacy = detect_legacy_context_files(segment_root)\n            if legacy:\n                typer.echo(\"❌ Legacy context files detected (Fail-Closed):\")\n                for lf in legacy:\n                    typer.echo(f\"   - _ctx/{lf} (rename to suffix format: rule 3+1)\")\n                telemetry.event(\n                    \"ctx.build\",\n                    {\"segment\": segment},\n                    {\"status\": \"legacy_files_error\", \"count\": len(legacy)},\n                    int((time.time() - start_time) * 1000),\n                )\n                telemetry.flush()\n                raise typer.Exit(code=1)\n\n    _, file_system, _ = _get_dependencies(segment, telemetry)\n    use_case = BuildContextPackUseCase(file_system, telemetry)\n    segment_fs = segment_root.resolve()\n\n    try:\n        match use_case.execute(segment_fs):\n            case Ok(pack):\n                typer.echo(pack)\n                telemetry.event(\n                    \"ctx.build\",\n                    {\"segment\": segment},\n                    {\"status\": \"ok\"},\n                    int((time.time() - start_time) * 1000),\n                )\n            case Err(errors):\n                typer.echo(\"❌ Build Failed:\")\n                for err in errors:\n                    typer.echo(f\"   - {err}\")\n                telemetry.event(\n                    \"ctx.build\",\n                    {\"segment\": segment},\n                    {\"status\": \"build_error\", \"errors\": len(errors)},\n                    int((time.time() - start_time) * 1000),\n                )\n                telemetry.flush()\n                raise typer.Exit(code=1)\n    except Exception as e:\n        telemetry.event(\n            \"ctx.build\",\n            {\"segment\": segment},\n            {\"status\": \"error\", \"error\": str(e)},\n            int((time.time() - start_time) * 1000),\n        )\n        typer.echo(_format_error(e, \"Build Failed\"), err=True)\n        raise typer.Exit(1)\n    finally:\n        telemetry.flush()\n\n\n@ctx_app.command(\"search\")\ndef search(\n    query: str = typer.Option(..., \"--query\", \"-q\", help=\"Search query\"),\n    segment: str = typer.Option(..., \"--segment\", \"-s\", help=HELP_SEGMENT),\n    limit: int = typer.Option(5, \"--limit\", \"-l\", help=\"Max results\"),\n    telemetry_level: str = typer.Option(\"lite\", \"--telemetry\", help=HELP_TELEMETRY),\n    no_lint: bool = typer.Option(\n        False, \"--no-lint\", help=\"Disable query linting (anchor guidance expansion)\"\n    ),\n) -> None:\n    \"\"\"Search for relevant chunks in the Context Pack.\n\n    Query Processing Pipeline:\n    1. Normalization: lowercase, strip, collapse whitespace\n    2. Linting (optional): anchor-based classification + expansion for vague queries\n    3. Tokenization: tokenize the FINAL query (post-linter)\n    4. Alias Expansion: synonym-based expansion using _ctx/aliases.yaml\n    5. Search: execute weighted search across all terms\n\n    Controls:\n      --no-lint              Disable linting for this search\n      TRIFECTA_LINT=0/1       Env var to enable/disable globally\n      Default: DISABLED (conservative rollout)\n\n    To ENABLE linting: omit --no-lint flag or set TRIFECTA_LINT=1\n    \"\"\"\n    telemetry = _get_telemetry(segment, telemetry_level)\n    start_time = time.time()\n    _, file_system, _ = _get_dependencies(segment, telemetry)\n\n    use_case = SearchUseCase(file_system, telemetry)\n\n    try:\n        # Determine if linting should be enabled (conservative default)\n        enable_lint = _get_lint_enabled(no_lint)\n        output = use_case.execute(\n            Path(segment).resolve(), query, limit=limit, enable_lint=enable_lint\n        )\n        typer.echo(output)\n        telemetry.observe(\"ctx.search\", int((time.time() - start_time) * 1000))\n    except Exception as e:\n        telemetry.event(\n            \"ctx.search\",\n            {\"query\": query},\n            {\"status\": \"error\"},\n            int((time.time() - start_time) * 1000),\n        )\n        typer.echo(_format_error(e, \"Search Error\"), err=True)\n        raise typer.Exit(1)\n    finally:\n        telemetry.flush()\n\n\n@ctx_app.command(\"get\")\ndef get(\n    ids: str = typer.Option(..., \"--ids\", \"-i\", help=\"Comma-separated Chunk IDs\"),\n    segment: str = typer.Option(..., \"--segment\", \"-s\", help=HELP_SEGMENT),\n    mode: Literal[\"raw\", \"excerpt\", \"skeleton\"] = typer.Option(\n        \"excerpt\", \"--mode\", \"-m\", help=\"Output mode: raw, excerpt, summary\"\n    ),\n    budget_token_est: int = typer.Option(1500, \"--budget-token-est\", \"-b\", help=\"Max token budget\"),\n    max_chunks: Optional[int] = typer.Option(\n        None, \"--max-chunks\", help=\"Max chunks to retrieve (early-stop)\"\n    ),\n    stop_on_evidence: bool = typer.Option(\n        False, \"--stop-on-evidence\", help=\"Stop early when evidence found (feature flag)\"\n    ),\n    query: Optional[str] = typer.Option(\n        None, \"--query\", \"-q\", help=\"Query term for evidence matching\"\n    ),\n    pd_report: bool = typer.Option(\n        False, \"--pd-report\", help=\"Output parseable PD metrics line (for testing)\"\n    ),\n    telemetry_level: str = typer.Option(\"lite\", \"--telemetry\", help=HELP_TELEMETRY),\n) -> None:\n    \"\"\"Retrieve full content for specific chunks.\"\"\"\n    telemetry = _get_telemetry(segment, telemetry_level)\n    start_time = time.time()\n    _, file_system, _ = _get_dependencies(segment, telemetry)\n\n    use_case = GetChunkUseCase(file_system, telemetry)\n\n    id_list = [x.strip() for x in ids.split(\",\") if x.strip()]\n\n    # Agent-safe defaults: Check env vars if CLI flags not provided\n    effective_max_chunks = max_chunks\n    if effective_max_chunks is None:\n        import os\n\n        env_max_chunks = os.environ.get(\"TRIFECTA_PD_MAX_CHUNKS\")\n        if env_max_chunks:\n            try:\n                effective_max_chunks = int(env_max_chunks)\n            except ValueError:\n                pass  # Ignore invalid env var, use None\n\n    effective_stop_on_evidence = stop_on_evidence\n    if not effective_stop_on_evidence:\n        import os\n\n        env_stop_on_evidence = os.environ.get(\"TRIFECTA_PD_STOP_ON_EVIDENCE\")\n        if env_stop_on_evidence and env_stop_on_evidence == \"1\":\n            effective_stop_on_evidence = True\n\n    try:\n        # Use execute_with_result when --pd-report is active for access to GetResult\n        if pd_report:\n            output, result = use_case.execute_with_result(\n                Path(segment).resolve(),\n                id_list,\n                mode=mode,\n                budget_token_est=budget_token_est,\n                max_chunks=effective_max_chunks,\n                stop_on_evidence=effective_stop_on_evidence,\n                query=query,\n            )\n            typer.echo(output)\n\n            # Emit PD_REPORT with version and invariant keys\n            strong_hit = 1 if result.evidence_metadata.get(\"strong_hit\") else 0\n            support = 1 if result.evidence_metadata.get(\"support\") else 0\n            typer.echo(\n                f\"PD_REPORT v=1 \"\n                f\"stop_reason={result.stop_reason} \"\n                f\"chunks_returned={result.chunks_returned} \"\n                f\"chunks_requested={result.chunks_requested} \"\n                f\"chars_returned_total={result.chars_returned_total} \"\n                f\"strong_hit={strong_hit} \"\n                f\"support={support}\"\n            )\n        else:\n            # Standard path: just get output string\n            output = use_case.execute(\n                Path(segment).resolve(),\n                id_list,\n                mode=mode,\n                budget_token_est=budget_token_est,\n                max_chunks=effective_max_chunks,\n                stop_on_evidence=effective_stop_on_evidence,\n                query=query,\n            )\n            typer.echo(output)\n\n        telemetry.observe(\"ctx.get\", int((time.time() - start_time) * 1000))\n    except Exception as e:\n        telemetry.event(\n            \"ctx.get\", {\"ids\": ids}, {\"status\": \"error\"}, int((time.time() - start_time) * 1000)\n        )\n        typer.echo(_format_error(e, \"Get Error\"), err=True)\n        raise typer.Exit(1)\n    finally:\n        telemetry.flush()\n\n\n@ctx_app.command(\"validate\")\ndef validate(\n    segment: str = typer.Option(..., \"--segment\", \"-s\", help=HELP_SEGMENT),\n    telemetry_level: str = typer.Option(\"lite\", \"--telemetry\", help=HELP_TELEMETRY),\n) -> None:\n    \"\"\"Validate Context Pack health.\"\"\"\n    telemetry = _get_telemetry(segment, telemetry_level)\n    start_time = time.time()\n    _, file_system, _ = _get_dependencies(segment, telemetry)\n\n    use_case = ValidateContextPackUseCase(file_system, telemetry)\n\n    try:\n        result = use_case.execute(Path(segment).resolve())\n        # Format ValidationResult for display\n        if result.passed:\n            output = \"✅ Validation Passed\"\n            if result.warnings:\n                output += \"\\n\\n⚠️  Warnings:\\n\" + \"\\n\".join(f\"   - {w}\" for w in result.warnings)\n        else:\n            output = \"❌ Validation Failed\\n\\n\" + \"\\n\".join(f\"   - {e}\" for e in result.errors)\n\n        typer.echo(output)\n        telemetry.observe(\"ctx.validate\", int((time.time() - start_time) * 1000))\n\n        # Exit with error code if validation failed\n        if not result.passed:\n            raise typer.Exit(code=1)\n\n    except Exception as e:\n        telemetry.event(\n            \"ctx.validate\", {}, {\"status\": \"error\"}, int((time.time() - start_time) * 1000)\n        )\n        typer.echo(_format_error(e, \"Validation Error\"), err=True)\n        if not isinstance(e, typer.Exit):\n            raise typer.Exit(1)\n        raise e\n    finally:\n        telemetry.flush()\n\n\n@ctx_app.command(\"stats\")\ndef stats(\n    segment: str = typer.Option(..., \"--segment\", \"-s\", help=HELP_SEGMENT),\n    window: int = typer.Option(0, \"--window\", \"-w\", help=\"Days to look back (0 = all)\"),\n    telemetry_level: str = typer.Option(\"lite\", \"--telemetry\", help=HELP_TELEMETRY),\n) -> None:\n    \"\"\"Show telemetry statistics for the segment.\"\"\"\n    telemetry = _get_telemetry(segment, telemetry_level)\n    start_time = time.time()\n    _, file_system, _ = _get_dependencies(segment, telemetry)\n\n    use_case = StatsUseCase(file_system, telemetry)\n\n    try:\n        result = use_case.execute(Path(segment), window=window)\n\n        # Format output\n        lines = []\n        lines.append(\"╭\" + \"─\" * 50 + \"╮\")\n        lines.append(\"│\" + \" \" * 15 + \"Trifecta Stats\" + \" \" * 23 + \"│\")\n        lines.append(\n            f\"│           Last {window} days\"\n            if window > 0\n            else \"│                  All time\" + \" \" * 22 + \"│\"\n        )\n        lines.append(\"╰\" + \"─\" * 50 + \"╯\")\n        lines.append(\"\")\n\n        # Summary\n        summary = result[\"summary\"]\n        lines.append(\"Summary\")\n        lines.append(\"─\" * 50)\n        lines.append(f\"  Total searches:      {summary['total_searches']}\")\n        lines.append(f\"  Hits:                {summary['hits']}\")\n        lines.append(f\"  Zero hits:           {summary['zero_hits']}\")\n        lines.append(f\"  Hit rate:            {summary['hit_rate']}%\")\n        lines.append(f\"  Avg latency:         {summary['avg_latency_ms']:.1f}ms\")\n        lines.append(\"\")\n\n        # Top zero-hit queries\n        lines.append(\"Top Zero-Hit Queries\")\n        lines.append(\"─\" * 50)\n        for item in result[\"top_zero_hit_queries\"][:10]:\n            lines.append(f\"  [{item['count']:2d}] {item['query'][:50]}\")\n        lines.append(\"\")\n\n        # Query type breakdown\n        lines.append(\"Query Type Breakdown\")\n        lines.append(\"─\" * 50)\n        total = sum(result[\"query_type_breakdown\"].values())\n        for qtype in [\"meta\", \"impl\", \"unknown\"]:\n            count = result[\"query_type_breakdown\"].get(qtype, 0)\n            pct = count / total * 100 if total > 0 else 0\n            lines.append(f\"  {qtype:<10} {count:>3}  ({pct:>5.1f}%)\")\n        lines.append(\"\")\n\n        # Hit target breakdown\n        if result[\"hit_target_breakdown\"]:\n            lines.append(\"Hit Target Breakdown\")\n            lines.append(\"─\" * 50)\n            total_hits = sum(result[\"hit_target_breakdown\"].values())\n            for target, count in sorted(\n                result[\"hit_target_breakdown\"].items(), key=lambda x: -x[1]\n            ):\n                pct = count / total_hits * 100 if total_hits > 0 else 0\n                lines.append(f\"  {target:<10} {count:>3}  ({pct:>5.1f}%)\")\n            lines.append(\"\")\n\n        typer.echo(\"\\n\".join(lines))\n        telemetry.observe(\"ctx.stats\", int((time.time() - start_time) * 1000))\n\n    except Exception as e:\n        telemetry.event(\n            \"ctx.stats\", {}, {\"status\": \"error\"}, int((time.time() - start_time) * 1000)\n        )\n        typer.echo(_format_error(e, \"Stats Error\"), err=True)\n        raise typer.Exit(1)\n    finally:\n        telemetry.flush()\n\n\n@ctx_app.command(\"plan\")\ndef plan(\n    segment: str = typer.Option(..., \"--segment\", \"-s\", help=HELP_SEGMENT),\n    task: str = typer.Option(..., \"--task\", \"-t\", help=\"Task description to plan\"),\n    telemetry_level: str = typer.Option(\"lite\", \"--telemetry\", help=HELP_TELEMETRY),\n    json_output: bool = typer.Option(False, \"--json\", \"-j\", help=\"Output as JSON\"),\n) -> None:\n    \"\"\"Generate execution plan using PRIME index (no RAG).\"\"\"\n    telemetry = _get_telemetry(segment, telemetry_level)\n    _, file_system, _ = _get_dependencies(segment, telemetry)\n\n    use_case = PlanUseCase(file_system, telemetry)\n\n    try:\n        result = use_case.execute(Path(segment).resolve(), task)\n\n        if json_output:\n            typer.echo(json.dumps(result, indent=2))\n        else:\n            # Human-readable output\n            lines = []\n            lines.append(\"╭\" + \"─\" * 50 + \"╮\")\n            lines.append(\"│\" + \" \" * 12 + \"Execution Plan\" + \" \" * 24 + \"│\")\n            lines.append(\"╰\" + \"─\" * 50 + \"╯\")\n            lines.append(\"\")\n\n            status = \"✅ HIT\" if result[\"plan_hit\"] else \"⚠️ NO HIT\"\n            lines.append(f\"Status: {status}\")\n            lines.append(\"\")\n\n            if result[\"selected_feature\"]:\n                lines.append(f\"Selected Feature: {result['selected_feature']}\")\n            else:\n                lines.append(\"Selected Feature: (none - using entrypoints)\")\n            lines.append(\"\")\n\n            if result[\"chunk_ids\"]:\n                lines.append(f\"Chunk IDs: {', '.join(result['chunk_ids'][:3])}\")\n                lines.append(f\"            ... ({len(result['chunk_ids'])} total)\")\n            else:\n                lines.append(\"Chunk IDs: (none)\")\n            lines.append(\"\")\n\n            if result[\"paths\"]:\n                lines.append(f\"Paths: {', '.join(result['paths'][:3])}\")\n                if len(result[\"paths\"]) > 3:\n                    lines.append(f\"       ... ({len(result['paths'])} total)\")\n            else:\n                lines.append(\"Paths: (entrypoints)\")\n            lines.append(\"\")\n\n            lines.append(\"Next Steps:\")\n            for i, step in enumerate(result[\"next_steps\"], 1):\n                lines.append(f\"  {i}. {step['action'].capitalize()}: {step['target']}\")\n            lines.append(\"\")\n\n            budget = result[\"budget_est\"]\n            lines.append(f\"Budget Estimate: ~{budget['tokens']} tokens\")\n            lines.append(f\"  ({budget['why']})\")\n            lines.append(\"\")\n\n            typer.echo(\"\\n\".join(lines))\n\n    except Exception as e:\n        typer.echo(_format_error(e, \"Plan Error\"), err=True)\n        raise typer.Exit(1)\n\n\n@ctx_app.command(\"eval-plan\")\ndef eval_plan(\n    segment: str = typer.Option(..., \"--segment\", \"-s\", help=HELP_SEGMENT),\n    dataset: str = typer.Option(\n        \"docs/plans/t9_plan_eval_tasks.md\",\n        \"--dataset\",\n        \"-d\",\n        help=\"Path to evaluation dataset markdown file\",\n    ),\n    telemetry_level: str = typer.Option(\"lite\", \"--telemetry\", help=HELP_TELEMETRY),\n    verbose: bool = typer.Option(False, \"--verbose\", \"-v\", help=\"Show per-task breakdown\"),\n) -> None:\n    \"\"\"Evaluate ctx.plan against a dataset of tasks.\"\"\"\n    import hashlib\n    import re\n    from datetime import datetime\n\n    telemetry = _get_telemetry(segment, telemetry_level)\n    _, file_system, _ = _get_dependencies(segment, telemetry)\n\n    # Load PRIME for PCC metrics\n    segment_path = Path(segment).resolve()\n    prime_files = list(segment_path.glob(\"_ctx/prime_*.md\"))\n    prime_path = prime_files[0] if prime_files else None\n    feature_map = {}\n    if prime_path:\n        try:\n            feature_map = parse_feature_map(prime_path)\n        except Exception as e:\n            typer.echo(f\"⚠️  PCC Metrics: Failed to parse feature_map from {prime_path.name}\")\n            typer.echo(f\"   Error: {e}\")\n            typer.echo(\"   PCC metrics will be disabled for this run.\")\n            typer.echo(\"\")\n\n    # Load dataset from markdown\n    dataset_path = Path(dataset).resolve()\n    if not dataset_path.exists():\n        typer.echo(f\"❌ Dataset file not found: {dataset_path}\")\n        raise typer.Exit(1)\n\n    content = dataset_path.read_text()\n\n    # Dataset identity for anti-gaming (T9.3.1)\n    dataset_sha256 = hashlib.sha256(content.encode()).hexdigest()[:16]\n    dataset_mtime = datetime.fromtimestamp(dataset_path.stat().st_mtime).isoformat()\n\n    # Extract tasks from markdown (quoted strings after numbers)\n    tasks = re.findall(r'^\\d+\\.\\s+\"([^\"]+)\"', content, re.MULTILINE)\n\n    # Parse expected_feature_id from dataset (T9.3.2)\n    # Format: number. \"task\" | expected_feature_id | notes\n    expected_features = {}\n    for line in content.split(\"\\n\"):\n        match = re.match(r'^\\d+\\.\\s+\"([^\"]+)\"\\s*\\|\\s*(\\w+)', line)\n        if match:\n            task_str = match.group(1)\n            expected_id = match.group(2)\n            expected_features[task_str] = expected_id\n\n    if not tasks:\n        typer.echo(\"❌ No tasks found in dataset file\")\n        raise typer.Exit(1)\n\n    # Run evaluation\n    use_case = PlanUseCase(file_system, telemetry)\n\n    results = []\n    feature_count = 0\n    nl_trigger_count = 0\n    alias_count = 0\n    fallback_count = 0\n    true_zero_count = 0\n    correct_predictions = 0  # T9.3.2: plan_accuracy_top1\n    pcc_metrics_rows = []  # PCC metrics per task\n\n    for i, task in enumerate(tasks, 1):\n        result = use_case.execute(Path(segment), task)\n        results.append({\"task_id\": i, \"task\": task, \"result\": result})\n\n        # Classify outcome (T9.3.2: 4-level hierarchy)\n        selected_by = result.get(\"selected_by\", \"fallback\")\n\n        if selected_by == \"feature\":\n            feature_count += 1\n        elif selected_by == \"nl_trigger\":\n            nl_trigger_count += 1\n        elif selected_by == \"alias\":\n            alias_count += 1\n        else:  # fallback\n            fallback_count += 1\n\n        # T9.3.2: Track accuracy if expected_feature_id is available\n        expected_id = expected_features.get(task)\n        selected_id = result.get(\"selected_feature\")\n\n        if expected_id:\n            if expected_id == \"fallback\":\n                # Correct if selected_feature is None\n                if selected_id is None:\n                    correct_predictions += 1\n            elif selected_id == expected_id:\n                # Correct if selected_feature matches expected\n                correct_predictions += 1\n        # Check for true_zero_guidance (bug condition)\n        chunks_count = len(result.get(\"chunk_ids\", []))\n        paths_count = len(result.get(\"paths\", []))\n        # entrypoints_count calculation removed (unused)\n        next_steps_count = len(result.get(\"next_steps\", []))\n\n        if chunks_count == 0 and paths_count == 0 and next_steps_count == 0:\n            true_zero_count += 1\n\n        # Compute PCC metrics if feature_map is available\n        if feature_map and expected_id:\n            pcc_row = evaluate_pcc(\n                expected_feature=expected_id,\n                predicted_feature=selected_id,\n                predicted_paths=result.get(\"paths\", []),\n                feature_map=feature_map,\n                selected_by=selected_by,\n            )\n            pcc_metrics_rows.append(pcc_row)\n\n    total = len(tasks)\n    expected_count = len(expected_features)  # T9.3.2: Number of labeled tasks\n\n    # Compute rates (T9.3.2: 4-level hierarchy)\n    feature_hit_rate = (feature_count / total * 100) if total > 0 else 0\n    nl_trigger_hit_rate = (nl_trigger_count / total * 100) if total > 0 else 0\n    alias_hit_rate = (alias_count / total * 100) if total > 0 else 0\n    fallback_rate = (fallback_count / total * 100) if total > 0 else 0\n    true_zero_guidance_rate = (true_zero_count / total * 100) if total > 0 else 0\n\n    # T9.3.2: Compute accuracy if expected labels exist\n    plan_accuracy_top1 = (\n        (correct_predictions / expected_count * 100) if expected_count > 0 else None\n    )\n\n    # Compute PCC summary\n    pcc_summary = summarize_pcc(pcc_metrics_rows) if pcc_metrics_rows else {}\n\n    # Output report\n    typer.echo(\"=\" * 80)\n    typer.echo(\"EVALUATION REPORT: ctx.plan\")\n    typer.echo(\"=\" * 80)\n    typer.echo(\"\")\n    typer.echo(f\"Dataset: {dataset_path}\")\n    typer.echo(f\"Dataset SHA256: {dataset_sha256}\")\n    typer.echo(f\"Dataset mtime: {dataset_mtime}\")\n    typer.echo(f\"Segment: {segment}\")\n    typer.echo(f\"Total tasks: {total}\")\n    typer.echo(\"\")\n    typer.echo(f\"Dataset: {dataset_path}\")\n    typer.echo(f\"Dataset SHA256: {dataset_sha256}\")\n    typer.echo(f\"Dataset mtime: {dataset_mtime}\")\n    typer.echo(f\"Segment: {segment}\")\n    typer.echo(f\"Total tasks: {total}\")\n    typer.echo(\"\")\n\n    typer.echo(f\"Distribution (MUST SUM TO {total}):\")\n    typer.echo(f\"  feature (L1):   {feature_count} ({feature_hit_rate:.1f}%)\")\n    typer.echo(f\"  nl_trigger (L2): {nl_trigger_count} ({nl_trigger_hit_rate:.1f}%)\")\n    typer.echo(f\"  alias (L3):      {alias_count} ({alias_hit_rate:.1f}%)\")\n    typer.echo(f\"  fallback (L4):   {fallback_count} ({fallback_rate:.1f}%)\")\n    typer.echo(\"  ─────────────────────────────\")\n    typer.echo(f\"  total:          {total} (100.0%)\")\n    typer.echo(\"\")\n\n    typer.echo(\"Computed Rates:\")\n    typer.echo(f\"  feature_hit_rate:       {feature_hit_rate:.1f}%\")\n    typer.echo(f\"  nl_trigger_hit_rate:    {nl_trigger_hit_rate:.1f}%\")\n    typer.echo(f\"  alias_hit_rate:         {alias_hit_rate:.1f}%\")\n    typer.echo(f\"  fallback_rate:          {fallback_rate:.1f}%\")\n    typer.echo(f\"  true_zero_guidance_rate: {true_zero_guidance_rate:.1f}%\")\n\n    # T9.3.2: Show accuracy if expected labels exist\n    if plan_accuracy_top1 is not None:\n        typer.echo(\n            f\"  plan_accuracy_top1:     {plan_accuracy_top1:.1f}% ({correct_predictions}/{expected_count} correct)\"\n        )\n    typer.echo(\"\")\n\n    # PCC Metrics (if feature_map is available)\n    if pcc_summary:\n        typer.echo(\"PCC Metrics:\")\n        typer.echo(f\"  path_correct_count:    {pcc_summary['path_correct_count']}\")\n        typer.echo(f\"  false_fallback_count:  {pcc_summary['false_fallback_count']}\")\n        typer.echo(f\"  safe_fallback_count:   {pcc_summary['safe_fallback_count']}\")\n        typer.echo(\"\")\n\n    # Verbose per-task table\n    if verbose:\n        typer.echo(\"Per-Task Breakdown:\")\n        typer.echo(\"─\" * 80)\n        for item in results:\n            tid = item[\"task_id\"]\n            task_short = item[\"task\"][:40] + \"...\" if len(item[\"task\"]) > 40 else item[\"task\"]\n            result = item[\"result\"]\n            outcome = result.get(\"selected_by\", \"fallback\")\n            feature = result.get(\"selected_feature\", \"N/A\")\n            match_terms = result.get(\"match_terms_count\", 0)\n            chunks = len(result.get(\"chunk_ids\", []))\n            paths = len(result.get(\"paths\", []))\n\n            typer.echo(f\"{tid:2d}. [{outcome:8s}] {task_short}\")\n            typer.echo(f\"    → feature:{feature} terms:{match_terms} chunks:{chunks} paths:{paths}\")\n        typer.echo(\"\")\n\n    # Top missed tasks (fallback)\n    missed = [r for r in results if r[\"result\"].get(\"selected_by\") == \"fallback\"]\n    if missed:\n        typer.echo(f\"Top Missed Tasks (fallback): {len(missed)} total\")\n        for i, item in enumerate(missed[:10], 1):\n            task_short = item[\"task\"][:60] + \"...\" if len(item[\"task\"]) > 60 else item[\"task\"]\n            typer.echo(f\"  {i}. {task_short}\")\n        typer.echo(\"\")\n\n    # Examples of hits\n    hits = [r for r in results if r[\"result\"].get(\"plan_hit\")]\n    if hits:\n        typer.echo(\"Examples (hits with selected_feature):\")\n        for i, item in enumerate(hits[:5], 1):\n            task_short = item[\"task\"][:50] + \"...\" if len(item[\"task\"]) > 50 else item[\"task\"]\n            result = item[\"result\"]\n            outcome = result.get(\"selected_by\", \"unknown\")\n            feature = result.get(\"selected_feature\", \"N/A\")\n            chunks = len(result.get(\"chunk_ids\", []))\n            paths = len(result.get(\"paths\", []))\n            typer.echo(f\"  {i}. [{outcome}] '{task_short}'\")\n            typer.echo(f\"     → {feature} ({chunks} chunks, {paths} paths)\")\n            if i >= 3:\n                break\n\n    typer.echo(\"\")\n\n    # Determine gate type based on dataset name (T9.3.1)\n    is_l1_dataset = \"_l1\" in dataset_path.name.lower()\n    gate_name = \"Gate-L1\" if is_l1_dataset else \"Gate-NL\"\n\n    # Gate decision (T9.3.1: separate gates for NL and L1)\n    go_criteria = []\n    no_go_reasons = []\n\n    if is_l1_dataset:\n        # Gate-L1 criteria (explicit feature:<id> tests)\n        if feature_hit_rate >= 95:\n            go_criteria.append(f\"feature_hit_rate {feature_hit_rate:.1f}% >= 95%\")\n        else:\n            no_go_reasons.append(f\"feature_hit_rate {feature_hit_rate:.1f}% < 95%\")\n\n        if fallback_rate <= 5:\n            go_criteria.append(f\"fallback_rate {fallback_rate:.1f}% <= 5%\")\n        else:\n            no_go_reasons.append(f\"fallback_rate {fallback_rate:.1f}% > 5%\")\n\n        if true_zero_guidance_rate == 0:\n            go_criteria.append(f\"true_zero_guidance_rate {true_zero_guidance_rate:.1f}% = 0%\")\n        else:\n            no_go_reasons.append(f\"true_zero_guidance_rate {true_zero_guidance_rate:.1f}% > 0%\")\n    else:\n        # Gate-NL criteria (natural language generalization)\n        if fallback_rate < 20:\n            go_criteria.append(f\"fallback_rate {fallback_rate:.1f}% < 20%\")\n        else:\n            no_go_reasons.append(f\"fallback_rate {fallback_rate:.1f}% >= 20%\")\n\n        if true_zero_guidance_rate == 0:\n            go_criteria.append(f\"true_zero_guidance_rate {true_zero_guidance_rate:.1f}% = 0%\")\n        else:\n            no_go_reasons.append(f\"true_zero_guidance_rate {true_zero_guidance_rate:.1f}% > 0%\")\n\n        if alias_hit_rate <= 70:\n            go_criteria.append(f\"alias_hit_rate {alias_hit_rate:.1f}% <= 70%\")\n        else:\n            no_go_reasons.append(f\"alias_hit_rate {alias_hit_rate:.1f}% > 70%\")\n\n        # Informative for NL (not required)\n        if feature_hit_rate >= 10:\n            go_criteria.append(f\"feature_hit_rate {feature_hit_rate:.1f}% >= 10% (informative)\")\n        else:\n            no_go_reasons.append(f\"feature_hit_rate {feature_hit_rate:.1f}% < 10% (informative)\")\n\n    if go_criteria and not no_go_reasons:\n        typer.echo(f\"✅ GO ({gate_name}): All criteria passed\")\n        for c in go_criteria:\n            typer.echo(f\"   ✓ {c}\")\n    else:\n        typer.echo(f\"❌ NO-GO ({gate_name}): Some criteria failed\")\n        for r in no_go_reasons:\n            typer.echo(f\"   ✗ {r}\")\n        if go_criteria:\n            typer.echo(\"\")\n            typer.echo(\"Passed criteria:\")\n            for c in go_criteria:\n                typer.echo(f\"   ✓ {c}\")\n\n    telemetry.flush()\n\n\n@ctx_app.command(\"sync\")\ndef sync(\n    segment: str = typer.Option(..., \"--segment\", \"-s\", help=HELP_SEGMENT),\n    telemetry_level: str = typer.Option(\"lite\", \"--telemetry\", help=HELP_TELEMETRY),\n) -> None:\n    \"\"\"Macro: Build + Validate.\"\"\"\n    telemetry = _get_telemetry(segment, telemetry_level)\n    start_time = time.time()\n    _, file_system, _ = _get_dependencies(segment, telemetry)\n\n    try:\n        typer.echo(\"🔄 Running build...\")\n        build_uc = BuildContextPackUseCase(file_system, telemetry)\n        build_uc.execute(Path(segment).resolve())\n\n        typer.echo(\"✅ Build complete. Validating...\")\n        validate_uc = ValidateContextPackUseCase(file_system, telemetry)\n        result = validate_uc.execute(Path(segment).resolve())\n\n        # Format ValidationResult for display\n        if result.passed:\n            output = \"✅ Validation Passed\"\n            if result.warnings:\n                output += \"\\n\\n⚠️  Warnings:\\n\" + \"\\n\".join(f\"   - {w}\" for w in result.warnings)\n        else:\n            output = \"❌ Validation Failed\\n\\n\" + \"\\n\".join(f\"   - {e}\" for e in result.errors)\n\n        typer.echo(output)\n\n        if result.passed:\n            # Regenerate stubs\n            typer.echo(\"🔄 Regenerating stubs...\")\n            stub_regen_uc = StubRegenUseCase(telemetry)\n            stub_result = stub_regen_uc.execute(Path(segment).resolve())\n\n            if stub_result[\"stubs\"]:\n                typer.echo(f\"   ✅ Regenerated: {', '.join(stub_result['stubs'])}\")\n\n            if stub_result[\"warnings\"]:\n                typer.echo(\"   ⚠️  Warnings:\")\n                for w in stub_result[\"warnings\"]:\n                    typer.echo(f\"      - {w}\")\n\n            if not stub_result[\"regen_ok\"]:\n                typer.echo(\"   ⚠️  Stub regeneration had errors:\")\n                for e in stub_result[\"errors\"]:\n                    typer.echo(f\"      - {e}\")\n\n        telemetry.event(\n            \"ctx.sync\",\n            {\"segment\": segment},\n            {\"status\": \"ok\"},\n            int((time.time() - start_time) * 1000),\n        )\n\n        if not result.passed:\n            raise typer.Exit(code=1)\n\n    # Type-based error classification (preferred - robust)\n    except Exception as e:\n        from src.application.exceptions import PrimeFileNotFoundError\n\n        if isinstance(e, PrimeFileNotFoundError):\n            # Prime file missing - emit SEGMENT_NOT_INITIALIZED Error Card\n            from src.cli.error_cards import render_error_card\n\n            error_card = render_error_card(\n                error_code=\"SEGMENT_NOT_INITIALIZED\",\n                error_class=\"PRECONDITION\",\n                cause=f\"Missing prime file: {e.expected_path}\",\n                next_steps=[\n                    f\"trifecta create -s {segment}\",\n                    f\"trifecta refresh-prime -s {segment}\",\n                ],\n                verify_cmd=f\"trifecta ctx sync -s {segment}\",\n            )\n            telemetry.event(\n                \"ctx.sync\",\n                {\"segment\": segment},\n                {\"status\": \"error\", \"error_code\": \"SEGMENT_NOT_INITIALIZED\"},\n                int((time.time() - start_time) * 1000),\n            )\n            typer.echo(error_card, err=True)\n            raise typer.Exit(1)\n\n        # Substring fallback for backward compatibility (deprecated)\n        elif isinstance(e, FileNotFoundError) and \"Expected prime file not found\" in str(e):\n            import sys\n            from src.cli.error_cards import render_error_card\n            from src.infrastructure.deprecations import maybe_emit_deprecated\n\n            # Track deprecated usage (policy: off|warn|fail via env var)\n            maybe_emit_deprecated(\"fallback_prime_missing_string_match\", telemetry)\n\n            # Emit deprecation warning for harness detection (legacy)\n            print(\"TRIFECTA_DEPRECATED: fallback_prime_missing_string_match_used\", file=sys.stderr)\n\n            error_card = render_error_card(\n                error_code=\"SEGMENT_NOT_INITIALIZED\",\n                error_class=\"PRECONDITION\",\n                cause=str(e),\n                next_steps=[\n                    f\"trifecta create -s {segment}\",\n                    f\"trifecta refresh-prime -s {segment}\",\n                ],\n                verify_cmd=f\"trifecta ctx sync -s {segment}\",\n            )\n            telemetry.event(\n                \"ctx.sync\",\n                {\"segment\": segment},\n                {\"status\": \"error\", \"error_code\": \"SEGMENT_NOT_INITIALIZED\"},\n                int((time.time() - start_time) * 1000),\n            )\n            typer.echo(error_card, err=True)\n            raise typer.Exit(1)\n\n        # All other exceptions (fail-closed)\n        else:\n            telemetry.event(\n                \"ctx.sync\",\n                {\"segment\": segment},\n                {\"status\": \"error\"},\n                int((time.time() - start_time) * 1000),\n            )\n        typer.echo(_format_error(e, \"Sync Error\"), err=True)\n        if not isinstance(e, typer.Exit):\n            raise typer.Exit(1)\n        raise e\n    finally:\n        telemetry.flush()\n\n\n@ctx_app.command(\"reset\")\ndef ctx_reset(\n    segment: str = typer.Option(..., \"--segment\", \"-s\", help=HELP_SEGMENT),\n    telemetry_level: str = typer.Option(\"lite\", \"--telemetry\", help=HELP_TELEMETRY),\n    force: bool = typer.Option(False, \"--force\", \"-f\", help=\"Skip confirmation prompt\"),\n) -> None:\n    \"\"\"[DESTRUCTIVE] Regenerate ALL context files (templates + pack). Use with caution.\"\"\"\n    telemetry = _get_telemetry(segment, telemetry_level)\n    start_time = time.time()\n    template_renderer, file_system, _ = _get_dependencies(segment, telemetry)\n\n    try:\n        if not force:\n            typer.echo(\n                \"⚠️  WARNING: This will overwrite skill.md, agent.md, session.md, readme_tf.md\"\n            )\n            typer.echo(\"Press Ctrl+C to cancel, or Enter to continue...\")\n            input()\n\n        typer.echo(\"🔄 Regenerating templates...\")\n        config_path = Path(segment) / \"_ctx\" / \"trifecta_config.json\"\n        if config_path.exists():\n            import json\n\n            config_data = json.loads(config_path.read_text())\n            from src.domain.models import TrifectaConfig\n\n            config = TrifectaConfig(**config_data)\n        else:\n            typer.echo(\"❌ No trifecta_config.json found. Use 'trifecta create' for new segments.\")\n            raise typer.Exit(1)\n\n        (Path(segment) / \"skill.md\").write_text(template_renderer.render_skill(config))\n        (Path(segment) / \"_ctx\" / \"agent.md\").write_text(template_renderer.render_agent(config))\n        (Path(segment) / \"_ctx\" / f\"session_{config.segment}.md\").write_text(\n            template_renderer.render_session(config)\n        )\n        (Path(segment) / \"readme_tf.md\").write_text(template_renderer.render_readme(config))\n\n        typer.echo(\"✅ Templates regenerated. Running sync...\")\n\n        build_uc = BuildContextPackUseCase(file_system, telemetry)\n        build_uc.execute(Path(segment))\n\n        validate_uc = ValidateContextPackUseCase(file_system, telemetry)\n        output = validate_uc.execute(Path(segment))\n        typer.echo(output)\n\n        telemetry.observe(\"ctx.reset\", int((time.time() - start_time) * 1000))\n\n        if not output.passed:\n            raise typer.Exit(code=1)\n\n    except KeyboardInterrupt:\n        typer.echo(\"\\n❌ Reset cancelled\")\n        raise typer.Exit(0)\n    except Exception as e:\n        telemetry.event(\n            \"ctx.reset\", {}, {\"status\": \"error\"}, int((time.time() - start_time) * 1000)\n        )\n        typer.echo(_format_error(e, \"Reset Error\"), err=True)\n        if not isinstance(e, typer.Exit):\n            raise typer.Exit(1)\n        raise e\n    finally:\n        telemetry.flush()\n\n\n# =============================================================================\n# Generator Commands\n# =============================================================================\n\n\n@app.command(\"create\")\ndef create(\n    segment: str = typer.Option(..., \"--segment\", \"-s\", help=\"Path to segment directory\"),\n    scope: str = typer.Option(\"Scope\", \"--scope\", help=\"Short description of segment scope\"),\n) -> None:\n    \"\"\"\n    Scaffold a new Trifecta Segment.\n\n    Generates:\n    - skill.md (Rules & Roles)\n    - _ctx/prime_{segment}.md (Reading list)\n    - _ctx/agent.md (Tech stack)\n    - _ctx/session_{segment}.md (Runbook)\n    - readme_tf.md (Documentation)\n    \"\"\"\n    # FIXED: -s is now path to target directory (consistent with ctx sync/search/get)\n    # Segment ID derived from directory name\n    target_dir = Path(segment).resolve()\n\n    template_renderer, _, _ = _get_dependencies(str(target_dir))\n\n    if not target_dir.exists():\n        target_dir.mkdir(parents=True)\n\n    # Derive segment_id from directory name (same logic as use_cases.py)\n    from src.domain.naming import normalize_segment_id\n\n    segment_id = normalize_segment_id(target_dir.name)\n\n    config = TrifectaConfig(\n        segment=segment_id,\n        scope=scope,\n        repo_root=str(target_dir),\n        last_verified=time.strftime(\"%Y-%m-%d\"),\n        default_profile=\"impl_patch\",\n    )\n\n    files = {\n        \"skill.md\": template_renderer.render_skill(config),\n        \"readme_tf.md\": template_renderer.render_readme(config),\n        f\"_ctx/prime_{segment_id}.md\": template_renderer.render_prime(config, []),\n        f\"_ctx/agent_{segment_id}.md\": template_renderer.render_agent(config),\n        f\"_ctx/session_{segment_id}.md\": template_renderer.render_session(config),\n    }\n\n    try:\n        for rel_path, content in files.items():\n            full_path = target_dir / rel_path\n            full_path.parent.mkdir(parents=True, exist_ok=True)\n            if (\n                not full_path.exists()\n            ):  # Don't overwrite unless force? Removed overwrite flag previously.\n                full_path.write_text(content)\n\n        # Verify line count of skill.md\n        skill_lines = len(files[\"skill.md\"].splitlines())\n        if skill_lines > 100:\n            raise ValueError(f\"skill.md exceeds 100 lines ({skill_lines})\")\n\n        typer.echo(f\"✅ Trifecta created at {target_dir}\")\n        for f in files:\n            typer.echo(f\"   ├── {f}\")\n\n        # Show quick commands from session\n        typer.echo(\n            files[f\"_ctx/session_{segment_id}.md\"]\n            .split(\"## Quick Commands (CLI)\")[1]\n            .split(\"```\")[1]\n        )\n\n    except Exception as e:\n        typer.echo(_format_error(e, \"Creation Error\"), err=True)\n        raise typer.Exit(1)\n\n\n@app.command(\"validate-trifecta\", hidden=True, help=\"[DEPRECATED] Use 'ctx validate' instead.\")\ndef validate_trifecta(\n    segment: str = typer.Option(..., \"--segment\", \"-s\", help=HELP_SEGMENT),\n) -> None:\n    \"\"\"\n    Validate structure of a Trifecta Segment (files exist, YAML valid).\n\n    TIP: Run this after creating or modifying a Trifecta pack.\n    \"\"\"\n    _, file_system, _ = _get_dependencies(segment)\n    use_case = ValidateTrifectaUseCase(file_system)\n\n    # Validate path exists\n    path = Path(segment)\n\n    try:\n        output = use_case.execute(path)\n        typer.echo(output)\n    except Exception as e:\n        typer.echo(_format_error(e, \"Validation Error\"), err=True)\n        raise typer.Exit(1)\n\n\n@app.command(\"refresh-prime\", hidden=True, help=\"[DEPRECATED] Use 'ctx sync' instead.\")\ndef refresh_prime(\n    segment: str = typer.Option(..., \"--segment\", \"-s\", help=HELP_SEGMENT),\n) -> None:\n    \"\"\"\n    Regenerate `_ctx/prime_{segment}.md` with latest file list.\n\n    TIP: The prime file is located at _ctx/prime_{segment}.md\n    \"\"\"\n    template_renderer, file_system, _ = _get_dependencies(segment)\n    use_case = RefreshPrimeUseCase(template_renderer, file_system)\n\n    # Validate paths\n    path = Path(segment).resolve()\n    repo_root = path.parent if path.parent != path else path\n    scan_path = path\n\n    try:\n        output = use_case.execute(path, scan_path, repo_root)\n        typer.echo(output)\n    except Exception as e:\n        typer.echo(_format_error(e, \"Refresh Error\"), err=True)\n        raise typer.Exit(1)\n\n\n# =============================================================================\n# Load Command (Plan A/B)\n# =============================================================================\n\n\n@app.command()\ndef load(\n    segment: str = typer.Option(..., \"--segment\", \"-s\", help=HELP_SEGMENT),\n    task: str = typer.Option(..., \"--task\", \"-t\", help=\"Task description for context selection\"),\n    mode: str = typer.Option(\n        \"pcc\", \"--mode\", \"-m\", help=\"Mode: pcc (Plan A) or fullfiles (Plan B)\"\n    ),\n    telemetry_level: str = typer.Option(\"lite\", \"--telemetry\", help=HELP_TELEMETRY),\n) -> None:\n    \"\"\"Macro command to load relevant context for a specific task.\n\n    If context_pack.json exists, it uses Programmatic Context Calling (Plan A).\n    Otherwise, it falls back to heuristic file selection (Plan B).\n    \"\"\"\n    telemetry = _get_telemetry(segment, telemetry_level)\n    start_time = time.time()\n    _, file_system, _ = _get_dependencies(segment, telemetry)\n\n    use_case = MacroLoadUseCase(file_system, telemetry)\n\n    try:\n        target_path = Path(segment).resolve()\n        if not target_path.exists():\n            raise ValueError(f\"Segment path does not exist: {target_path}\")\n\n        output = use_case.execute(target_path, task, mode=mode)\n        typer.echo(output)\n        telemetry.event(\n            \"load\",\n            {\"segment\": segment, \"mode\": mode},\n            {\"status\": \"ok\"},\n            int((time.time() - start_time) * 1000),\n        )\n    except Exception as e:\n        telemetry.event(\n            \"load\",\n            {\"segment\": segment, \"mode\": mode},\n            {\"status\": \"error\"},\n            int((time.time() - start_time) * 1000),\n        )\n        typer.echo(_format_error(e, \"Load Error\"), err=True)\n        raise typer.Exit(1)\n    finally:\n        telemetry.flush()\n\n\n# =============================================================================\n# Session Commands\n# =============================================================================\n\n\n@session_app.command(\"append\")\ndef session_append(\n    segment: str = typer.Option(..., \"--segment\", \"-s\", help=HELP_SEGMENT),\n    summary: str = typer.Option(..., \"--summary\", help=\"Summary of work done\"),\n    files: str = typer.Option(\"\", \"--files\", help=\"Comma-separated list of files touched\"),\n    commands: str = typer.Option(\"\", \"--commands\", help=\"Comma-separated list of commands run\"),\n) -> None:\n    \"\"\"Append entry to session log (proactive logging without LLM).\"\"\"\n    import hashlib\n    from datetime import datetime, timezone\n\n    segment_path = Path(segment).resolve()\n    segment_name = segment_path.name\n    session_file = segment_path / \"_ctx\" / f\"session_{segment_name}.md\"\n\n    # Ensure _ctx directory exists\n    (segment_path / \"_ctx\").mkdir(parents=True, exist_ok=True)\n\n    # Get pack_sha if context_pack.json exists\n    pack_sha = None\n    pack_path = segment_path / \"_ctx\" / \"context_pack.json\"\n    if pack_path.exists():\n        try:\n            content = pack_path.read_bytes()\n            pack_sha = hashlib.sha256(content).hexdigest()[:16]\n        except Exception:\n            pass\n\n    # Parse CSV inputs\n    files_list = [f.strip() for f in files.split(\",\") if f.strip()]\n    commands_list = [c.strip() for c in commands.split(\",\") if c.strip()]\n\n    # Create entry\n    entry_lines = [\n        f\"## {datetime.now(timezone.utc).strftime('%Y-%m-%d %H:%M')} UTC\",\n        f\"- **Summary**: {summary}\",\n    ]\n\n    if files_list:\n        entry_lines.append(f\"- **Files**: {', '.join(files_list)}\")\n\n    if commands_list:\n        entry_lines.append(f\"- **Commands**: {', '.join(commands_list)}\")\n\n    if pack_sha:\n        entry_lines.append(f\"- **Pack SHA**: `{pack_sha}`\")\n\n    entry_lines.append(\"\")  # Blank line after entry\n\n    # Create or append to session file\n    if not session_file.exists():\n        # Create new file with header\n        header = f\"# Session Log - {segment_name}\\n\\n## History\\n\\n\"\n        session_file.write_text(header + \"\\n\".join(entry_lines), encoding=\"utf-8\")\n        typer.echo(f\"✅ Created {session_file.relative_to(segment_path)}\")\n    else:\n        # Append to existing file\n        with open(session_file, \"a\", encoding=\"utf-8\") as f:\n            f.write(\"\\n\".join(entry_lines) + \"\\n\")\n        typer.echo(f\"✅ Appended to {session_file.relative_to(segment_path)}\")\n\n    typer.echo(f\"   Summary: {summary}\")\n\n\n# =============================================================================\n# Telemetry Commands\n# =============================================================================\n\n\n@telemetry_app.command(\"report\")\ndef telemetry_report(\n    segment: str = typer.Option(..., \"--segment\", \"-s\", help=HELP_SEGMENT),\n    last: int = typer.Option(7, \"--last\", help=\"Last N days (0 = all)\"),\n    format_type: str = typer.Option(\"table\", \"--format\", help=\"Output format: table, json\"),\n) -> None:\n    \"\"\"Generate telemetry report.\"\"\"\n    segment_path = Path(segment).resolve()\n\n    report = generate_report(segment_path, last, format_type)\n    typer.echo(report)\n\n\n@telemetry_app.command(\"export\")\ndef telemetry_export(\n    segment: str = typer.Option(..., \"--segment\", \"-s\", help=HELP_SEGMENT),\n    format_type: str = typer.Option(\"json\", \"--format\", help=\"Export format: json, csv\"),\n    output: str = typer.Option(None, \"--output\", \"-o\", help=\"Output file path\"),\n) -> None:\n    \"\"\"Export telemetry data.\"\"\"\n    segment_path = Path(segment).resolve()\n    output_path = Path(output) if output else None\n\n    data = export_data(segment_path, format_type, output_path)\n\n    if output_path:\n        typer.echo(f\"✅ Exported to {output_path}\")\n    else:\n        typer.echo(data)\n\n\n@telemetry_app.command(\"chart\")\ndef telemetry_chart(\n    segment: str = typer.Option(..., \"--segment\", \"-s\", help=HELP_SEGMENT),\n    chart_type: str = typer.Option(\"hits\", \"--type\", help=\"Chart type: hits, latency, commands\"),\n    days: int = typer.Option(7, \"--days\", help=\"Last N days\"),\n) -> None:\n    \"\"\"Generate ASCII chart.\"\"\"\n    segment_path = Path(segment).resolve()\n\n    chart = generate_chart(segment_path, chart_type, days)\n    typer.echo(chart)\n\n\n@legacy_app.command(\"scan\")\ndef legacy_scan(\n    path: str = typer.Option(\".\", \"--path\", \"-p\", help=\"Root path to scan\"),\n) -> None:\n    \"\"\"Scan for undeclared legacy code. Fails if new legacy appears.\"\"\"\n    from src.application.legacy_use_case import scan_legacy\n    from src.domain.result import Err, Ok\n\n    repo_root = Path(path).resolve()\n    manifest_path = repo_root / \"docs/legacy_manifest.json\"\n\n    typer.echo(f\"🔍 Scanning for legacy debt in {repo_root}...\")\n    typer.echo(f\"   Manifest: {manifest_path}\")\n\n    match scan_legacy(repo_root, manifest_path):\n        case Ok(legacy_items):\n            typer.echo(\"✅ Legacy Check Passed.\")\n            if legacy_items:\n                typer.echo(f\"   Found {len(legacy_items)} declared legacy items (Technical Debt).\")\n            else:\n                typer.echo(\"   Zero legacy debt found!\")\n        case Err(errors):\n            typer.echo(\"❌ Legacy Check Failed (Undeclared Debt):\")\n            for err in errors:\n                typer.echo(f\"   - {err}\")\n            raise typer.Exit(code=1)\n\n\n# =============================================================================\n# Obsidian Integration Commands\n# =============================================================================\n\n\n@obsidian_app.command(\"sync\")\ndef obsidian_sync(\n    segment: str = typer.Option(\".\", \"--segment\", \"-s\", help=HELP_SEGMENT),\n    vault_path: Optional[str] = typer.Option(\n        None, \"--vault-path\", \"-v\", help=\"Obsidian vault path\"\n    ),\n    min_priority: str = typer.Option(\"P5\", \"--min-priority\", \"-p\", help=\"Minimum priority (P1-P5)\"),\n    dry_run: bool = typer.Option(False, \"--dry-run\", help=\"Preview without writing\"),\n    include_hookify: bool = typer.Option(\n        True, \"--include-hookify/--no-hookify\", help=\"Include hookify violations\"\n    ),\n    include_telemetry: bool = typer.Option(\n        True, \"--include-telemetry/--no-telemetry\", help=\"Include telemetry anomalies\"\n    ),\n    include_micro_audit: bool = typer.Option(\n        True, \"--include-micro-audit/--no-micro-audit\", help=\"Include micro-audit report findings\"\n    ),\n) -> None:\n    \"\"\"Sync findings to Obsidian vault as atomic notes.\"\"\"\n    segment_path = Path(segment).expanduser().resolve()\n\n    # Validate priority\n    valid_priorities = {\"P1\", \"P2\", \"P3\", \"P4\", \"P5\"}\n    if min_priority not in valid_priorities:\n        typer.echo(f\"❌ Invalid priority: {min_priority}. Must be one of {valid_priorities}\")\n        raise typer.Exit(code=1)\n\n    # Create use case with config\n    try:\n        use_case = create_sync_use_case(\n            vault_path=Path(vault_path).expanduser() if vault_path else None,\n            min_priority=min_priority,  # type: ignore\n        )\n    except Exception as e:\n        typer.echo(f\"❌ Configuration error: {e}\")\n        typer.echo(\"\\n💡 Tip: Run 'trifecta obsidian config --vault-path <path>' first\")\n        raise typer.Exit(code=1)\n\n    # Execute sync\n    sources = {\n        \"hookify\": include_hookify,\n        \"telemetry\": include_telemetry,\n        \"micro_audit\": include_micro_audit,\n    }\n\n    try:\n        result = use_case.execute(\n            segment_path=segment_path,\n            min_priority=min_priority,  # type: ignore\n            dry_run=dry_run,\n            sources=sources,\n        )\n    except RuntimeError as e:\n        typer.echo(f\"❌ Sync failed: {e}\")\n        raise typer.Exit(code=1)\n\n    # Show summary\n    typer.echo(\"\\n✨ Sync complete!\")\n    typer.echo(\n        f\"  Sources: {', '.join(result.active_sources) if result.active_sources else 'None'}\"\n    )\n    typer.echo(f\"  Findings: {result.total_findings}\")\n    typer.echo(f\"  Notes created: {result.notes_created}\")\n    typer.echo(f\"  Notes updated: {result.notes_updated}\")\n    typer.echo(f\"  Notes skipped: {result.notes_skipped}\")\n    typer.echo(f\"  Duration: {result.duration_ms}ms\")\n\n    if dry_run and result.previews:\n        typer.echo(f\"\\n🔍 Dry-run mode - {len(result.previews)} notes would be created:\")\n        for preview in result.previews[:5]:  # Show first 5\n            typer.echo(f\"\\n  📄 {preview['path']}\")\n            typer.echo(f\"     {preview['content'][:200]}...\")\n        if len(result.previews) > 5:\n            typer.echo(f\"\\n  ... and {len(result.previews) - 5} more\")\n\n\n@obsidian_app.command(\"config\")\ndef obsidian_config(\n    vault_path: Optional[str] = typer.Option(None, \"--vault-path\", \"-v\", help=\"Set vault path\"),\n    show: bool = typer.Option(False, \"--show\", help=\"Show current config\"),\n) -> None:\n    \"\"\"Configure Obsidian integration.\"\"\"\n    config_manager = ObsidianConfigManager()\n\n    if show:\n        typer.echo(config_manager.show())\n    elif vault_path:\n        config = config_manager.load()\n        # Update vault path\n        from src.domain.obsidian_models import ObsidianConfig\n\n        new_config = ObsidianConfig(\n            vault_path=Path(vault_path).expanduser().resolve(),\n            default_segment=config.default_segment,\n            min_priority=config.min_priority,\n            note_folder=config.note_folder,\n            auto_link=config.auto_link,\n            date_format=config.date_format,\n        )\n        config_manager.save(new_config)\n        typer.echo(f\"✅ Vault path set to: {new_config.vault_path}\")\n        typer.echo(\"\\nRun 'trifecta obsidian config --show' to see full config\")\n    else:\n        typer.echo(\"Usage:\")\n        typer.echo(\"  trifecta obsidian config --vault-path <path>   Set vault path\")\n        typer.echo(\"  trifecta obsidian config --show               Show current config\")\n        raise typer.Exit(code=1)\n\n\n@obsidian_app.command(\"validate\")\ndef obsidian_validate() -> None:\n    \"\"\"Validate Obsidian vault configuration.\"\"\"\n    try:\n        use_case = create_sync_use_case()\n    except Exception as e:\n        typer.echo(f\"❌ Configuration error: {e}\")\n        raise typer.Exit(code=1)\n\n    validation = use_case.validate_vault()\n\n    if validation.valid:\n        typer.echo(\"✅ Vault is valid and writable\")\n        typer.echo(f\"   Findings folder: {validation.findings_dir}\")\n        typer.echo(f\"   Existing notes: {validation.existing_notes}\")\n    else:\n        typer.echo(\"❌ Vault validation failed\")\n        typer.echo(f\"   Error: {validation.error}\")\n        raise typer.Exit(code=1)\n\n\ndef main() -> None:\n    \"\"\"Main entry point with custom error handling for invalid options.\"\"\"\n    try:\n        # Use standalone_mode=False to capture exceptions\n        # Note: typer.Exit is converted to a return value when standalone_mode=False\n        exit_code = app(standalone_mode=False)\n\n        # If app returned a non-zero exit code, exit with it\n        if exit_code is not None and exit_code != 0:\n            sys.exit(exit_code)\n\n    except UsageError as e:\n        # Handle Click UsageError (includes \"No such option\" errors)\n        error_msg = str(e)\n\n        # Check if this is an invalid option error\n        if \"no such option\" in error_msg.lower():\n            enhanced_msg = handle_invalid_option_error(error_msg, sys.argv)\n            typer.echo(enhanced_msg, err=True)\n            sys.exit(2)\n\n        # For other usage errors, show the original message\n        typer.echo(f\"Error: {error_msg}\", err=True)\n        sys.exit(2)\n    except click.exceptions.Exit as e:\n        # Handle Click/typer.Exit exceptions (inherited from RuntimeError, not SystemExit)\n        if e.exit_code != 0:\n            sys.exit(e.exit_code)\n    except SystemExit as e:\n        # Handle normal exit codes\n        if e.code != 0:\n            sys.exit(e.code)\n    except Exception as e:\n        # Handle unexpected errors\n        typer.echo(f\"Error: {e}\", err=True)\n        sys.exit(1)\n\n\nif __name__ == \"__main__\":\n    main()\n# Audit Trigger\n# Audit Trigger Code\n",
-      "char_count": 62853,
-      "token_est": 15713,
+      "text": "\"\"\"Trifecta CLI with T8 Telemetry.\"\"\"\n\nimport json\nimport os\nimport sys\nimport time\nimport traceback\nfrom pathlib import Path\nfrom typing import Literal, Optional, Tuple\n\nimport click\nimport typer  # type: ignore\nfrom click.exceptions import UsageError\n\n# AST/LSP Integration (Phase 2a/2b)\nfrom src.infrastructure.cli_ast import ast_app\n\nfrom src.cli.invalid_option_handler import handle_invalid_option_error\nfrom src.application.search_get_usecases import GetChunkUseCase, SearchUseCase\nfrom src.application.telemetry_charts import generate_chart\nfrom src.application.telemetry_reports import export_data, generate_report\nfrom src.application.plan_use_case import PlanUseCase\nfrom src.application.stub_regen_use_case import StubRegenUseCase\nfrom src.application.pcc_metrics import parse_feature_map, evaluate_pcc, summarize_pcc\nfrom src.application.use_cases import (\n    BuildContextPackUseCase,\n    MacroLoadUseCase,\n    RefreshPrimeUseCase,\n    StatsUseCase,\n    ValidateContextPackUseCase,\n    ValidateTrifectaUseCase,\n)\nfrom src.domain.models import TrifectaConfig\n\nfrom src.infrastructure.file_system import FileSystemAdapter\nfrom src.infrastructure.telemetry import Telemetry\nfrom src.infrastructure.templates import TemplateRenderer\nfrom src.application.obsidian_sync_use_case import create_sync_use_case\nfrom src.infrastructure.obsidian_config import ObsidianConfigManager\n\n\nclass TrifectaGroup(typer.core.TyperGroup):\n    \"\"\"Custom Typer Group with enhanced error handling for invalid options.\"\"\"\n\n    def __call__(self, *args, **kwargs):\n        \"\"\"Override to catch and enhance invalid option errors.\"\"\"\n        try:\n            return self.main(*args, **kwargs)\n        except UsageError as e:\n            # Handle invalid option errors with enhanced messaging\n            error_msg = str(e)\n            if \"no such option\" in error_msg.lower():\n                enhanced_msg = handle_invalid_option_error(error_msg, sys.argv)\n                typer.echo(enhanced_msg, err=True)\n                sys.exit(2)\n            # Re-raise other usage errors\n            raise\n\n\napp = typer.Typer(\n    name=\"trifecta\",\n    help=\"Trifecta Context Engine v2.0 - Agentic Context Management (PCC).\",\n    rich_markup_mode=\"rich\",\n    cls=TrifectaGroup,\n)\n\napp.add_typer(ast_app, name=\"ast\")\n\nctx_app = typer.Typer(\n    help=\"Manage Trifecta Context Packs (ctx.search, ctx.get).\",\n    cls=TrifectaGroup,\n)\nsession_app = typer.Typer(help=\"Session logging commands\", cls=TrifectaGroup)\ntelemetry_app = typer.Typer(help=\"Telemetry analysis commands\", cls=TrifectaGroup)\nobsidian_app = typer.Typer(help=\"Obsidian vault integration for findings\", cls=TrifectaGroup)\n\napp.add_typer(ctx_app, name=\"ctx\")\napp.add_typer(session_app, name=\"session\")\napp.add_typer(telemetry_app, name=\"telemetry\")\napp.add_typer(obsidian_app, name=\"obsidian\")\n\n# Legacy Burn-Down\nlegacy_app = typer.Typer(help=\"Legacy Burn-Down commands\", cls=TrifectaGroup)\napp.add_typer(legacy_app, name=\"legacy\")\n\nHELP_SEGMENT = \"Target segment path (e.g., 'debug_terminal' or '.')\"\nHELP_TELEMETRY = \"Telemetry level: off, lite (default), full\"\n\nHELP_TELEMETRY = \"Telemetry level: off, lite (default), full\"\n\n\ndef _get_telemetry(segment: str, level: str) -> Telemetry:\n    \"\"\"Initialize telemetry.\"\"\"\n    # Convert segment string to path\n    path = Path(segment).resolve()\n    # Check env override\n    env_level = os.environ.get(\"TRIFECTA_TELEMETRY_LEVEL\", level)\n    return Telemetry(path, level=env_level)\n\n\ndef _get_lint_enabled(no_lint_flag: bool) -> bool:\n    \"\"\"Determine if linting should be enabled based on flag + env var.\n\n    Precedence:\n    1. --no-lint flag = True → disabled\n    2. TRIFECTA_LINT env var = \"0\" or \"false\" → disabled\n    3. TRIFECTA_LINT env var = \"1\" or \"true\" → enabled\n    4. Default: DISABLED (conservative rollout)\n\n    This allows gradual rollout without breaking existing workflows.\n    \"\"\"\n    if no_lint_flag:\n        return False\n    env_val = os.environ.get(\"TRIFECTA_LINT\", \"\").lower()\n    if env_val in (\"0\", \"false\", \"no\"):\n        return False\n    if env_val in (\"1\", \"true\", \"yes\"):\n        return True\n    return False  # Conservative default: OFF until explicitly enabled\n\n\ndef _get_dependencies(\n    segment: str, telemetry: Optional[Telemetry] = None\n) -> Tuple[TemplateRenderer, FileSystemAdapter, Optional[Telemetry]]:\n    # Simplified: just return filesystem and template renderer\n    fs = FileSystemAdapter()\n    template_renderer = TemplateRenderer()\n    return template_renderer, fs, telemetry\n\n\ndef _format_error(e: Exception, title: str = \"Error\") -> str:\n    \"\"\"Format exceptions for CLI output.\"\"\"\n    return f\"❌ {title}\\n   Detail: {str(e)}\"\n\n\n# =============================================================================\n# T8: Stats Command\n# =============================================================================\n\n\n@ctx_app.command(\"stats\")\ndef ctx_stats(\n    segment: str = typer.Option(..., \"--segment\", \"-s\", help=HELP_SEGMENT),\n) -> None:\n    \"\"\"[T8] Show telemetry stats for a segment.\"\"\"\n    path = Path(segment).resolve()\n    telemetry_dir = path / \"_ctx\" / \"telemetry\"\n\n    if not telemetry_dir.exists():\n        typer.echo(f\"No telemetry found at {telemetry_dir}\")\n        return\n\n    # Load metrics\n    metrics = {}\n    metrics_path = telemetry_dir / \"metrics.json\"\n    if metrics_path.exists():\n        try:\n            metrics = json.loads(metrics_path.read_text())\n        except Exception:\n            pass\n\n    # Load last run\n    last_run = {}\n    last_run_path = telemetry_dir / \"last_run.json\"\n    if last_run_path.exists():\n        try:\n            last_run = json.loads(last_run_path.read_text())\n        except Exception:\n            pass\n\n    typer.echo(f\"📊 Telemetry for {segment}\")\n    typer.echo(f\"Path: {telemetry_dir}\\n\")\n\n    typer.echo(\"Counters:\")\n    for k, v in sorted(metrics.items()):\n        typer.echo(f\"  {k}: {v}\")\n\n    # Alias expansion summary\n    alias_expansion_count = metrics.get(\"ctx_search_alias_expansion_count\", 0)\n    alias_terms_total = metrics.get(\"ctx_search_alias_terms_total\", 0)\n    search_count = metrics.get(\"ctx_search_count\", 0)\n\n    if alias_expansion_count > 0 and search_count > 0:\n        avg_terms = alias_terms_total / alias_expansion_count if alias_expansion_count > 0 else 0\n        typer.echo(\"\\nAlias Expansion:\")\n        typer.echo(\n            f\"  {alias_expansion_count} searches expanded ({alias_expansion_count / search_count * 100:.1f}%), avg {avg_terms:.1f} terms\"\n        )\n\n    if last_run:\n        typer.echo(\"\\nLast Run:\")\n        typer.echo(f\"  Timestamp: {last_run.get('ts', 'unknown')}\")\n        latencies = last_run.get(\"latencies\", {})\n        if latencies:\n            typer.echo(\"  Latencies:\")\n            for cmd, stats in latencies.items():\n                count = stats.get(\"count\", 0)\n                # Read new keys (p50_ms, p95_ms, max_ms) with backward compat\n                p50 = stats.get(\"p50_ms\", stats.get(\"p50\", 0))\n                p95 = stats.get(\"p95_ms\", stats.get(\"p95\", 0))\n                max_ms = stats.get(\"max_ms\", stats.get(\"max\", 0))\n\n                if count == 0:\n                    typer.echo(f\"    {cmd}: no samples\")\n                else:\n                    typer.echo(\n                        f\"    {cmd}: p50={p50:.3f}ms p95={p95:.3f}ms max={max_ms:.3f}ms (n={count})\"\n                    )\n\n        warnings = last_run.get(\"top_warnings\", [])\n        if warnings:\n            typer.echo(\"\\n  Top Warnings:\")\n            for w in warnings:\n                typer.echo(f\"    - {w}\")\n\n\n# =============================================================================\n# Context Commands\n# =============================================================================\n\n\n@ctx_app.command(\"build\")\ndef build(\n    segment: str = typer.Option(..., \"--segment\", \"-s\", help=HELP_SEGMENT),\n    telemetry_level: str = typer.Option(\"lite\", \"--telemetry\", help=HELP_TELEMETRY),\n) -> None:\n    \"\"\"Build a Context Pack (context_pack.json) for a segment.\"\"\"\n    from src.domain.result import Err, Ok\n    from src.infrastructure.validators import (\n        detect_legacy_context_files,\n        validate_agents_constitution,\n        validate_segment_fp,\n    )\n\n    segment_root = Path(segment)\n    telemetry = _get_telemetry(segment, telemetry_level)\n    start_time = time.time()\n\n    # FP Gate: North Star Strict Validation\n    match validate_segment_fp(segment_root):\n        case Err(errors):\n            typer.echo(\"❌ Validation Failed (North Star Gate):\")\n            for err in errors:\n                typer.echo(f\"   - {err}\")\n            telemetry.event(\n                \"ctx.build\",\n                {\"segment\": segment},\n                {\"status\": \"validation_failed\", \"errors\": len(errors)},\n                int((time.time() - start_time) * 1000),\n            )\n            telemetry.flush()\n            raise typer.Exit(code=1)\n        case Ok(_):\n            # 1. Fail-Closed: AGENTS.md Constitution\n            match validate_agents_constitution(segment_root):\n                case Err(errors):\n                    typer.echo(\"❌ Constitution Failed (AGENTS.md):\")\n                    for err in errors:\n                        typer.echo(f\"   - {err}\")\n                    telemetry.event(\n                        \"ctx.build\",\n                        {\"segment\": segment},\n                        {\"status\": \"constitution_failed\", \"errors\": len(errors)},\n                        int((time.time() - start_time) * 1000),\n                    )\n                    telemetry.flush()\n                    raise typer.Exit(code=1)\n                case Ok(_):\n                    pass\n\n            # 2. Check for legacy file errors (Blocking)\n            legacy = detect_legacy_context_files(segment_root)\n            if legacy:\n                typer.echo(\"❌ Legacy context files detected (Fail-Closed):\")\n                for lf in legacy:\n                    typer.echo(f\"   - _ctx/{lf} (rename to suffix format: rule 3+1)\")\n                telemetry.event(\n                    \"ctx.build\",\n                    {\"segment\": segment},\n                    {\"status\": \"legacy_files_error\", \"count\": len(legacy)},\n                    int((time.time() - start_time) * 1000),\n                )\n                telemetry.flush()\n                raise typer.Exit(code=1)\n\n    _, file_system, _ = _get_dependencies(segment, telemetry)\n    use_case = BuildContextPackUseCase(file_system, telemetry)\n    segment_fs = segment_root.resolve()\n\n    try:\n        match use_case.execute(segment_fs):\n            case Ok(pack):\n                typer.echo(pack)\n                telemetry.event(\n                    \"ctx.build\",\n                    {\"segment\": segment},\n                    {\"status\": \"ok\"},\n                    int((time.time() - start_time) * 1000),\n                )\n            case Err(errors):\n                typer.echo(\"❌ Build Failed:\")\n                for err in errors:\n                    typer.echo(f\"   - {err}\")\n                telemetry.event(\n                    \"ctx.build\",\n                    {\"segment\": segment},\n                    {\"status\": \"build_error\", \"errors\": len(errors)},\n                    int((time.time() - start_time) * 1000),\n                )\n                telemetry.flush()\n                raise typer.Exit(code=1)\n    except Exception as e:\n        telemetry.event(\n            \"ctx.build\",\n            {\"segment\": segment},\n            {\"status\": \"error\", \"error\": str(e)},\n            int((time.time() - start_time) * 1000),\n        )\n        typer.echo(_format_error(e, \"Build Failed\"), err=True)\n        raise typer.Exit(1)\n    finally:\n        telemetry.flush()\n\n\n@ctx_app.command(\"search\")\ndef search(\n    query: str = typer.Option(..., \"--query\", \"-q\", help=\"Search query\"),\n    segment: str = typer.Option(..., \"--segment\", \"-s\", help=HELP_SEGMENT),\n    limit: int = typer.Option(5, \"--limit\", \"-l\", help=\"Max results\"),\n    telemetry_level: str = typer.Option(\"lite\", \"--telemetry\", help=HELP_TELEMETRY),\n    no_lint: bool = typer.Option(\n        False, \"--no-lint\", help=\"Disable query linting (anchor guidance expansion)\"\n    ),\n) -> None:\n    \"\"\"Search for relevant chunks in the Context Pack.\n\n    Query Processing Pipeline:\n    1. Normalization: lowercase, strip, collapse whitespace\n    2. Linting (optional): anchor-based classification + expansion for vague queries\n    3. Tokenization: tokenize the FINAL query (post-linter)\n    4. Alias Expansion: synonym-based expansion using _ctx/aliases.yaml\n    5. Search: execute weighted search across all terms\n\n    Controls:\n      --no-lint              Disable linting for this search\n      TRIFECTA_LINT=0/1       Env var to enable/disable globally\n      Default: DISABLED (conservative rollout)\n\n    To ENABLE linting: omit --no-lint flag or set TRIFECTA_LINT=1\n    \"\"\"\n    telemetry = _get_telemetry(segment, telemetry_level)\n    start_time = time.time()\n    _, file_system, _ = _get_dependencies(segment, telemetry)\n\n    use_case = SearchUseCase(file_system, telemetry)\n\n    try:\n        # Determine if linting should be enabled (conservative default)\n        enable_lint = _get_lint_enabled(no_lint)\n        output = use_case.execute(\n            Path(segment).resolve(), query, limit=limit, enable_lint=enable_lint\n        )\n        typer.echo(output)\n        telemetry.observe(\"ctx.search\", int((time.time() - start_time) * 1000))\n    except Exception as e:\n        telemetry.event(\n            \"ctx.search\",\n            {\"query\": query},\n            {\"status\": \"error\"},\n            int((time.time() - start_time) * 1000),\n        )\n        typer.echo(_format_error(e, \"Search Error\"), err=True)\n        raise typer.Exit(1)\n    finally:\n        telemetry.flush()\n\n\n@ctx_app.command(\"get\")\ndef get(\n    ids: str = typer.Option(..., \"--ids\", \"-i\", help=\"Comma-separated Chunk IDs\"),\n    segment: str = typer.Option(..., \"--segment\", \"-s\", help=HELP_SEGMENT),\n    mode: Literal[\"raw\", \"excerpt\", \"skeleton\"] = typer.Option(\n        \"excerpt\", \"--mode\", \"-m\", help=\"Output mode: raw, excerpt, summary\"\n    ),\n    budget_token_est: int = typer.Option(1500, \"--budget-token-est\", \"-b\", help=\"Max token budget\"),\n    max_chunks: Optional[int] = typer.Option(\n        None, \"--max-chunks\", help=\"Max chunks to retrieve (early-stop)\"\n    ),\n    stop_on_evidence: bool = typer.Option(\n        False, \"--stop-on-evidence\", help=\"Stop early when evidence found (feature flag)\"\n    ),\n    query: Optional[str] = typer.Option(\n        None, \"--query\", \"-q\", help=\"Query term for evidence matching\"\n    ),\n    pd_report: bool = typer.Option(\n        False, \"--pd-report\", help=\"Output parseable PD metrics line (for testing)\"\n    ),\n    telemetry_level: str = typer.Option(\"lite\", \"--telemetry\", help=HELP_TELEMETRY),\n) -> None:\n    \"\"\"Retrieve full content for specific chunks.\"\"\"\n    telemetry = _get_telemetry(segment, telemetry_level)\n    start_time = time.time()\n    _, file_system, _ = _get_dependencies(segment, telemetry)\n\n    use_case = GetChunkUseCase(file_system, telemetry)\n\n    id_list = [x.strip() for x in ids.split(\",\") if x.strip()]\n\n    # Agent-safe defaults: Check env vars if CLI flags not provided\n    effective_max_chunks = max_chunks\n    if effective_max_chunks is None:\n        import os\n\n        env_max_chunks = os.environ.get(\"TRIFECTA_PD_MAX_CHUNKS\")\n        if env_max_chunks:\n            try:\n                effective_max_chunks = int(env_max_chunks)\n            except ValueError:\n                pass  # Ignore invalid env var, use None\n\n    effective_stop_on_evidence = stop_on_evidence\n    if not effective_stop_on_evidence:\n        import os\n\n        env_stop_on_evidence = os.environ.get(\"TRIFECTA_PD_STOP_ON_EVIDENCE\")\n        if env_stop_on_evidence and env_stop_on_evidence == \"1\":\n            effective_stop_on_evidence = True\n\n    try:\n        # Use execute_with_result when --pd-report is active for access to GetResult\n        if pd_report:\n            output, result = use_case.execute_with_result(\n                Path(segment).resolve(),\n                id_list,\n                mode=mode,\n                budget_token_est=budget_token_est,\n                max_chunks=effective_max_chunks,\n                stop_on_evidence=effective_stop_on_evidence,\n                query=query,\n            )\n            typer.echo(output)\n\n            # Emit PD_REPORT with version and invariant keys\n            strong_hit = 1 if result.evidence_metadata.get(\"strong_hit\") else 0\n            support = 1 if result.evidence_metadata.get(\"support\") else 0\n            typer.echo(\n                f\"PD_REPORT v=1 \"\n                f\"stop_reason={result.stop_reason} \"\n                f\"chunks_returned={result.chunks_returned} \"\n                f\"chunks_requested={result.chunks_requested} \"\n                f\"chars_returned_total={result.chars_returned_total} \"\n                f\"strong_hit={strong_hit} \"\n                f\"support={support}\"\n            )\n        else:\n            # Standard path: just get output string\n            output = use_case.execute(\n                Path(segment).resolve(),\n                id_list,\n                mode=mode,\n                budget_token_est=budget_token_est,\n                max_chunks=effective_max_chunks,\n                stop_on_evidence=effective_stop_on_evidence,\n                query=query,\n            )\n            typer.echo(output)\n\n        telemetry.observe(\"ctx.get\", int((time.time() - start_time) * 1000))\n    except Exception as e:\n        telemetry.event(\n            \"ctx.get\", {\"ids\": ids}, {\"status\": \"error\"}, int((time.time() - start_time) * 1000)\n        )\n        typer.echo(_format_error(e, \"Get Error\"), err=True)\n        raise typer.Exit(1)\n    finally:\n        telemetry.flush()\n\n\n@ctx_app.command(\"validate\")\ndef validate(\n    segment: str = typer.Option(..., \"--segment\", \"-s\", help=HELP_SEGMENT),\n    telemetry_level: str = typer.Option(\"lite\", \"--telemetry\", help=HELP_TELEMETRY),\n) -> None:\n    \"\"\"Validate Context Pack health.\"\"\"\n    telemetry = _get_telemetry(segment, telemetry_level)\n    start_time = time.time()\n    _, file_system, _ = _get_dependencies(segment, telemetry)\n\n    use_case = ValidateContextPackUseCase(file_system, telemetry)\n\n    try:\n        result = use_case.execute(Path(segment).resolve())\n        # Format ValidationResult for display\n        if result.passed:\n            output = \"✅ Validation Passed\"\n            if result.warnings:\n                output += \"\\n\\n⚠️  Warnings:\\n\" + \"\\n\".join(f\"   - {w}\" for w in result.warnings)\n        else:\n            output = \"❌ Validation Failed\\n\\n\" + \"\\n\".join(f\"   - {e}\" for e in result.errors)\n\n        typer.echo(output)\n        telemetry.observe(\"ctx.validate\", int((time.time() - start_time) * 1000))\n\n        # Exit with error code if validation failed\n        if not result.passed:\n            raise typer.Exit(code=1)\n\n    except Exception as e:\n        telemetry.event(\n            \"ctx.validate\", {}, {\"status\": \"error\"}, int((time.time() - start_time) * 1000)\n        )\n        typer.echo(_format_error(e, \"Validation Error\"), err=True)\n        if not isinstance(e, typer.Exit):\n            raise typer.Exit(1)\n        raise e\n    finally:\n        telemetry.flush()\n\n\n@ctx_app.command(\"stats\")\ndef stats(\n    segment: str = typer.Option(..., \"--segment\", \"-s\", help=HELP_SEGMENT),\n    window: int = typer.Option(0, \"--window\", \"-w\", help=\"Days to look back (0 = all)\"),\n    telemetry_level: str = typer.Option(\"lite\", \"--telemetry\", help=HELP_TELEMETRY),\n) -> None:\n    \"\"\"Show telemetry statistics for the segment.\"\"\"\n    telemetry = _get_telemetry(segment, telemetry_level)\n    start_time = time.time()\n    _, file_system, _ = _get_dependencies(segment, telemetry)\n\n    use_case = StatsUseCase(file_system, telemetry)\n\n    try:\n        result = use_case.execute(Path(segment), window=window)\n\n        # Format output\n        lines = []\n        lines.append(\"╭\" + \"─\" * 50 + \"╮\")\n        lines.append(\"│\" + \" \" * 15 + \"Trifecta Stats\" + \" \" * 23 + \"│\")\n        lines.append(\n            f\"│           Last {window} days\"\n            if window > 0\n            else \"│                  All time\" + \" \" * 22 + \"│\"\n        )\n        lines.append(\"╰\" + \"─\" * 50 + \"╯\")\n        lines.append(\"\")\n\n        # Summary\n        summary = result[\"summary\"]\n        lines.append(\"Summary\")\n        lines.append(\"─\" * 50)\n        lines.append(f\"  Total searches:      {summary['total_searches']}\")\n        lines.append(f\"  Hits:                {summary['hits']}\")\n        lines.append(f\"  Zero hits:           {summary['zero_hits']}\")\n        lines.append(f\"  Hit rate:            {summary['hit_rate']}%\")\n        lines.append(f\"  Avg latency:         {summary['avg_latency_ms']:.1f}ms\")\n        lines.append(\"\")\n\n        # Top zero-hit queries\n        lines.append(\"Top Zero-Hit Queries\")\n        lines.append(\"─\" * 50)\n        for item in result[\"top_zero_hit_queries\"][:10]:\n            lines.append(f\"  [{item['count']:2d}] {item['query'][:50]}\")\n        lines.append(\"\")\n\n        # Query type breakdown\n        lines.append(\"Query Type Breakdown\")\n        lines.append(\"─\" * 50)\n        total = sum(result[\"query_type_breakdown\"].values())\n        for qtype in [\"meta\", \"impl\", \"unknown\"]:\n            count = result[\"query_type_breakdown\"].get(qtype, 0)\n            pct = count / total * 100 if total > 0 else 0\n            lines.append(f\"  {qtype:<10} {count:>3}  ({pct:>5.1f}%)\")\n        lines.append(\"\")\n\n        # Hit target breakdown\n        if result[\"hit_target_breakdown\"]:\n            lines.append(\"Hit Target Breakdown\")\n            lines.append(\"─\" * 50)\n            total_hits = sum(result[\"hit_target_breakdown\"].values())\n            for target, count in sorted(\n                result[\"hit_target_breakdown\"].items(), key=lambda x: -x[1]\n            ):\n                pct = count / total_hits * 100 if total_hits > 0 else 0\n                lines.append(f\"  {target:<10} {count:>3}  ({pct:>5.1f}%)\")\n            lines.append(\"\")\n\n        typer.echo(\"\\n\".join(lines))\n        telemetry.observe(\"ctx.stats\", int((time.time() - start_time) * 1000))\n\n    except Exception as e:\n        telemetry.event(\n            \"ctx.stats\", {}, {\"status\": \"error\"}, int((time.time() - start_time) * 1000)\n        )\n        typer.echo(_format_error(e, \"Stats Error\"), err=True)\n        raise typer.Exit(1)\n    finally:\n        telemetry.flush()\n\n\n@ctx_app.command(\"plan\")\ndef plan(\n    segment: str = typer.Option(..., \"--segment\", \"-s\", help=HELP_SEGMENT),\n    task: str = typer.Option(..., \"--task\", \"-t\", help=\"Task description to plan\"),\n    telemetry_level: str = typer.Option(\"lite\", \"--telemetry\", help=HELP_TELEMETRY),\n    json_output: bool = typer.Option(False, \"--json\", \"-j\", help=\"Output as JSON\"),\n) -> None:\n    \"\"\"Generate execution plan using PRIME index (no RAG).\"\"\"\n    telemetry = _get_telemetry(segment, telemetry_level)\n    _, file_system, _ = _get_dependencies(segment, telemetry)\n\n    use_case = PlanUseCase(file_system, telemetry)\n\n    try:\n        result = use_case.execute(Path(segment).resolve(), task)\n\n        if json_output:\n            typer.echo(json.dumps(result, indent=2))\n        else:\n            # Human-readable output\n            lines = []\n            lines.append(\"╭\" + \"─\" * 50 + \"╮\")\n            lines.append(\"│\" + \" \" * 12 + \"Execution Plan\" + \" \" * 24 + \"│\")\n            lines.append(\"╰\" + \"─\" * 50 + \"╯\")\n            lines.append(\"\")\n\n            status = \"✅ HIT\" if result[\"plan_hit\"] else \"⚠️ NO HIT\"\n            lines.append(f\"Status: {status}\")\n            lines.append(\"\")\n\n            if result[\"selected_feature\"]:\n                lines.append(f\"Selected Feature: {result['selected_feature']}\")\n            else:\n                lines.append(\"Selected Feature: (none - using entrypoints)\")\n            lines.append(\"\")\n\n            if result[\"chunk_ids\"]:\n                lines.append(f\"Chunk IDs: {', '.join(result['chunk_ids'][:3])}\")\n                lines.append(f\"            ... ({len(result['chunk_ids'])} total)\")\n            else:\n                lines.append(\"Chunk IDs: (none)\")\n            lines.append(\"\")\n\n            if result[\"paths\"]:\n                lines.append(f\"Paths: {', '.join(result['paths'][:3])}\")\n                if len(result[\"paths\"]) > 3:\n                    lines.append(f\"       ... ({len(result['paths'])} total)\")\n            else:\n                lines.append(\"Paths: (entrypoints)\")\n            lines.append(\"\")\n\n            lines.append(\"Next Steps:\")\n            for i, step in enumerate(result[\"next_steps\"], 1):\n                lines.append(f\"  {i}. {step['action'].capitalize()}: {step['target']}\")\n            lines.append(\"\")\n\n            budget = result[\"budget_est\"]\n            lines.append(f\"Budget Estimate: ~{budget['tokens']} tokens\")\n            lines.append(f\"  ({budget['why']})\")\n            lines.append(\"\")\n\n            typer.echo(\"\\n\".join(lines))\n\n    except Exception as e:\n        typer.echo(_format_error(e, \"Plan Error\"), err=True)\n        raise typer.Exit(1)\n\n\n@ctx_app.command(\"eval-plan\")\ndef eval_plan(\n    segment: str = typer.Option(..., \"--segment\", \"-s\", help=HELP_SEGMENT),\n    dataset: str = typer.Option(\n        \"docs/plans/t9_plan_eval_tasks.md\",\n        \"--dataset\",\n        \"-d\",\n        help=\"Path to evaluation dataset markdown file\",\n    ),\n    telemetry_level: str = typer.Option(\"lite\", \"--telemetry\", help=HELP_TELEMETRY),\n    verbose: bool = typer.Option(False, \"--verbose\", \"-v\", help=\"Show per-task breakdown\"),\n) -> None:\n    \"\"\"Evaluate ctx.plan against a dataset of tasks.\"\"\"\n    import hashlib\n    import re\n    from datetime import datetime\n\n    telemetry = _get_telemetry(segment, telemetry_level)\n    _, file_system, _ = _get_dependencies(segment, telemetry)\n\n    # Load PRIME for PCC metrics\n    segment_path = Path(segment).resolve()\n    prime_files = list(segment_path.glob(\"_ctx/prime_*.md\"))\n    prime_path = prime_files[0] if prime_files else None\n    feature_map = {}\n    if prime_path:\n        try:\n            feature_map = parse_feature_map(prime_path)\n        except Exception as e:\n            typer.echo(f\"⚠️  PCC Metrics: Failed to parse feature_map from {prime_path.name}\")\n            typer.echo(f\"   Error: {e}\")\n            typer.echo(\"   PCC metrics will be disabled for this run.\")\n            typer.echo(\"\")\n\n    # Load dataset from markdown\n    dataset_path = Path(dataset).resolve()\n    if not dataset_path.exists():\n        typer.echo(f\"❌ Dataset file not found: {dataset_path}\")\n        raise typer.Exit(1)\n\n    content = dataset_path.read_text()\n\n    # Dataset identity for anti-gaming (T9.3.1)\n    dataset_sha256 = hashlib.sha256(content.encode()).hexdigest()[:16]\n    dataset_mtime = datetime.fromtimestamp(dataset_path.stat().st_mtime).isoformat()\n\n    # Extract tasks from markdown (quoted strings after numbers)\n    tasks = re.findall(r'^\\d+\\.\\s+\"([^\"]+)\"', content, re.MULTILINE)\n\n    # Parse expected_feature_id from dataset (T9.3.2)\n    # Format: number. \"task\" | expected_feature_id | notes\n    expected_features = {}\n    for line in content.split(\"\\n\"):\n        match = re.match(r'^\\d+\\.\\s+\"([^\"]+)\"\\s*\\|\\s*(\\w+)', line)\n        if match:\n            task_str = match.group(1)\n            expected_id = match.group(2)\n            expected_features[task_str] = expected_id\n\n    if not tasks:\n        typer.echo(\"❌ No tasks found in dataset file\")\n        raise typer.Exit(1)\n\n    # Run evaluation\n    use_case = PlanUseCase(file_system, telemetry)\n\n    results = []\n    feature_count = 0\n    nl_trigger_count = 0\n    alias_count = 0\n    fallback_count = 0\n    true_zero_count = 0\n    correct_predictions = 0  # T9.3.2: plan_accuracy_top1\n    pcc_metrics_rows = []  # PCC metrics per task\n\n    for i, task in enumerate(tasks, 1):\n        result = use_case.execute(Path(segment), task)\n        results.append({\"task_id\": i, \"task\": task, \"result\": result})\n\n        # Classify outcome (T9.3.2: 4-level hierarchy)\n        selected_by = result.get(\"selected_by\", \"fallback\")\n\n        if selected_by == \"feature\":\n            feature_count += 1\n        elif selected_by == \"nl_trigger\":\n            nl_trigger_count += 1\n        elif selected_by == \"alias\":\n            alias_count += 1\n        else:  # fallback\n            fallback_count += 1\n\n        # T9.3.2: Track accuracy if expected_feature_id is available\n        expected_id = expected_features.get(task)\n        selected_id = result.get(\"selected_feature\")\n\n        if expected_id:\n            if expected_id == \"fallback\":\n                # Correct if selected_feature is None\n                if selected_id is None:\n                    correct_predictions += 1\n            elif selected_id == expected_id:\n                # Correct if selected_feature matches expected\n                correct_predictions += 1\n        # Check for true_zero_guidance (bug condition)\n        chunks_count = len(result.get(\"chunk_ids\", []))\n        paths_count = len(result.get(\"paths\", []))\n        # entrypoints_count calculation removed (unused)\n        next_steps_count = len(result.get(\"next_steps\", []))\n\n        if chunks_count == 0 and paths_count == 0 and next_steps_count == 0:\n            true_zero_count += 1\n\n        # Compute PCC metrics if feature_map is available\n        if feature_map and expected_id:\n            pcc_row = evaluate_pcc(\n                expected_feature=expected_id,\n                predicted_feature=selected_id,\n                predicted_paths=result.get(\"paths\", []),\n                feature_map=feature_map,\n                selected_by=selected_by,\n            )\n            pcc_metrics_rows.append(pcc_row)\n\n    total = len(tasks)\n    expected_count = len(expected_features)  # T9.3.2: Number of labeled tasks\n\n    # Compute rates (T9.3.2: 4-level hierarchy)\n    feature_hit_rate = (feature_count / total * 100) if total > 0 else 0\n    nl_trigger_hit_rate = (nl_trigger_count / total * 100) if total > 0 else 0\n    alias_hit_rate = (alias_count / total * 100) if total > 0 else 0\n    fallback_rate = (fallback_count / total * 100) if total > 0 else 0\n    true_zero_guidance_rate = (true_zero_count / total * 100) if total > 0 else 0\n\n    # T9.3.2: Compute accuracy if expected labels exist\n    plan_accuracy_top1 = (\n        (correct_predictions / expected_count * 100) if expected_count > 0 else None\n    )\n\n    # Compute PCC summary\n    pcc_summary = summarize_pcc(pcc_metrics_rows) if pcc_metrics_rows else {}\n\n    # Output report\n    typer.echo(\"=\" * 80)\n    typer.echo(\"EVALUATION REPORT: ctx.plan\")\n    typer.echo(\"=\" * 80)\n    typer.echo(\"\")\n    typer.echo(f\"Dataset: {dataset_path}\")\n    typer.echo(f\"Dataset SHA256: {dataset_sha256}\")\n    typer.echo(f\"Dataset mtime: {dataset_mtime}\")\n    typer.echo(f\"Segment: {segment}\")\n    typer.echo(f\"Total tasks: {total}\")\n    typer.echo(\"\")\n    typer.echo(f\"Dataset: {dataset_path}\")\n    typer.echo(f\"Dataset SHA256: {dataset_sha256}\")\n    typer.echo(f\"Dataset mtime: {dataset_mtime}\")\n    typer.echo(f\"Segment: {segment}\")\n    typer.echo(f\"Total tasks: {total}\")\n    typer.echo(\"\")\n\n    typer.echo(f\"Distribution (MUST SUM TO {total}):\")\n    typer.echo(f\"  feature (L1):   {feature_count} ({feature_hit_rate:.1f}%)\")\n    typer.echo(f\"  nl_trigger (L2): {nl_trigger_count} ({nl_trigger_hit_rate:.1f}%)\")\n    typer.echo(f\"  alias (L3):      {alias_count} ({alias_hit_rate:.1f}%)\")\n    typer.echo(f\"  fallback (L4):   {fallback_count} ({fallback_rate:.1f}%)\")\n    typer.echo(\"  ─────────────────────────────\")\n    typer.echo(f\"  total:          {total} (100.0%)\")\n    typer.echo(\"\")\n\n    typer.echo(\"Computed Rates:\")\n    typer.echo(f\"  feature_hit_rate:       {feature_hit_rate:.1f}%\")\n    typer.echo(f\"  nl_trigger_hit_rate:    {nl_trigger_hit_rate:.1f}%\")\n    typer.echo(f\"  alias_hit_rate:         {alias_hit_rate:.1f}%\")\n    typer.echo(f\"  fallback_rate:          {fallback_rate:.1f}%\")\n    typer.echo(f\"  true_zero_guidance_rate: {true_zero_guidance_rate:.1f}%\")\n\n    # T9.3.2: Show accuracy if expected labels exist\n    if plan_accuracy_top1 is not None:\n        typer.echo(\n            f\"  plan_accuracy_top1:     {plan_accuracy_top1:.1f}% ({correct_predictions}/{expected_count} correct)\"\n        )\n    typer.echo(\"\")\n\n    # PCC Metrics (if feature_map is available)\n    if pcc_summary:\n        typer.echo(\"PCC Metrics:\")\n        typer.echo(f\"  path_correct_count:    {pcc_summary['path_correct_count']}\")\n        typer.echo(f\"  false_fallback_count:  {pcc_summary['false_fallback_count']}\")\n        typer.echo(f\"  safe_fallback_count:   {pcc_summary['safe_fallback_count']}\")\n        typer.echo(\"\")\n\n    # Verbose per-task table\n    if verbose:\n        typer.echo(\"Per-Task Breakdown:\")\n        typer.echo(\"─\" * 80)\n        for item in results:\n            tid = item[\"task_id\"]\n            task_short = item[\"task\"][:40] + \"...\" if len(item[\"task\"]) > 40 else item[\"task\"]\n            result = item[\"result\"]\n            outcome = result.get(\"selected_by\", \"fallback\")\n            feature = result.get(\"selected_feature\", \"N/A\")\n            match_terms = result.get(\"match_terms_count\", 0)\n            chunks = len(result.get(\"chunk_ids\", []))\n            paths = len(result.get(\"paths\", []))\n\n            typer.echo(f\"{tid:2d}. [{outcome:8s}] {task_short}\")\n            typer.echo(f\"    → feature:{feature} terms:{match_terms} chunks:{chunks} paths:{paths}\")\n        typer.echo(\"\")\n\n    # Top missed tasks (fallback)\n    missed = [r for r in results if r[\"result\"].get(\"selected_by\") == \"fallback\"]\n    if missed:\n        typer.echo(f\"Top Missed Tasks (fallback): {len(missed)} total\")\n        for i, item in enumerate(missed[:10], 1):\n            task_short = item[\"task\"][:60] + \"...\" if len(item[\"task\"]) > 60 else item[\"task\"]\n            typer.echo(f\"  {i}. {task_short}\")\n        typer.echo(\"\")\n\n    # Examples of hits\n    hits = [r for r in results if r[\"result\"].get(\"plan_hit\")]\n    if hits:\n        typer.echo(\"Examples (hits with selected_feature):\")\n        for i, item in enumerate(hits[:5], 1):\n            task_short = item[\"task\"][:50] + \"...\" if len(item[\"task\"]) > 50 else item[\"task\"]\n            result = item[\"result\"]\n            outcome = result.get(\"selected_by\", \"unknown\")\n            feature = result.get(\"selected_feature\", \"N/A\")\n            chunks = len(result.get(\"chunk_ids\", []))\n            paths = len(result.get(\"paths\", []))\n            typer.echo(f\"  {i}. [{outcome}] '{task_short}'\")\n            typer.echo(f\"     → {feature} ({chunks} chunks, {paths} paths)\")\n            if i >= 3:\n                break\n\n    typer.echo(\"\")\n\n    # Determine gate type based on dataset name (T9.3.1)\n    is_l1_dataset = \"_l1\" in dataset_path.name.lower()\n    gate_name = \"Gate-L1\" if is_l1_dataset else \"Gate-NL\"\n\n    # Gate decision (T9.3.1: separate gates for NL and L1)\n    go_criteria = []\n    no_go_reasons = []\n\n    if is_l1_dataset:\n        # Gate-L1 criteria (explicit feature:<id> tests)\n        if feature_hit_rate >= 95:\n            go_criteria.append(f\"feature_hit_rate {feature_hit_rate:.1f}% >= 95%\")\n        else:\n            no_go_reasons.append(f\"feature_hit_rate {feature_hit_rate:.1f}% < 95%\")\n\n        if fallback_rate <= 5:\n            go_criteria.append(f\"fallback_rate {fallback_rate:.1f}% <= 5%\")\n        else:\n            no_go_reasons.append(f\"fallback_rate {fallback_rate:.1f}% > 5%\")\n\n        if true_zero_guidance_rate == 0:\n            go_criteria.append(f\"true_zero_guidance_rate {true_zero_guidance_rate:.1f}% = 0%\")\n        else:\n            no_go_reasons.append(f\"true_zero_guidance_rate {true_zero_guidance_rate:.1f}% > 0%\")\n    else:\n        # Gate-NL criteria (natural language generalization)\n        if fallback_rate < 20:\n            go_criteria.append(f\"fallback_rate {fallback_rate:.1f}% < 20%\")\n        else:\n            no_go_reasons.append(f\"fallback_rate {fallback_rate:.1f}% >= 20%\")\n\n        if true_zero_guidance_rate == 0:\n            go_criteria.append(f\"true_zero_guidance_rate {true_zero_guidance_rate:.1f}% = 0%\")\n        else:\n            no_go_reasons.append(f\"true_zero_guidance_rate {true_zero_guidance_rate:.1f}% > 0%\")\n\n        if alias_hit_rate <= 70:\n            go_criteria.append(f\"alias_hit_rate {alias_hit_rate:.1f}% <= 70%\")\n        else:\n            no_go_reasons.append(f\"alias_hit_rate {alias_hit_rate:.1f}% > 70%\")\n\n        # Informative for NL (not required)\n        if feature_hit_rate >= 10:\n            go_criteria.append(f\"feature_hit_rate {feature_hit_rate:.1f}% >= 10% (informative)\")\n        else:\n            no_go_reasons.append(f\"feature_hit_rate {feature_hit_rate:.1f}% < 10% (informative)\")\n\n    if go_criteria and not no_go_reasons:\n        typer.echo(f\"✅ GO ({gate_name}): All criteria passed\")\n        for c in go_criteria:\n            typer.echo(f\"   ✓ {c}\")\n    else:\n        typer.echo(f\"❌ NO-GO ({gate_name}): Some criteria failed\")\n        for r in no_go_reasons:\n            typer.echo(f\"   ✗ {r}\")\n        if go_criteria:\n            typer.echo(\"\")\n            typer.echo(\"Passed criteria:\")\n            for c in go_criteria:\n                typer.echo(f\"   ✓ {c}\")\n\n    telemetry.flush()\n\n\n@ctx_app.command(\"sync\")\ndef sync(\n    segment: str = typer.Option(..., \"--segment\", \"-s\", help=HELP_SEGMENT),\n    telemetry_level: str = typer.Option(\"lite\", \"--telemetry\", help=HELP_TELEMETRY),\n) -> None:\n    \"\"\"Macro: Build + Validate.\"\"\"\n    telemetry = _get_telemetry(segment, telemetry_level)\n    start_time = time.time()\n    _, file_system, _ = _get_dependencies(segment, telemetry)\n\n    try:\n        typer.echo(\"🔄 Running build...\")\n        build_uc = BuildContextPackUseCase(file_system, telemetry)\n        build_uc.execute(Path(segment).resolve())\n\n        typer.echo(\"✅ Build complete. Validating...\")\n        validate_uc = ValidateContextPackUseCase(file_system, telemetry)\n        result = validate_uc.execute(Path(segment).resolve())\n\n        # Format ValidationResult for display\n        if result.passed:\n            output = \"✅ Validation Passed\"\n            if result.warnings:\n                output += \"\\n\\n⚠️  Warnings:\\n\" + \"\\n\".join(f\"   - {w}\" for w in result.warnings)\n        else:\n            output = \"❌ Validation Failed\\n\\n\" + \"\\n\".join(f\"   - {e}\" for e in result.errors)\n\n        typer.echo(output)\n\n        if result.passed:\n            # Regenerate stubs\n            typer.echo(\"🔄 Regenerating stubs...\")\n            stub_regen_uc = StubRegenUseCase(telemetry)\n            stub_result = stub_regen_uc.execute(Path(segment).resolve())\n\n            if stub_result[\"stubs\"]:\n                typer.echo(f\"   ✅ Regenerated: {', '.join(stub_result['stubs'])}\")\n\n            if stub_result[\"warnings\"]:\n                typer.echo(\"   ⚠️  Warnings:\")\n                for w in stub_result[\"warnings\"]:\n                    typer.echo(f\"      - {w}\")\n\n            if not stub_result[\"regen_ok\"]:\n                typer.echo(\"   ⚠️  Stub regeneration had errors:\")\n                for e in stub_result[\"errors\"]:\n                    typer.echo(f\"      - {e}\")\n\n        telemetry.event(\n            \"ctx.sync\",\n            {\"segment\": segment},\n            {\"status\": \"ok\"},\n            int((time.time() - start_time) * 1000),\n        )\n\n        if not result.passed:\n            raise typer.Exit(code=1)\n\n    # Type-based error classification (preferred - robust)\n    except Exception as e:\n        from src.application.exceptions import PrimeFileNotFoundError\n\n        if isinstance(e, PrimeFileNotFoundError):\n            # Prime file missing - emit SEGMENT_NOT_INITIALIZED Error Card\n            from src.cli.error_cards import render_error_card\n\n            error_card = render_error_card(\n                error_code=\"SEGMENT_NOT_INITIALIZED\",\n                error_class=\"PRECONDITION\",\n                cause=f\"Missing prime file: {e.expected_path}\",\n                next_steps=[\n                    f\"trifecta create -s {segment}\",\n                    f\"trifecta refresh-prime -s {segment}\",\n                ],\n                verify_cmd=f\"trifecta ctx sync -s {segment}\",\n            )\n            telemetry.event(\n                \"ctx.sync\",\n                {\"segment\": segment},\n                {\"status\": \"error\", \"error_code\": \"SEGMENT_NOT_INITIALIZED\"},\n                int((time.time() - start_time) * 1000),\n            )\n            typer.echo(error_card, err=True)\n            raise typer.Exit(1)\n\n        # Substring fallback for backward compatibility (deprecated)\n        elif isinstance(e, FileNotFoundError) and \"Expected prime file not found\" in str(e):\n            from src.cli.error_cards import render_error_card\n            from src.infrastructure.deprecations import maybe_emit_deprecated\n\n            # Track deprecated usage (policy: off|warn|fail via env var)\n            maybe_emit_deprecated(\"fallback_prime_missing_string_match\", telemetry)\n\n            # Emit deprecation warning for harness detection (legacy)\n            typer.echo(\"TRIFECTA_DEPRECATED: fallback_prime_missing_string_match_used\", err=True)\n\n            error_card = render_error_card(\n                error_code=\"SEGMENT_NOT_INITIALIZED\",\n                error_class=\"PRECONDITION\",\n                cause=str(e),\n                next_steps=[\n                    f\"trifecta create -s {segment}\",\n                    f\"trifecta refresh-prime -s {segment}\",\n                ],\n                verify_cmd=f\"trifecta ctx sync -s {segment}\",\n            )\n            telemetry.event(\n                \"ctx.sync\",\n                {\"segment\": segment},\n                {\"status\": \"error\", \"error_code\": \"SEGMENT_NOT_INITIALIZED\"},\n                int((time.time() - start_time) * 1000),\n            )\n            typer.echo(error_card, err=True)\n            raise typer.Exit(1)\n\n        # All other exceptions (fail-closed)\n        else:\n            telemetry.event(\n                \"ctx.sync\",\n                {\"segment\": segment},\n                {\"status\": \"error\"},\n                int((time.time() - start_time) * 1000),\n            )\n        typer.echo(_format_error(e, \"Sync Error\"), err=True)\n        if not isinstance(e, typer.Exit):\n            raise typer.Exit(1)\n        raise e\n    finally:\n        telemetry.flush()\n\n\n@ctx_app.command(\"reset\")\ndef ctx_reset(\n    segment: str = typer.Option(..., \"--segment\", \"-s\", help=HELP_SEGMENT),\n    telemetry_level: str = typer.Option(\"lite\", \"--telemetry\", help=HELP_TELEMETRY),\n    force: bool = typer.Option(False, \"--force\", \"-f\", help=\"Skip confirmation prompt\"),\n) -> None:\n    \"\"\"[DESTRUCTIVE] Regenerate ALL context files (templates + pack). Use with caution.\"\"\"\n    telemetry = _get_telemetry(segment, telemetry_level)\n    start_time = time.time()\n    template_renderer, file_system, _ = _get_dependencies(segment, telemetry)\n\n    try:\n        if not force:\n            typer.echo(\n                \"⚠️  WARNING: This will overwrite skill.md, agent.md, session.md, readme_tf.md\"\n            )\n            typer.echo(\"Press Ctrl+C to cancel, or Enter to continue...\")\n            input()\n\n        typer.echo(\"🔄 Regenerating templates...\")\n        config_path = Path(segment) / \"_ctx\" / \"trifecta_config.json\"\n        if config_path.exists():\n            import json\n\n            config_data = json.loads(config_path.read_text())\n            from src.domain.models import TrifectaConfig\n\n            config = TrifectaConfig(**config_data)\n        else:\n            typer.echo(\"❌ No trifecta_config.json found. Use 'trifecta create' for new segments.\")\n            raise typer.Exit(1)\n\n        (Path(segment) / \"skill.md\").write_text(template_renderer.render_skill(config))\n        (Path(segment) / \"_ctx\" / \"agent.md\").write_text(template_renderer.render_agent(config))\n        (Path(segment) / \"_ctx\" / f\"session_{config.segment}.md\").write_text(\n            template_renderer.render_session(config)\n        )\n        (Path(segment) / \"readme_tf.md\").write_text(template_renderer.render_readme(config))\n\n        typer.echo(\"✅ Templates regenerated. Running sync...\")\n\n        build_uc = BuildContextPackUseCase(file_system, telemetry)\n        build_uc.execute(Path(segment))\n\n        validate_uc = ValidateContextPackUseCase(file_system, telemetry)\n        output = validate_uc.execute(Path(segment))\n        typer.echo(output)\n\n        telemetry.observe(\"ctx.reset\", int((time.time() - start_time) * 1000))\n\n        if not output.passed:\n            raise typer.Exit(code=1)\n\n    except KeyboardInterrupt:\n        typer.echo(\"\\n❌ Reset cancelled\")\n        raise typer.Exit(0)\n    except Exception as e:\n        telemetry.event(\n            \"ctx.reset\", {}, {\"status\": \"error\"}, int((time.time() - start_time) * 1000)\n        )\n        typer.echo(_format_error(e, \"Reset Error\"), err=True)\n        if not isinstance(e, typer.Exit):\n            raise typer.Exit(1)\n        raise e\n    finally:\n        telemetry.flush()\n\n\n# =============================================================================\n# Generator Commands\n# =============================================================================\n\n\n@app.command(\"create\")\ndef create(\n    segment: str = typer.Option(..., \"--segment\", \"-s\", help=\"Path to segment directory\"),\n    scope: str = typer.Option(\"Scope\", \"--scope\", help=\"Short description of segment scope\"),\n) -> None:\n    \"\"\"\n    Scaffold a new Trifecta Segment.\n\n    Generates:\n    - skill.md (Rules & Roles)\n    - _ctx/prime_{segment}.md (Reading list)\n    - _ctx/agent.md (Tech stack)\n    - _ctx/session_{segment}.md (Runbook)\n    - readme_tf.md (Documentation)\n    \"\"\"\n    # FIXED: -s is now path to target directory (consistent with ctx sync/search/get)\n    # Segment ID derived from directory name\n    target_dir = Path(segment).resolve()\n\n    template_renderer, _, _ = _get_dependencies(str(target_dir))\n\n    if not target_dir.exists():\n        target_dir.mkdir(parents=True)\n\n    # Derive segment_id from directory name (same logic as use_cases.py)\n    from src.domain.naming import normalize_segment_id\n\n    segment_id = normalize_segment_id(target_dir.name)\n\n    config = TrifectaConfig(\n        segment=segment_id,\n        scope=scope,\n        repo_root=str(target_dir),\n        last_verified=time.strftime(\"%Y-%m-%d\"),\n        default_profile=\"impl_patch\",\n    )\n\n    files = {\n        \"skill.md\": template_renderer.render_skill(config),\n        \"readme_tf.md\": template_renderer.render_readme(config),\n        f\"_ctx/prime_{segment_id}.md\": template_renderer.render_prime(config, []),\n        f\"_ctx/agent_{segment_id}.md\": template_renderer.render_agent(config),\n        f\"_ctx/session_{segment_id}.md\": template_renderer.render_session(config),\n    }\n\n    try:\n        for rel_path, content in files.items():\n            full_path = target_dir / rel_path\n            full_path.parent.mkdir(parents=True, exist_ok=True)\n            if (\n                not full_path.exists()\n            ):  # Don't overwrite unless force? Removed overwrite flag previously.\n                full_path.write_text(content)\n\n        # Verify line count of skill.md\n        skill_lines = len(files[\"skill.md\"].splitlines())\n        if skill_lines > 100:\n            raise ValueError(f\"skill.md exceeds 100 lines ({skill_lines})\")\n\n        typer.echo(f\"✅ Trifecta created at {target_dir}\")\n        for f in files:\n            typer.echo(f\"   ├── {f}\")\n\n        # Show quick commands from session\n        typer.echo(\n            files[f\"_ctx/session_{segment_id}.md\"]\n            .split(\"## Quick Commands (CLI)\")[1]\n            .split(\"```\")[1]\n        )\n\n    except Exception as e:\n        typer.echo(_format_error(e, \"Creation Error\"), err=True)\n        raise typer.Exit(1)\n\n\n@app.command(\"validate-trifecta\", hidden=True, help=\"[DEPRECATED] Use 'ctx validate' instead.\")\ndef validate_trifecta(\n    segment: str = typer.Option(..., \"--segment\", \"-s\", help=HELP_SEGMENT),\n) -> None:\n    \"\"\"\n    Validate structure of a Trifecta Segment (files exist, YAML valid).\n\n    TIP: Run this after creating or modifying a Trifecta pack.\n    \"\"\"\n    _, file_system, _ = _get_dependencies(segment)\n    use_case = ValidateTrifectaUseCase(file_system)\n\n    # Validate path exists\n    path = Path(segment)\n\n    try:\n        output = use_case.execute(path)\n        typer.echo(output)\n    except Exception as e:\n        typer.echo(_format_error(e, \"Validation Error\"), err=True)\n        raise typer.Exit(1)\n\n\n@app.command(\"refresh-prime\", hidden=True, help=\"[DEPRECATED] Use 'ctx sync' instead.\")\ndef refresh_prime(\n    segment: str = typer.Option(..., \"--segment\", \"-s\", help=HELP_SEGMENT),\n) -> None:\n    \"\"\"\n    Regenerate `_ctx/prime_{segment}.md` with latest file list.\n\n    TIP: The prime file is located at _ctx/prime_{segment}.md\n    \"\"\"\n    template_renderer, file_system, _ = _get_dependencies(segment)\n    use_case = RefreshPrimeUseCase(template_renderer, file_system)\n\n    # Validate paths\n    path = Path(segment).resolve()\n    repo_root = path.parent if path.parent != path else path\n    scan_path = path\n\n    try:\n        output = use_case.execute(path, scan_path, repo_root)\n        typer.echo(output)\n    except Exception as e:\n        typer.echo(_format_error(e, \"Refresh Error\"), err=True)\n        raise typer.Exit(1)\n\n\n# =============================================================================\n# Load Command (Plan A/B)\n# =============================================================================\n\n\n@app.command()\ndef load(\n    segment: str = typer.Option(..., \"--segment\", \"-s\", help=HELP_SEGMENT),\n    task: str = typer.Option(..., \"--task\", \"-t\", help=\"Task description for context selection\"),\n    mode: str = typer.Option(\n        \"pcc\", \"--mode\", \"-m\", help=\"Mode: pcc (Plan A) or fullfiles (Plan B)\"\n    ),\n    telemetry_level: str = typer.Option(\"lite\", \"--telemetry\", help=HELP_TELEMETRY),\n) -> None:\n    \"\"\"Macro command to load relevant context for a specific task.\n\n    If context_pack.json exists, it uses Programmatic Context Calling (Plan A).\n    Otherwise, it falls back to heuristic file selection (Plan B).\n    \"\"\"\n    telemetry = _get_telemetry(segment, telemetry_level)\n    start_time = time.time()\n    _, file_system, _ = _get_dependencies(segment, telemetry)\n\n    use_case = MacroLoadUseCase(file_system, telemetry)\n\n    try:\n        target_path = Path(segment).resolve()\n        if not target_path.exists():\n            raise ValueError(f\"Segment path does not exist: {target_path}\")\n\n        output = use_case.execute(target_path, task, mode=mode)\n        typer.echo(output)\n        telemetry.event(\n            \"load\",\n            {\"segment\": segment, \"mode\": mode},\n            {\"status\": \"ok\"},\n            int((time.time() - start_time) * 1000),\n        )\n    except Exception as e:\n        telemetry.event(\n            \"load\",\n            {\"segment\": segment, \"mode\": mode},\n            {\"status\": \"error\"},\n            int((time.time() - start_time) * 1000),\n        )\n        typer.echo(_format_error(e, \"Load Error\"), err=True)\n        raise typer.Exit(1)\n    finally:\n        telemetry.flush()\n\n\n# =============================================================================\n# Session Commands\n# =============================================================================\n\n\n@session_app.command(\"append\")\ndef session_append(\n    segment: str = typer.Option(..., \"--segment\", \"-s\", help=HELP_SEGMENT),\n    summary: str = typer.Option(..., \"--summary\", help=\"Summary of work done\"),\n    files: str = typer.Option(\"\", \"--files\", help=\"Comma-separated list of files touched\"),\n    commands: str = typer.Option(\"\", \"--commands\", help=\"Comma-separated list of commands run\"),\n) -> None:\n    \"\"\"Append entry to session log (proactive logging without LLM).\"\"\"\n    import hashlib\n    from datetime import datetime, timezone\n\n    segment_path = Path(segment).resolve()\n    segment_name = segment_path.name\n    session_file = segment_path / \"_ctx\" / f\"session_{segment_name}.md\"\n\n    # Ensure _ctx directory exists\n    (segment_path / \"_ctx\").mkdir(parents=True, exist_ok=True)\n\n    # Get pack_sha if context_pack.json exists\n    pack_sha = None\n    pack_path = segment_path / \"_ctx\" / \"context_pack.json\"\n    if pack_path.exists():\n        try:\n            content = pack_path.read_bytes()\n            pack_sha = hashlib.sha256(content).hexdigest()[:16]\n        except Exception:\n            pass\n\n    # Parse CSV inputs\n    files_list = [f.strip() for f in files.split(\",\") if f.strip()]\n    commands_list = [c.strip() for c in commands.split(\",\") if c.strip()]\n\n    # Create entry\n    entry_lines = [\n        f\"## {datetime.now(timezone.utc).strftime('%Y-%m-%d %H:%M')} UTC\",\n        f\"- **Summary**: {summary}\",\n    ]\n\n    if files_list:\n        entry_lines.append(f\"- **Files**: {', '.join(files_list)}\")\n\n    if commands_list:\n        entry_lines.append(f\"- **Commands**: {', '.join(commands_list)}\")\n\n    if pack_sha:\n        entry_lines.append(f\"- **Pack SHA**: `{pack_sha}`\")\n\n    entry_lines.append(\"\")  # Blank line after entry\n\n    # Create or append to session file\n    if not session_file.exists():\n        # Create new file with header\n        header = f\"# Session Log - {segment_name}\\n\\n## History\\n\\n\"\n        session_file.write_text(header + \"\\n\".join(entry_lines), encoding=\"utf-8\")\n        typer.echo(f\"✅ Created {session_file.relative_to(segment_path)}\")\n    else:\n        # Append to existing file\n        with open(session_file, \"a\", encoding=\"utf-8\") as f:\n            f.write(\"\\n\".join(entry_lines) + \"\\n\")\n        typer.echo(f\"✅ Appended to {session_file.relative_to(segment_path)}\")\n\n    typer.echo(f\"   Summary: {summary}\")\n\n\n# =============================================================================\n# Telemetry Commands\n# =============================================================================\n\n\n@telemetry_app.command(\"report\")\ndef telemetry_report(\n    segment: str = typer.Option(..., \"--segment\", \"-s\", help=HELP_SEGMENT),\n    last: int = typer.Option(7, \"--last\", help=\"Last N days (0 = all)\"),\n    format_type: str = typer.Option(\"table\", \"--format\", help=\"Output format: table, json\"),\n) -> None:\n    \"\"\"Generate telemetry report.\"\"\"\n    segment_path = Path(segment).resolve()\n\n    report = generate_report(segment_path, last, format_type)\n    typer.echo(report)\n\n\n@telemetry_app.command(\"export\")\ndef telemetry_export(\n    segment: str = typer.Option(..., \"--segment\", \"-s\", help=HELP_SEGMENT),\n    format_type: str = typer.Option(\"json\", \"--format\", help=\"Export format: json, csv\"),\n    output: str = typer.Option(None, \"--output\", \"-o\", help=\"Output file path\"),\n) -> None:\n    \"\"\"Export telemetry data.\"\"\"\n    segment_path = Path(segment).resolve()\n    output_path = Path(output) if output else None\n\n    data = export_data(segment_path, format_type, output_path)\n\n    if output_path:\n        typer.echo(f\"✅ Exported to {output_path}\")\n    else:\n        typer.echo(data)\n\n\n@telemetry_app.command(\"chart\")\ndef telemetry_chart(\n    segment: str = typer.Option(..., \"--segment\", \"-s\", help=HELP_SEGMENT),\n    chart_type: str = typer.Option(\"hits\", \"--type\", help=\"Chart type: hits, latency, commands\"),\n    days: int = typer.Option(7, \"--days\", help=\"Last N days\"),\n) -> None:\n    \"\"\"Generate ASCII chart.\"\"\"\n    segment_path = Path(segment).resolve()\n\n    chart = generate_chart(segment_path, chart_type, days)\n    typer.echo(chart)\n\n\n@legacy_app.command(\"scan\")\ndef legacy_scan(\n    path: str = typer.Option(\".\", \"--path\", \"-p\", help=\"Root path to scan\"),\n) -> None:\n    \"\"\"Scan for undeclared legacy code. Fails if new legacy appears.\"\"\"\n    from src.application.legacy_use_case import scan_legacy\n    from src.domain.result import Err, Ok\n\n    repo_root = Path(path).resolve()\n    manifest_path = repo_root / \"docs/legacy_manifest.json\"\n\n    typer.echo(f\"🔍 Scanning for legacy debt in {repo_root}...\")\n    typer.echo(f\"   Manifest: {manifest_path}\")\n\n    match scan_legacy(repo_root, manifest_path):\n        case Ok(legacy_items):\n            typer.echo(\"✅ Legacy Check Passed.\")\n            if legacy_items:\n                typer.echo(f\"   Found {len(legacy_items)} declared legacy items (Technical Debt).\")\n            else:\n                typer.echo(\"   Zero legacy debt found!\")\n        case Err(errors):\n            typer.echo(\"❌ Legacy Check Failed (Undeclared Debt):\")\n            for err in errors:\n                typer.echo(f\"   - {err}\")\n            raise typer.Exit(code=1)\n\n\n# =============================================================================\n# Obsidian Integration Commands\n# =============================================================================\n\n\n@obsidian_app.command(\"sync\")\ndef obsidian_sync(\n    segment: str = typer.Option(\".\", \"--segment\", \"-s\", help=HELP_SEGMENT),\n    vault_path: Optional[str] = typer.Option(\n        None, \"--vault-path\", \"-v\", help=\"Obsidian vault path\"\n    ),\n    min_priority: str = typer.Option(\"P5\", \"--min-priority\", \"-p\", help=\"Minimum priority (P1-P5)\"),\n    dry_run: bool = typer.Option(False, \"--dry-run\", help=\"Preview without writing\"),\n    include_hookify: bool = typer.Option(\n        True, \"--include-hookify/--no-hookify\", help=\"Include hookify violations\"\n    ),\n    include_telemetry: bool = typer.Option(\n        True, \"--include-telemetry/--no-telemetry\", help=\"Include telemetry anomalies\"\n    ),\n    include_micro_audit: bool = typer.Option(\n        True, \"--include-micro-audit/--no-micro-audit\", help=\"Include micro-audit report findings\"\n    ),\n) -> None:\n    \"\"\"Sync findings to Obsidian vault as atomic notes.\"\"\"\n    segment_path = Path(segment).expanduser().resolve()\n\n    # Validate priority\n    valid_priorities = {\"P1\", \"P2\", \"P3\", \"P4\", \"P5\"}\n    if min_priority not in valid_priorities:\n        typer.echo(f\"❌ Invalid priority: {min_priority}. Must be one of {valid_priorities}\")\n        raise typer.Exit(code=1)\n\n    # Create use case with config\n    try:\n        use_case = create_sync_use_case(\n            vault_path=Path(vault_path).expanduser() if vault_path else None,\n            min_priority=min_priority,  # type: ignore\n        )\n    except Exception as e:\n        typer.echo(f\"❌ Configuration error: {e}\")\n        typer.echo(\"\\n💡 Tip: Run 'trifecta obsidian config --vault-path <path>' first\")\n        raise typer.Exit(code=1)\n\n    # Execute sync\n    sources = {\n        \"hookify\": include_hookify,\n        \"telemetry\": include_telemetry,\n        \"micro_audit\": include_micro_audit,\n    }\n\n    try:\n        result = use_case.execute(\n            segment_path=segment_path,\n            min_priority=min_priority,  # type: ignore\n            dry_run=dry_run,\n            sources=sources,\n        )\n    except RuntimeError as e:\n        typer.echo(f\"❌ Sync failed: {e}\")\n        raise typer.Exit(code=1)\n\n    # Show summary\n    typer.echo(\"\\n✨ Sync complete!\")\n    typer.echo(\n        f\"  Sources: {', '.join(result.active_sources) if result.active_sources else 'None'}\"\n    )\n    typer.echo(f\"  Findings: {result.total_findings}\")\n    typer.echo(f\"  Notes created: {result.notes_created}\")\n    typer.echo(f\"  Notes updated: {result.notes_updated}\")\n    typer.echo(f\"  Notes skipped: {result.notes_skipped}\")\n    typer.echo(f\"  Duration: {result.duration_ms}ms\")\n\n    if dry_run and result.previews:\n        typer.echo(f\"\\n🔍 Dry-run mode - {len(result.previews)} notes would be created:\")\n        for preview in result.previews[:5]:  # Show first 5\n            typer.echo(f\"\\n  📄 {preview['path']}\")\n            typer.echo(f\"     {preview['content'][:200]}...\")\n        if len(result.previews) > 5:\n            typer.echo(f\"\\n  ... and {len(result.previews) - 5} more\")\n\n\n@obsidian_app.command(\"config\")\ndef obsidian_config(\n    vault_path: Optional[str] = typer.Option(None, \"--vault-path\", \"-v\", help=\"Set vault path\"),\n    show: bool = typer.Option(False, \"--show\", help=\"Show current config\"),\n) -> None:\n    \"\"\"Configure Obsidian integration.\"\"\"\n    config_manager = ObsidianConfigManager()\n\n    if show:\n        typer.echo(config_manager.show())\n    elif vault_path:\n        config = config_manager.load()\n        # Update vault path\n        from src.domain.obsidian_models import ObsidianConfig\n\n        new_config = ObsidianConfig(\n            vault_path=Path(vault_path).expanduser().resolve(),\n            default_segment=config.default_segment,\n            min_priority=config.min_priority,\n            note_folder=config.note_folder,\n            auto_link=config.auto_link,\n            date_format=config.date_format,\n        )\n        config_manager.save(new_config)\n        typer.echo(f\"✅ Vault path set to: {new_config.vault_path}\")\n        typer.echo(\"\\nRun 'trifecta obsidian config --show' to see full config\")\n    else:\n        typer.echo(\"Usage:\")\n        typer.echo(\"  trifecta obsidian config --vault-path <path>   Set vault path\")\n        typer.echo(\"  trifecta obsidian config --show               Show current config\")\n        raise typer.Exit(code=1)\n\n\n@obsidian_app.command(\"validate\")\ndef obsidian_validate() -> None:\n    \"\"\"Validate Obsidian vault configuration.\"\"\"\n    try:\n        use_case = create_sync_use_case()\n    except Exception as e:\n        typer.echo(f\"❌ Configuration error: {e}\")\n        raise typer.Exit(code=1)\n\n    validation = use_case.validate_vault()\n\n    if validation.valid:\n        typer.echo(\"✅ Vault is valid and writable\")\n        typer.echo(f\"   Findings folder: {validation.findings_dir}\")\n        typer.echo(f\"   Existing notes: {validation.existing_notes}\")\n    else:\n        typer.echo(\"❌ Vault validation failed\")\n        typer.echo(f\"   Error: {validation.error}\")\n        raise typer.Exit(code=1)\n\n\ndef main() -> None:\n    \"\"\"Main entry point with custom error handling for invalid options.\"\"\"\n    try:\n        # Use standalone_mode=False to capture exceptions\n        # Note: typer.Exit is converted to a return value when standalone_mode=False\n        exit_code = app(standalone_mode=False)\n\n        # If app returned a non-zero exit code, exit with it\n        if exit_code is not None and exit_code != 0:\n            sys.exit(exit_code)\n\n    except UsageError as e:\n        # Handle Click UsageError (includes \"No such option\" errors)\n        error_msg = str(e)\n\n        # Check if this is an invalid option error\n        if \"no such option\" in error_msg.lower():\n            enhanced_msg = handle_invalid_option_error(error_msg, sys.argv)\n            typer.echo(enhanced_msg, err=True)\n            sys.exit(2)\n\n        # For other usage errors, show the original message\n        typer.echo(f\"Error: {error_msg}\", err=True)\n        sys.exit(2)\n    except click.exceptions.Exit as e:\n        # Handle Click/typer.Exit exceptions (inherited from SystemExit)\n        if e.exit_code != 0:\n            sys.exit(e.exit_code)\n    except SystemExit as e:\n        # Handle normal exit codes\n        if e.code is not None and e.code != 0:\n            sys.exit(e.code)\n    except Exception as e:\n        # Handle unexpected errors with traceback for debugging\n        typer.echo(f\"Error: {e}\", err=True)\n        typer.echo(traceback.format_exc(), err=True)\n        sys.exit(1)\n\n\nif __name__ == \"__main__\":\n    main()\n# Audit Trigger\n# Audit Trigger Code\n",
+      "char_count": 62932,
+      "token_est": 15733,
       "source_path": "cli.py",
       "chunking_method": "whole_file"
     },
@@ -4939,17 +5125,29 @@
       "chunking_method": "whole_file"
     },
     {
-      "id": "repo:CLAUDE.md:c279474056",
+      "id": "repo:CLAUDE.md:1c7efe0bac",
       "doc": "repo:CLAUDE.md",
       "title_path": [
         "CLAUDE.md"
       ],
-      "text": "# CLAUDE.md\n\nThis file provides guidance to Claude Code (claude.ai/code) when working with code in this repository.\n\n---\n\n## Quick Start\n\n```bash\n# Install\nuv sync --all-groups\n\n# Run CLI\nuv run trifecta --help\n\n# Tests\nuv run pytest                    # All tests\nuv run pytest -m \"not slow\"      # Skip slow tests\nuv run pytest tests/acceptance/  # Acceptance gate\n\n# Type check & lint\nuv run mypy src/ --strict\nuv run ruff check src/\nuv run ruff format src/\n```\n\n---\n\n## Architecture Overview\n\n**Python + Clean Architecture** with strict layer separation:\n\n- **Domain** (`src/domain/`) - Pure business logic (no IO, no async, no framework dependencies)\n- **Application** (`src/application/`) - Use cases, orchestration\n- **Infrastructure** (`src/infrastructure/`) - Framework adapters, IO, external services\n\n**Critical Rule:** Dependencies point INWARD. Domain → Application → Infrastructure.\n\nSee `docs/CONTRACTS.md` and architecture docs in `docs/adr/` for complete patterns.\n\n---\n\n## Key Patterns\n\n- **Frozen dataclasses** for domain entities (immutable)\n- **Pure functions** in domain services (testable without mocks)\n- **Protocols** for infrastructure interfaces (ports/adapters)\n- **Result types** for error handling (`Ok[T] | Err[E]`)\n- **Telemetry** for observability (no side-effect in tests via `TRIFECTA_NO_TELEMETRY`)\n\n---\n\n## Development Workflow\n\n- **TDD**: Write tests BEFORE implementation (RED → GREEN → REFACTOR)\n- **Domain first**: Business logic is pure and tested in isolation\n- **Use `uv`**: Package management and task runner\n- **Pre-commit hooks**: Auto-run tests on commit (bypass with `--no-verify` if needed)\n\n---\n\n## Red Flags\n\n| Violation | Why It's Wrong | Fix |\n|-----------|----------------|-----|\n| IO in domain | Domain must be pure | Move to infrastructure adapter |\n| Async in domain | Domain is synchronous | Move to application/infra |\n| Pydantic in domain | Framework coupling | Use frozen dataclasses |\n| Untested pure functions | Easy to test, no excuse | Write unit tests |\n| Hardcoded paths | Portability issues | Use `repo_root()` helper |\n\n---\n\n## Testing\n\n- **Unit tests** (`tests/unit/`) - Domain logic, pure functions\n- **Integration tests** (`tests/integration/`) - Use cases with real adapters\n- **Acceptance tests** (`tests/acceptance/`) - Black-box CLI tests (gate: `-m \"not slow\"`)\n- **Roadmap tests** (`tests/roadmap/`) - Future features (isolated, `--ignore`)\n\n**Coverage target**: ≥80% branch coverage\n\n---\n\n## Source of Truth\n\n- **README.md** - Project overview, installation\n- **docs/CONTRACTS.md** - API contracts, schemas\n- **docs/CLI_WORKFLOW.md** - Official CLI usage\n- **docs/adr/** - Architecture decision records\n- **_ctx/agent_trifecta_dope.md** - Active features, tech stack\n- **_ctx/session_trifecta_dope.md** - Session history, runbook\n\n---\n\n## Trifecta-Specific  Rules\n\n### _ctx/ Directory Conventions\n- **_ctx/logs/**: ONLY .log files (command stdout/stderr). Use /tmp/ for intermediate .md files.\n- **When updating session.md**: Create temp in /tmp/, append with `cat`, then cleanup. Never store .md in _ctx/logs/.\n\n### Context Pack Workflow\n1. `trifecta create --segment .` - Bootstrap metadata\n2. `trifecta ctx sync --segment .` - Build context pack\n3. `trifecta ctx validate --segment .` - Verify integrity\n4. `trifecta ctx search --segment . --query \"...\"` - Search\n5. `trifecta ctx get --segment . --ids \"...\"` - Retrieve chunks\n\n### Environment & Ops\n- **Scope Separation**: `pyproject.toml` / `pytest-env` is for **Tests**. `.envrc` (direnv) is for **Dev CLI**.\n- **Default Enablement**: Must be verified via CLI *without* env var prefixes.\n- **Audit-Grade Gates**: `exit 0` is not enough. Verify internal state (telemetry backend, file creation).\n- **Rollback**: Must be verifiable in <5 minutes via env var override.\n\n---\n\n## Backlog System\n\n**Structure**: State-segregated Work Orders (WO) + Epic registry\n\n```\n_ctx/\n├── backlog/backlog.yaml        # Epic registry (YAML only, no .md)\n├── jobs/\n│   ├── pending/*.yaml          # WO awaiting work\n│   ├── running/*.yaml          # WO in progress\n│   ├── done/*.yaml             # WO completed\n│   └── failed/*.yaml           # WO failed\n└── dod/*.yaml                  # Definition of Done catalog\n```\n\n**Key Files**:\n- **Epic organization**: `_ctx/backlog/backlog.yaml`\n- **Schema validation**: `docs/backlog/schema/*.schema.json`\n- **Validator**: `python scripts/ctx_backlog_validate.py --strict`\n- **Migration guide**: `docs/backlog/MIGRATION.md`\n\n**WO Fields**:\n- Required: `id`, `epic_id`, `title`, `priority`, `status`, `scope`, `verify`, `dod_id`\n- Done WOs: add `verified_at_sha` (explicit SHA, not \"HEAD\"), `dependencies`, `evidence_logs`\n- Legacy fields: prefix with `x_` (e.g., `x_objective`, `x_notes`)\n\n**Critical Rules**:\n- **Single Source of Truth**: A WO YAML must exist in exactly ONE state folder (`pending/`, `running/`, `done/`). Use `mv` to transition, never copy.\n- `verified_at_sha`: Use explicit commit SHA (e.g., `c2d0338`), never `\"HEAD\"`\n- `dependencies`: List prerequisite WO IDs (e.g., `[WO-P2.1]`)\n- `evidence_logs`: Relative paths to proof (logs gitignored but documented)\n- Epic registry: Track phases with SHAs, mark complete when all WOs done\n- No `.md` files in `_ctx/backlog/` - documentation goes to `docs/` or `_ctx/session_*.md`\n\n**Cross-references**: Every WO must reference valid `epic_id` (E-XXXX) and `dod_id`.\n\n---\n\n## Telemetry\n- **Production**: Events logged to `_ctx/telemetry/events.jsonl`\n- **Testing**: Use `TRIFECTA_NO_TELEMETRY=1` for zero side-effects\n- **Pre-commit**: Auto-redirects telemetry via `TRIFECTA_TELEMETRY_DIR`\n\n---\n\n## Common Tasks\n\n```bash\n# Create new segment\nuv run trifecta create --segment /path/to/project\n\n# Sync context\nuv run trifecta ctx sync --segment .\n\n# Search + get workflow\nuv run trifecta ctx search --segment . --query \"ErrorCard\" --limit 5\nuv run trifecta ctx get --segment . --ids \"prime:abc123\" --mode excerpt\n\n# AST symbols (M1)\nuv run trifecta ast symbols \"sym://python/mod/src.domain.result\" --segment .\n\n# Run gate\nbash scripts/gate_clean_worktree_repro.sh  # WO-0007 reproducibility\n```\n\n---\n\n**Living Document**: Update this file when friction is encountered or new patterns emerge.\n",
-      "char_count": 6213,
-      "token_est": 1553,
+      "text": "# CLAUDE.md\n\nThis file provides guidance to Claude Code (claude.ai/code) when working with code in this repository.\n\n---\n\n## ⚠️ CRITICAL: READ THIS FIRST BEFORE ANY TASK\n\n**DO NOT PROCEED WITH ANY TASK WITHOUT READING THESE CONTEXT FILES.**\n\nAssuming anything about this project without consulting these files is a breach of the work contract.\n\n### Agent Context Files (MANDATORY - READ THESE FIRST)\n\nThese files contain **CURRENT PROJECT STATE, ACTIVE FEATURES, AND ARCHITECTURE DECISIONS**. Ignoring them will result in:\n- ✗ Breaking existing implementations\n- ✗ Duplicating work already done\n- ✗ Misunderstanding the current system state\n- ✗ Failing verification gates\n\n**READ IN THIS ORDER:**\n\n0. **[skill.md](skill.md)** ← START HERE FIRST (3 min read)\n   - **What**: Skills, roles, and core rules for this project\n   - **Why**: Know the mandatory patterns and commands to use\n   - **Contains**: Setup instructions, context cycle, session persistence\n   - **CRITICAL**: Skip this → you'll use wrong commands and waste cycles\n\n1. **[_ctx/agent_trifecta_dope.md](_ctx/agent_trifecta_dope.md)** ← THEN READ THIS (5 min read)\n   - **What**: Current implementation status and active features\n   - **Why**: Know what's ACTUALLY implemented vs. what's planned\n   - **Contains**: Tech stack versions, active patterns, completed work\n   - **CRITICAL**: Skip this → you'll duplicate work or break things\n\n2. **[_ctx/session_trifecta_dope.md](_ctx/session_trifecta_dope.md)** ← THEN READ THIS (2 min skim)\n   - **What**: Session history and continuation points\n   - **Why**: Understand what was done in the last session\n   - **Contains**: Previous decisions, known workarounds, open issues\n   - **CRITICAL**: Skip this → you'll miss workarounds and hit known bugs\n\n3. **[_ctx/prime_trifecta_dope.md](_ctx/prime_trifecta_dope.md)** ← REFERENCE THIS (1 min check)\n   - **What**: Architectural reference and system structure\n   - **Why**: Understand the fundamental system design\n   - **Contains**: Core patterns, layer separation, dependency rules\n   - **CRITICAL**: Skip this → you'll violate architectural constraints\n\n### If You Skip These Files\n\n⛔ **YOU WILL:**\n- Propose features that already exist\n- Break working implementations\n- Violate architectural patterns\n- Fail the verification gate\n- Use wrong commands and waste tokens\n- Waste time and tokens\n\n✅ **INSTEAD:**\n1. Read the 4 context files (11 min total)\n2. Then start your task\n3. Reference them constantly\n4. Update session_trifecta_dope.md when you finish\n\n---\n\n## Quick Start\n\n```bash\n# Install\nuv sync --all-groups\n\n# Run CLI\nuv run trifecta --help\n\n# Tests\nuv run pytest                    # All tests\nuv run pytest -m \"not slow\"      # Skip slow tests\nuv run pytest tests/acceptance/  # Acceptance gate\n\n# Type check & lint\nuv run mypy src/ --strict\nuv run ruff check src/\nuv run ruff format src/\n```\n\n---\n\n## Architecture Overview\n\n**Python + Clean Architecture** with strict layer separation:\n\n- **Domain** (`src/domain/`) - Pure business logic (no IO, no async, no framework dependencies)\n- **Application** (`src/application/`) - Use cases, orchestration\n- **Infrastructure** (`src/infrastructure/`) - Framework adapters, IO, external services\n\n**Critical Rule:** Dependencies point INWARD. Domain → Application → Infrastructure.\n\nSee `docs/CONTRACTS.md` and architecture docs in `docs/adr/` for complete patterns.\n\n---\n\n## Key Patterns\n\n- **Frozen dataclasses** for domain entities (immutable)\n- **Pure functions** in domain services (testable without mocks)\n- **Protocols** for infrastructure interfaces (ports/adapters)\n- **Result types** for error handling (`Ok[T] | Err[E]`)\n- **Telemetry** for observability (no side-effect in tests via `TRIFECTA_NO_TELEMETRY`)\n\n---\n\n## Development Workflow\n\n- **TDD**: Write tests BEFORE implementation (RED → GREEN → REFACTOR)\n- **Domain first**: Business logic is pure and tested in isolation\n- **Use `uv`**: Package management and task runner\n- **Pre-commit hooks**: Auto-run tests on commit (bypass with `--no-verify` if needed)\n\n---\n\n## Red Flags\n\n| Violation | Why It's Wrong | Fix |\n|-----------|----------------|-----|\n| IO in domain | Domain must be pure | Move to infrastructure adapter |\n| Async in domain | Domain is synchronous | Move to application/infra |\n| Pydantic in domain | Framework coupling | Use frozen dataclasses |\n| Untested pure functions | Easy to test, no excuse | Write unit tests |\n| Hardcoded paths | Portability issues | Use `repo_root()` helper |\n\n---\n\n## Testing\n\n- **Unit tests** (`tests/unit/`) - Domain logic, pure functions\n- **Integration tests** (`tests/integration/`) - Use cases with real adapters\n- **Acceptance tests** (`tests/acceptance/`) - Black-box CLI tests (gate: `-m \"not slow\"`)\n- **Roadmap tests** (`tests/roadmap/`) - Future features (isolated, `--ignore`)\n\n**Coverage target**: ≥80% branch coverage\n\n---\n\n## Source of Truth\n\n### Repository Documentation\n- **README.md** - Project overview, installation\n- **docs/CONTRACTS.md** - API contracts, schemas\n- **docs/CLI_WORKFLOW.md** - Official CLI usage\n- **docs/adr/** - Architecture decision records\n- **docs/backlog/** - Work Order system (WORKFLOW.md, OPERATIONS.md, TROUBLESHOOTING.md)\n\n---\n\n## Trifecta-Specific Rules\n\n### _ctx/ Directory Conventions\n- **_ctx/logs/**: ONLY .log files (command stdout/stderr). Use /tmp/ for intermediate .md files.\n- **When updating session.md**: Create temp in /tmp/, append with `cat`, then cleanup. Never store .md in _ctx/logs/.\n\n### Context Pack Workflow\n1. `trifecta create --segment .` - Bootstrap metadata\n2. `trifecta ctx sync --segment .` - Build context pack\n3. `trifecta ctx validate --segment .` - Verify integrity\n4. `trifecta ctx search --segment . --query \"...\"` - Search\n5. `trifecta ctx get --segment . --ids \"...\"` - Retrieve chunks\n\n### Environment & Ops\n- **Scope Separation**: `pyproject.toml` / `pytest-env` is for **Tests**. `.envrc` (direnv) is for **Dev CLI**.\n- **Default Enablement**: Must be verified via CLI *without* env var prefixes.\n- **Audit-Grade Gates**: `exit 0` is not enough. Verify internal state (telemetry backend, file creation).\n- **Rollback**: Must be verifiable in <5 minutes via env var override.\n\n---\n\n## Work Orders (WO System)\n\nThe WO system provides isolated development environments using git worktrees.\n\n### Quick Workflow\n\n```bash\n# List pending WOs\npython scripts/ctx_wo_take.py --list\n\n# Take WO (auto-creates branch + worktree)\npython scripts/ctx_wo_take.py WO-XXXX\n\n# Navigate & work\ncd .worktrees/WO-XXXX\n\n# Complete WO\npython scripts/ctx_wo_finish.py WO-XXXX\n```\n\n### Key Scripts\n\n| Script | Purpose |\n|--------|---------|\n| `ctx_wo_take.py` | Take WO with auto branch/worktree creation |\n| `ctx_wo_finish.py` | Complete WO with DoD validation |\n| `helpers.py` | Core utilities (worktree, lock, branch) |\n| `ctx_reconcile_state.py` | Repair state inconsistencies |\n\n### Structure & State Machine\n\n```\n_ctx/jobs/\n├── pending/*.yaml    → [take] → running/*.yaml → [finish] → done/*.yaml\n└── failed/*.yaml\n```\n\n**States**: pending → running → done (or failed)\n\n### Worktree Management\n\n- **Branch**: `feat/wo-WO-XXXX` (from `main`)\n- **Path**: `.worktrees/WO-XXXX`\n- **Lock**: `_ctx/jobs/running/WO-XXXX.lock` (atomic, stale >1h auto-cleaned)\n\n```bash\ngit worktree list              # List worktrees\ngit worktree remove .worktrees/WO-XXXX  # Cleanup\n```\n\n### Detailed Documentation\n\n- **[WORKFLOW.md](docs/backlog/WORKFLOW.md)** — Complete lifecycle guide\n- **[OPERATIONS.md](docs/backlog/OPERATIONS.md)** — Daily operations playbook\n- **[TROUBLESHOOTING.md](docs/backlog/TROUBLESHOOTING.md)** — Common issues\n- **[README.md](docs/backlog/README.md)** — Quick reference\n\n---\n\n## Telemetry\n\n- **Production**: Events logged to `_ctx/telemetry/events.jsonl`\n- **Testing**: Use `TRIFECTA_NO_TELEMETRY=1` for zero side-effects\n- **Pre-commit**: Auto-redirects telemetry via `TRIFECTA_TELEMETRY_DIR`\n\n---\n\n## Common Tasks\n\n```bash\n# Create new segment\nuv run trifecta create --segment /path/to/project\n\n# Sync context\nuv run trifecta ctx sync --segment .\n\n# Search + get workflow\nuv run trifecta ctx search --segment . --query \"ErrorCard\" --limit 5\nuv run trifecta ctx get --segment . --ids \"prime:abc123\" --mode excerpt\n\n# AST symbols (M1)\nuv run trifecta ast symbols \"sym://python/mod/src.domain.result\" --segment .\n\n# Run gate\nbash scripts/gate_clean_worktree_repro.sh  # WO-0007 reproducibility\n```\n\n---\n\n**Living Document**: Update this file when friction is encountered or new patterns emerge.\n",
+      "char_count": 8499,
+      "token_est": 2124,
       "source_path": "CLAUDE.md",
       "chunking_method": "whole_file"
     },
+    {
+      "id": "repo:agents.md:1efa3b40bc",
+      "doc": "repo:agents.md",
+      "title_path": [
+        "agents.md"
+      ],
+      "text": "# CLAUDE.md\n\nThis file provides guidance to Claude Code (claude.ai/code) when working with code in this repository.\n\n---\n\n## ⚠️ CRITICAL: READ THIS FIRST BEFORE ANY TASK\n\n**DO NOT PROCEED WITH ANY TASK WITHOUT READING THESE CONTEXT FILES.**\n\nAssuming anything about this project without consulting these files is a breach of the work contract.\n\n### Agent Context Files (MANDATORY - READ THESE FIRST)\n\nThese files contain **CURRENT PROJECT STATE, ACTIVE FEATURES, AND ARCHITECTURE DECISIONS**. Ignoring them will result in:\n- ✗ Breaking existing implementations\n- ✗ Duplicating work already done\n- ✗ Misunderstanding the current system state\n- ✗ Failing verification gates\n\n**READ IN THIS ORDER:**\n\n0. **[skill.md](skill.md)** ← START HERE FIRST (3 min read)\n   - **What**: Skills, roles, and core rules for this project\n   - **Why**: Know the mandatory patterns and commands to use\n   - **Contains**: Setup instructions, context cycle, session persistence\n   - **CRITICAL**: Skip this → you'll use wrong commands and waste cycles\n\n1. **[_ctx/agent_trifecta_dope.md](_ctx/agent_trifecta_dope.md)** ← THEN READ THIS (5 min read)\n   - **What**: Current implementation status and active features\n   - **Why**: Know what's ACTUALLY implemented vs. what's planned\n   - **Contains**: Tech stack versions, active patterns, completed work\n   - **CRITICAL**: Skip this → you'll duplicate work or break things\n\n2. **[_ctx/session_trifecta_dope.md](_ctx/session_trifecta_dope.md)** ← THEN READ THIS (2 min skim)\n   - **What**: Session history and continuation points\n   - **Why**: Understand what was done in the last session\n   - **Contains**: Previous decisions, known workarounds, open issues\n   - **CRITICAL**: Skip this → you'll miss workarounds and hit known bugs\n\n3. **[_ctx/prime_trifecta_dope.md](_ctx/prime_trifecta_dope.md)** ← REFERENCE THIS (1 min check)\n   - **What**: Architectural reference and system structure\n   - **Why**: Understand the fundamental system design\n   - **Contains**: Core patterns, layer separation, dependency rules\n   - **CRITICAL**: Skip this → you'll violate architectural constraints\n\n### If You Skip These Files\n\n⛔ **YOU WILL:**\n- Propose features that already exist\n- Break working implementations\n- Violate architectural patterns\n- Fail the verification gate\n- Use wrong commands and waste tokens\n- Waste time and tokens\n\n✅ **INSTEAD:**\n1. Read the 4 context files (11 min total)\n2. Then start your task\n3. Reference them constantly\n4. Update session_trifecta_dope.md when you finish\n\n---\n\n## Quick Start\n\n```bash\n# Install\nuv sync --all-groups\n\n# Run CLI\nuv run trifecta --help\n\n# Tests\nuv run pytest                    # All tests\nuv run pytest -m \"not slow\"      # Skip slow tests\nuv run pytest tests/acceptance/  # Acceptance gate\n\n# Type check & lint\nuv run mypy src/ --strict\nuv run ruff check src/\nuv run ruff format src/\n```\n\n---\n\n## Architecture Overview\n\n**Python + Clean Architecture** with strict layer separation:\n\n- **Domain** (`src/domain/`) - Pure business logic (no IO, no async, no framework dependencies)\n- **Application** (`src/application/`) - Use cases, orchestration\n- **Infrastructure** (`src/infrastructure/`) - Framework adapters, IO, external services\n\n**Critical Rule:** Dependencies point INWARD. Domain → Application → Infrastructure.\n\nSee `docs/CONTRACTS.md` and architecture docs in `docs/adr/` for complete patterns.\n\n---\n\n## Key Patterns\n\n- **Frozen dataclasses** for domain entities (immutable)\n- **Pure functions** in domain services (testable without mocks)\n- **Protocols** for infrastructure interfaces (ports/adapters)\n- **Result types** for error handling (`Ok[T] | Err[E]`)\n- **Telemetry** for observability (no side-effect in tests via `TRIFECTA_NO_TELEMETRY`)\n\n---\n\n## Development Workflow\n\n- **TDD**: Write tests BEFORE implementation (RED → GREEN → REFACTOR)\n- **Domain first**: Business logic is pure and tested in isolation\n- **Use `uv`**: Package management and task runner\n- **Pre-commit hooks**: Auto-run tests on commit (bypass with `--no-verify` if needed)\n\n---\n\n## Red Flags\n\n| Violation | Why It's Wrong | Fix |\n|-----------|----------------|-----|\n| IO in domain | Domain must be pure | Move to infrastructure adapter |\n| Async in domain | Domain is synchronous | Move to application/infra |\n| Pydantic in domain | Framework coupling | Use frozen dataclasses |\n| Untested pure functions | Easy to test, no excuse | Write unit tests |\n| Hardcoded paths | Portability issues | Use `repo_root()` helper |\n\n---\n\n## Testing\n\n- **Unit tests** (`tests/unit/`) - Domain logic, pure functions\n- **Integration tests** (`tests/integration/`) - Use cases with real adapters\n- **Acceptance tests** (`tests/acceptance/`) - Black-box CLI tests (gate: `-m \"not slow\"`)\n- **Roadmap tests** (`tests/roadmap/`) - Future features (isolated, `--ignore`)\n\n**Coverage target**: ≥80% branch coverage\n\n---\n\n## Source of Truth\n\n### Repository Documentation\n- **README.md** - Project overview, installation\n- **docs/CONTRACTS.md** - API contracts, schemas\n- **docs/CLI_WORKFLOW.md** - Official CLI usage\n- **docs/adr/** - Architecture decision records\n- **docs/backlog/** - Work Order system (WORKFLOW.md, OPERATIONS.md, TROUBLESHOOTING.md)\n\n---\n\n## Trifecta-Specific Rules\n\n### _ctx/ Directory Conventions\n- **_ctx/logs/**: ONLY .log files (command stdout/stderr). Use /tmp/ for intermediate .md files.\n- **When updating session.md**: Create temp in /tmp/, append with `cat`, then cleanup. Never store .md in _ctx/logs/.\n\n### Context Pack Workflow\n1. `trifecta create --segment .` - Bootstrap metadata\n2. `trifecta ctx sync --segment .` - Build context pack\n3. `trifecta ctx validate --segment .` - Verify integrity\n4. `trifecta ctx search --segment . --query \"...\"` - Search\n5. `trifecta ctx get --segment . --ids \"...\"` - Retrieve chunks\n\n### Environment & Ops\n- **Scope Separation**: `pyproject.toml` / `pytest-env` is for **Tests**. `.envrc` (direnv) is for **Dev CLI**.\n- **Default Enablement**: Must be verified via CLI *without* env var prefixes.\n- **Audit-Grade Gates**: `exit 0` is not enough. Verify internal state (telemetry backend, file creation).\n- **Rollback**: Must be verifiable in <5 minutes via env var override.\n\n---\n\n## Work Orders (WO System)\n\nThe WO system provides isolated development environments using git worktrees.\n\n### Quick Workflow\n\n```bash\n# List pending WOs\npython scripts/ctx_wo_take.py --list\n\n# Take WO (auto-creates branch + worktree)\npython scripts/ctx_wo_take.py WO-XXXX\n\n# Navigate & work\ncd .worktrees/WO-XXXX\n\n# Complete WO\npython scripts/ctx_wo_finish.py WO-XXXX\n```\n\n### Key Scripts\n\n| Script | Purpose |\n|--------|---------|\n| `ctx_wo_take.py` | Take WO with auto branch/worktree creation |\n| `ctx_wo_finish.py` | Complete WO with DoD validation |\n| `helpers.py` | Core utilities (worktree, lock, branch) |\n| `ctx_reconcile_state.py` | Repair state inconsistencies |\n\n### Structure & State Machine\n\n```\n_ctx/jobs/\n├── pending/*.yaml    → [take] → running/*.yaml → [finish] → done/*.yaml\n└── failed/*.yaml\n```\n\n**States**: pending → running → done (or failed)\n\n### Worktree Management\n\n- **Branch**: `feat/wo-WO-XXXX` (from `main`)\n- **Path**: `.worktrees/WO-XXXX`\n- **Lock**: `_ctx/jobs/running/WO-XXXX.lock` (atomic, stale >1h auto-cleaned)\n\n```bash\ngit worktree list              # List worktrees\ngit worktree remove .worktrees/WO-XXXX  # Cleanup\n```\n\n### Detailed Documentation\n\n- **[WORKFLOW.md](docs/backlog/WORKFLOW.md)** — Complete lifecycle guide\n- **[OPERATIONS.md](docs/backlog/OPERATIONS.md)** — Daily operations playbook\n- **[TROUBLESHOOTING.md](docs/backlog/TROUBLESHOOTING.md)** — Common issues\n- **[README.md](docs/backlog/README.md)** — Quick reference\n\n---\n\n## Telemetry\n\n- **Production**: Events logged to `_ctx/telemetry/events.jsonl`\n- **Testing**: Use `TRIFECTA_NO_TELEMETRY=1` for zero side-effects\n- **Pre-commit**: Auto-redirects telemetry via `TRIFECTA_TELEMETRY_DIR`\n\n---\n\n## Common Tasks\n\n```bash\n# Create new segment\nuv run trifecta create --segment /path/to/project\n\n# Sync context\nuv run trifecta ctx sync --segment .\n\n# Search + get workflow\nuv run trifecta ctx search --segment . --query \"ErrorCard\" --limit 5\nuv run trifecta ctx get --segment . --ids \"prime:abc123\" --mode excerpt\n\n# AST symbols (M1)\nuv run trifecta ast symbols \"sym://python/mod/src.domain.result\" --segment .\n\n# Run gate\nbash scripts/gate_clean_worktree_repro.sh  # WO-0007 reproducibility\n```\n\n---\n\n**Living Document**: Update this file when friction is encountered or new patterns emerge.\n",
+      "char_count": 8499,
+      "token_est": 2124,
+      "source_path": "agents.md",
+      "chunking_method": "whole_file"
+    },
     {
       "id": "repo:readme_tf.md:13332b0b4a",
       "doc": "repo:readme_tf.md",
@@ -5031,10 +5229,10 @@
       "token_est": 1992
     },
     {
-      "id": "session:785e4f2fe3",
+      "id": "session:335bc3c6a3",
       "title_path_norm": "session_trifecta_dope.md",
       "preview": "# session.md - Trifecta Context Runbook\n\nsegment: trifecta-dope\n\n## Purpose\nThis file is a **runbook** for using Trifecta Context tools efficiently:\n- progressive disclosure (search -> get)\n- strict b...",
-      "token_est": 14489
+      "token_est": 14807
     },
     {
       "id": "repo:docs/telemetry_concurrency.md:36eb376664",
@@ -5330,12 +5528,30 @@
       "preview": "Informe de Auditoría Técnica: Arquitecturas Deterministas de Navegación de Código para Agentes de Software (Enfoque Lean)\nResumen Ejecutivo\nEste informe técnico establece una hoja de ruta para la impl...",
       "token_est": 7898
     },
+    {
+      "id": "repo:docs/backlog/WORKFLOW.md:d1475c0575",
+      "title_path_norm": "WORKFLOW.md",
+      "preview": "# Work Order Workflow Guide\n\nComplete guide to the Work Order (WO) lifecycle in Trifecta Dope.\n\n## Overview\n\nThe WO system provides atomic, isolated development environments for each work order using...",
+      "token_est": 2809
+    },
     {
       "id": "repo:docs/backlog/MIGRATION.md:f90fdf7627",
       "title_path_norm": "MIGRATION.md",
       "preview": "# Backlog Migration\n\n## Source\n\n- `docs/backlog/legacy/inputs/central_telefonica_v0.1.yaml`\n\n## Mapping\n\n- Epic `E-0001` copied into `_ctx/backlog/backlog.yaml`\n- `generated_at` preserved, `curated_at...",
       "token_est": 111
     },
+    {
+      "id": "repo:docs/backlog/OPERATIONS.md:33228b1dfa",
+      "title_path_norm": "OPERATIONS.md",
+      "preview": "# Work Order Operations Playbook\n\nDaily operations guide for working with Trifecta Dope Work Orders.\n\n## Quick Reference\n\n```bash\n# Start of day\npython scripts/ctx_wo_take.py --list      # See pending...",
+      "token_est": 2719
+    },
+    {
+      "id": "repo:docs/backlog/TROUBLESHOOTING.md:797a0cb75a",
+      "title_path_norm": "TROUBLESHOOTING.md",
+      "preview": "# Work Order Troubleshooting Guide\n\nCommon issues, errors, and solutions for the Trifecta Dope WO system.\n\n## Quick Diagnostics\n\n**Run these commands first:**\n\n```bash\n# Check system status\npython scr...",
+      "token_est": 2781
+    },
     {
       "id": "repo:docs/backlog/LESSONS.md:fa78b1dc77",
       "title_path_norm": "LESSONS.md",
@@ -5343,10 +5559,10 @@
       "token_est": 55
     },
     {
-      "id": "repo:docs/backlog/README.md:b1178ab455",
+      "id": "repo:docs/backlog/README.md:1b804b230e",
       "title_path_norm": "README.md",
-      "preview": "# Backlog + Work Orders Pipeline\n\n## State machine\n\nWork orders move through these states:\n\n- `pending` -> `running` -> `done`\n- `pending` -> `running` -> `failed`\n\nA WO can only be `done` when its Do...",
-      "token_est": 194
+      "preview": "# Backlog + Work Orders Pipeline\n\n## Quick Start\n\n```bash\n# 1. List pending work orders\npython scripts/ctx_wo_take.py --list\n\n# 2. Take a work order (auto-creates branch + worktree)\npython scripts/ctx...",
+      "token_est": 1566
     },
     {
       "id": "repo:docs/bugs/create_cwd_bug.md:c3f0529e5f",
@@ -5798,6 +6014,12 @@
       "preview": "# Trifecta Northstar Kanban SOT - Implementation Plan\n\n> **For Claude:** REQUIRED SUB-SKILL: Use superpowers:executing-plans to implement this plan task-by-task.\n\n**Goal:** Crear un Kanban vivo que ac...",
       "token_est": 1607
     },
+    {
+      "id": "repo:docs/plans/2026-01-06-fix-debug-scripts.md:1d8996a76c",
+      "title_path_norm": "2026-01-06-fix-debug-scripts.md",
+      "preview": "# Fix Debug Scripts Implementation Plan\n\n> **For Claude:** REQUIRED SUB-SKILL: Use superpowers:executing-plans to implement this plan task-by-task.\n\n**Goal:** Formalize `scripts/debug` contents into a...",
+      "token_est": 422
+    },
     {
       "id": "repo:docs/plans/t9_3_eval_report.md:f116b8ee19",
       "title_path_norm": "t9_3_eval_report.md",
@@ -5840,6 +6062,12 @@
       "preview": "# WO-P2.1: AST Cache Telemetry Implementation Plan\n\n**Date**: 2026-01-06  \n**Status**: ACTIVE  \n**Priority**: P0 (Blocks global enable)\n\n---\n\n## Objective\n\nIntegrate audit-grade telemetry into AST cac...",
       "token_est": 1460
     },
+    {
+      "id": "repo:docs/plans/2026-01-09-wo0013-ast-adoption-observability.md:e87504cae8",
+      "title_path_norm": "2026-01-09-wo0013-ast-adoption-observability.md",
+      "preview": "# WO-0013: AST Persist Adoption Observability Implementation Plan\n\n> **For Claude:** REQUIRED SUB-SKILL: Use superpowers:executing-plans to implement this plan task-by-task.\n\n**Goal:** Implement telem...",
+      "token_est": 7308
+    },
     {
       "id": "repo:docs/plans/2026-01-02-auditability-gates-v2-antipatterns.md:a825638827",
       "title_path_norm": "2026-01-02-auditability-gates-v2-antipatterns.md",
@@ -6038,6 +6266,12 @@
       "preview": "# Field Exercises Evaluation - Continuous Improvement Guide\n\n## Overview\n\nField Exercises is a **living evaluation system** designed to track search quality metrics over time. Each evaluation run is v...",
       "token_est": 1510
     },
+    {
+      "id": "repo:docs/reports/code_complexity_analysis.md:b726570e50",
+      "title_path_norm": "code_complexity_analysis.md",
+      "preview": "# Code Complexity Analysis Report\n\n**Date:** 2026-01-09\n**Analyzed Files:**\n- `/Users/felipe_gonzalez/Developer/agent_h/trifecta_dope/eval/scripts/analyze_adoption_telemetry.py`\n- `/Users/felipe_gonza...",
+      "token_est": 8196
+    },
     {
       "id": "repo:docs/reports/KNOWN_FAILS.md:10a35718a8",
       "title_path_norm": "KNOWN_FAILS.md",
@@ -6116,6 +6350,12 @@
       "preview": "# Repository Scoop v1.1 — Fail-Closed Audit (CLAIM→EVIDENCE→SHA→VERDICT)\n\n**Auditor**: Gemini (Red Team, Read-Only Protocol)  \n**Timestamp**: 2026-01-05T20:01:00-03:00  \n**Repo Root**: `/Users/felipe_...",
       "token_est": 3023
     },
+    {
+      "id": "repo:docs/reports/2026-01-11-pr18-error-handling-audit.md:f23747f8dd",
+      "title_path_norm": "2026-01-11-pr18-error-handling-audit.md",
+      "preview": "# Error Handling Audit Report: PR #18 (WO Orchestration Improvements)\n\n**Audit Date**: 2026-01-11\n**Auditor**: Claude Code (Error Handling Specialist)\n**Scope**: Transaction safety, rollback mechanism...",
+      "token_est": 10527
+    },
     {
       "id": "repo:docs/reports/anchor_dictionary_v1.md:cf19eb986f",
       "title_path_norm": "anchor_dictionary_v1.md",
@@ -6303,10 +6543,10 @@
       "token_est": 390
     },
     {
-      "id": "repo:src/application/use_cases.py:b8ad6b88dd",
+      "id": "repo:src/application/use_cases.py:c856d17cfb",
       "title_path_norm": "use_cases.py",
-      "preview": "import json\nimport re\nimport subprocess\nfrom datetime import datetime\nfrom pathlib import Path\nfrom typing import Any\n\nimport yaml  # type: ignore[import-untyped]\n\nfrom src.application.context_service...",
-      "token_est": 9521
+      "preview": "import json\nimport re\nimport subprocess\nimport sys\nfrom datetime import datetime\nfrom pathlib import Path\nfrom typing import Any\n\nimport yaml  # type: ignore[import-untyped]\n\nfrom src.application.cont...",
+      "token_est": 9516
     },
     {
       "id": "repo:src/application/exceptions.py:ce36f32302",
@@ -6387,10 +6627,10 @@
       "token_est": 284
     },
     {
-      "id": "repo:src/application/obsidian_sync_use_case.py:1624323f39",
+      "id": "repo:src/application/obsidian_sync_use_case.py:2bfd345dab",
       "title_path_norm": "obsidian_sync_use_case.py",
       "preview": "\"\"\"Obsidian sync use case.\n\nThis module orchestrates the end-to-end sync of findings to Obsidian,\nfollowing Trifecta's Clean Architecture use case pattern.\n\nFollowing Trifecta Clean Architecture:\n- Ap...",
-      "token_est": 1820
+      "token_est": 1826
     },
     {
       "id": "repo:src/application/lsp_manager.py:fedb1ab41a",
@@ -6399,10 +6639,10 @@
       "token_est": 1924
     },
     {
-      "id": "repo:src/application/search_get_usecases.py:a218ecc485",
+      "id": "repo:src/application/search_get_usecases.py:af8ae18020",
       "title_path_norm": "search_get_usecases.py",
       "preview": "\"\"\"Use case wrappers for Search and Get with telemetry.\"\"\"\n\nimport hashlib\nfrom pathlib import Path\nfrom typing import Any, Literal, Optional\n\nfrom src.application.context_service import ContextServic...",
-      "token_est": 2894
+      "token_est": 2895
     },
     {
       "id": "repo:src/application/__init__.py:2f9e4ccbad",
@@ -6489,10 +6729,22 @@
       "token_est": 374
     },
     {
-      "id": "repo:src/domain/query_linter.py:edf8e3cc57",
+      "id": "repo:src/domain/wo_transactions.py:68d0a58109",
+      "title_path_norm": "wo_transactions.py",
+      "preview": "\"\"\"\nTransaction management for WO operations.\nPure domain logic - defines rollback operations.\n\"\"\"\nfrom dataclasses import dataclass\nfrom enum import StrEnum\nfrom typing import Optional\n\n\nclass Rollba...",
+      "token_est": 581
+    },
+    {
+      "id": "repo:src/domain/query_linter.py:5f92862d50",
       "title_path_norm": "query_linter.py",
       "preview": "from typing import TypedDict\nfrom src.domain.anchor_extractor import extract_anchors\n\n\nclass LinterChanges(TypedDict):\n    \"\"\"Type for linter changes structure.\"\"\"\n\n    added_strong: list[str]\n    add...",
-      "token_est": 1559
+      "token_est": 1542
+    },
+    {
+      "id": "repo:src/domain/wo_entities.py:36eb466b99",
+      "title_path_norm": "wo_entities.py",
+      "preview": "\"\"\"\nWork Order domain entities and business rules.\nPure domain module - no IO, no external dependencies.\n\"\"\"\nimport re\nfrom dataclasses import dataclass, field\nfrom datetime import datetime, timezone...",
+      "token_est": 1346
     },
     {
       "id": "repo:src/cli/error_cards.py:3edc60e345",
@@ -6501,10 +6753,16 @@
       "token_est": 205
     },
     {
-      "id": "repo:src/cli/invalid_option_handler.py:e50c0a64c8",
+      "id": "repo:src/cli/invalid_option_handler.py:938358e463",
       "title_path_norm": "invalid_option_handler.py",
-      "preview": "\"\"\"\nInvalid Option Handler for CLI error messages.\n\nProvides fuzzy matching and helpful suggestions when users provide invalid flags.\n\"\"\"\n\nfrom __future__ import annotations\n\nimport difflib\nfrom datac...",
-      "token_est": 1977
+      "preview": "\"\"\"Invalid Option Handler for CLI error messages.\n\nProvides fuzzy matching and helpful suggestions when users provide invalid flags.\nUses runtime introspection (not static mappings) to ensure suggesti...",
+      "token_est": 2097
+    },
+    {
+      "id": "repo:src/cli/introspection.py:60e5f4dd96",
+      "title_path_norm": "introspection.py",
+      "preview": "\"\"\"Introspection module for CLI option discovery.\n\nProvides runtime introspection of Click/Typer commands to extract\nvalid flags and options. This is the single source of truth for\ncurrently available...",
+      "token_est": 2333
     },
     {
       "id": "repo:src/cli/__init__.py:5589da29ee",
@@ -6519,22 +6777,22 @@
       "token_est": 707
     },
     {
-      "id": "repo:src/infrastructure/lsp_daemon.py:eefb94ce95",
+      "id": "repo:src/infrastructure/lsp_daemon.py:89bd5a31c5",
       "title_path_norm": "lsp_daemon.py",
       "preview": "import os\nimport sys\nimport socket\nimport time\nimport json\nimport signal\nimport fcntl\nimport subprocess\nfrom pathlib import Path\nfrom typing import Any, Optional, Dict\nfrom src.infrastructure.lsp_clie...",
-      "token_est": 2345
+      "token_est": 2348
     },
     {
-      "id": "repo:src/infrastructure/cli_ast.py:2e4eab4aa4",
+      "id": "repo:src/infrastructure/cli_ast.py:fbed31ac9b",
       "title_path_norm": "cli_ast.py",
       "preview": "import typer  # type: ignore\nimport time\nimport json\nfrom pathlib import Path\nfrom typing import Optional\nfrom src.infrastructure.telemetry import Telemetry\nfrom src.domain.result import Ok, Err\nfrom...",
-      "token_est": 1659
+      "token_est": 1660
     },
     {
-      "id": "repo:src/infrastructure/file_locked_cache.py:25e018095e",
+      "id": "repo:src/infrastructure/file_locked_cache.py:719f157fa6",
       "title_path_norm": "file_locked_cache.py",
       "preview": "\"\"\"\nFile-locked wrapper for AstCache.\n\nThis wrapper adds deterministic file locking around any AstCache implementation\nwithout modifying the underlying cache. Keeps OS concerns in infrastructure layer...",
-      "token_est": 964
+      "token_est": 979
     },
     {
       "id": "repo:src/infrastructure/alias_loader.py:039a44a995",
@@ -6585,16 +6843,16 @@
       "token_est": 253
     },
     {
-      "id": "repo:src/infrastructure/lsp_client.py:896a0c5354",
+      "id": "repo:src/infrastructure/lsp_client.py:6a0a85882f",
       "title_path_norm": "lsp_client.py",
-      "preview": "import subprocess\nimport json\nimport shutil\nimport threading\nimport os\nfrom typing import Optional, Dict, Any\nfrom enum import Enum\nfrom pathlib import Path\n\n\nclass LSPState(Enum):\n    COLD = \"COLD\"...",
-      "token_est": 3335
+      "preview": "import subprocess\nimport json\nimport shutil\nimport threading\nimport os\nimport sys\nfrom typing import Optional, Dict, Any\nfrom enum import Enum\nfrom pathlib import Path\n\n\nclass LSPState(Enum):\n    COLD...",
+      "token_est": 3344
     },
     {
-      "id": "repo:src/infrastructure/config_loader.py:603a1cbb46",
+      "id": "repo:src/infrastructure/config_loader.py:23849e59a6",
       "title_path_norm": "config_loader.py",
       "preview": "\"\"\"Load YAML configs with graceful error handling and auditable markers.\"\"\"\n\nimport sys\nfrom pathlib import Path\nfrom typing import Dict, Any\nimport yaml\n\n\nclass ConfigLoader:\n    \"\"\"Load YAML configs...",
-      "token_est": 851
+      "token_est": 831
     },
     {
       "id": "repo:src/infrastructure/hookify_logger.py:482ff187be",
@@ -6603,16 +6861,16 @@
       "token_est": 2798
     },
     {
-      "id": "repo:src/infrastructure/deprecations.py:9beecf81f5",
+      "id": "repo:src/infrastructure/deprecations.py:0306d5da51",
       "title_path_norm": "deprecations.py",
       "preview": "\"\"\"Deprecated code path tracking utilities.\n\nEmits telemetry events when deprecated code paths are used.\nPolicy controlled by TRIFECTA_DEPRECATED env var (off|warn|fail).\n\"\"\"\n\nimport os\nimport sys\nfro...",
-      "token_est": 335
+      "token_est": 334
     },
     {
-      "id": "repo:src/infrastructure/cli.py:2f7bb84cfd",
+      "id": "repo:src/infrastructure/cli.py:009ba2b361",
       "title_path_norm": "cli.py",
-      "preview": "\"\"\"Trifecta CLI with T8 Telemetry.\"\"\"\n\nimport json\nimport os\nimport sys\nimport time\nfrom pathlib import Path\nfrom typing import Literal, Optional, Tuple\n\nimport click\nimport typer  # type: ignore\nfrom...",
-      "token_est": 15713
+      "preview": "\"\"\"Trifecta CLI with T8 Telemetry.\"\"\"\n\nimport json\nimport os\nimport sys\nimport time\nimport traceback\nfrom pathlib import Path\nfrom typing import Literal, Optional, Tuple\n\nimport click\nimport typer  #...",
+      "token_est": 15733
     },
     {
       "id": "repo:src/infrastructure/telemetry_cache.py:8bff1d2e2d",
@@ -6645,10 +6903,16 @@
       "token_est": 3347
     },
     {
-      "id": "repo:CLAUDE.md:c279474056",
+      "id": "repo:CLAUDE.md:1c7efe0bac",
       "title_path_norm": "CLAUDE.md",
-      "preview": "# CLAUDE.md\n\nThis file provides guidance to Claude Code (claude.ai/code) when working with code in this repository.\n\n---\n\n## Quick Start\n\n```bash\n# Install\nuv sync --all-groups\n\n# Run CLI\nuv run trife...",
-      "token_est": 1553
+      "preview": "# CLAUDE.md\n\nThis file provides guidance to Claude Code (claude.ai/code) when working with code in this repository.\n\n---\n\n## ⚠️ CRITICAL: READ THIS FIRST BEFORE ANY TASK\n\n**DO NOT PROCEED WITH ANY TAS...",
+      "token_est": 2124
+    },
+    {
+      "id": "repo:agents.md:1efa3b40bc",
+      "title_path_norm": "agents.md",
+      "preview": "# CLAUDE.md\n\nThis file provides guidance to Claude Code (claude.ai/code) when working with code in this repository.\n\n---\n\n## ⚠️ CRITICAL: READ THIS FIRST BEFORE ANY TASK\n\n**DO NOT PROCEED WITH ANY TAS...",
+      "token_est": 2124
     },
     {
       "id": "repo:readme_tf.md:13332b0b4a",
diff --git a/_ctx/generated/repo_map.md b/_ctx/generated/repo_map.md
index 196f880..a887466 100644
--- a/_ctx/generated/repo_map.md
+++ b/_ctx/generated/repo_map.md
@@ -2,7 +2,7 @@
 
 > **Generated**: __DATE__
 > **Purpose**: High-level module navigation for ctx.plan code_navigation feature
-> **Hash**: 67577d22d499
+> **Hash**: 143605f7e8b5
 
 ---
 
diff --git a/_ctx/generated/symbols_stub.md b/_ctx/generated/symbols_stub.md
index 4b94405..73a66e1 100644
--- a/_ctx/generated/symbols_stub.md
+++ b/_ctx/generated/symbols_stub.md
@@ -2,7 +2,7 @@
 
 > **Status**: Placeholder for symbol-level navigation
 > **Version**: v1 (Prime-based) → v2 (AST/LSP-based, planned)
-> **Hash**: 67577d22d499
+> **Hash**: 143605f7e8b5
 
 ---
 
diff --git a/_ctx/jobs/pending/E-0012.yaml b/_ctx/jobs/pending/E-0012.yaml
deleted file mode 100644
index dbd4670..0000000
--- a/_ctx/jobs/pending/E-0012.yaml
+++ /dev/null
@@ -1,56 +0,0 @@
-version: 1
-id: E-0012
-title: "WO System Compliance & Test Coverage"
-description: |
-  Fix WO-0012 manual closure retroactively, add process guards to prevent future bypasses,
-  and implement comprehensive test coverage for WO closure workflow.
-
-status: pending
-priority: P1
-
-wo_queue:
-  - WO-0018A # Fix WO-0012 & Add Process Guards
-  - WO-0018B # WO Closure Test Coverage
-  - WO-0018C # Documentation & Telemetry Cleanup
-
-x_phases:
-  - name: "WO-0018A: Fix & Guard"
-    status: pending
-    description: "Retro-fix WO-0012, add fail-closed validation, prevent manual closures"
-  - name: "WO-0018B: Test Coverage"
-    status: pending
-    description: "Add comprehensive tests for closure workflow (30+ tests)"
-  - name: "WO-0018C: Docs & Cleanup"
-    status: pending
-    description: "Feature flag docs, telemetry rotation, backlog update"
-
-x_context: |
-  **Background:**
-  WO-0012 was manually closed (commit c2ef040) by creating done/WO-0012.yaml directly,
-  bypassing ctx_wo_finish.py which validates DoD artifacts.
-
-  **Multi-Agent Review Findings:**
-  - Code Reviewer: 7 high-confidence implementation issues
-  - Test Analyzer: 11 test coverage gaps
-  - Silent Failure Hunter: 11 error handling issues
-  - Total: 25+ issues identified and fixed in plan
-
-  **Key Design Decisions:**
-  1. Document (don't hide) pre-existing test failures in verdict.json
-  2. Use real subprocess in tests, not mocks (matches existing patterns)
-  3. Atomic temp-dir pattern for artifact generation
-  4. Transaction wrapper with rollback for finish operation
-
-x_success_criteria:
-  - WO-0012 has proper DoD artifacts in _ctx/handoff/WO-0012/
-  - Future WO closures cannot bypass ctx_wo_finish.py validation
-  - Test suite covers all failure modes (≥80% coverage)
-  - Feature flag documentation enables onboarding
-  - Telemetry growth is controlled
-
-x_risks:
-  - WO-0018A modifies critical closure script (ctx_wo_finish.py)
-  - Pre-commit hook can be bypassed with --no-verify
-  - Test suite uses real subprocess (slower but more reliable)
-
-generated_at: "2026-01-13T11:30:00-03:00"
diff --git a/_ctx/telemetry/events.jsonl b/_ctx/telemetry/events.jsonl
index 772e945..38b28dc 100644
--- a/_ctx/telemetry/events.jsonl
+++ b/_ctx/telemetry/events.jsonl
@@ -5505,3 +5505,50 @@
 {"ts": "2026-02-10T07:40:12+0000", "run_id": "run_1770709212", "segment_id": "8d144eb3", "cmd": "ast.cache.write", "args": {"cache_key": "/tmp/tmp3lmh0q05:/tmp/tmp3lmh0q05/example.py:4626d8abd9e1ba43:1"}, "result": {"backend": "InMemoryLRUCache", "segment_id": "/tmp/tmp3lmh0q05"}, "timing_ms": 1, "warnings": [], "x": {}}
 {"ts": "2026-02-10T07:40:12+0000", "run_id": "run_1770709212", "segment_id": "8d144eb3", "cmd": "ast.parse", "args": {"file": "/tmp/tmp3lmh0q05/example.py"}, "result": {"status": "ok", "symbols_count": 2}, "timing_ms": 1, "warnings": [], "x": {"file": "/tmp/tmp3lmh0q05/example.py", "cache_key": "/tmp/tmp3lmh0q05:/tmp/tmp3lmh0q05/example.py:4626d8abd9e1ba43:1", "cache_status": "miss", "symbols_count": 2, "skeleton_bytes": 313}}
 {"ts": "2026-02-10T07:40:13+0000", "run_id": "run_1770709213", "segment_id": "8d144eb3", "cmd": "ctx.build", "args": {"segment": "/tmp/pytest-of-vscode/pytest-62/test_installer_does_not_write_0/segment"}, "result": {"status": "ok"}, "timing_ms": 2, "warnings": [], "x": {}}
+{"ts": "2026-02-10T08:48:59+0000", "run_id": "run_1770713338", "segment_id": "b64328bb", "cmd": "ctx.sync.stub_regen", "args": {"stub_name": "repo_map.md"}, "result": {"regen_ok": true, "reason": ""}, "timing_ms": 1, "warnings": [], "x": {}}
+{"ts": "2026-02-10T08:48:59+0000", "run_id": "run_1770713338", "segment_id": "b64328bb", "cmd": "ctx.sync.stub_regen", "args": {"stub_name": "symbols_stub.md"}, "result": {"regen_ok": true, "reason": ""}, "timing_ms": 1, "warnings": [], "x": {}}
+{"ts": "2026-02-10T08:48:59+0000", "run_id": "run_1770713338", "segment_id": "b64328bb", "cmd": "ctx.sync", "args": {"segment": "."}, "result": {"status": "ok"}, "timing_ms": 1523, "warnings": [], "x": {}}
+{"ts": "2026-02-10T08:49:17+0000", "run_id": "run_1770713356", "segment_id": "b64328bb", "cmd": "ctx.search", "args": {"query_preview": "Find documentation about Click command introspection and how to extract option parameters from Click commands", "query_hash": "a83a1156a6f5f789", "query_len": 109, "limit": 5, "alias_expanded": false, "alias_terms_count": 0, "alias_keys_used": [], "linter_query_class": "disabled", "linter_expanded": false, "linter_added_strong_count": 0, "linter_added_weak_count": 0, "linter_reasons": []}, "result": {"hits": 5, "returned_ids": ["repo:src/cli/introspection.py:60e5f4dd96", "repo:src/cli/invalid_option_handler.py:938358e463", "repo:src/application/hookify_extractor.py:1612c8bb5c", "repo:docs/reports/fixtures/merge_readiness_BAD.md:75a177eb5a", "repo:src/application/query_expander.py:d751995453"]}, "timing_ms": 1, "warnings": [], "x": {}}
+{"ts": "2026-02-10T08:49:33+0000", "run_id": "run_1770713373", "segment_id": "b64328bb", "cmd": "ctx.get", "args": {"ids": ["repo:src/cli/introspection.py:60e5f4dd96", "repo:src/cli/invalid_option_handler.py:938358e463"], "mode": "excerpt", "budget": 900, "max_chunks": null, "stop_on_evidence": false}, "result": {"chunks_returned": 2, "total_tokens": 475, "trimmed": false, "stop_reason": "complete", "chunks_requested": 2, "chars_returned_total": 1904, "evidence": {"strong_hit": false, "support": false}}, "timing_ms": 1, "warnings": [], "x": {}}
+{"ts": "2026-02-10T08:58:07+0000", "run_id": "run_1770713887", "segment_id": "b64328bb", "cmd": "invalid_option", "args": {"command_path": "trifecta load", "invalid_flag": "--dry-run", "argv_len": 7}, "result": {"suggestions_count": 0, "help_suggested": false, "had_match": false}, "timing_ms": 1, "warnings": [], "x": {"platform": "linux", "is_tty": false}}
+{"ts": "2026-02-10T08:58:07+0000", "run_id": "run_1770713887", "segment_id": "b64328bb", "cmd": "invalid_option", "args": {"command_path": "trifecta ctx plan", "invalid_flag": "--max-steps", "argv_len": 9}, "result": {"suggestions_count": 0, "help_suggested": false, "had_match": false}, "timing_ms": 1, "warnings": [], "x": {"platform": "linux", "is_tty": false}}
+{"ts": "2026-02-10T08:58:07+0000", "run_id": "run_1770713887", "segment_id": "b64328bb", "cmd": "invalid_option", "args": {"command_path": "trifecta load", "invalid_flag": "--hepl", "argv_len": 3}, "result": {"suggestions_count": 3, "help_suggested": true, "had_match": true}, "timing_ms": 1, "warnings": [], "x": {"platform": "linux", "is_tty": false}}
+{"ts": "2026-02-10T08:58:07+0000", "run_id": "run_1770713887", "segment_id": "b64328bb", "cmd": "invalid_option", "args": {"command_path": "trifecta load", "invalid_flag": "--dry-run", "argv_len": 7}, "result": {"suggestions_count": 0, "help_suggested": false, "had_match": false}, "timing_ms": 1, "warnings": [], "x": {"platform": "linux", "is_tty": false}}
+{"ts": "2026-02-10T08:58:07+0000", "run_id": "run_1770713887", "segment_id": "b64328bb", "cmd": "invalid_option", "args": {"command_path": "trifecta ctx plan", "invalid_flag": "--max-steps", "argv_len": 9}, "result": {"suggestions_count": 0, "help_suggested": false, "had_match": false}, "timing_ms": 1, "warnings": [], "x": {"platform": "linux", "is_tty": false}}
+{"ts": "2026-02-10T08:58:08+0000", "run_id": "run_1770713888", "segment_id": "b64328bb", "cmd": "invalid_option", "args": {"command_path": "trifecta load", "invalid_flag": "--dry-run", "argv_len": 7}, "result": {"suggestions_count": 0, "help_suggested": false, "had_match": false}, "timing_ms": 1, "warnings": [], "x": {"platform": "linux", "is_tty": false}}
+{"ts": "2026-02-10T08:58:08+0000", "run_id": "run_1770713888", "segment_id": "b64328bb", "cmd": "invalid_option", "args": {"command_path": "trifecta ctx plan", "invalid_flag": "--max-steps", "argv_len": 9}, "result": {"suggestions_count": 0, "help_suggested": false, "had_match": false}, "timing_ms": 1, "warnings": [], "x": {"platform": "linux", "is_tty": false}}
+{"ts": "2026-02-10T08:58:08+0000", "run_id": "run_1770713888", "segment_id": "b64328bb", "cmd": "invalid_option", "args": {"command_path": "trifecta load", "invalid_flag": "--dry-run", "argv_len": 7}, "result": {"suggestions_count": 0, "help_suggested": false, "had_match": false}, "timing_ms": 1, "warnings": [], "x": {"platform": "linux", "is_tty": false}}
+{"ts": "2026-02-10T08:58:09+0000", "run_id": "run_1770713889", "segment_id": "b64328bb", "cmd": "invalid_option", "args": {"command_path": "trifecta ctx plan", "invalid_flag": "--max-steps", "argv_len": 9}, "result": {"suggestions_count": 0, "help_suggested": false, "had_match": false}, "timing_ms": 1, "warnings": [], "x": {"platform": "linux", "is_tty": false}}
+{"ts": "2026-02-10T08:58:09+0000", "run_id": "run_1770713889", "segment_id": "b64328bb", "cmd": "invalid_option", "args": {"command_path": "trifecta load", "invalid_flag": "--dry-run", "argv_len": 7}, "result": {"suggestions_count": 0, "help_suggested": false, "had_match": false}, "timing_ms": 1, "warnings": [], "x": {"platform": "linux", "is_tty": false}}
+{"ts": "2026-02-10T08:58:09+0000", "run_id": "run_1770713889", "segment_id": "b64328bb", "cmd": "invalid_option", "args": {"command_path": "trifecta ctx plan", "invalid_flag": "--max-steps", "argv_len": 9}, "result": {"suggestions_count": 0, "help_suggested": false, "had_match": false}, "timing_ms": 1, "warnings": [], "x": {"platform": "linux", "is_tty": false}}
+{"ts": "2026-02-10T09:02:52+0000", "run_id": "run_1770714172", "segment_id": "b64328bb", "cmd": "invalid_option", "args": {"command_path": "trifecta load", "invalid_flag": "--dry-run", "argv_len": 7}, "result": {"suggestions_count": 0, "help_suggested": false, "had_match": false}, "timing_ms": 1, "warnings": [], "x": {"platform": "linux", "is_tty": false}}
+{"ts": "2026-02-10T09:02:52+0000", "run_id": "run_1770714172", "segment_id": "b64328bb", "cmd": "invalid_option", "args": {"command_path": "trifecta ctx plan", "invalid_flag": "--max-steps", "argv_len": 9}, "result": {"suggestions_count": 0, "help_suggested": false, "had_match": false}, "timing_ms": 1, "warnings": [], "x": {"platform": "linux", "is_tty": false}}
+{"ts": "2026-02-10T09:02:52+0000", "run_id": "run_1770714172", "segment_id": "b64328bb", "cmd": "invalid_option", "args": {"command_path": "trifecta load", "invalid_flag": "--hepl", "argv_len": 3}, "result": {"suggestions_count": 3, "help_suggested": true, "had_match": true}, "timing_ms": 1, "warnings": [], "x": {"platform": "linux", "is_tty": false}}
+{"ts": "2026-02-10T09:02:53+0000", "run_id": "run_1770714173", "segment_id": "b64328bb", "cmd": "invalid_option", "args": {"command_path": "trifecta load", "invalid_flag": "--dry-run", "argv_len": 7}, "result": {"suggestions_count": 0, "help_suggested": false, "had_match": false}, "timing_ms": 1, "warnings": [], "x": {"platform": "linux", "is_tty": false}}
+{"ts": "2026-02-10T09:02:53+0000", "run_id": "run_1770714173", "segment_id": "b64328bb", "cmd": "invalid_option", "args": {"command_path": "trifecta ctx plan", "invalid_flag": "--max-steps", "argv_len": 9}, "result": {"suggestions_count": 0, "help_suggested": false, "had_match": false}, "timing_ms": 1, "warnings": [], "x": {"platform": "linux", "is_tty": false}}
+{"ts": "2026-02-10T09:02:53+0000", "run_id": "run_1770714173", "segment_id": "b64328bb", "cmd": "invalid_option", "args": {"command_path": "trifecta load", "invalid_flag": "--dry-run", "argv_len": 7}, "result": {"suggestions_count": 0, "help_suggested": false, "had_match": false}, "timing_ms": 1, "warnings": [], "x": {"platform": "linux", "is_tty": false}}
+{"ts": "2026-02-10T09:02:54+0000", "run_id": "run_1770714174", "segment_id": "b64328bb", "cmd": "invalid_option", "args": {"command_path": "trifecta ctx plan", "invalid_flag": "--max-steps", "argv_len": 9}, "result": {"suggestions_count": 0, "help_suggested": false, "had_match": false}, "timing_ms": 1, "warnings": [], "x": {"platform": "linux", "is_tty": false}}
+{"ts": "2026-02-10T09:02:54+0000", "run_id": "run_1770714174", "segment_id": "b64328bb", "cmd": "invalid_option", "args": {"command_path": "trifecta load", "invalid_flag": "--dry-run", "argv_len": 7}, "result": {"suggestions_count": 0, "help_suggested": false, "had_match": false}, "timing_ms": 1, "warnings": [], "x": {"platform": "linux", "is_tty": false}}
+{"ts": "2026-02-10T09:02:54+0000", "run_id": "run_1770714174", "segment_id": "b64328bb", "cmd": "invalid_option", "args": {"command_path": "trifecta ctx plan", "invalid_flag": "--max-steps", "argv_len": 9}, "result": {"suggestions_count": 0, "help_suggested": false, "had_match": false}, "timing_ms": 1, "warnings": [], "x": {"platform": "linux", "is_tty": false}}
+{"ts": "2026-02-10T09:02:54+0000", "run_id": "run_1770714174", "segment_id": "b64328bb", "cmd": "invalid_option", "args": {"command_path": "trifecta load", "invalid_flag": "--dry-run", "argv_len": 7}, "result": {"suggestions_count": 0, "help_suggested": false, "had_match": false}, "timing_ms": 1, "warnings": [], "x": {"platform": "linux", "is_tty": false}}
+{"ts": "2026-02-10T09:02:55+0000", "run_id": "run_1770714175", "segment_id": "b64328bb", "cmd": "invalid_option", "args": {"command_path": "trifecta ctx plan", "invalid_flag": "--max-steps", "argv_len": 9}, "result": {"suggestions_count": 0, "help_suggested": false, "had_match": false}, "timing_ms": 1, "warnings": [], "x": {"platform": "linux", "is_tty": false}}
+{"ts": "2026-02-10T09:07:25+0000", "run_id": "run_1770714445", "segment_id": "b64328bb", "cmd": "invalid_option", "args": {"command_path": "trifecta load", "invalid_flag": "--dry-run", "argv_len": 7}, "result": {"suggestions_count": 0, "help_suggested": false, "had_match": false}, "timing_ms": 1, "warnings": [], "x": {"platform": "linux", "is_tty": false}}
+{"ts": "2026-02-10T09:07:25+0000", "run_id": "run_1770714445", "segment_id": "b64328bb", "cmd": "invalid_option", "args": {"command_path": "trifecta ctx plan", "invalid_flag": "--max-steps", "argv_len": 9}, "result": {"suggestions_count": 0, "help_suggested": false, "had_match": false}, "timing_ms": 1, "warnings": [], "x": {"platform": "linux", "is_tty": false}}
+{"ts": "2026-02-10T09:07:25+0000", "run_id": "run_1770714445", "segment_id": "b64328bb", "cmd": "invalid_option", "args": {"command_path": "trifecta load", "invalid_flag": "--hepl", "argv_len": 3}, "result": {"suggestions_count": 3, "help_suggested": true, "had_match": true}, "timing_ms": 1, "warnings": [], "x": {"platform": "linux", "is_tty": false}}
+{"ts": "2026-02-10T09:07:25+0000", "run_id": "run_1770714445", "segment_id": "b64328bb", "cmd": "invalid_option", "args": {"command_path": "trifecta load", "invalid_flag": "--dry-run", "argv_len": 7}, "result": {"suggestions_count": 0, "help_suggested": false, "had_match": false}, "timing_ms": 1, "warnings": [], "x": {"platform": "linux", "is_tty": false}}
+{"ts": "2026-02-10T09:07:26+0000", "run_id": "run_1770714446", "segment_id": "b64328bb", "cmd": "invalid_option", "args": {"command_path": "trifecta ctx plan", "invalid_flag": "--max-steps", "argv_len": 9}, "result": {"suggestions_count": 0, "help_suggested": false, "had_match": false}, "timing_ms": 1, "warnings": [], "x": {"platform": "linux", "is_tty": false}}
+{"ts": "2026-02-10T09:07:26+0000", "run_id": "run_1770714446", "segment_id": "b64328bb", "cmd": "invalid_option", "args": {"command_path": "trifecta load", "invalid_flag": "--dry-run", "argv_len": 7}, "result": {"suggestions_count": 0, "help_suggested": false, "had_match": false}, "timing_ms": 1, "warnings": [], "x": {"platform": "linux", "is_tty": false}}
+{"ts": "2026-02-10T09:07:26+0000", "run_id": "run_1770714446", "segment_id": "b64328bb", "cmd": "invalid_option", "args": {"command_path": "trifecta ctx plan", "invalid_flag": "--max-steps", "argv_len": 9}, "result": {"suggestions_count": 0, "help_suggested": false, "had_match": false}, "timing_ms": 1, "warnings": [], "x": {"platform": "linux", "is_tty": false}}
+{"ts": "2026-02-10T09:07:27+0000", "run_id": "run_1770714447", "segment_id": "b64328bb", "cmd": "invalid_option", "args": {"command_path": "trifecta load", "invalid_flag": "--dry-run", "argv_len": 7}, "result": {"suggestions_count": 0, "help_suggested": false, "had_match": false}, "timing_ms": 1, "warnings": [], "x": {"platform": "linux", "is_tty": false}}
+{"ts": "2026-02-10T09:07:27+0000", "run_id": "run_1770714447", "segment_id": "b64328bb", "cmd": "invalid_option", "args": {"command_path": "trifecta ctx plan", "invalid_flag": "--max-steps", "argv_len": 9}, "result": {"suggestions_count": 0, "help_suggested": false, "had_match": false}, "timing_ms": 1, "warnings": [], "x": {"platform": "linux", "is_tty": false}}
+{"ts": "2026-02-10T09:07:27+0000", "run_id": "run_1770714447", "segment_id": "b64328bb", "cmd": "invalid_option", "args": {"command_path": "trifecta load", "invalid_flag": "--dry-run", "argv_len": 7}, "result": {"suggestions_count": 0, "help_suggested": false, "had_match": false}, "timing_ms": 1, "warnings": [], "x": {"platform": "linux", "is_tty": false}}
+{"ts": "2026-02-10T09:07:27+0000", "run_id": "run_1770714447", "segment_id": "b64328bb", "cmd": "invalid_option", "args": {"command_path": "trifecta ctx plan", "invalid_flag": "--max-steps", "argv_len": 9}, "result": {"suggestions_count": 0, "help_suggested": false, "had_match": false}, "timing_ms": 1, "warnings": [], "x": {"platform": "linux", "is_tty": false}}
+{"ts": "2026-02-10T09:09:25+0000", "run_id": "run_1770714565", "segment_id": "b64328bb", "cmd": "invalid_option", "args": {"command_path": "trifecta load", "invalid_flag": "--dry-run", "argv_len": 7}, "result": {"suggestions_count": 0, "help_suggested": false, "had_match": false}, "timing_ms": 1, "warnings": [], "x": {"platform": "linux", "is_tty": false}}
+{"ts": "2026-02-10T09:09:25+0000", "run_id": "run_1770714565", "segment_id": "b64328bb", "cmd": "invalid_option", "args": {"command_path": "trifecta ctx plan", "invalid_flag": "--max-steps", "argv_len": 9}, "result": {"suggestions_count": 0, "help_suggested": false, "had_match": false}, "timing_ms": 1, "warnings": [], "x": {"platform": "linux", "is_tty": false}}
+{"ts": "2026-02-10T09:09:25+0000", "run_id": "run_1770714565", "segment_id": "b64328bb", "cmd": "invalid_option", "args": {"command_path": "trifecta load", "invalid_flag": "--hepl", "argv_len": 3}, "result": {"suggestions_count": 3, "help_suggested": true, "had_match": true}, "timing_ms": 1, "warnings": [], "x": {"platform": "linux", "is_tty": false}}
+{"ts": "2026-02-10T09:09:25+0000", "run_id": "run_1770714565", "segment_id": "b64328bb", "cmd": "ctx.build", "args": {"segment": "/tmp/pytest-of-vscode/pytest-68/test_build_fails_missing_agent0/test_seg_missing"}, "result": {"status": "constitution_failed", "errors": 1}, "timing_ms": 1, "warnings": [], "x": {}}
+{"ts": "2026-02-10T09:09:25+0000", "run_id": "run_1770714565", "segment_id": "b64328bb", "cmd": "ctx.build", "args": {"segment": "/tmp/pytest-of-vscode/pytest-68/test_build_fails_empty_agents_0/test_seg_empty"}, "result": {"status": "constitution_failed", "errors": 1}, "timing_ms": 1, "warnings": [], "x": {}}
+{"ts": "2026-02-10T09:09:25+0000", "run_id": "run_1770714565", "segment_id": "b64328bb", "cmd": "ctx.build", "args": {"segment": "/tmp/pytest-of-vscode/pytest-68/test_build_passes_valid_agents0/test_seg_valid"}, "result": {"status": "ok"}, "timing_ms": 4, "warnings": [], "x": {}}
+{"ts": "2026-02-10T09:09:26+0000", "run_id": "run_1770714566", "segment_id": "b64328bb", "cmd": "ctx.build", "args": {"segment": "/tmp/pytest-of-vscode/pytest-68/test_ctx_build_fails_on_invali0/bad_segment"}, "result": {"status": "validation_failed", "errors": 2}, "timing_ms": 1, "warnings": [], "x": {}}
+{"ts": "2026-02-10T09:09:26+0000", "run_id": "run_1770714566", "segment_id": "b64328bb", "cmd": "ctx.build", "args": {"segment": "/tmp/pytest-of-vscode/pytest-68/test_ctx_build_succeeds_on_val0/valid_test"}, "result": {"status": "ok"}, "timing_ms": 6, "warnings": [], "x": {}}
+{"ts": "2026-02-10T09:09:26+0000", "run_id": "run_1770714566", "segment_id": "b64328bb", "cmd": "ctx.build", "args": {"segment": "/tmp/pytest-of-vscode/pytest-68/test_ctx_build_shows_specific_0/missing_skill"}, "result": {"status": "validation_failed", "errors": 1}, "timing_ms": 1, "warnings": [], "x": {}}
diff --git a/_ctx/telemetry/last_run.json b/_ctx/telemetry/last_run.json
index d8c2a7e..8ffdfcf 100644
--- a/_ctx/telemetry/last_run.json
+++ b/_ctx/telemetry/last_run.json
@@ -1,7 +1,7 @@
 {
-  "run_id": "run_1770709213",
-  "segment_id": "8d144eb3",
-  "ts": "2026-02-10 07:40:13",
+  "run_id": "run_1770714566",
+  "segment_id": "b64328bb",
+  "ts": "2026-02-10 09:09:26",
   "ast": {
     "ast_parse_count": 0,
     "ast_cache_hit_count": 0,
diff --git a/src/cli/invalid_option_handler.py b/src/cli/invalid_option_handler.py
index 6e3bd10..87bc55c 100644
--- a/src/cli/invalid_option_handler.py
+++ b/src/cli/invalid_option_handler.py
@@ -11,7 +11,10 @@ Fail-closed: If introspection fails, returns helpful message without suggestions
 from __future__ import annotations
 
 import difflib
+import os
+import sys
 from dataclasses import dataclass
+from pathlib import Path
 from typing import Optional
 
 from src.cli.introspection import (
@@ -200,8 +203,9 @@ def render_enhanced_error(
     """
     lines = []
 
-    # Header with error
-    lines.append(f"❌ Error: No such option: {invalid_flag}")
+    # Header with error (cross-platform icon)
+    error_icon = _get_error_icon()
+    lines.append(f"{error_icon} Error: No such option: {invalid_flag}")
     lines.append("")
 
     # Suggested similar flags
@@ -268,9 +272,163 @@ def handle_invalid_option_error(error_message: str, argv: list[str]) -> str:
     suggested_flags = find_similar_flags(invalid_flag, valid_flags)
 
     # Render enhanced error
-    return render_enhanced_error(
+    enhanced_error = render_enhanced_error(
         invalid_flag=invalid_flag,
         command_path=command_path,
         suggested_flags=suggested_flags,
         original_error=error_message,
     )
+
+    # Emit telemetry event
+    _emit_invalid_option_telemetry(
+        command_path=command_path,
+        invalid_flag=invalid_flag,
+        suggested_flags=suggested_flags,
+        argv=argv,
+    )
+
+    return enhanced_error
+
+
+# Telemetry support
+
+_telemetry_instance = None
+
+
+def _get_telemetry():
+    """Get or create the telemetry instance (lazy import)."""
+    global _telemetry_instance
+    if _telemetry_instance is None:
+        try:
+            from src.infrastructure.telemetry import Telemetry
+
+            _telemetry_instance = Telemetry()
+        except Exception:
+            # Fail silently if telemetry is not available
+            pass
+    return _telemetry_instance
+
+
+def _is_tty() -> bool:
+    """Check if running in a TTY."""
+    return sys.stdout.isatty()
+
+
+def _get_platform() -> str:
+    """Get platform string for telemetry."""
+    return sys.platform
+
+
+def _emit_invalid_option_telemetry(
+    command_path: str,
+    invalid_flag: str,
+    suggested_flags: list[tuple[str, float]],
+    argv: list[str],
+) -> None:
+    """Emit telemetry event for invalid option error."""
+    telemetry = _get_telemetry()
+    if telemetry is None:
+        return
+
+    # Check if --help was suggested
+    help_suggested = any(flag == "--help" for flag, _ in suggested_flags)
+
+    # Increment KPI counter
+    telemetry.incr("invalid_option_count")
+
+    # Emit event
+    telemetry.event(
+        cmd="invalid_option",
+        args={
+            "command_path": command_path,
+            "invalid_flag": invalid_flag,
+            "argv_len": len(argv),
+        },
+        result={
+            "suggestions_count": len(suggested_flags),
+            "help_suggested": help_suggested,
+            "had_match": len(suggested_flags) > 0,
+        },
+        timing_ms=0,  # Error handling is fast, no timing needed
+        platform=_get_platform(),
+        is_tty=_is_tty(),
+    )
+
+
+def emit_help_used_telemetry(command_path: str, argv: list[str]) -> None:
+    """Emit telemetry event when --help is used."""
+    telemetry = _get_telemetry()
+    if telemetry is None:
+        return
+
+    # Increment KPI counter
+    telemetry.incr("help_used_count")
+
+    # Emit event
+    telemetry.event(
+        cmd="help_used",
+        args={
+            "command_path": command_path,
+            "argv_len": len(argv),
+        },
+        result={},
+        timing_ms=0,
+        platform=_get_platform(),
+        is_tty=_is_tty(),
+    )
+
+
+def get_telemetry_kpis() -> dict:
+    """Get current KPI values from telemetry."""
+    telemetry = _get_telemetry()
+    if telemetry is None:
+        return {
+            "invalid_option_count": 0,
+            "help_used_count": 0,
+        }
+
+    return {
+        "invalid_option_count": telemetry.metrics.get("invalid_option_count", 0),
+        "help_used_count": telemetry.metrics.get("help_used_count", 0),
+    }
+
+
+def reset_telemetry() -> None:
+    """Reset the telemetry instance (useful for testing)."""
+    global _telemetry_instance
+    _telemetry_instance = None
+
+
+# Cross-platform support
+
+def _supports_unicode() -> bool:
+    """Check if the terminal supports Unicode characters.
+
+    Returns:
+        True if Unicode is supported, False otherwise (fallback to ASCII)
+    """
+    # Check if we're on a TTY
+    if not sys.stdout.isatty():
+        return False
+
+    # Check platform-specific encoding
+    encoding = sys.stdout.encoding or ""
+    if "utf" in encoding.lower():
+        return True
+
+    # Check environment variables
+    if os.environ.get("LANG", "").lower().find("utf") != -1:
+        return True
+
+    return False
+
+
+def _get_error_icon() -> str:
+    """Get the appropriate error icon for the terminal.
+
+    Returns:
+        Unicode error icon if supported, ASCII fallback otherwise
+    """
+    if _supports_unicode():
+        return "❌"
+    return "[ERROR]"
diff --git a/tests/fixtures/reconcile/running_wo_without_worktree/_ctx/logs/reconcile/reconcile.log b/tests/fixtures/reconcile/running_wo_without_worktree/_ctx/logs/reconcile/reconcile.log
index fada5a7..8a8fca0 100644
--- a/tests/fixtures/reconcile/running_wo_without_worktree/_ctx/logs/reconcile/reconcile.log
+++ b/tests/fixtures/reconcile/running_wo_without_worktree/_ctx/logs/reconcile/reconcile.log
@@ -1,7 +1,7 @@
-timestamp: 2026-02-10T07:23:16.221087+00:00
+timestamp: 2026-02-10T09:09:27.534591+00:00
 applied: True
 issues:
 - RUNNING_WO_WITHOUT_WORKTREE WO-0003 ['/workspaces/trifecta_dope/tests/fixtures/reconcile/running_wo_without_worktree/_ctx/jobs/running/WO-0003.yaml']
-- WORKTREE_WITHOUT_RUNNING_WO None ['worktree']
 - WORKTREE_WITHOUT_RUNNING_WO None ['HEAD']
 - WORKTREE_WITHOUT_RUNNING_WO None ['branch']
+- WORKTREE_WITHOUT_RUNNING_WO None ['worktree']
diff --git a/tests/unit/cli/test_invalid_option_handler.py b/tests/unit/cli/test_invalid_option_handler.py
index 9459da7..156d469 100644
--- a/tests/unit/cli/test_invalid_option_handler.py
+++ b/tests/unit/cli/test_invalid_option_handler.py
@@ -137,7 +137,9 @@ class TestRenderEnhancedError:
             command_path="trifecta load",
             suggested_flags=[],
         )
-        assert "❌ Error: No such option: --dry-run" in result
+        # Accept both Unicode and ASCII fallback
+        assert ("❌ Error: No such option: --dry-run" in result or
+                "[ERROR] Error: No such option: --dry-run" in result)
 
     def test_renders_suggested_flags(self):
         """Should render suggested flags section."""
@@ -190,7 +192,9 @@ class TestHandleInvalidOptionError:
 
         result = handle_invalid_option_error(error_msg, sys.argv)
 
-        assert "❌ Error: No such option: --dry-run" in result
+        # Accept both Unicode and ASCII fallback
+        assert ("❌ Error: No such option: --dry-run" in result or
+                "[ERROR] Error: No such option: --dry-run" in result)
         assert "trifecta load --help" in result
         assert "Ejemplo de uso:" in result
 
@@ -211,7 +215,9 @@ class TestHandleInvalidOptionError:
 
         result = handle_invalid_option_error(error_msg, sys.argv)
 
-        assert "❌ Error: No such option: --max-steps" in result
+        # Accept both Unicode and ASCII fallback
+        assert ("❌ Error: No such option: --max-steps" in result or
+                "[ERROR] Error: No such option: --max-steps" in result)
         assert "trifecta ctx plan --help" in result
 
     def test_returns_original_if_no_flag_found(self):
