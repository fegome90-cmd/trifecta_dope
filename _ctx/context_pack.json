{
  "schema_version": 1,
  "segment": "trifecta_dope",
  "created_at": "2025-12-31T12:42:49.267464",
  "digest": "",
  "source_files": [
    {
      "path": "trifecta_dope/skill.md",
      "sha256": "5055bae97e8a61acc0e335435cd90241767fdb26dc7d141333647246a554718d",
      "mtime": 1767053782.2645926,
      "chars": 3541
    },
    {
      "path": "trifecta_dope/_ctx/prime_trifecta_dope.md",
      "sha256": "3dd749f4cfc5caba67e59b60190d6a6969c6b4609ab22c53762804ca53559f75",
      "mtime": 1767193378.1114116,
      "chars": 2688
    },
    {
      "path": "trifecta_dope/_ctx/session_trifecta_dope.md",
      "sha256": "dd9c3593c6de59095d7bc7f57f15399c28b799727a2198ebf4c24d05434af383",
      "mtime": 1767193234.475353,
      "chars": 8362
    },
    {
      "path": "trifecta_dope/README.md",
      "sha256": "c4d3c8efc29db2e5ece18dd47ef9973bce55f2ad244736b970a6f886b2c93a25",
      "mtime": 1767190648.7138612,
      "chars": 12758
    },
    {
      "path": "trifecta_dope/RELEASE_NOTES_v1.md",
      "sha256": "81ddd6f56a6b40293cedee9e63be9218162c0fff7fdc220c0be563b0fa9482b6",
      "mtime": 1767036080.277814,
      "chars": 1696
    }
  ],
  "chunks": [
    {
      "id": "skill:773705da1d",
      "doc": "skill",
      "title_path": [
        "skill.md"
      ],
      "text": "---\nname: trifecta_dope\ndescription: Use when working on Verification\n---\n## Overview\nVerification\n\n**Ubicaci√≥n**: `/Users/felipe_gonzalez/Developer/agent_h/trifecta_dope/`\n\n## ‚ö†Ô∏è ONBOARDING OBLIGATORIO ‚ö†Ô∏è\n\n1. **skill.md** (este archivo) - Reglas y roles\n2. **[PRIME](./_ctx/prime_trifecta_dope.md)** - Docs obligatorios\n3. **[AGENT](./_ctx/agent.md)** - Stack t√©cnico y gates\n4. **[SESSION](./_ctx/session_trifecta_dope.md)** - Log de handoffs y estado actual\n\n> NO ejecutes c√≥digo ni hagas cambios sin leer los 4 archivos.\n\n## Core Rules\n1. **Sync First**: Valida `.env` antes de cambios\n2. **Test Locally**: Tests del segmento antes de commit\n3. **Read Before Write**: Lee c√≥digo antes de modificar\n4. **Document**: Actualiza `session_..md`\n\n### CRITICAL PROTOCOL: Session Evidence Persistence (Trifecta)\n\nAntes de ejecutar cualquier herramienta (Trifecta CLI o agentes externos), DEBES seguir este orden. NO tomes atajos.\n\n1) PERSISTE intencion minima (CLI proactivo - NO depende del LLM):\n```bash\ntrifecta session append --segment . --summary \"<que vas a hacer>\" --files \"<csv>\" --commands \"<csv>\"\n```\n\n2) SYNC del segmento\n```bash\ntrifecta ctx sync --segment .\n```\n\n3) LEE lo que acabas de escribir (confirma Objective/Plan registrado en session.md)\n\n4) EJECUTA el ciclo de contexto (Plan A por defecto)\n```bash\ntrifecta ctx search --segment . --query \"<tema>\" --limit 6\ntrifecta ctx get --segment . --ids \"<id1>,<id2>\" --mode excerpt --budget-token-est 900\n```\n\n5) REGISTRA resultado (CLI proactivo):\n```bash\ntrifecta session append --segment . --summary \"Completed <task>\" --files \"<touched>\" --commands \"<executed>\"\n```\n\nSTALE FAIL-CLOSED PROTOCOL (CRITICAL):\n- Si `ctx validate` falla o `stale_detected=true` -> STOP inmediatamente\n- Ejecutar: `trifecta ctx sync --segment .` + `trifecta ctx validate --segment .`\n- Registrar en session.md: \"Stale: true -> sync+validate executed\"\n- Prohibido continuar hasta PASS\n\nProhibido:\n- YAML de historial largo\n- rutas absolutas fuera del segmento\n- ejecutar scripts legacy de ingestion\n- \"fallback silencioso\"\n- continuar con pack stale\n\n## When to Use\n\n- Cuando necesites sincronizar o validar el contexto de un segmento.\n- Al realizar un handoff entre sesiones (registrar en `session.md`).\n- Para buscar informaci√≥n espec√≠fica en el pack de contexto sin cargar archivos completos.\n\n## Core Pattern\n\n### The Context Cycle (Search -> Get)\n1. **Search**: Encuentra el `chunk_id` relevante.\n2. **Get (Excerpt)**: Lee un resumen/inicio para confirmar relevancia.\n3. **Get (Raw)**: Carga el contenido completo solo si es necesario y cabe en el presupuesto.\n\n### Session Persistence\n\n> [!IMPORTANT]\n> **Todo** cambio significativo o comando ejecutado **DEBE** ser registrado en `session.md` para mantener la continuidad del agente. Sin esto, el sistema Trifecta es solo un CLI; la persistencia es lo que permite la colaboraci√≥n multi-agente funcional.\n\n## Common Mistakes\n\n- **Indexar c√≥digo**: El pack es para DOCS (`.md`). El c√≥digo se accede v√≠a prime links.\n- **Ignorar validaciones**: Continuar si `ctx validate` falla es una violaci√≥n cr√≠tica.\n- **Presupuesto excedido**: Intentar cargar m√°s de 1200 tokens en un solo turno degrada la atenci√≥n del agente.\n- **Rutas absolutas**: Siempre usa rutas relativas al segmento o al repo root.\n\n## Resources (On-Demand)\n- `@_ctx/prime_trifecta_dope.md` - Lista de lectura obligatoria\n- `@_ctx/agent.md` - Stack t√©cnico y gates\n- `@_ctx/session_trifecta_dope.md` - Log de handoffs (runtime)\n\n---\n**Profile**: `impl_patch` | **Updated**: 2025-12-29\n",
      "char_count": 3541,
      "token_est": 885,
      "source_path": "skill.md",
      "chunking_method": "whole_file"
    },
    {
      "id": "prime:9851467005",
      "doc": "prime",
      "title_path": [
        "prime_trifecta_dope.md"
      ],
      "text": "---\nsegment: trifecta-dope\nprofile: load_only\n---\n\n# Prime Trifecta Dope - Lista de Lectura\n\n> **REPO_ROOT**: `/Users/felipe_gonzalez/Developer/agent_h/trifecta_dope`\n> Todas las rutas son relativas a esta raiz.\n>\n> **Orden de lectura**: Fundamentos -> Implementacion -> Referencias\n\n## [HIGH] Prioridad ALTA - Fundamentos\n\n**Leer primero para entender el contexto del segmento.**\n\n1. `README.md` - Visi√≥n general del proyecto y CLI\n2. `skill.md` - Reglas de oro y protocolos de sesi√≥n\n3. `RELEASE_NOTES_v1.md` - Estado actual y cambios recientes (T7/T8 Hardening)\n\n## [MED] Prioridad MEDIA - Implementacion\n\n<!-- Documentacion de implementacion especifica -->\n<!-- Ejemplos: guias de uso, patrones de disenio -->\n\n## [LOW] Prioridad BAJA - Referencias\n\n<!-- Documentacion de referencia, archivada -->\n<!-- Ejemplos: API docs, especificaciones -->\n\n## [MAP] Mapa Mental\n\n```mermaid\nmindmap\n  root(trifecta-dope)\n    <!-- Agregar conceptos clave del segmento -->\n    <!-- Ejemplo:\n    Fundamentos\n    Arquitectura\n    Componentes\n    Interfaces\n    -->\n```\n\n## [DICT] Glosario\n\n| Termino | Definicion |\n|---------|------------|\n| <!-- Agregar terminos clave del segmento --> | <!-- Definiciones breves --> |\n\n## [NOTE] Notas\n\n- **Fecha ultima actualizacion**: 2025-12-31\n- **Mantenedor**: <!-- Agregar si aplica -->\n- **Ver tambien**: [skill.md](../skill.md) | [agent.md](./agent.md)\n\n---\n\n## [INDEX] Index para ctx.plan\n\n### index.entrypoints\n\nPuntos de entrada principales del segmento:\n\n| Path | Raz√≥n |\n|------|-------|\n| `README.md` | Visi√≥n general del proyecto |\n| `skill.md` | Reglas de oro y protocolos |\n| `RELEASE_NOTES_v1.md` | Estado actual y cambios recientes |\n| `src/infrastructure/cli.py` | CLI commands (ctx, telemetry) |\n| `src/application/use_cases.py` | Use cases (Build, Stats, Load, Validate) |\n| `src/infrastructure/telemetry.py` | Telemetry system |\n\n### index.feature_map\n\nMapa de caracter√≠sticas ‚Üí chunks relacionados:\n\n| Feature | Chunk IDs | Paths | Keywords |\n|---------|-----------|-------|-----------|\n| telemetry | `skill:*`, `agent:*`, `ref:RELEASE_NOTES_v1.md` | `README.md`, `RELEASE_NOTES_v1.md`, `src/infrastructure/telemetry.py` | telemetry, events, metrics, token tracking |\n| context_pack | `skill:*`, `prime:*`, `agent:*` | `src/application/use_cases.py`, `src/domain/context_models.py` | context pack, build, sync, validate |\n| cli_commands | `skill:*` | `src/infrastructure/cli.py` | ctx.search, ctx.get, ctx.sync, ctx.stats, load |\n| search | `skill:*`, `agent:*` | `src/application/search_get_usecases.py` | SearchUseCase, search, query |\n| stats | `skill:*`, `agent:*` | `src/application/use_cases.py` | StatsUseCase, statistics, zero-hits |\n",
      "char_count": 2688,
      "token_est": 672,
      "source_path": "prime_trifecta_dope.md",
      "chunking_method": "whole_file"
    },
    {
      "id": "session:811cc9280e",
      "doc": "session",
      "title_path": [
        "session_trifecta_dope.md"
      ],
      "text": "# session.md - Trifecta Context Runbook\n\nsegment: trifecta-dope\n\n## Purpose\nThis file is a **runbook** for using Trifecta Context tools efficiently:\n- progressive disclosure (search -> get)\n- strict budget/backpressure\n- evidence cited by [chunk_id]\n\n## Quick Commands (CLI)\n```bash\n# SEGMENT=\".\" es valido SOLO si tu cwd es el repo target (el segmento).\n# Si ejecutas trifecta desde otro lugar (p.ej. desde el repo del CLI), usa un path absoluto:\n# SEGMENT=\"/abs/path/to/AST\"\nSEGMENT=\".\"\n\n# Usa un termino que exista en el segmento (ej: nombre de archivo, clase, funcion).\n# Si no hay hits, refina el query o busca por simbolos.\ntrifecta ctx sync --segment \"$SEGMENT\"\ntrifecta ctx search --segment \"$SEGMENT\" --query \"<query>\" --limit 6\ntrifecta ctx get --segment \"$SEGMENT\" --ids \"<id1>,<id2>\" --mode excerpt --budget-token-est 900\ntrifecta ctx validate --segment \"$SEGMENT\"\ntrifecta load --segment \"$SEGMENT\" --mode fullfiles --task \"Explain how symbols are extracted\"\n```\n\n## Rules (must follow)\n\n* Max **1 ctx.search + 1 ctx.get** per user turn.\n* Prefer **mode=excerpt**; use raw only if necessary and within budget.\n* Cite evidence using **[chunk_id]**.\n* If **validate fails**: stop, rebuild. **No silent fallback**.\n* **STALE FAIL-CLOSED**: If `stale_detected=true`, STOP -> `ctx sync` + `ctx validate` -> log \"Stale: true -> sync+validate executed\" -> continue only if PASS.\n\n## Session Log (append-only)\n\n### Entry Template (max 12 lines)\n```md\n## YYYY-MM-DD HH:MM - ctx cycle\n- Segment: .\n- Objective: <que necesitas resolver>\n- Plan: ctx sync -> ctx search -> ctx get (excerpt, budget=900)\n- Commands: (pending/executed)\n- Evidence: (pending/[chunk_id] list)\n- Warnings: (none/<code>)\n- Next: <1 concrete step>\n```\n\nReglas:\n- **append-only** (no reescribir entradas previas)\n- una entrada por run\n- no mas de 12 lineas\n\n## TRIFECTA_SESSION_CONTRACT (NON-EXECUTABLE in v1)\n\n> Documentation only. Not executed automatically in v1.\n\n```yaml\nschema_version: 1\nsegment: .\nautopilot:\n  enabled: false\n  note: \"v2 idea only - NOT executed in v1\"\n```\n\n## Watcher Example (optional)\n\n```bash\n# Ignore _ctx to avoid loops.\nfswatch -o -e \"_ctx/.*\" -i \"skill.md|prime.md|agent.md|session.md\" . \\\n  | while read; do trifecta ctx sync --segment \"$SEGMENT\"; done\n```\n\n## Next User Request\n\n<!-- The next agent starts here -->\n\n## 2025-12-29 23:44 UTC\n- **Summary**: Corrected T9.A to Context Routing Accuracy (not RAG). Updated aliases for routing, created evidence reports.\n- **Files**: implementation_plan.md, t9a_context_routing_accuracy.md, aliases.yaml\n- **Commands**: ctx sync, ctx search, session append\n- **Pack SHA**: `a38f1cacdb4f0afc`\n\n## 2025-12-29 23:49 UTC\n- **Summary**: Demonstrated Trifecta CLI usage: ctx search, ctx get, ctx stats\n- **Files**: skill.md\n- **Commands**: ctx search, ctx get, ctx stats\n- **Pack SHA**: `557f59c5e54ff34c`\n\n## 2025-12-29 23:54 UTC\n- **Summary**: Analyzed scope deviations: T9.A corrected (PCC not RAG), identified pending tasks (trifecta load, MCP, Progressive Disclosure)\n- **Files**: scope_analysis.md\n- **Commands**: mini-rag query, ctx search\n- **Pack SHA**: `557f59c5e54ff34c`\n\n## 2025-12-29 23:58 UTC\n- **Summary**: T9 Correction Evidence Report completed: 7/9 PASS, 1 FAIL (missing prohibition), 1 BELOW (routing 75%)\n- **Files**: t9-correction-evidence.md\n- **Commands**: ctx validate, ctx search, ctx get, pytest\n- **Pack SHA**: `557f59c5e54ff34c`\n\n## 2025-12-30 00:12 UTC\n- **Summary**: Updated prime docs (Paths), agent SOT (Tech Stack/Gates), and synced context pack.\n- **Files**: _ctx/prime_trifecta_dope.md, _ctx/agent.md, _ctx/session_trifecta_dope.md, readme_tf.md\n- **Commands**: ctx sync, session append\n- **Pack SHA**: `c3c0a4a0003f2420`\n\n## 2025-12-30 10:55 UTC\n- **Summary**: Applying documentation deprecation fixes (3 files)\n- **Files**: docs/plans/2025-12-29-context-pack-ingestion.md, docs/implementation/context-pack-implementation.md, docs/plans/t9-correction-evidence.md\n- **Commands**: multi_replace_file_content\n- **Pack SHA**: `307e1f35d7b883ec`\n\n## 2025-12-30 10:57 UTC\n- **Summary**: Completed documentation deprecation fixes (3 files)\n- **Files**: docs/plans/2025-12-29-context-pack-ingestion.md, docs/implementation/context-pack-implementation.md, docs/plans/t9-correction-evidence.md\n- **Commands**: trifecta ctx sync, grep\n- **Pack SHA**: `7e5a55959d7531a5`\n\n\n## 2025-12-31 11:00 UTC - Telemetry Data Science Plan\n- Segment: .\n- Objective: Dise√±ar sistema de an√°lisis de telemetry para CLI Trifecta\n- Plan: Investigaci√≥n web + brainstorming ‚Üí dise√±o arquitectura\n- Commands: (pendiente sync - bug encontrado)\n- Evidence: [docs/plans/2025-12-31_telemetry_data_science_plan.md]\n- Warnings: `ctx sync -s .` falla por falta de `.resolve()` en cli.py:334\n- Next: Continuar dise√±o Secci√≥n 3 (Agent Skill), luego implementar\n## 2025-12-31 14:25 UTC\n- **Summary**: Strict Naming Contract Enforcement (Gate 3+1): Fail-closed legacy files, symmetric ambiguity checks. Verified 143/143 tests.\n- **Files**: src/infrastructure/cli.py, src/application/use_cases.py, tests/integration/\n- **Pack SHA**: `7e5a55959d7531a5`\n\n\n## 2025-12-31 12:00 UTC - Telemetry CLI Implementation Complete\n- Segment: .\n- Objective: Implementar comandos CLI de telemetry\n- Plan: Phase 1 completada - report, export, chart commands funcionando\n- Commands: ejecutados\n  - `trifecta telemetry report -s . --last 30` ‚úÖ\n  - `trifecta telemetry chart -s . --type hits` ‚úÖ\n  - `trifecta telemetry chart -s . --type latency` ‚úÖ\n  - `trifecta telemetry chart -s . --type commands` ‚úÖ\n- Evidence:\n  - `src/application/telemetry_reports.py` creado ‚úÖ\n  - `src/application/telemetry_charts.py` creado ‚úÖ\n  - `telemetry_analysis/skills/analyze/skill.md` creado ‚úÖ\n- Warnings: Bug de `.resolve()` en cli.py:334 fue corregido autom√°ticamente por linter\n- Next: Escribir tests, documentar, actualizar plan\n\n## 2025-12-31 - Telemetry System COMPLETE\n- **Summary**: Sistema de telemetry CLI completado y testeado\n- **Phase 1**: CLI commands (report, export, chart) ‚úÖ\n- **Phase 2**: Agent skill creado en `telemetry_analysis/skills/analyze/` ‚úÖ\n- **Tests**: 44 eventos analizados, reporte generado siguiendo formato skill ‚úÖ\n- **Comandos funcionando**:\n  - `trifecta telemetry report -s . --last 30`\n  - `trifecta telemetry export -s . --format json`\n  - `trifecta telemetry chart -s . --type hits|latency|commands`\n- **Pack SHA**: `7e5a55959d7531a5`\n- **Status**: COMPLETADO - Lista para producci√≥n\n\n## 2025-12-31 - Token Tracking (Opci√≥n A) IMPLEMENTADO\n- **Summary**: Estimaci√≥n autom√°tica de tokens en eventos de telemetry\n- **M√©todo**: Estimaci√≥n desde output (1 token ‚âà 4 chars)\n- **Archivos modificados**:\n  - `src/infrastructure/telemetry.py` - Agregado `_estimate_tokens()`, `_estimate_token_usage()`, tracking en `event()`, stats en `flush()`\n  - `src/application/telemetry_reports.py` - Agregada secci√≥n \"Token Efficiency\"\n- **Eventos JSONL ahora incluyen**:\n  - `tokens.input_tokens` - Estimado desde args\n  - `tokens.output_tokens` - Estimado desde result\n  - `tokens.total_tokens` - Suma\n  - `tokens.retrieved_tokens` - De result.total_tokens si existe\n- **last_run.json ahora incluye**:\n  - `tokens.{cmd}.{total_input_tokens,total_output_tokens,total_tokens,total_retrieved_tokens,avg_tokens_per_call}`\n- **Pack SHA**: `5e6ad2eb365aea98`\n- **Status**: COMPLETADO - Funcionando (‚âà3-8 tokens/call promedio)\n\n## 2025-12-31 - Tarea: Reducir Zero-Hits sin RAG (En Progreso)\n- **Objetivo**: Reducir zero-hits a <20% sin embeddings/vector DB/RAG\n- **Enfoque**: Mejorar routing y fallback usando PRIME (PCC)\n- **Plan**: `docs/plans/2025-12-31_reduce_zero_hits_no_rag.md`\n\n### Completado\n- ‚úÖ A) Diagn√≥stico de telemetr√≠a ANTES\n  - `scripts/telemetry_diagnostic.py` - Script reproducible\n  - `docs/plans/telemetry_before.md` - Reporte (hit_rate: 31.6%)\n- ‚úÖ B) ctx.stats command\n  - `src/application/use_cases.py` - `StatsUseCase`\n  - `trifecta ctx stats -s . --window 30`\n\n### Pendiente (Inmediato)\n- ‚è≥ C) ctx.plan command - PRIME-only planning\n  - Leer `_ctx/prime_*.md` para index.entrypoints y index.feature_map\n  - Salida JSON con selected_feature, plan_hit, chunk_ids, paths, next_steps\n- ‚è≥ D) Dataset de evaluaci√≥n (20 tareas: 10 meta + 10 impl)\n- ‚è≥ E) Baseline y evaluaci√≥n\n\n**Pack SHA**: `5e6ad2eb365aea98`\n**Comandos √∫tiles**:\n  - `trifecta ctx stats -s . --window 30`\n  - `python3 scripts/telemetry_diagnostic.py --segment .`\n",
      "char_count": 8362,
      "token_est": 2090,
      "source_path": "session_trifecta_dope.md",
      "chunking_method": "whole_file"
    },
    {
      "id": "ref:README.md:fde90d226b",
      "doc": "ref:README.md",
      "title_path": [
        "README.md"
      ],
      "text": "# Trifecta Generator\n\n> **North Star**: Un agente entienda cualquier segmento del repo en <60 segundos leyendo solo 3 archivos + 1 log.\n\n# Trifecta ‚Äî Programming Context Calling (para agentes de c√≥digo)\n\n## Qu√© somos\nTrifecta es un **sistema de ‚ÄúProgramming Context Calling‚Äù** dise√±ado para **agentes que trabajan con c√≥digo**.  \nTratamos el **contexto como una herramienta**: el runtime entrega al agente **un set peque√±o, curado y versionado** de ‚Äúcontext-tools‚Äù (p. ej. `prime`, `agent`, `session`, `skill`) para que el agente act√∫e con **disciplina, trazabilidad y bajo costo cognitivo**.\n\n## A qu√© apuntamos\n- **Reducir fricci√≥n**: que el agente no pierda tiempo explorando √°rboles de carpetas ni ‚Äúadivinando‚Äù arquitectura/estado.\n- **Operaci√≥n repetible**: decisiones basadas en artefactos (`prime.md`, `agent.md`, `session.md`, `skill.md`), no en improvisaci√≥n.\n- **Evidencia y auditor√≠a**: cada paso tiene soporte (qu√© se consult√≥, por qu√© y con qu√© versi√≥n).\n- **Control**: presupuesto de contexto, pol√≠ticas de escalada y l√≠mites expl√≠citos.\n\n## Qu√© solucionamos\n- ‚ÄúDeep dive‚Äù innecesario por el repo para entender por d√≥nde empezar.\n- Alucinaci√≥n de arquitectura/stack/estado por falta de gu√≠a expl√≠cita.\n- Sesiones donde se repite trabajo porque no existe un **estado de sesi√≥n** confiable.\n- Contextos inflados y ca√≥ticos que degradan el rendimiento del agente (‚Äútodo el repo al prompt‚Äù).\n- Falta de procedimiento: el agente no sabe ‚Äúqu√© hacer ahora‚Äù y deriva.\n\n## NO SOMOS (expl√≠cito y no negociable)\n**Trifecta NO ES un RAG gen√©rico.**  \nNo es un buscador global del repositorio ni un sistema que ‚Äúindexa todo el c√≥digo‚Äù para maximizar recall.\n\n**Trifecta NO ES una base vectorial / embeddings-first por defecto.**  \nNo depende de vectorizar `src/` ni de ‚Äúbuscar trozos‚Äù como estrategia primaria.\n\n**Trifecta NO ES ‚Äúchat con memoria‚Äù ni un notebook de notas.**  \nNo pretende almacenar conocimiento libre o conversaciones; opera con artefactos curados y versionables.\n\n**Trifecta NO ES una excusa para explorar carpetas a ciegas.**  \nEl agente no debe recorrer 3 niveles de directorios para ‚Äúentender‚Äù el repo: usa `prime` y la sesi√≥n.\n\n**Trifecta NO ES un sistema de recuperaci√≥n indiscriminada de contexto.**  \nEl objetivo no es ‚Äútraer m√°s texto‚Äù, es **activar el contexto correcto** como si fuera una tool.\n\n## Principio operativo\n**Meta-first, c√≥digo on-demand.**  \nEl agente inicia con `skill ‚Üí prime ‚Üí agent ‚Üí session`.  \nSolo escala a c√≥digo cuando es estrictamente necesario y siguiendo rutas/contratos curados.\n\n## Problema\n\nLos agentes de c√≥digo (Claude, Gemini, Codex) parsean miles de l√≠neas de c√≥digo innecesariamente, consumen contexto, y terminan con informaci√≥n obsoleta o incompleta.\n\n## Soluci√≥n\n\nEl sistema **Trifecta** proporciona una estructura estandarizada de **5 archivos** que permite:\n\n- **Comprensi√≥n r√°pida**: <60 segundos para entender un segmento\n- **Contexto eficiente**: Solo carga lo necesario (progressive disclosure)\n- **Mantenimiento simple**: Estructura predecible, sin drift\n- **Onboarding autom√°tico**: README con gu√≠a para nuevos agentes\n\n---\n\n## üèóÔ∏è Arquectura del Generador\n\n> **‚ö†Ô∏è IMPORTANTE**: Este generador ya est√° implementado con Clean Architecture. No recrear desde cero.\n\n```\ntrifecta_dope/\n‚îú‚îÄ‚îÄ src/\n‚îÇ   ‚îú‚îÄ‚îÄ domain/           # Entidades de negocio (Pydantic models)\n‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ models.py     # TrifectaConfig, TrifectaPack, ValidationResult\n‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ constants.py  # MAX_SKILL_LINES, etc.\n‚îÇ   ‚îÇ\n‚îÇ   ‚îú‚îÄ‚îÄ application/      # Use cases (l√≥gica de negocio)\n‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ use_cases.py  # Create, Validate, RefreshPrime\n‚îÇ   ‚îÇ\n‚îÇ   ‚îî‚îÄ‚îÄ infrastructure/   # Implementaciones concretas\n‚îÇ       ‚îú‚îÄ‚îÄ cli.py        # Typer CLI (entrypoint)\n‚îÇ       ‚îú‚îÄ‚îÄ templates.py  # TemplateRenderer (markdown generation)\n‚îÇ       ‚îî‚îÄ‚îÄ file_system.py # FileSystemAdapter (disk I/O)\n‚îÇ\n‚îú‚îÄ‚îÄ tests/                # Unit tests (pytest)\n‚îú‚îÄ‚îÄ braindope.md          # Especificaci√≥n completa\n‚îî‚îÄ‚îÄ README.md             # Este archivo\n```\n\n### Capas (Clean Architecture)\n\n| Capa | Responsabilidad | Archivos clave |\n|------|-----------------|----------------|\n| **Domain** | Modelos de datos, validadores | `models.py`, `constants.py` |\n| **Application** | Casos de uso, orquestaci√≥n | `use_cases.py` |\n| **Infrastructure** | CLI, templates, I/O | `cli.py`, `templates.py`, `file_system.py` |\n\n### Flujo de Creaci√≥n\n\n```\nCLI (cli.py)\n    ‚Üì\nCreateTrifectaUseCase (use_cases.py)\n    ‚Üì\nTemplateRenderer.render_{skill,prime,agent,session,readme}\n    ‚Üì\nFileSystemAdapter.save_trifecta\n    ‚Üì\n5 archivos en disco\n```\n\n### Reglas de Dise√±o\n\n1. **Domain** ‚Üí sin dependencias externas (solo Pydantic)\n2. **Application** ‚Üí solo depende de Domain\n3. **Infrastructure** ‚Üí implementa interfaces de Application/Domain\n4. **Templates** ‚Üí f-strings, sin Jinja2 (simplicidad)\n\n### Extensiones\n\nPara agregar un nuevo comando:\n\n1. Crear use case en `application/use_cases.py`\n2. Agregar comando en `infrastructure/cli.py`\n3. Agregar tests en `tests/test_use_cases.py`\n\n---\n\n## Estructura Trifecta (Output)\n\n```\n<segment-name>/\n‚îú‚îÄ‚îÄ README.md                              # Gu√≠a r√°pida del segmento\n‚îú‚îÄ‚îÄ skill.md                               # Reglas (MAX 100 l√≠neas)\n‚îî‚îÄ‚îÄ _ctx/\n    ‚îú‚îÄ‚îÄ prime_<segment-name>.md            # Lista de lectura\n    ‚îú‚îÄ‚îÄ agent.md                           # Stack t√©cnico\n    ‚îî‚îÄ‚îÄ session_<segment-name>.md          # Log de handoff (runtime)\n```\n\n### Archivos\n\n| Archivo | Prop√≥sito | L√≠neas aprox |\n|---------|-----------|--------------|\n| `README.md` | Gu√≠a r√°pida + onboarding | ~50-80 |\n| `skill.md` | Reglas, contratos, workflows | ‚â§100 |\n| `prime_*.md` | Lista de lectura obligatoria | ~50-100 |\n| `agent.md` | Stack t√©cnico, dependencies | ~100-150 |\n| `session_*.md` | Bit√°cora de handoffs | Append-only |\n\n## Perfiles de Output\n\nEl sistema usa perfiles (nvim-style modeline) para definir contratos de output:\n\n| Profile | Prop√≥sito | Contract |\n|---------|-----------|----------|\n| `diagnose_micro` | M√°ximo texto, c√≥digo ‚â§3 l√≠neas | `code_max_lines: 3` |\n| `impl_patch` | Patch con verificaci√≥n | `require: [FilesTouched, CommandsToVerify]` |\n| `only_code` | Solo archivos + diff + comandos | `forbid: [explanations]` |\n| `plan` | DoD + pasos (sin c√≥digo) | `forbid: [code_blocks]` |\n| `handoff_log` | Bit√°cora + handoff | `append_only: true` |\n\n## Progressive Disclosure\n\n| Nivel | Trigger | Tokens |\n|-------|---------|--------|\n| **L0** | Score < 0.6 | ~50 (solo frontmatter) |\n| **L1** | Score 0.6-0.9 | ~500-1000 (skill completo) |\n| **L2** | Score > 0.9 | ~200-500 (resources) |\n\n## Uso\n\n### 1. Alias (Recomendado)\nPara usar `trifecta` desde cualquier carpeta sin instalarlo globalmente:\n\n```fish\n# Agregar a ~/.config/fish/config.fish\nalias trifecta=\"/Users/felipe_gonzalez/.local/bin/uv --directory /Users/felipe_gonzalez/Developer/agent_h/trifecta_dope run trifecta\"\n```\n\nLuego:\n```bash\ncd ~/Developer/AST\ntrifecta ctx build .\n```\n\n### 2. Ejecuci√≥n Directa (Sin Alias)\n```bash\n# Desde cualquier directorio\nuv --directory ~/Developer/agent_h/trifecta_dope run trifecta load --path ~/Developer/AST --segment ast --task \"Fix bug\"\n```\n\n### 3. Autocompletado (Fish)\nPara tener autocompletado nativo en todos los comandos:\n\n```bash\nmkdir -p ~/.config/fish/completions\nln -s $(pwd)/completions/trifecta.fish ~/.config/fish/completions/trifecta.fish\nsource ~/.config/fish/completions/trifecta.fish\n```\n\n### Generar Trifecta (Ejemplos)\n```bash\n# Crear trifecta para un segmento\ntrifecta create --segment eval-harness --path eval/eval-harness/ --scan-docs eval/docs/\n\n# Validar trifecta existente\ntrifecta validate --path eval/eval-harness/\n```\n\n### Generar Context Pack (Programming Context Calling)\n\nEl **Context Pack** es un √≠ndice estructurado que permite al agente:\n1. Descubrir qu√© chunks existen (`ctx.search`)\n2. Invocar chunks espec√≠ficos (`ctx.get --ids X`)\n3. Operar con presupuesto estricto (budget-aware)\n\n**Analog√≠a**: Como \"Tool Search Tool\" de Anthropic, pero para contexto.\n\n```bash\n# Comando oficial (recomendado)\ntrifecta ctx build --segment /path/to/segment\n\n# Validar integridad\ntrifecta ctx validate --segment /path/to/segment\n```\n\n> **DEPRECADO**: `scripts/ingest_trifecta.py` ser√° removido en v2.  \n> Usar solo para debugging interno del CLI.\n\n**Estructura del Context Pack:**\n\n```json\n{\n  \"schema_version\": 1,\n  \"segment\": \"debug_terminal\",\n  \"created_at\": \"2025-12-29T15:47:37.502279Z\",\n  \"digest\": [           // Siempre en prompt (~10-30 l√≠neas)\n    {\"doc\": \"skill\", \"summary\": \"...\", \"source_chunk_ids\": [...]}\n  ],\n  \"index\": [            // Siempre en prompt (referencias)\n    {\"id\": \"skill:a1b2...\", \"title_path\": [...], \"preview\": \"...\", \"token_est\": 150}\n  ],\n  \"chunks\": [           // Entregado bajo demanda v√≠a tool\n    {\"id\": \"skill:a1b2...\", \"text\": \"...\", \"source_path\": \"...\"}\n  ]\n}\n```\n\n**C√≥mo funciona:**\n\n1. **Prompt base** incluye solo `digest` + `index` (referencias)\n2. **Agente llama** `ctx.get --ids X` cuando necesita evidencia espec√≠fica\n3. **Sistema entrega** chunks dentro del presupuesto (budget-aware)\n4. **Agente cita** evidencia con `[chunk_id]`\n\n**El agente decide qu√© cargar, cu√°ndo y con qu√© presupuesto. NO es recuperaci√≥n autom√°tica.**\n\n> Ver [`docs/plans/2025-12-29-context-pack-ingestion.md`](./docs/plans/2025-12-29-context-pack-ingestion.md) para especificaci√≥n completa.\n\n## üîß Mini-RAG (Herramienta de Desarrollo)\n\n> **NOTA**: Mini-RAG es una herramienta **externa** para que T√ö (desarrollador) consultes  \n> la documentaci√≥n del CLI. **NO es parte del paradigma Trifecta.**\n\nTrifecta usa b√∫squeda lexical (grep-like), NO embeddings.\n\n### Setup (solo para desarrollo del CLI)\n\n```bash\n# Desde la ra√≠z del proyecto\nmake minirag-setup MINIRAG_SOURCE=~/Developer/Minirag\nmake minirag-chunk\nmake minirag-index\n```\n\n### Consultas\n\n```bash\nmake minirag-query MINIRAG_QUERY=\"PCC\"\n```\n\n> El √≠ndice usa `.mini-rag/chunks/**/*.md` (generados) y `knowledge/**/*.pdf` definidos en\n> `.mini-rag/config.yaml`.\n\n**Para agentes**: Usar `trifecta ctx search`, NO Mini-RAG.\n\n## Instalaci√≥n\n\n```bash\ncd trifecta_dope\nuv sync\n```\n\n### Multi-Segment Installation\n\nPara instalar contexto en m√∫ltiples segmentos del repositorio, usa el script estable:\n\n```bash\n# Script recomendado (Clean Architecture compliant)\nuv run python scripts/install_FP.py --segment /path/to/segment1 --segment /path/to/segment2\n\n# DEPRECATED: scripts/install_trifecta_context.py (backward compatibility only)\n```\n\nEl script `install_FP.py` utiliza validadores desde `src/infrastructure/validators.py` y sigue principios de Clean Architecture.\n\n## Tests\n\n```bash\nuv run pytest tests/ -v\n```\n\n## Desarrollo\n\n```bash\n# Ejecutar CLI con Typer\nuv run typer src/infrastructure/cli.py run create --help\n```\n\n## Referencias\n\n- [`docs/braindope.md`](./docs/braindope.md) - Especificaci√≥n completa del sistema\n- [`writing-skills`](../.claude/skills/superpowers/writing-skills/) - Metodolog√≠a para crear SKILL.md\n\n## Roadmap\n\n### CLI & Templates\n- [x] Especificaci√≥n completa (braindope.md)\n- [x] Clean Architecture implementation\n- [x] CLI con comandos `create`, `validate`, `refresh-prime`\n- [x] README.md autom√°tico en cada segmento\n- [x] Enhanced templates (skill, agent, prime) con ejemplos concretos\n- [x] CLI UX improvements: validaci√≥n, errores contextuales, dry-run\n- [x] Fish shell completions\n\n### Context Pack\n- [x] Context Pack ingestion script (token-optimized)\n- [x] Schema v1 con digest + index + chunks\n- [x] Fence-aware chunking (respeta bloques de c√≥digo)\n- [x] Digest determinista (scoring system)\n- [x] IDs estables (normalized hash)\n- [x] E2E tests (34 tests passing)\n\n### Pending\n- [ ] Prueba con segmentos reales (`debug_terminal`, `hemdov`, `eval`)\n- [ ] MCP Discovery Tool para activaci√≥n autom√°tica\n- [ ] Progressive Disclosure (L0/L1/L2) en hooks\n\n---\n\n## üõ†Ô∏è Best Practices & Troubleshooting\n\n### 1. Reglas de Oro para Operaci√≥n Multi-Workspace\n*   **Target Segment**: Usa siempre `--segment /path/to/target`. El flag `--path` est√° deprecado para comandos `ctx` y `load`.\n*   **Validar PCC**: Si quieres usar Plan A (b√∫squeda inteligente), verifica que exista `segment/_ctx/context_pack.json`. Si no existe, corre `trifecta ctx build --segment ...`.\n\n### 2. Depuraci√≥n de B√∫squeda (0 Hits)\nSi `trifecta load` cae a fallback cuando no deber√≠a:\n1.  **Diagn√≥stico**: Ejecuta `trifecta ctx search --segment Path --query \"keyword\"`.\n2.  **Causa**: Si retorna vac√≠o, tus palabras clave no est√°n en el √≠ndice.\n3.  **Soluci√≥n**:\n    *   Agrega los documentos relevantes a `segment/_ctx/prime_*.md`.\n    *   Regenera el √≠ndice: `trifecta ctx build --segment Path`.\n\n### 3. Rutas Hardcoded\nEl CLI imprime lo que lee. Si ves rutas extra√±as en el output de `load`, provienen de los archivos del segmento (`prime`, `agent`, `skill`), no del CLI. Edita los archivos del segmento para corregirlas.\n",
      "char_count": 12758,
      "token_est": 3189,
      "source_path": "README.md",
      "chunking_method": "whole_file"
    },
    {
      "id": "ref:RELEASE_NOTES_v1.md:e2b673d762",
      "doc": "ref:RELEASE_NOTES_v1.md",
      "title_path": [
        "RELEASE_NOTES_v1.md"
      ],
      "text": "# Trifecta Context Loading v1 ‚Äî Release Notes\n\n**Status**: Verified & Ready for Integration\n**Date**: 2025-12-29\n\n## üöÄ What's Included\n1.  **Plan A (Programmatic Context Calling)**:\n    - `ctx search`: Lexical search with top-k limits.\n    - `ctx get`: ID-based retrieval with budget awareness (value-per-token sorting).\n2.  **Plan B (Fallback Strategy)**:\n    - `load --mode fullfiles`: Resilient loading when packs are missing or access is critical.\n3.  **Strict Validation Gates**:\n    - Atomic writes (`_ctx/.autopilot.lock`).\n    - Fail-closed validation (SHA-256 deep checks).\n4.  **Dumb Macro Sync**:\n    - `ctx sync`: Fixed macro (`build` + `validate`) for deterministic state.\n\n## ‚ö†Ô∏è Known Limitations (v1)\n- **No Embeddings**: Search is purely lexical (grep-like heuristics).\n- **Documentation Only Contracts**: `session.md` YAML is for reference; not executed by the system.\n- **Segment-Local Only**: No global index; operations are scoped to the current segment.\n\n## üõ†Ô∏è Usage Guide (Top 5 Commands)\n\n### 1. Build & Sync (Routine Maintenance)\n```bash\ntrifecta ctx sync --segment .\n```\n\n### 2. Search (Discovery)\n```bash\ntrifecta ctx search --segment . --query \"authentication\" --limit 5\n```\n\n### 3. Get Context (retrieval)\n```bash\ntrifecta ctx get --segment . --ids \"skill:1,agent:3\" --budget-token-est 1000\n```\n\n### 4. Create New Pack (Setup)\n```bash\nmake trifecta-create SEGMENT=my-feature PATH=.\n```\n\n### 5. Fallback Load (Emergency)\n```bash\ntrifecta load --segment . --task \"rescue mission\" --mode fullfiles\n```\n\n## üêõ Bug Reporting\nAttach the following files:\n- `_ctx/autopilot.log` (if available)\n- `_ctx/context_pack.json`\n- `_ctx/validation_report.json` (if verification fails)\n",
      "char_count": 1696,
      "token_est": 424,
      "source_path": "RELEASE_NOTES_v1.md",
      "chunking_method": "whole_file"
    }
  ],
  "index": [
    {
      "id": "skill:773705da1d",
      "title_path_norm": "skill.md",
      "preview": "---\nname: trifecta_dope\ndescription: Use when working on Verification\n---\n## Overview\nVerification\n\n**Ubicaci√≥n**: `/Users/felipe_gonzalez/Developer/agent_h/trifecta_dope/`\n\n## ‚ö†Ô∏è ONBOARDING OBLIGATOR...",
      "token_est": 885
    },
    {
      "id": "prime:9851467005",
      "title_path_norm": "prime_trifecta_dope.md",
      "preview": "---\nsegment: trifecta-dope\nprofile: load_only\n---\n\n# Prime Trifecta Dope - Lista de Lectura\n\n> **REPO_ROOT**: `/Users/felipe_gonzalez/Developer/agent_h/trifecta_dope`\n> Todas las rutas son relativas a...",
      "token_est": 672
    },
    {
      "id": "session:811cc9280e",
      "title_path_norm": "session_trifecta_dope.md",
      "preview": "# session.md - Trifecta Context Runbook\n\nsegment: trifecta-dope\n\n## Purpose\nThis file is a **runbook** for using Trifecta Context tools efficiently:\n- progressive disclosure (search -> get)\n- strict b...",
      "token_est": 2090
    },
    {
      "id": "ref:README.md:fde90d226b",
      "title_path_norm": "README.md",
      "preview": "# Trifecta Generator\n\n> **North Star**: Un agente entienda cualquier segmento del repo en <60 segundos leyendo solo 3 archivos + 1 log.\n\n# Trifecta ‚Äî Programming Context Calling (para agentes de c√≥dig...",
      "token_est": 3189
    },
    {
      "id": "ref:RELEASE_NOTES_v1.md:e2b673d762",
      "title_path_norm": "RELEASE_NOTES_v1.md",
      "preview": "# Trifecta Context Loading v1 ‚Äî Release Notes\n\n**Status**: Verified & Ready for Integration\n**Date**: 2025-12-29\n\n## üöÄ What's Included\n1.  **Plan A (Programmatic Context Calling)**:\n    - `ctx search`...",
      "token_est": 424
    }
  ]
}